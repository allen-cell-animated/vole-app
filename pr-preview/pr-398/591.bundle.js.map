{"version":3,"file":"591.bundle.js","mappings":"gIAMe,MAAMA,EAanB,WAAAC,CAAYC,GACVC,KAAKC,WAAa,EAClBD,KAAKE,WAAa,EAClBF,KAAKG,OAAS,EACdH,KAAKI,KAAO,IAAIC,YAChBL,KAAKM,IAAM,EACXN,KAAKO,IAAM,EACXP,KAAKQ,QAAU,EAGf,MAAMC,EAAQZ,EAAUa,mBAAmBX,EA7BjC,KA8BVC,KAAKI,KAAOK,EAAML,KAClBJ,KAAKM,IAAMG,EAAMH,IACjBN,KAAKO,IAAME,EAAMF,IACjBP,KAAKQ,QAAUC,EAAMD,QAIrB,IAAK,IAAIG,EAAI,EAAGA,EAAIX,KAAKI,KAAKQ,OAAQD,IACpC,GAAIX,KAAKI,KAAKO,GAAK,EAAG,CACpBX,KAAKC,WAAaU,EAClB,KACF,CAEF,IAAK,IAAIA,EAAIX,KAAKI,KAAKQ,OAAS,EAAGD,GAAK,EAAGA,IACzC,GAAIX,KAAKI,KAAKO,GAAK,EAAG,CACpBX,KAAKE,WAAaS,EAClB,KACF,CAEFX,KAAKa,WAAad,EAAKa,OAGvBZ,KAAKG,OAAS,EACd,IAAII,EAAMP,KAAKI,KAAK,GACpB,IAAK,IAAIO,EAAI,EAAGA,EAAIX,KAAKI,KAAKQ,OAAQD,IAChCX,KAAKI,KAAKO,GAAKJ,IACjBP,KAAKG,OAASQ,EACdJ,EAAMP,KAAKI,KAAKO,GAGtB,CAGA,cAAOG,CAAQC,EAAWC,EAASR,EAASS,GAC1C,IAAIC,EAAWC,KAAKC,OAAOL,EAAYC,GAAWR,GAKlD,OAHIU,IAAaD,GACfC,IAEKA,CACT,CAGA,cAAAG,CAAeC,GACb,OAAOzB,EAAUiB,QAAQQ,EAAOtB,KAAKM,IAAKN,KAAKQ,QA1ErC,IA2EZ,CAMA,UAAAe,GACE,OAAOvB,KAAKM,GACd,CAMA,UAAAkB,GACE,OAAOxB,KAAKO,GACd,CAMA,MAAAkB,GACE,OAAOzB,KAAKC,UACd,CAMA,MAAAyB,GAEE,OAAO1B,KAAKE,UACd,CACA,UAAAyB,GACE,OAAO3B,KAAKI,KAAKQ,MACnB,CACA,MAAAgB,CAAOjB,GACL,OAAOX,KAAKI,KAAKO,EACnB,CACA,WAAAkB,CAAYlB,GACV,MAAO,CAACX,KAAKM,IAAMK,EAAIX,KAAKQ,QAASR,KAAKM,KAAOK,EAAI,GAAKX,KAAKQ,QACjE,CAOA,mBAAAsB,CAAoBC,GAClB,MAAMC,EAAQhC,KAAKa,WAAakB,EAChC,IAAIpB,EAAI,EACJsB,EAAQ,EACZ,IAAKtB,EAAI,EAAGA,EAAIX,KAAKI,KAAKQ,SACxBqB,GAASjC,KAAKI,KAAKO,KACfsB,EAAQD,MAFsBrB,GAMpC,OAAOA,CACT,CAGA,eAAAuB,GACE,MAEMF,EAFWhC,KAAKa,WAEG,GACzB,IAAIF,EAAI,EACJsB,EAAQ,EACZ,IAAKtB,EAAI,EAAGA,EAAIX,KAAKI,KAAKQ,SACxBqB,GAASjC,KAAKI,KAAKO,KACfsB,EAAQD,MAFsBrB,GAMpC,MAAMwB,EAAOxB,EAEb,IADAsB,EAAQ,EACHtB,EAAIX,KAAKI,KAAKQ,OAAS,EAAGD,GAAK,IAClCsB,GAASjC,KAAKI,KAAKO,KACfsB,EAAQD,MAF2BrB,GAOzC,MAAO,CAACwB,EADKxB,EAEf,CAGA,cAAAyB,GAGE,MACMC,EAAWrC,KAAKa,WAEhBmB,EAAQK,EAAW,GACnBC,EAAYD,EAJK,IAOvB,IAAIF,EAAOnC,KAAKI,KAAKQ,OAAS,EAC1B2B,EAAO,EACX,IAAK,IAAI5B,EAAI,EAAGA,EAAIX,KAAKI,KAAKQ,SAAUD,EACtC,GAAIX,KAAKI,KAAKO,GAAK2B,GAAatC,KAAKI,KAAKO,IAAMqB,EAAO,CACrDG,EAAOxB,EACP,KACF,CAEF,IAAK,IAAIA,EAAIX,KAAKI,KAAKQ,OAAS,EAAGD,GAAK,IAAKA,EAC3C,GAAIX,KAAKI,KAAKO,GAAK2B,GAAatC,KAAKI,KAAKO,IAAMqB,EAAO,CACrDO,EAAO5B,EACP,KACF,CAMF,OAJI4B,EAAOJ,IACTA,EAAO,EACPI,EAAO,KAEF,CAACJ,EAAMI,EAChB,CAGA,cAAAC,GAGE,MACMC,EAAKtB,KAAKC,MADG,GACGpB,KAAKI,KAAKJ,KAAKG,SACrC,IAAIuC,EAAI,EACJC,EAAI3C,KAAKI,KAAKQ,OAAS,EAC3B,IAAK,IAAIgC,EAAI,EAAGA,EAAI5C,KAAKI,KAAKQ,SAAUgC,EACtC,GAAI5C,KAAKI,KAAKwC,GAAKH,EAAI,CACrBC,EAAIE,EACJ,KACF,CAEF,IAAK,IAAIA,EAAI5C,KAAKI,KAAKQ,OAAS,EAAGgC,GAAK,IAAKA,EAC3C,GAAI5C,KAAKI,KAAKwC,GAAKH,EAAI,CACrBE,EAAIC,EACJ,KACF,CAEF,MAAO,CAACF,EAAGC,EACb,CACA,yBAAOjC,CAAmBmC,EAAK5B,EAAU,GACnCA,EAAU,IACZA,EAAU,GAQZ,IAAIX,EAAMuC,EAAI,GACVtC,EAAMsC,EAAI,GACd,IAAK,IAAIlC,EAAI,EAAGA,EAAIkC,EAAIjC,OAAQD,IAC1BkC,EAAIlC,GAAKL,EACXA,EAAMuC,EAAIlC,GACDkC,EAAIlC,GAAKJ,IAClBA,EAAMsC,EAAIlC,IAGd,MAAMP,EAAO,IAAIC,YAAYY,GAAS6B,KAAK,GACrCtC,GAAWD,EAAMD,GAAOW,GAAY,EAAI,GAAKV,EAAMD,GAAOW,EAChE,IAAK,IAAIN,EAAI,EAAGA,EAAIkC,EAAIjC,OAAQD,IAAK,CACnC,MAAMoC,EAAOF,EAAIlC,GAEjBP,EADiBP,EAAUiB,QAAQiC,EAAMzC,EAAKE,EAASS,KAEzD,CACA,MAAO,CACLb,OACAE,MACAC,MACAC,UAEJ,E,mEC9OK,SAASwC,EAAWC,GACzB,OAAO,IAAI,MAAQA,EAAWC,MAAM,GAAID,EAAWC,MAAM,GAAID,EAAWC,MAAM,GAChF,CCVO,SAASC,IACd,MAAO,CACLC,KAAM,GACNC,cAAe,CAAC,EAAG,GACnBC,cAAe,CAAC,EAAG,EAAG,GACtBC,gBAAiB,CAAC,EAAG,EAAG,GACxBC,oBAAqB,EACrBC,aAAc,CAAC,KACfC,cAAe,CAAC,CAAC,IAAK,IAAK,MAC3BC,gBAAiB,EACjBC,oBAAqB,CAAC,CACpBV,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBW,QAAS,CAAC,EAAG,EAAG,EAAG,EAAG,GACtBC,UAAW,GACXC,SAAU,GACVC,SAAU,UAEZC,UAAW,CACTC,YAAa,CAAC,EAAG,EAAG,GACpBC,SAAU,CAAC,EAAG,EAAG,GACjBC,MAAO,CAAC,EAAG,EAAG,IAGpB,CACO,MAAMC,EACX,WAAAvE,CAAYwE,GACVtE,KAAKsE,UAAYA,GAzBZ,CACLlB,KAAM,GACNC,cAAe,CAAC,EAAG,GACnBC,cAAe,CAAC,EAAG,EAAG,GACtBC,gBAAiB,CAAC,EAAG,EAAG,GACxBC,oBAAqB,EACrBC,aAAc,CAAC,KACfC,cAAe,CAAC,CAAC,IAAK,IAAK,MAC3BC,gBAAiB,EACjBC,oBAAqB,CAAC,CACpBV,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBW,QAAS,CAAC,EAAG,EAAG,EAAG,EAAG,GACtBC,UAAW,GACXC,SAAU,GACVC,SAAU,UAEZC,UAAW,CACTC,YAAa,CAAC,EAAG,EAAG,GACpBC,SAAU,CAAC,EAAG,EAAG,GACjBC,MAAO,CAAC,EAAG,EAAG,IAOlB,CACA,oBAAIG,GACF,OAAOvE,KAAKsE,UAAUV,oBAAoB5D,KAAKsE,UAAUX,gBAC3D,CAGA,eAAIa,GACF,OAAOxE,KAAKsE,UAAUd,mBACxB,CAGA,gBAAIiB,GACF,OAAOzB,EAAWhD,KAAKsE,UAAUV,oBAAoB,GACvD,CAGA,cAAIZ,GACF,OAAOA,EAAWhD,KAAKuE,iBACzB,CAGA,qBAAIG,GACF,ODtC8BzB,ECsCLjD,KAAKsE,UAAUV,oBAAoB,GDrCvD,IAAI,MAAQX,EAAWY,QAAQ,GAAIZ,EAAWY,QAAQ,GAAIZ,EAAWY,QAAQ,IAD/E,IAA2BZ,CCuChC,CAGA,eAAI0B,GACF,OAAO3E,KAAKsE,UAAUV,oBAAoB,GAAGE,SAC/C,CAGA,SAAIc,GAEF,OAAO5E,KAAKuE,iBAAiBrB,MAAM,EACrC,CAGA,aAAI2B,GAEF,OAAO7E,KAAKuE,iBAAiBV,QAAQ,EACvC,CAGA,YAAIE,GACF,OAAO/D,KAAKuE,iBAAiBR,QAC/B,CAGA,uBAAIe,GACF,OAAO9E,KAAKsE,UAAUV,oBAAoBhD,MAC5C,CAGA,gBAAI6C,GACF,OAAOzD,KAAKsE,UAAUb,YACxB,CAGA,iBAAIC,GACF,OAAO1D,KAAKsE,UAAUZ,aACxB,CAGA,iBAAIJ,GACF,OAAO,IAAI,SAAWtD,KAAKsE,UAAUhB,cACvC,CAGA,mBAAIC,GACF,OAAO,IAAI,SAAWvD,KAAKsE,UAAUf,gBACvC,CACA,mBAAII,GACF,OAAO3D,KAAKsE,UAAUX,eACxB,CAMA,iBAAIN,GACF,OAAO,IAAI,SAAWrD,KAAKsE,UAAUjB,cACvC,CACA,aAAIY,GACF,MAAO,CACLC,YAAa,IAAI,SAAWlE,KAAKsE,UAAUL,UAAUC,aACrDC,SAAU,IAAI,SAAWnE,KAAKsE,UAAUL,UAAUE,UAClDC,MAAO,IAAI,SAAWpE,KAAKsE,UAAUL,UAAUG,OAEnD,EAEK,SAASW,EAAiBT,GAC/B,MAAM,cACJjB,GACEiB,EACEU,EAAUV,EAAUV,oBAAoBU,EAAUX,iBAExD,MAAO,CAACN,EAAc,GAAK2B,EAAQ9B,MAAM,GAAIG,EAAc,GAAK2B,EAAQ9B,MAAM,GAChF,C,kCC9HA,MAAM+B,EAAWpC,GAAOA,EAAIqC,OAAMC,GAAKA,IAAMtC,EAAI,KAC3CuC,EAAQ,CAACvC,EAAKwC,EAAKC,KACvB,IAAK,IAAI3E,EAAI,EAAGA,EAAI2E,EAAG3E,IACrBkC,EAAI0C,KAAKF,EACX,EAEIG,EAAmBC,IACvB,MAAMC,EAASD,GAAO,EACtB,OAAOC,EAASC,OAAkB,IAAXD,EAAa,EAEtC,SAASE,EAAaP,EAAKQ,GACrBR,EAAMQ,EAAO,KACfA,EAAO,GAAKR,GAEVA,EAAMQ,EAAO,KACfA,EAAO,GAAKR,EAEhB,CAQe,MAAMS,EACnB,WAAAhG,CAAYiG,EAAQC,EAAuBC,EAAsBC,EAAoBC,GAAyB,GAE5G,MAAMC,EAAU,CAAC,CAACC,KAAU,KAAY,CAACA,KAAU,KAAY,CAACA,KAAU,KAAY,CAACA,KAAU,MACjG,IAAK,MAAMC,KAASP,EAClBH,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAIjC,GAAIA,EAAQG,OAAOC,MAAKnB,IAAQM,OAAOc,SAASpB,KAG9C,OAFArF,KAAK0G,gBAAkB,QACvB1G,KAAK2G,wBAA0B,IAKjC3G,KAAK0G,gBAAkB,GACvB1G,KAAK2G,wBAA0B,GAK/B,IAAK,MAAOC,EAAWC,KAAUT,EAAQG,OAAOO,UAAW,CACzD,MAAMC,EAAYH,GAAa,EACzBI,EAAaD,EAAYpB,OAAqB,IAAdoB,GACtC,IAAIE,EACJ,GAAgB,EAAZL,EAAe,CAGjB,MAAMM,EAAgBjB,EAAqBkB,KAAIC,GACtCjG,KAAKb,IAAIuG,EAAQb,EAAsBe,GAAYK,EAAUJ,GAAc,KAIpF,GAAI/B,EAASiC,GACXD,EAAMC,EAAc,OACf,CAELD,EAAM,GACN,IAAK,MAAOtG,EAAG0G,KAAcH,EAAcJ,UACzC1B,EAAM6B,EAAKI,EAAWpB,EAAqBtF,GAAG,GAElD,CAEF,MAGEsG,EAAM9F,KAAKZ,IAAIsG,EAAQb,EAAsBe,GAAY,GAE3D,MAAMO,EAAiB,CACrBV,YACAC,QACAI,MACAlB,OAAQ,IAENG,GAAsBA,EAAmBqB,SAASX,GACpD5G,KAAK2G,wBAAwBpB,KAAK+B,GAG7BnB,GACHnG,KAAK0G,gBAAgBnB,KAAK+B,EAGhC,CAGA,IAAK,MAAMhB,KAASP,EAAQ,CAC1B,IAAK,MAAMN,KAAOzF,KAAK0G,gBACjBJ,EAAMd,EAAiBC,EAAImB,cAAgBnB,EAAIoB,OACjDpB,EAAIM,OAAOR,KAAKe,GAGpB,IAAK,MAAMb,KAAOzF,KAAK2G,wBACjBL,EAAMd,EAAiBC,EAAImB,cAAgBnB,EAAIoB,OACjDpB,EAAIM,OAAOR,KAAKe,EAGtB,CACF,CACA,wBAAQkB,CAAkBC,GACxB,IAAIC,EAAS,EACb,KAAOD,EAAW7G,OAAS,GAAG,CAE5B6G,EAAaA,EAAWE,QAAOlC,IAC7B,MAAMwB,EAAMW,MAAMC,QAAQpC,EAAIwB,KAAO9F,KAAKZ,OAAOkF,EAAIwB,KAAOxB,EAAIwB,IAChE,OAAoB,EAAhBxB,EAAImB,UACCnB,EAAIoB,MAAQa,GAAUT,EAEtBxB,EAAIoB,MAAQa,GAAUT,CAC/B,IAIF,IAAK,MAAMxB,KAAOgC,EAAY,CAC5B,MAAMK,EAAYJ,GAA0B,EAAhBjC,EAAImB,UAAgB,GAAK,GACrD,IAAK,MAAMN,KAASb,EAAIM,OAAQ,CAE9B,GAAI6B,MAAMC,QAAQpC,EAAIwB,MAAQX,EAAMd,EAAiBC,EAAImB,YAAckB,EAAYrC,EAAIwB,IAAIX,EAAM,IAC/F,SAEF,MAAMyB,EAAWzB,EAAM0B,QACvBD,EAASvC,EAAiBC,EAAImB,aAAekB,QACvCC,CACR,CACF,CACAL,GAAU,CACZ,CACF,CACA,EAAEO,OAAOC,YAEP,GAAIlI,KAAK2G,wBAAwB/F,OAAS,EACxC,IAAK,MAAM0F,KAASR,EAAsB0B,kBAAkBxH,KAAK2G,+BACzDL,EAKV,IAAK,MAAMA,KAASR,EAAsB0B,kBAAkBxH,KAAK0G,uBACzDJ,CAEV,E,6FClJK,SAAS6B,EAAsBC,GACpC,GAAIA,EAAIC,eAAeC,SACrB,OAAOF,EAAIC,cAAcC,SAASnB,KAAI,EACpCoB,SACCC,IAAQD,GAAS,WAAWC,EAAMJ,EAAIK,kBAE3C,MAAMC,EAAON,EAAIO,UAAU,GACrB/H,EAAS8H,EAAO,EAAI,EAAIN,EAAIQ,YAAY,GAAG1F,MAAMwF,GACvD,OAAOd,MAAMiB,KAAK,CAChBjI,WACC,CAACkI,EAAGN,IAAQ,WAAWA,EAAMJ,EAAIK,iBACtC,CAGO,MAAMM,EAAoB,EAAEC,EAAGC,EAAGC,KAAO,EAAIvD,OAAOqD,GAAK,GAAKrD,OAAOsD,GAAK,GAAKtD,OAAOuD,GAAK,GAC3F,SAASC,EAAiBC,GAC/B,MAAMT,EAAY,EAAE,GAAI,GAAI,GAAI,GAAI,GAC9BU,EAAY,CAAC,IAAK,IAAK,IAAK,IAAK,KACvCD,EAAKE,SAAQ,CAACC,EAAMf,KAClB,MAAMgB,EAAUH,EAAUI,QAAQF,EAAKnG,MACvC,KAAIoG,GAAW,GAGb,MAAM,IAAI,KAAgB,8BAA8BD,EAAKnG,OAAQ,CACnEsG,KAAM,KAAoBC,mBAH5BhB,EAAUa,GAAWhB,CAKvB,IAIF,MAAMoB,GAA4B,IAAlBjB,EAAU,GAC1B,GAAIiB,IAA6B,IAAlBjB,EAAU,GACvB,MAAM,IAAI,KAAgB,gBAAgBiB,EAAU,OAAS,qBAAsB,CACjFF,KAAM,KAAoBC,mBAG9B,OAAOhB,CACT,CAGO,SAASkB,EAAiBC,EAAWC,GAC1C,MAAMC,EAAUjB,EAAkBgB,GAC5BE,EAASrC,MAAMoC,GAWrB,OAVAD,EAAWT,SAAQ,CAACjE,EAAKmD,KACvB,GAAInD,GAAO,EAAG,CACZ,GAAIA,GAAO2E,EACT,MAAM,IAAI,KAAgB,kCAAkC3E,IAAO,CACjEqE,KAAM,KAAoBC,mBAG9BM,EAAO5E,GAAOyE,EAAUtB,EAC1B,KAEKyB,CACT,CAGO,SAASC,EAAaC,EAAeJ,EAAYK,GACtD,MAAMH,EAAS,CAACG,EAAcA,EAAcA,EAAcA,EAAcA,GAWxE,OAVAL,EAAWT,SAAQ,CAACjE,EAAKmD,KACvB,GAAInD,GAAO,EAAG,CACZ,GAAIA,GAAO8E,EAAcvJ,OACvB,MAAM,IAAI,KAAgB,kCAAkCyE,IAAO,CACjEqE,KAAM,KAAoBC,mBAG9BM,EAAOzB,GAAO2B,EAAc9E,EAC9B,KAEK4E,CACT,CAGO,SAASI,EAASC,EAASP,GAChC,MAAMQ,EAAaD,EAAQE,0BAC3B,QAAmBC,IAAfF,EAEF,OADAG,QAAQC,KAAK,0EACN,CAAC,EAAG,EAAG,EAAG,EAAG,GAItB,MAIMC,EAAiBL,EAAWM,MAJT7B,GAAgB,UAAXA,EAAEU,OAKhC,OAAKkB,EAKEV,EADOU,EAAexG,MAAM4D,QACR+B,EAAY,IAJrCW,QAAQC,KAAK,yFACN,CAAC,EAAG,EAAG,EAAG,EAAG,GAIxB,CAQA,SAASG,EAAqBC,EAAMC,EAAQC,EAAMC,GAChD,MAEMC,GAFKH,EAAO,IAAM,EAAID,EAAK7H,MAAM8H,EAAO,IAAM,IACzCE,EAAO,IAAM,EAAID,EAAK/H,MAAMgI,EAAO,IAAM,GAE9CE,EAAQL,EAAK7H,MAAM8H,EAAO,IAAMC,EAAK/H,MAAMgI,EAAO,IAClDG,EAAQN,EAAK7H,MAAM8H,EAAO,IAAMC,EAAK/H,MAAMgI,EAAO,IACxD,OAAc,IAAVC,GAAyB,IAAVC,GAAyB,IAAVC,EACzB,EACEF,GAAS,GAAKC,GAAS,GAAKC,GAAS,GACtC,EACCF,GAAS,GAAKC,GAAS,GAAKC,GAAS,EACvC,OAEP,CAEJ,CACA,MACMC,EAAc,CAACC,EAAG7I,IAAMvB,KAAKqK,IAAID,EAAI7I,GAD3B,KAEhB,SAAS+I,EAAwBC,EAAMC,EAAQC,EAAMC,GACnD,MAAMC,EAASzB,EAASqB,EAAKK,mBAAmBC,SAASL,GAASD,EAAK/C,WACjEsD,EAAS5B,EAASuB,EAAKG,mBAAmBC,SAASH,GAASD,EAAKjD,WACvE,OAAO2C,EAAYQ,EAAO,GAAIG,EAAO,KAAOX,EAAYQ,EAAO,GAAIG,EAAO,KAAOX,EAAYQ,EAAO,GAAIG,EAAO,GACjH,CAYO,SAASC,EAAuBC,GACrC,GAAIA,EAAQvL,OAAS,EACnB,OAIF,MAAMwL,EAAgBxE,MAAMiB,KAAK,CAC/BjI,OAAQuL,EAAQvL,SACf,IAAM,KACHyL,EAAezE,MAAMiB,KAAK,CAC9BjI,OAAQuL,EAAQvL,SACf,IAAM,KAGH0L,EAAe,IAAI1E,MAAMuE,EAAQvL,QAAQkC,KAAK,GACpD,KAAOwJ,EAAapH,OAAM,CAACG,EAAKmD,IAAQnD,EAAM8G,EAAQ3D,GAAKI,YAAYhI,UAAS,CAE9E,IAAIqE,GAAW,EACXsH,EAAc,EACdC,EAAcL,EAAQ,GACtBM,EAAcD,EAAY5D,YAAY0D,EAAa,IACvD,IAAK,IAAII,EAAa,EAAGA,EAAaP,EAAQvL,OAAQ8L,IAAc,CAClE,MAAMC,EAAaR,EAAQO,GACrBE,EAAaD,EAAW/D,YAAY0D,EAAaI,IACjDG,EAAW/B,EAAqB2B,EAAaD,EAAY7D,UAAWiE,EAAYD,EAAWhE,WACjG,GAAKkE,EA0BH5H,GAAW,EACP4H,EAAW,IACbN,EAAcG,EACdF,EAAcG,EACdF,EAAcG,OA9BH,CAEb,QAAiBnC,IAAboC,EACF,MAAM,IAAI,KAAgB,4DAA6D,CACrFnD,KAAM,KAAoBoD,4BAMzBrB,EAAwBe,EAAaF,EAAaC,GAAcI,EAAYL,EAAaI,KAI5FhC,QAAQC,KAAK,6FAIf,MAAMoC,EAAWP,EAAY7D,UAAU,IAAM,EAAI8D,EAAYvJ,MAAMsJ,EAAY7D,UAAU,IAAM,EACzFqE,EAAWL,EAAWhE,UAAU,IAAM,EAAIiE,EAAW1J,MAAMyJ,EAAWhE,UAAU,IAAM,EACxFoE,IAAaC,GAGftC,QAAQC,KAAK,6DAA6DoC,QAAeC,IAE7F,CAQF,CACA,GAAI/H,EAEF,IAAK,IAAItE,EAAI,EAAGA,EAAI2L,EAAa1L,OAAQD,IAAK,CAC5C,MAAMgM,EAAaR,EAAQxL,GACrBsM,EAAoBX,EAAa3L,GACvCyL,EAAczL,GAAG4E,KAAKoH,EAAW/D,YAAYqE,IAC7CZ,EAAa1L,GAAG4E,KAAKoH,EAAWZ,mBAAmBC,SAASiB,IAC5DX,EAAa3L,IAAM,CACrB,MAGA,IAAK,MAAO6H,EAAK0E,KAAWZ,EAAaxF,UAAW,CAClD,MAAM6F,EAAaR,EAAQ3D,GACrBoE,EAAaD,EAAW/D,YAAYsE,GAEzB,IADApC,EAAqB2B,EAAaD,EAAY7D,UAAWiE,EAAYD,EAAWhE,aAE/F2D,EAAa9D,IAAQ,EAEzB,CAEJ,CACA,GAAsC,IAAlC2D,EAAQ,GAAGvD,YAAYhI,OACzB,MAAM,IAAI,KAAgB,sFAAuF,CAC/G8I,KAAM,KAAoBoD,4BAG9B,IAAK,IAAInM,EAAI,EAAGA,EAAIwL,EAAQvL,OAAQD,IAClCwL,EAAQxL,GAAGiI,YAAcwD,EAAczL,GACvCwL,EAAQxL,GAAGoL,mBAAmBC,SAAWK,EAAa1L,EAE1D,C,kEC1NO,MAAMwM,EAAkBC,GAAQA,EAAKC,KAAOD,EACnD,SAASE,EAAiBC,EAAKC,GAC7B,MAAsB,iBAARD,GAA4B,OAARA,GAAgBC,KAAQD,CAC5D,CACA,SAASE,EAAsBF,EAAKC,EAAMpK,EAAO,QAC/C,IAAKkK,EAAiBC,EAAKC,GACzB,MAAM,IAAI,KAAgB,GAAGpK,yCAA4CoK,KAAS,CAChF9D,KAAM,KAAoBC,kBAGhC,CACA,SAAS+D,EAAkBH,EAAKC,EAAMpK,EAAO,QAC3C,IAAKwE,MAAMC,QAAQ0F,EAAIC,IACrB,MAAM,IAAI,KAAgB,GAAGpK,qBAAwBoK,qBAAyB,CAC5E9D,KAAM,KAAoBC,kBAGhC,CAIO,SAASgE,EAA6BP,EAAMhK,EAAO,QAExDqK,EAAsBL,EAAM,cAAehK,GAC3CsK,EAAkBN,EAAM,cAAehK,EACzC,CAOO,SAASwK,EAAwBR,EAAMS,EAAgB,EAAGzK,EAAO,QAEtE,MAAM0K,EAAiBV,EAAKW,YAAYF,GACxC,IAAKC,EACH,MAAM,IAAI,KAAgB,GAAG1K,uDAA0DyK,IAAiB,CACtGnE,KAAM,KAAoBC,mBAG9B,MACMqE,EAAiB,GAAG5K,gBAAmByK,IADlBP,EAAiBQ,EAAgB,QAAU,MAAMA,EAAe1K,QAAU,KAIrGqK,EAAsBK,EAAgB,OAAQE,GAC9CN,EAAkBI,EAAgB,OAAQE,GAC1CF,EAAe1E,KAAKE,SAAQ,CAACC,EAAM5I,IAAM8M,EAAsBlE,EAAM,OAAQ,GAAGyE,UAAuBrN,OAGvG8M,EAAsBK,EAAgB,WAAY1K,GAClDsK,EAAkBI,EAAgB,WAAY1K,GAC9C0K,EAAe9B,SAAS1C,SAAQ,CAACvJ,EAAMY,IAAM8M,EAAsB1N,EAAM,OAAQ,GAAGiO,aAA0BrN,MAChH,C,iBC1CO,SAASsN,EAAYC,EAAKxG,EAAQ9G,EAAQuN,EAAO,CAAC,GAWrD,YAVe1D,IAAX/C,QAAmC+C,IAAX7J,IAExBuN,EAAO,IACAA,EACHC,QAAS,IACFD,EAAKC,QACRC,MAAO,SAAS3G,KAAUA,EAAS9G,EAAS,OAIjD0N,MAAMJ,EAAKC,EACtB,CC5BA,SAASI,EAAQC,EAAMC,GACnB,MAAMC,EAAuB,iBAATF,EAAoB,IAAIG,IAAIH,GAAQA,EACnDE,EAAKE,SAASC,SAAS,OAExBH,EAAKE,UAAY,KAErB,MAAME,EAAW,IAAIH,IAAIF,EAAKzG,MAAM,GAAI0G,GAGxC,OADAI,EAASC,OAASL,EAAKK,OAChBD,CACX,CACAE,eAAeC,EAAgBC,GAC3B,GAAwB,MAApBA,EAASC,OAAb,CAGA,GAAwB,MAApBD,EAASC,QAAsC,MAApBD,EAASC,OACpC,OAAO,IAAIC,iBAAiBF,EAASG,eAEzC,MAAM,IAAIC,MAAM,8BAA8BJ,EAASC,UAAUD,EAASK,aAJ1E,CAKJ,C,yBAyDA,QA9BA,MACIrB,IACA,GACA,GACA,WAAApO,CAAYoO,EAAKsB,EAAU,CAAC,GACxBxP,KAAKkO,IAAMA,EACXlO,MAAK,EAAawP,EAAQC,WAAa,CAAC,EACxCzP,MAAK,EAAsBwP,EAAQE,mBAAoB,CAC3D,CACA,GAAYD,GACR,OD3BmBE,EC2BD3P,MAAK,ED3BY4P,EC2BAH,EDzBhC,IACAE,KACAC,EACHxB,QAAS,IACFuB,EAAevB,WACfwB,EAAiBxB,UAPzB,IAAoBuB,EAAgBC,CC4BvC,CACA,SAAMC,CAAIC,EAAKN,EAAU,CAAC,GACtB,IAAIO,EAAOxB,EAAQvO,KAAKkO,IAAK4B,GAAKC,KAElC,OAAOd,QADcX,MAAMyB,EAAM/P,MAAK,EAAYwP,IAEtD,CACA,cAAMQ,CAASF,EAAKG,EAAOT,EAAU,CAAC,GAClC,IAEIN,EAFAhB,EAAMK,EAAQvO,KAAKkO,IAAK4B,GACxBI,EAAOlQ,MAAK,EAAYwP,GAQ5B,OALIN,EADA,iBAAkBe,QA/C9BjB,eAA4Bd,EAAKiC,EAAeD,EAAME,GAClD,GAAIA,EACA,OAAO9B,MAAMJ,EAAK,IACXgC,EACH9B,QAAS,IAAK8B,EAAK9B,QAASC,MAAO,UAAU8B,OAGrD,IAAIjB,QAAiBZ,MAAMJ,EAAK,IAAKgC,EAAMG,OAAQ,SACnD,IAAKnB,EAASoB,GAEV,OAAOpB,EAEX,IAAIqB,EAAiBrB,EAASd,QAAQyB,IAAI,kBACtCjP,EAAS+E,OAAO4K,GACpB,OAAOtC,EAAYC,EAAKtN,EAASuP,EAAevP,EAAQsP,EAC5D,CAiC6BM,CAAatC,EAAK+B,EAAMQ,aAAcP,EAAMlQ,MAAK,SAGjDiO,EAAYC,EAAK+B,EAAMvI,OAAQuI,EAAMrP,OAAQsP,GAE3DjB,EAAgBC,EAC3B,G,aCzEW,SAASwB,EAAUC,EAAOC,EAAUC,EAAOC,GACxD,MACMC,GADOH,EAAS/B,SAAS,KAAO+B,EAAS5I,MAAM,GAAI,GAAK4I,GACvCD,EAAMlC,MAAQkC,EAAMlC,KAAKI,SAAS,KAAO,GAAK,KAC/DmC,EAAWhC,MAAOiC,EAAQ9C,KAC1BA,GAAM+C,YAAc/C,EAAKgD,aAC3BhD,EAAKgD,YAAYF,EAAQ9C,EAAK+C,YAEhC,MAAME,EAAUL,EAAUE,EAAOI,KAAK,KAChCC,EAAcT,GAAOhB,IAAIuB,GAC/B,GAAIE,IAAe,OAAQA,GACzB,OAAOA,EAET,IAAIrH,EAOJ,OALEA,EADE6G,GAAS3C,GAAM+C,iBACFJ,EAAMS,WAAWH,EAASjD,GAAM+C,YAAY,IAAMP,EAAMK,SAASC,EAAQ9C,IAAOA,EAAKqD,kBAErFb,EAAMK,SAASC,EAAQ9C,GAExC0C,GAAOY,OAAOL,EAASnH,GAChBA,CAAM,EAEf,OAAO,IAAIyH,MAAMf,EAAO,CACtBd,IAAK,CAAC8B,EAAQnE,KACZ,GAAa,aAATA,EACF,OAAOwD,EAIT,MAAM1P,EAAQqQ,EAAOnE,GACrB,OAAIlM,aAAiBsQ,SACZ,YAAaC,GAClB,OAAOvQ,EAAMwQ,MAAMH,EAAQE,EAC7B,EAEKvQ,CAAK,GAGlB,CACO,MAAMyQ,UAA0B,EACrC,WAAAjS,CAAYkS,EAASxC,GACnByC,MAAMD,EAASxC,EACjB,CAIA,SAAMK,CAAIC,EAAKN,EAAU,CAAC,GACxB,IACE,aAAayC,MAAMpC,IAAIC,EAAKN,EAE9B,CAAE,MAAO7M,GACP,GAAIA,GAAGuP,SAASC,WAAW,kCACzB,OAEF,MAAMxP,CACR,CACF,E,kCCvDK,MAAMyP,EAAgC,oBAW9B,MAAMC,EA0BnB,WAAAvS,CAAYwS,EAAoB,GAAIC,EAAyB,GAC3DvS,KAAKwS,YAAc,IAAIC,IACvBzS,KAAK0S,eAAiB,IAAIC,IAC1B3S,KAAK8Q,MAAQ,GACb9Q,KAAK4S,iBAAmB,GACxB5S,KAAKsS,kBAAoBA,EACzBtS,KAAKuS,uBAAyBpR,KAAKb,IAAIgS,EAAmBC,EAC5D,CAQA,eAAAM,CAAgB/C,EAAKgD,GAInB,IAAIC,EAAgBC,EACpB,MAAMC,EAAU,IAAIC,SAAQ,CAAC3E,EAAS4E,KACpCJ,EAAiBxE,EACjByE,EAAgBG,CAAM,IAGlBC,EAAc,CAClBtD,IAAKA,EACLuD,OAAQP,EACRvE,QAASwE,EACTI,OAAQH,EACRC,WAGF,OADAjT,KAAKwS,YAAYc,IAAIxD,EAAKsD,GACnBA,CACT,CAOA,iBAAAG,CAAkBzD,EAAK0D,GAErB,GAAIxT,KAAKwS,YAAYiB,IAAI3D,GAAM,CAE7B,MAAMsD,EAAcpT,KAAKwS,YAAY3C,IAAIC,GACrCsD,GAAeA,EAAYM,YAC7BC,aAAaP,EAAYM,WACzBN,EAAYM,eAAYjJ,GAErBzK,KAAK8Q,MAAMvJ,SAASuI,IAAS9P,KAAK4S,iBAAiBrL,SAASuI,KAE3D0D,EACFxT,KAAK4S,iBAAiBrN,KAAKuK,GAE3B9P,KAAK8Q,MAAMvL,KAAKuK,GAElB9P,KAAK4T,UAET,CACF,CAoBA,UAAArC,CAAWzB,EAAKgD,EAAeU,GAAc,EAAOK,EAAU,GAC5D,GAAK7T,KAAKwS,YAAYiB,IAAI3D,GAYnB,CACL,MAAMgE,EAAmB9T,KAAK4S,iBAAiBnJ,QAAQqG,GACnDgE,GAAoB,IAAMN,GAG5BxT,KAAK4S,iBAAiBmB,OAAOD,EAAkB,GAC/C9T,KAAKuT,kBAAkBzD,IACd+D,GAAW,GAGpB7T,KAAKuT,kBAAkBzD,EAAK0D,EAEhC,KAxBgC,CAE9B,MAAMJ,EAAcpT,KAAK6S,gBAAgB/C,EAAKgD,GAE9C,GAAIe,EAAU,EAAG,CACf,MAAMH,EAAYM,YAAW,IAAMhU,KAAKuT,kBAAkBzD,EAAK0D,IAAcK,GAE7ET,EAAYM,UAAYA,CAC1B,MAEE1T,KAAKuT,kBAAkBzD,EAAK0D,EAEhC,CAaA,MAAMP,EAAUjT,KAAKwS,YAAY3C,IAAIC,IAAMmD,QAC3C,IAAKA,EACH,MAAM,IAAI3D,MAAM,gEAElB,OAAO2D,CACT,CAaA,WAAAgB,CAAYC,EAAUV,GAAc,EAAOK,EAAU,IACnD,MAAMM,EAAW,GACjB,IAAK,IAAIxT,EAAI,EAAGA,EAAIuT,EAAStT,OAAQD,IAAK,CACxC,MAAMoC,EAAOmR,EAASvT,GAChBsS,EAAUjT,KAAKuR,WAAWxO,EAAK+M,IAAK/M,EAAK+P,cAAeU,EAAaK,EAAUlT,GACrFwT,EAAS5O,KAAK0N,EAChB,CACA,OAAOkB,CACT,CAOA,aAAMP,GACJ,MAAMQ,EAAcpU,KAAK0S,eAAe2B,KACxC,GAAID,GAAepU,KAAKsS,mBAA2C,IAAtBtS,KAAK8Q,MAAMlQ,SAAiBwT,GAAepU,KAAKuS,wBAA2D,IAAjCvS,KAAK4S,iBAAiBhS,QAC3I,OAEF,MAAM0T,EAAatU,KAAK8Q,MAAMyD,SAAWvU,KAAK4S,iBAAiB2B,QAC/D,IAAKD,EACH,OAEF,GAAItU,KAAK0S,eAAee,IAAIa,GAG1B,YADAtU,KAAK4T,UAGP,MAAMR,EAAcpT,KAAKwS,YAAY3C,IAAIyE,GACzC,IAAKlB,EACH,OAEF,MAAMtD,EAAMsD,EAAYtD,IAExB9P,KAAK0S,eAAe8B,IAAI1E,SAClBsD,EAAYC,SAASoB,KAAKrB,EAAY7E,QAAS6E,EAAYD,QACjEnT,KAAK0S,eAAegC,OAAO5E,GAC3B9P,KAAKwS,YAAYkC,OAAO5E,GACxB9P,KAAK4T,SACP,CAOA,aAAAe,CAAc7E,EAAK8E,EAAexC,GAChC,IAAKpS,KAAKwS,YAAYiB,IAAI3D,GACxB,OAEF,MAAMsD,EAAcpT,KAAKwS,YAAY3C,IAAIC,GACrCsD,IACEA,EAAYM,WAEdC,aAAaP,EAAYM,WAG3BN,EAAYD,OAAOyB,IAErB,MAAMC,EAAa7U,KAAK8Q,MAAMrH,QAAQqG,GACtC,GAAI+E,GAAc,EAChB7U,KAAK8Q,MAAMiD,OAAOc,EAAY,OACzB,CACL,MAAMf,EAAmB9T,KAAK4S,iBAAiBnJ,QAAQqG,GACnDgE,GAAoB,GACtB9T,KAAK4S,iBAAiBmB,OAAOD,EAAkB,EAEnD,CACA9T,KAAKwS,YAAYkC,OAAO5E,GACxB9P,KAAK0S,eAAegC,OAAO5E,EAC7B,CAMA,iBAAAgF,CAAkBF,EAAexC,GAE/BpS,KAAK8Q,MAAQ,GACb9Q,KAAK4S,iBAAmB,GACxB,IAAK,MAAM9C,KAAO9P,KAAKwS,YAAYuC,OACjC/U,KAAK2U,cAAc7E,EAAK8E,EAE5B,CAOA,UAAAI,CAAWlF,GACT,OAAO9P,KAAKwS,YAAYiB,IAAI3D,EAC9B,CAOA,cAAAmF,CAAenF,GACb,OAAO9P,KAAK0S,eAAee,IAAI3D,EACjC,E,gDCjQa,MAAMoF,EAenB,WAAApV,CAAYwS,EAAmBC,GAE3BvS,KAAK8Q,MAD0B,iBAAtBwB,QAAwD7H,IAAtB6H,EAC9B,IAAI,IAAaA,EAAmBC,GAEpCD,EAEftS,KAAKmV,iBAAmB,EACxBnV,KAAKoV,YAAc,IAAI3C,IACvBzS,KAAKkU,SAAW,IAAIzB,GACtB,CAGA,UAAA4C,CAAWvF,EAAKxO,GACd,MAAM4S,EAAWlU,KAAKkU,SAASrE,IAAIC,GACnC,GAAIoE,EAAU,CACZ,IAAK,MAAM,QACT3F,EAAO,aACP+G,KACGpB,EACH3F,EAAQjN,GACRtB,KAAKoV,YAAYvF,IAAIyF,IAAeZ,OAAO5E,GAE7C9P,KAAKkU,SAASQ,OAAO5E,EACvB,CACF,CAGA,SAAAyF,CAAUzF,EAAK0F,GACb,MAAMtB,EAAWlU,KAAKkU,SAASrE,IAAIC,GACnC,GAAIoE,EAAU,CACZ,IAAK,MAAM,OACTf,EAAM,aACNmC,KACGpB,EACHf,EAAOqC,GACPxV,KAAKoV,YAAYvF,IAAIyF,IAAeZ,OAAO5E,GAE7C9P,KAAKkU,SAASQ,OAAO5E,EACvB,CACF,CAGA,aAAA2F,GACE,MAAMH,EAAetV,KAAKmV,iBAG1B,OAFAnV,KAAKmV,mBACLnV,KAAKoV,YAAY9B,IAAIgC,EAAc,IAAI7C,KAChC6C,CACT,CAOA,UAAA/D,CAAWzB,EAAKwF,EAAcxC,EAAeU,EAAaK,GAQxD,GANA7T,KAAK8Q,MAAMS,WAAWzB,EAAKgD,EAAeU,EAAaK,GAASY,MAAKnT,GAAStB,KAAKqV,WAAWvF,EAAKxO,KAAQoU,OAAMF,GAAUxV,KAAKuV,UAAUzF,EAAK0F,KAC1IxV,KAAKkU,SAAST,IAAI3D,IACrB9P,KAAKkU,SAASZ,IAAIxD,EAAK,IAIrBwF,GAAgBtV,KAAKmV,kBAAoBG,EAAe,EAC1D,MAAM,IAAIhG,MAAM,2CAA2CgG,6BAG7D,IADmBtV,KAAKoV,YAAYvF,IAAIyF,GAEtC,MAAM,IAAIhG,MAAM,2CAA2CgG,sBAI7D,OAAO,IAAIpC,SAAQ,CAAC3E,EAAS4E,KAC3BnT,KAAKkU,SAASrE,IAAIC,IAAMvK,KAAK,CAC3BgJ,UACA4E,SACAmC,iBAEF,MAAMpE,EAAalR,KAAKoV,YAAYvF,IAAIyF,GAClCK,EAAkBzE,GAAYrB,IAAIC,GACpC6F,EACFA,EAAgBpQ,KAAK4N,GAErBjC,GAAYoC,IAAIxD,EAAK,CAACqD,GACxB,GAEJ,CAMA,kBAAAyC,CAAmB9F,EAAKqD,EAAQyB,GAE9BzB,EAAOyB,GAGP,MAAMiB,EAAgB7V,KAAKkU,SAASrE,IAAIC,GACxC,IAAK+F,EAEH,OAGF,MAAMrN,EAAMqN,EAAcC,WAAUC,GAAOA,EAAI5C,SAAWA,IACtD3K,GAAO,GACTqN,EAAc9B,OAAOvL,EAAK,GAIxBqN,EAAcjV,OAAS,IAAMZ,KAAK8Q,MAAMmE,eAAenF,KACzD9P,KAAK8Q,MAAM6D,cAAc7E,EAAK8E,GAC9B5U,KAAKkU,SAASQ,OAAO5E,GAEzB,CAGA,aAAA6E,CAAc7E,EAAKwF,EAAcV,GAC/B,MAAM1D,EAAalR,KAAKoV,YAAYvF,IAAIyF,GACxC,IAAKpE,EACH,OAAO,EAET,MAAM8E,EAAY9E,EAAWrB,IAAIC,GACjC,IAAKkG,IAAcA,EAAUpV,OAC3B,OAAO,EAET,IAAK,MAAMuS,KAAU6C,EACnBhW,KAAK4V,mBAAmB9F,EAAKqD,EAAQyB,GAGvC,OADA1D,EAAWwD,OAAO5E,IACX,CACT,CAGA,gBAAAmG,CAAiBX,EAAcV,GAC7B,MAAMiB,EAAgB7V,KAAKoV,YAAYvF,IAAIyF,GAC3C,GAAIO,EAAe,CACjB,IAAK,MAAO/F,EAAKkG,KAAcH,EAAc/O,UAC3C,IAAK,MAAMqM,KAAU6C,EACnBhW,KAAK4V,mBAAmB9F,EAAKqD,EAAQyB,GAGzC5U,KAAKoV,YAAYV,OAAOY,EAC1B,CACF,CAGA,UAAAN,CAAWlF,GACT,OAAO9P,KAAK8Q,MAAMkE,WAAWlF,EAC/B,CAGA,cAAAmF,CAAenF,GACb,OAAO9P,KAAK8Q,MAAMmE,eAAenF,EACnC,CAGA,aAAAoG,CAAcZ,GACZ,OAAOtV,KAAKoV,YAAY3B,IAAI6B,EAC9B,CAGA,YAAAa,CAAab,EAAcxF,GACzB,OAAO9P,KAAKoV,YAAYvF,IAAIyF,IAAe7B,IAAI3D,KAAQ,CACzD,E,qDCxLK,IAAIsG,EAA6B,SAAUA,GAUhD,OATAA,EAAcA,EAAoB,KAAI,GAAK,OAC3CA,EAAcA,EAA6B,cAAI,GAAK,gBACpDA,EAAcA,EAA4B,aAAI,GAAK,eACnDA,EAAcA,EAA6B,cAAI,GAAK,gBACpDA,EAAcA,EAAyB,UAAI,GAAK,YAChDA,EAAcA,EAAgC,iBAAI,GAAK,mBACvDA,EAAcA,EAAgD,iCAAI,GAAK,mCACvEA,EAAcA,EAAgD,iCAAI,GAAK,mCACvEA,EAAcA,EAAoC,qBAAI,GAAK,uBACpDA,CACT,CAXwC,CAWtC,CAAC,GAOQC,EAAoC,SAAUA,GAIvD,OAHAA,EAAqBA,EAA8B,QAAI,GAAK,UAC5DA,EAAqBA,EAA4B,MAAI,GAAK,QAC1DA,EAAqBA,EAA4B,MAAI,GAAK,QACnDA,CACT,CAL+C,CAK7C,CAAC,GAGQC,EAA+B,SAAUA,GAKlD,OAHAA,EAAgBA,EAAiC,gBAAI,GAAK,kBAE1DA,EAAgBA,EAA8B,aAAI,GAAK,eAChDA,CACT,CAN0C,CAMxC,CAAC,E,gDC/BI,SAASC,EAAgBC,GAC9B,MAAO,IACFA,EACHC,UAAW,IAAI,OAAK,IAAI,OAAUC,KAAKF,EAAKC,UAAUnW,MAAM,IAAI,OAAUoW,KAAKF,EAAKC,UAAUlW,MAElG,C,qFCUO,MAAMoW,EACTC,KAAO,iBACP,WAAA9W,CAAY+W,EAAeC,IACvB,QAAOD,EAAcE,UAAY,EAAG,oCACxC,CACA,iBAAOC,CAAWH,EAAezJ,GAC7B,OAAO,IAAIuJ,EAAcE,EAAezJ,EAC5C,CAKA,MAAA6J,CAAOC,GACH,MAAM,IAAI5H,MAAM,iHACpB,CAMA,MAAA6H,CAAOtU,GACH,OAAOA,CACX,ECtCJ,MAAMuU,EACN,WACI,MAAM7L,EAAI,IAAIlL,YAAY,CAAC,YAE3B,QAAkB,KADR,IAAI+O,WAAW7D,EAAE8L,OAAQ9L,EAAE+L,WAAY/L,EAAEgM,YACxC,GACf,CALyBC,GAMzB,SAASC,EAAkBC,GACvB,MAAI,sBAAuBA,EAChBA,EAAWC,kBAGf,CACX,CACO,MAAMC,EACThB,KAAO,iBACP,GACA,GACA,GACA,GACA,GACA,WAAA9W,CAAY+W,EAAezJ,GACvBpN,MAAK,EAAU6W,GAAegB,OAC9B7X,MAAK,GAAc,QAAQoN,EAAK0K,WAChC9X,MAAK,EAASoN,EAAKlK,MACnBlD,MAAK,GAAU,QAAYoN,EAAKlK,MAAO,KAGvC,MAAM6U,EAAS,IAAI/X,MAAK,EAAY,GACpCA,MAAK,EAAqB+X,EAAOJ,iBACrC,CACA,iBAAOX,CAAWH,EAAezJ,GAC7B,OAAO,IAAIwK,EAAWf,EAAezJ,EACzC,CACA,MAAA6J,CAAOpU,GACH,IAAImV,EAAQ,IAAI5I,WAAWvM,EAAI9C,KAAKsX,QAIpC,OAHID,GAAqC,QAAjBpX,MAAK,IACzB,QAAiBgY,EAAOP,EAAkBzX,MAAK,IAE5CgY,CACX,CACA,MAAAb,CAAOa,GAIH,OAHIZ,GAAqC,QAAjBpX,MAAK,IACzB,QAAiBgY,EAAOP,EAAkBzX,MAAK,IAE5C,CACHD,KAAM,IAAIC,MAAK,EAAYgY,EAAMX,OAAQW,EAAMV,WAAYU,EAAMT,WAAavX,MAAK,GACnFkD,MAAOlD,MAAK,EACZiY,OAAQjY,MAAK,EAErB,EClDG,MAAMkY,EACTtB,KAAO,iBACP,iBAAOI,GACH,OAAO,IAAIkB,CACf,CACA,MAAAjB,CAAOnO,GACH,MAAM,IAAIwG,MAAM,kBACpB,CACA,MAAA6H,CAAOtU,GACH,OAAO,IAAIuM,WAAWvM,EAAIwU,OAAQxU,EAAIyU,WAAYzU,EAAI0U,WAAa,EACvE,ECTG,MAAMY,EACTvB,KAAO,iBACP,iBAAOI,CAAWlO,GACd,OAAO,IAAIqP,CACf,CACA,MAAAlB,CAAOmB,GACH,MAAM,IAAI9I,MAAM,iGACpB,CACA,YAAM6H,CAAOa,GACT,MAAMX,QAAe,QAAWW,EAAO,CAAEK,OAAQ,SACjD,OAAO,IAAIjJ,WAAWiI,EAC1B,ECVJ,SAASiB,EAAsBC,EAAMjX,GAIjC,OAHA,SAAQqE,OAAO6S,MAAMlX,GAAQ,0EAC7B,QAAOA,IAAUqE,OAAO8S,kBAAmB,+EAC3C,QAAOnX,IAAUqE,OAAO+S,kBAAmB,+EACpCpX,CACX,CAEA,SAASqX,EAAmBJ,EAAMjX,GAC9B,OAAOA,aAAiBsX,SAAWhR,MAAMC,QAAQvG,GAC3CsX,OAAO7D,KAAKzT,GACTuX,OACAC,QAAO,CAACC,EAAQjJ,KACjBiJ,EAAOjJ,GAAOxO,EAAMwO,GACbiJ,IACR,CAAC,GACFzX,CACV,CACO,MAAM0X,EACTnC,cACAD,KAAO,iBACP,GACA,GACA,WAAA9W,CAAY+W,EAAgB,CAAC,GACzB7W,KAAK6W,cAAgBA,EAErB,MAAM,SAAEoC,EAAW,QAAO,SAAEC,GAAW,EAAK,aAAEC,GAAe,EAAI,eAAEC,GAAiB,EAAI,UAAEC,GAAY,EAAI,UAAEC,GAAY,EAAI,OAAEC,EAAM,OAAEC,GAAS,GAAU3C,EACzJ,IAAI4C,EAAa5C,EAAc4C,WAC1BA,IAOGA,EAJCF,EAIY,CAAC,KAAM,MAHP,CAAC,IAAK,MAM3BvZ,MAAK,EAAkB,CACnBiZ,WACAC,WACAC,eACAC,iBACAC,YACAE,SACAE,aACAH,aAEJtZ,MAAK,EAAkB,CAAEwZ,SAC7B,CACA,iBAAOxC,CAAWH,GACd,OAAO,IAAImC,EAAUnC,EACzB,CACA,MAAAI,CAAOyC,GACH,MAAM,OAAEH,EAAM,SAAEN,EAAQ,aAAEE,EAAY,eAAEC,EAAc,UAAEC,EAAS,UAAEC,GAAetZ,MAAK,GACvF,QAAoB,UAAbiZ,EAAsB,sDAC7B,MAAMU,EAAqB,IAG3B,QAAOP,EAAgB,8FAClBC,GAEDM,EAAmBpU,KAAK+S,GAExBgB,GAGAK,EAAmBpU,KAAKoT,GAE5B,MAAMiB,EAAQhS,MAAMiB,KAAK6Q,EAAI3Z,MAG7B,IAAI8Z,EAFJD,EAAMrU,KAAK,MACXqU,EAAMrU,KAAKmU,EAAIxW,OAEXyW,EAAmB/Y,SACnBiZ,EAAW,CAAC/J,EAAKxO,KACb,IAAIwY,EAAYxY,EAChB,IAAK,IAAIyY,KAAgBJ,EACrBG,EAAYC,EAAajK,EAAKgK,GAElC,OAAOA,CAAS,GAGxB,IAAIE,EAAWC,KAAKC,UAAUN,EAAOC,EAAUN,GAY/C,OAXIJ,IAKAa,EAAWA,EAASG,QAAQ,oBAAqBC,IAC7C,MAAMC,EAAW,OAAOD,EAAIE,WAAW,GAAGC,SAAS,MAEnD,MAAO,MADSF,EAASG,UAAUH,EAASzZ,OAAS,IAC/B,MAGvB,IAAI6Z,aAAcxD,OAAO+C,EACpC,CACA,MAAA7C,CAAOa,GACH,MAAM,OAAEwB,GAAWxZ,MAAK,GAExB,QAAOwZ,EAAQ,uDACf,MAAMI,GAAQ,QAAmB5B,GAC3B9U,EAAQ0W,EAAMc,MAMpB,OALAd,EAAMc,OAEN,QAAOxX,EAAO,qCAGP,CAAEnD,KADI6Z,EACE1W,QAAO+U,QAFP,QAAY/U,EAAO,KAGtC,E,cC3GJ,SAASyX,EAAM9X,GACX,OAAIA,aAAe,MACfA,aAAe,MACfA,aAAe,KAEF,IAAI6O,MAAM7O,EAAK,CACxBgN,IAAG,CAAC8B,EAAQnE,IACDmE,EAAO9B,IAAIlK,OAAO6H,IAE7B8F,IAAG,CAAC3B,EAAQnE,EAAMlM,KAEdqQ,EAAO2B,IAAI3N,OAAO6H,GAAOlM,IAClB,KAMZuB,CACX,CA0DO,MAAM+X,EACThE,KAAO,iBACP,GACA,GACA,WAAA9W,CAAY+W,EAAezJ,GACvB,IAAI9L,EAAQuV,EAAcgE,OAAS,IAC/BC,EAAO1N,EAAKlK,MAAMtC,OAClBia,EAAQ,IAAIjT,MAAMkT,GAClBC,EAAe,IAAInT,MAAMkT,GAC7B,GAAc,MAAVxZ,EACA,IAAK,IAAIX,EAAI,EAAGA,EAAIma,IAAQna,EACxBka,EAAMla,GAAKA,EACXoa,EAAapa,GAAKA,OAGrB,GAAc,MAAVW,EACL,IAAK,IAAIX,EAAI,EAAGA,EAAIma,IAAQna,EACxBka,EAAMla,GAAKma,EAAOna,EAAI,EACtBoa,EAAapa,GAAKma,EAAOna,EAAI,OAIjCka,EAAQvZ,EACRuZ,EAAMvR,SAAQ,CAAC1G,EAAGjC,MACd,aAA2B8J,IAApBsQ,EAAanY,GAAkB,wBAAwBqX,KAAKC,UAAU5Y,MAC7EyZ,EAAanY,GAAKjC,CAAC,IAG3BX,MAAK,EAAS6a,EACd7a,MAAK,EAAgB+a,CACzB,CACA,iBAAO/D,CAAWH,EAAezJ,GAC7B,OAAO,IAAIwN,EAAe/D,EAAezJ,EAC7C,CACA,MAAA6J,CAAOpU,GACH,OAxCR,SAAuByD,EAAOqL,GAC1B,IAAIqJ,EATR,SAAmB1U,GACf,IAAIwU,EAAOxU,EAAMpD,MAAMtC,OAEvB,OADA,QAAOka,IAASxU,EAAM2R,OAAOrX,OAAQ,+CAC9B0F,EAAM2R,OACR9Q,KAAI,CAAC8T,EAAGta,KAAM,CAAGsX,OAAQgD,EAAGC,MAAOva,MACnCkY,MAAK,CAACtN,EAAG7I,IAAMA,EAAEuV,OAAS1M,EAAE0M,SAC5B9Q,KAAKgU,GAAUA,EAAMD,OAC9B,CAEiBE,CAAU9U,GAEvB,OADA,QAAO0U,EAAOpa,SAAW+Q,EAAO/Q,OAAQ,qBACjCoa,EAAO9V,OAAM,CAACmW,EAAK1a,IAAM0a,IAAQ1J,EAAOhR,IACnD,CAoCY2a,CAAczY,EAAK7C,MAAK,GAEjB6C,EA7EnB,SAA6BuF,EAAKuJ,GAC9B,IAAI4J,EAlBR,SAAoBjV,EAAOuU,GACvB,IAAI9a,EAUJ,OAPIA,EAFAuG,EAAMvG,gBAAgB,MACtBuG,EAAMvG,gBAAgB,KACf,IAAIuG,EAAMxG,YAEjBwG,EAAMvG,KAAKa,OAAQ0F,EAAMvG,KAAKyb,OAGvB,IAAIlV,EAAMxG,YAAYwG,EAAMvG,KAAKa,QAErC,CACHb,OACAmD,MAAOoD,EAAMpD,MACb+U,QAAQ,QAAY3R,EAAMpD,MAAO2X,GAEzC,CAEcY,CAAWrT,EAAKuJ,GACtB+J,EAAStT,EAAIlF,MAAMtC,OACnByT,EAAOjM,EAAIrI,KAAKa,OAChBsa,EAAQtT,MAAM8T,GAAQ5Y,KAAK,GAC3B6Y,EAAWhB,EAAMvS,EAAIrI,MACrB6b,EAAWjB,EAAMY,EAAIxb,MACzB,IAAK,IAAI8b,EAAU,EAAGA,EAAUxH,EAAMwH,IAAW,CAC7C,IAAIC,EAAU,EACd,IAAK,IAAIT,EAAM,EAAGA,EAAMK,EAAQL,IAC5BS,GAAWZ,EAAMG,GAAOE,EAAItD,OAAOoD,GAEvCO,EAASE,GAAWH,EAASE,GAC7BX,EAAM,IAAM,EACZ,IAAK,IAAIG,EAAM,EAAGA,EAAMK,EAAQL,IAC5B,GAAIH,EAAMG,KAASjT,EAAIlF,MAAMmY,GAAM,CAC/B,GAAIA,EAAM,IAAMK,EACZ,MAEJR,EAAMG,GAAO,EACbH,EAAMG,EAAM,IAAM,CACtB,CAER,CACA,OAAOE,CACX,CAsDeQ,CAAoBlZ,EAAK7C,MAAK,EACzC,CACA,MAAAmX,CAAOtU,GACH,MAAO,CACH9C,KAAM8C,EAAI9C,KACVmD,MAAOL,EAAIK,MACX+U,QAAQ,QAAYpV,EAAIK,MAAOlD,MAAK,GAE5C,EC7HG,MAAMgc,EACTpF,KAAO,iBACP,GACA,GACA,WAAA9W,CAAYoD,GACRlD,MAAK,EAASkD,EACdlD,MAAK,GAAW,QAAYkD,EAAO,IACvC,CACA,iBAAO8T,CAAWlO,EAAGsE,GACjB,OAAO,IAAI4O,EAAS5O,EAAKlK,MAC7B,CACA,MAAA+T,CAAOgF,GACH,MAAM,IAAI3M,MAAM,0BACpB,CACA,MAAA6H,CAAOa,GACH,IAAIkE,EAAU,IAAIC,YACdC,EAAO,IAAIC,SAASrE,EAAMX,QAC1BtX,EAAO6H,MAAMwU,EAAKE,UAAU,GAAG,IAC/BC,EAAM,EACV,IAAK,IAAI5b,EAAI,EAAGA,EAAIZ,EAAKa,OAAQD,IAAK,CAClC,IAAI6b,EAAcJ,EAAKE,UAAUC,GAAK,GACtCA,GAAO,EACPxc,EAAKY,GAAKub,EAAQ/E,OAAOa,EAAMX,OAAOrP,MAAMuU,EAAKA,EAAMC,IACvDD,GAAOC,CACX,CACA,MAAO,CAAEzc,OAAMmD,MAAOlD,MAAK,EAAQiY,OAAQjY,MAAK,EACpD,EC1BG,MAAMyc,EACT7F,KAAO,iBACP,iBAAOI,CAAWlO,GACd,OAAO,IAAI2T,CACf,CACA,MAAAxF,CAAOmB,GACH,MAAM,IAAI9I,MAAM,0FACpB,CACA,YAAM6H,CAAOa,GACT,MAAMX,QAAe,QAAWW,EAAO,CAAEK,OAAQ,YACjD,OAAO,IAAIjJ,WAAWiI,EAC1B,ECWG,MAAMqF,GAbF,IAAIjK,KACNa,IAAI,SAAS,IAAM,8BAA0BmB,MAAMkI,GAAMA,EAAEC,YAC3DtJ,IAAI,OAAO,IAAM,8BAAwBmB,MAAMkI,GAAMA,EAAEC,YACvDtJ,IAAI,QAAQ,IAAM,8BAAyBmB,MAAMkI,GAAMA,EAAEC,YACzDtJ,IAAI,QAAQ,IAAM6E,IAClB7E,IAAI,QAAQ,IAAMmJ,IAClBnJ,IAAI,aAAa,IAAMsH,IACvBtH,IAAI,SAAS,IAAMsE,IACnBtE,IAAI,UAAU,IAAM4E,IACpB5E,IAAI,aAAa,IAAM0I,IACvB1I,IAAI,SAAS,IAAM0F,IACnB1F,IAAI,YAAY,IAAMqD,IAGxB,SAASkG,EAAsBC,GAClC,IAAIC,EACJ,MAAO,CACH,YAAM9F,CAAO3Q,GACJyW,IACDA,QAAeC,EAAYF,IAC/B,IAAK,MAAMG,KAASF,EAAOG,eACvB5W,QAAc2W,EAAMhG,OAAO3Q,GAE/B,IAAI0R,QAAc+E,EAAOI,eAAelG,OAAO3Q,GAC/C,IAAK,MAAM2W,KAASF,EAAOK,eACvBpF,QAAciF,EAAMhG,OAAOe,GAE/B,OAAOA,CACX,EACA,YAAMb,CAAOa,GACJ+E,IACDA,QAAeC,EAAYF,IAC/B,IAAK,IAAInc,EAAIoc,EAAOK,eAAexc,OAAS,EAAGD,GAAK,EAAGA,IACnDqX,QAAc+E,EAAOK,eAAezc,GAAGwW,OAAOa,GAElD,IAAI1R,QAAcyW,EAAOI,eAAehG,OAAOa,GAC/C,IAAK,IAAIrX,EAAIoc,EAAOG,eAAetc,OAAS,EAAGD,GAAK,EAAGA,IACnD2F,QAAcyW,EAAOG,eAAevc,GAAGwW,OAAO7Q,GAElD,OAAOA,CACX,EAER,CACA0I,eAAegO,EAAYK,GACvB,IAMIF,EANAhJ,EAAWkJ,EAAWN,OAAO5V,KAAI6H,MAAO5B,IACxC,IAAIkQ,QAAcZ,EAAS7M,IAAIzC,EAAKhK,KAAlBsZ,MAElB,OADA,QAAOY,EAAO,kBAAkBlQ,EAAKhK,QAC9B,CAAEka,QAAOlQ,OAAM,IAEtB8P,EAAiB,GAEjBE,EAAiB,GACrB,UAAW,IAAI,MAAEE,EAAK,KAAElQ,KAAU+G,EAAU,CACxC,IAAI8I,EAAQK,EAAMtG,WAAW5J,EAAKyJ,cAAewG,GACjD,OAAQJ,EAAMrG,MACV,IAAK,iBACDsG,EAAe3X,KAAK0X,GACpB,MACJ,IAAK,iBACDE,EAAiBF,EACjB,MACJ,QACIG,EAAe7X,KAAK0X,GAEhC,CAKA,OAJKE,KACD,QAMsB,cANUE,EAMxBvF,UANqC,iBAAiBuF,EAAWvF,sCACzEqF,EAAiBvF,EAAWZ,WAAW,CAAEa,OAAQ,UAAYwF,IAE1D,CAAEH,iBAAgBC,iBAAgBC,iBAC7C,CC9EA,MAAMG,EAAe,sBACd,SAASC,EAA4BC,EAAUC,EAAaC,EAAkBC,IACjF,QAAOH,EAASI,MAAM7N,SAAU,yCAChC,IAAI8N,EAAYL,EAASI,MAAM7N,SAAS+N,KAAKN,EAASI,OAClDG,EAAcN,EAAYvW,KAAI,CAAC8W,EAAGtd,IAAMsd,EAAIL,EAAgBM,YAAYvd,KACxEwd,EAActB,EAAsB,CACpC/E,UAAW,SACX5U,MAAO,IAAI8a,EAAa,GACxBjB,OAAQa,EAAgBQ,eAExBvN,EAAQ,CAAC,EACb,OAAO7B,MAAOqP,IACV,IAEInD,EAFAoD,EAAcD,EAAYlX,KAAI,CAAC8W,EAAGtd,IAAMQ,KAAKC,MAAM6c,EAAID,EAAYrd,MACnE4d,EAAad,EAASlP,QAAQoP,EAAiBW,IAAc7P,KAEjE,GAAI8P,KAAc1N,EACdqK,EAAQrK,EAAM0N,OAEb,CACD,IAAIC,EAAgB,EAChBC,EAAa,GAAKT,EAAYlF,QAAO,CAACvN,EAAG7I,IAAM6I,EAAI7I,GAAG,GACtDsV,QAAc8F,EAAUS,EAAY,CACpC9N,aAAcgO,EAAaD,IAE/BtD,EAAQrK,EAAM0N,GAAcvG,QAChBmG,EAAYhH,OAAOa,GACzB,IACV,CACA,GAAc,OAAVkD,EACA,OAEJ,IAAI,KAAEnb,EAAI,MAAEmD,EAAK,OAAE+U,GAAWiD,EAC1BwD,EAAgBL,EACflX,KAAI,CAAC8W,EAAGtd,IAAMsd,EAAI/a,EAAMvC,KACxBmY,QAAO,CAAC6F,EAAKC,EAAKpW,IAAQmW,EAAMC,EAAM3G,EAAOzP,IAAM,GACpDd,EAAS3H,EAAK2e,GACd9d,EAASb,EAAK2e,EAAgB,GAElC,OAAIhX,IAAW6V,GAAgB3c,IAAW2c,EAGnCO,EAAUS,EAAY,CACzB7W,OAAQ/B,OAAO+B,GACf9G,OAAQ+E,OAAO/E,UALnB,CAME,CAEV,CC5CO,MAAMie,EACThB,MACApP,KACA,WAAA3O,CAAY+d,EAAOpP,EAAO,KACtBzO,KAAK6d,MAAQA,EACb7d,KAAKyO,KAAOA,CAChB,CACA,OAAAF,CAAQE,GAGJ,IAAID,EAAO,IAAIG,IAAI,UAAU3O,KAAKyO,KAAKI,SAAS,KAAO7O,KAAKyO,KAAO,GAAGzO,KAAKyO,WAC3E,OAAO,IAAIoQ,EAAS7e,KAAK6d,MAAO,IAAIlP,IAAIF,EAAMD,GAAMI,SACxD,EAEG,SAASJ,EAAKqP,GACjB,OAAO,IAAIgB,EAAShB,GAAS,IAAIpL,IACrC,CACO,MAAMqM,UAAcD,EACvBjI,KAAO,QACP,GACA,WAAA9W,CAAY+d,EAAOpP,EAAMsQ,GACrB9M,MAAM4L,EAAOpP,GACbzO,MAAK,EAAY+e,CACrB,CACA,SAAIC,GACA,OAAOhf,MAAK,EAAUif,UAC1B,EAEJ,SAASC,EAAgBnC,GACrB,MAAMoC,EAAwBpC,EAAOlS,MAAM5B,GAAiB,cAAXA,EAAE7F,OAEnD,OAAO+b,GAAuBtI,eAAegE,OAAS,GAC1D,CACA,MAAMuE,EAAiBnX,OAAO,mBACvB,SAASoX,EAAY9R,GACxB,OAAOA,EAAI6R,EACf,CA6CO,MAAM,UAAcP,EACvBjI,KAAO,QACP,GACA,CAACwI,GACD,WAAAtf,CAAY+d,EAAOpP,EAAMsQ,GACrB9M,MAAM4L,EAAOpP,GACbzO,MAAK,EAAY,IACV+e,EACHO,YAAY,QAAsBP,IAEtC/e,KAAKof,GAtDb,SAAwB3B,EAAUsB,GAC9B,IAAI,cAAElI,GAAkBkI,EAAShC,OAAOlS,KAAK,MAAsB,CAAC,EAChE0U,EAAiB,CACjBC,kBAAkB,QAAyBT,EAASU,oBACpD/H,YAAY,QAAQqH,EAASjH,WAC7BwH,WAAYP,EAASO,YAEzB,GAAIzI,EAAe,CACf,IAAI6I,EAAeR,EAAgBrI,EAAckG,QACjD,MAAO,IACAwC,EACH3I,KAAM,UACNsH,YAAarH,EAAcqH,YAC3BjB,MAAOJ,EAAsB,CACzB/E,UAAWiH,EAASjH,UACpB5U,MAAO2T,EAAcqH,YACrBnB,OAAQlG,EAAckG,SAE1B4C,YAAYzc,IACD,QAAYA,EAAOwc,GAE9BE,gBAAiBpC,EAA4BC,EAAUsB,EAASc,WAAWhJ,cAAcqH,YAAaqB,EAAeC,iBAAkB3I,GAE/I,CACA,IAAI6I,EAAeR,EAAgBH,EAAShC,QAC5C,MAAO,IACAwC,EACH3I,KAAM,UACNsH,YAAaa,EAASc,WAAWhJ,cAAcqH,YAC/CjB,MAAOJ,EAAsB,CACzB/E,UAAWiH,EAASjH,UACpB5U,MAAO6b,EAASc,WAAWhJ,cAAcqH,YACzCnB,OAAQgC,EAAShC,SAErB4C,YAAYzc,IACD,QAAYA,EAAOwc,GAE9B,qBAAME,CAAgBE,EAActQ,GAChC,IAAIuQ,EAAYR,EAAeC,iBAAiBM,GAC5CE,EAAavC,EAASlP,QAAQwR,GAAWtR,KAC7C,OAAOgP,EAASI,MAAMhO,IAAImQ,EAAYxQ,EAC1C,EAER,CAW+ByQ,CAAejgB,KAAM+e,EAChD,CACA,SAAIC,GACA,OAAOhf,MAAK,EAAUif,UAC1B,CACA,SAAI/b,GACA,OAAOlD,MAAK,EAAUkD,KAC1B,CACA,UAAI6C,GACA,OAAO/F,KAAKof,GAAgBlB,WAChC,CACA,SAAIgC,GACA,OAAOlgB,MAAK,EAAU8X,SAC1B,CACA,cAAM9G,CAAS8O,EAActQ,GACzB,IAAI2Q,EAAUngB,KAAKof,GACfgB,QAAoBD,EAAQP,gBAAgBE,EAActQ,GAC9D,IAAK4Q,EAAa,CACd,IAAI/L,EAAO8L,EAAQjC,YAAYpF,QAAO,CAACvN,EAAG7I,IAAM6I,EAAI7I,GAAG,GACnD3C,EAAO,IAAIogB,EAAQzI,WAAWrD,GAGlC,OADAtU,EAAK+C,KAAKqd,EAAQb,YACX,CACHvf,OACAmD,MAAOid,EAAQjC,YACfjG,OAAQkI,EAAQR,YAAYQ,EAAQjC,aAE5C,CACA,OAAOiC,EAAQlD,MAAM9F,OAAOiJ,EAChC,CAkBA,EAAAC,CAAGC,GACC,OAAO,QAAStgB,KAAKkgB,MAAOI,EAChC,E,8GC/IG,MAAMC,UAAmBjR,MAC5B,WAAAxP,CAAY0gB,GACRvO,MAAMuO,GACNxgB,KAAKoD,KAAO,YAChB,EA6BJ,MAAMqd,EACFC,QACAC,QACAC,cACAC,OACA,WAAA/gB,EAAY,QAAE4gB,EAAO,QAAEC,EAAO,cAAEC,IAE5BF,EApBD,SAAqCA,EAASC,GAWjD,OATAD,EAAUvf,KAAK2f,MAAMJ,IAEP,IACVA,EAAUC,EAAUD,IAGpBA,GAAWC,GAAWD,EAAU,IAnBxC,SAAyBC,GACrB,MAAM,IAAIJ,EAAW,iDAAiDI,IAC1E,CAkBQI,CAAgBJ,GAEbD,CACX,CAQkBM,CAA4BN,EAASC,GAE/C3gB,KAAK0gB,QAAUA,EACf1gB,KAAK2gB,QAAUA,EACf3gB,KAAK4gB,cAAgBA,EACrB5gB,KAAK6gB,OAAS,CAClB,CACA,EAAE5Y,OAAOC,YACL,MAAM+Y,EAAe9f,KAAKC,MAAMpB,KAAK0gB,QAAU1gB,KAAK4gB,eAC9CM,EAAaD,EAAejhB,KAAK4gB,cACjCO,EAAgBnhB,KAAK0gB,QAAUQ,OAC/B,CAAED,eAAcE,gBAC1B,EAEJ,MAAMC,EACFva,MACAwa,KACAC,KACAX,QACAC,cACAC,OACAU,QACA,WAAAzhB,EAAY,QAAE4gB,EAAO,QAAEC,EAAO,cAAEC,IAE5B,MAAO/Z,EAAOwa,EAAMC,IAAQ,QAAcZ,EAASC,GACnD3gB,KAAK6G,MAAQA,EACb7G,KAAKqhB,KAAOA,EACZrhB,KAAKshB,KAAOA,EACRthB,KAAKshB,KAAO,GAxDxB,WACI,MAAM,IAAIf,EAAW,2CACzB,CAuDYiB,GAEJxhB,KAAK2gB,QAAUA,EACf3gB,KAAK4gB,cAAgBA,EACrB5gB,KAAK6gB,OAAS1f,KAAKZ,IAAI,EAAGY,KAAKsgB,MAAMzhB,KAAKqhB,KAAOrhB,KAAK6G,OAAS7G,KAAKshB,OACpEthB,KAAKuhB,QAAUpgB,KAAKsgB,KAAKzhB,KAAK2gB,QAAU3gB,KAAK4gB,cACjD,CACA,EAAE3Y,OAAOC,YAEL,MAAMwZ,EAAoBvgB,KAAKC,MAAMpB,KAAK6G,MAAQ7G,KAAK4gB,eACjDe,EAAkBxgB,KAAKsgB,KAAKzhB,KAAKqhB,KAAOrhB,KAAK4gB,eACnD,IAAK,MAAMK,KAAgB,QAAMS,EAAmBC,GAAkB,CAElE,MAAMT,EAAaD,EAAejhB,KAAK4gB,cACjCgB,EAAYzgB,KAAKb,IAAIN,KAAK2gB,SAAUM,EAAe,GAAKjhB,KAAK4gB,eAE7DA,EAAgBgB,EAAYV,EAClC,IAAIW,EAAiB,EACjBC,EAAsB,EAC1B,GAAI9hB,KAAK6G,MAAQqa,EAAY,CAEzB,MAAMa,GAAab,EAAalhB,KAAK6G,OAAS7G,KAAKshB,KAC/CS,IACAD,GAAuB9hB,KAAKshB,KAAOS,GAEvCF,EAAiB1gB,KAAKsgB,MAAMP,EAAalhB,KAAK6G,OAAS7G,KAAKshB,KAChE,MAGIQ,EAAsB9hB,KAAK6G,MAAQqa,EAIvC,MAAMc,EAAqBhiB,KAAKqhB,KAAOO,EAAYhB,EAAgB5gB,KAAKqhB,KAAOH,EACzEC,EAAgB,CAClBW,EACAE,EACAhiB,KAAKshB,MAGHW,EAAc,CAChBJ,EACAA,EAHqB1gB,KAAKsgB,MAAMO,EAAqBF,GAAuB9hB,KAAKshB,MAIjF,QAEE,CAAEL,eAAcE,gBAAec,cACzC,CACJ,EAaG,MAAMC,EACTC,aACAjf,MACA,WAAApD,EAAY,UAAEsiB,EAAS,MAAElf,EAAK,YAAEgb,IAE5Ble,KAAKmiB,aAhBN,SAA6BC,EAAWlf,GAC3C,IAAImf,EAAa,GAQjB,OAPkB,OAAdD,EACAC,EAAanf,EAAMiE,KAAK2B,IAAM,QAAM,QAE/BlB,MAAMC,QAAQua,KACnBC,EAAaD,EAAUjb,KAAK8T,GAAMA,IAAK,QAAM,SA7GrD,SAAgCmH,EAAWlf,GACnCkf,EAAUxhB,OAASsC,EAAMtC,QAVjC,SAA8BwhB,EAAWlf,GACrC,MAAM,IAAIqd,EAAW,yCAAyCrd,EAAMtC,eAAewhB,EAAUxhB,SACjG,CASQ0hB,CAAqBF,EAAWlf,EAExC,CA2GIqf,CAAuBF,EAAYnf,GAC5Bmf,CACX,CAM4BG,CAAoBJ,EAAWlf,GAAOiE,KAAI,CAACuZ,EAAS/f,IAC7D,IAAwB,iBAAZ+f,EAAuBD,EAAgBW,GAAiB,CAEvEV,QAASA,EACTC,QAASzd,EAAMvC,GACfigB,cAAe1C,EAAYvd,OAGnCX,KAAKkD,MAAQlD,KAAKmiB,aACbxa,QAAQ8a,GAAQA,aAAerB,IAC/Bja,KAAKub,GAASA,EAAK7B,QAC5B,CACA,EAAE5Y,OAAOC,YACL,IAAK,MAAMya,KAAmB,WAAW3iB,KAAKmiB,cAAe,CACzD,MAAMrC,EAAe6C,EAAgBxb,KAAKyb,GAAMA,EAAE3B,eAC5C4B,EAAUF,EAAgBxb,KAAKyb,GAC7B,gBAAiBA,EACV,CAAE/Z,KAAM+Z,EAAEzB,cAAe2B,GAAIF,EAAEX,aAEnC,CAAEpZ,KAAM+Z,EAAEzB,cAAe2B,GAAI,aAElC,CAAEhD,eAAc+C,UAC1B,CACJ,EC3JJ,SAASE,EAAkBlgB,EAAK6E,EAAS,EAAG2M,GACxC,IAAIzT,EAASyT,GAAQxR,EAAIjC,OAAS8G,EAClC,MAAO,CACH9G,SACAoiB,SAAQ,CAACna,EAAMia,EAAKliB,IACTmiB,EAAkBlgB,EAAK6E,EAASmB,EAAMia,EAAKja,GAEtD,GAAAyK,CAAIvT,EAAM8G,EAAQ,GACd,IAAK,IAAIlG,EAAI,EAAGA,EAAIZ,EAAKa,OAAQD,IAC7BkC,EAAI6E,EAASb,EAAQlG,GAAKZ,EAAK8P,IAAIlP,EAE3C,EACAkP,IAAIqL,GACOrY,EAAI6E,EAASwT,GAGhC,CAWA,SAAS+H,EAAapgB,GAClB,OAAIqgB,WAAWtb,MAAMC,QAAQhF,EAAI9C,MACtB,CAEHA,KAAMgjB,EAAkBlgB,EAAI9C,MAC5BkY,OAAQpV,EAAIoV,OACZR,kBAAmB,GAGpB,CACH1X,KAAM,IAAIqP,WAAWvM,EAAI9C,KAAKsX,OAAQxU,EAAI9C,KAAKuX,WAAYzU,EAAI9C,KAAKwX,YACpEU,OAAQpV,EAAIoV,OACZR,kBAAmB5U,EAAI9C,KAAK4X,kBAEpC,CA8BO,MAAMwL,EAAS,CAClBC,QAAO,CAACrjB,EAAMmD,EAAO+U,KACV,CAAElY,OAAMmD,QAAO+U,WAE1B,UAAAoL,CAAWC,EAAM1E,EAAKtd,GAClB,IAAI8a,EAAO6G,EAAaK,GACxBC,EAAkBnH,EAAMwC,EAhBhC,SAAuB/b,EAAKvB,GACxB,GAAI4hB,WAAWtb,MAAMC,QAAQhF,EAAI9C,MAE7B,OAAOgjB,EAAkB,CAACzhB,IAE9B,IAEIvB,EAAO,IAzBf,SAAqC8C,GACjC,MAAI,UAAWA,EAGJA,EAAI/C,YAAYie,KAAK,KAAMlb,EAAI2Y,OAEnC3Y,EAAI/C,WACf,CAgBqB0jB,CAA4B3gB,EAAI9C,MAEtC,CAAe,CAACuB,IAC3B,OAAO,IAAI8N,WAAWrP,EAAKsX,OAAQtX,EAAKuX,WAAYvX,EAAKwX,WAC7D,CAOqCkM,CAAcH,EAAMhiB,GAAQ8a,EAAK3E,kBAClE,EACA,cAAAiM,CAAeJ,EAAMlb,EAAKub,GACtB,IAAIvH,EAAO6G,EAAaK,GACxBM,EAAsBxH,EAAM6G,EAAa7a,GAAMgU,EAAK3E,kBAAmBkM,EAC3E,GAGG3U,eAAe,EAAInM,EAAKuf,EAAY,KAAMjU,EAAO,CAAC,GACrD,OCnFGa,eAAmBnM,EAAKuf,EAAWjU,EAAMgV,GAC5C,IAAIhD,GAAU,QAAYtd,GACtBghB,EAAU,IAAI3B,EAAa,CAC3BE,YACAlf,MAAOL,EAAIK,MACXgb,YAAarb,EAAIkD,SAEjBwV,EAAM4H,EAAOC,QAAQ,IAAIjD,EAAQzI,WAAWmM,EAAQ3gB,MAAM4V,QAAO,CAACvN,EAAG7I,IAAM6I,EAAI7I,GAAG,IAAKmhB,EAAQ3gB,MAAOid,EAAQR,YAAYkE,EAAQ3gB,QAClI4N,EAAQ3C,EAAK2V,mBAAoB,UACrC,IAAK,MAAM,aAAEhE,EAAY,QAAE+C,KAAagB,EACpC/S,EAAM0D,KAAIxF,UACN,IAAI,KAAEjP,EAAI,MAAEmD,EAAK,OAAE+U,SAAiBpV,EAAImO,SAAS8O,EAAc3R,EAAKA,MAChE7H,EAAQ6c,EAAOC,QAAQrjB,EAAMmD,EAAO+U,GACxCkL,EAAOO,eAAenI,EAAKjV,EAAOuc,EAAQ,IAMlD,aAHM/R,EAAMiT,SAGoB,IAAzBF,EAAQ3gB,MAAMtC,OAtBzB,SAAgBiC,GACZ,MAAQ,QAASA,EAAMA,EAAIgN,IAqB0B,GArBfhN,EAqBe,EApBzD,CAoBwCmhB,CAAOzI,EAAIxb,MAAWwb,CAC9D,CD+DW1L,CAAgBhN,EAAKuf,EAAWjU,EAAMgV,EACjD,CAKA,SAASc,EAAYpd,EAAOwa,EAAMC,GAC9B,OAAIA,EAAO,GAAKD,EAAOxa,EACZ1F,KAAKC,OAAOyF,EAAQwa,EAAO,IAAMC,GAAQ,EAEhDza,EAAQwa,EACDlgB,KAAKC,OAAOigB,EAAOxa,EAAQ,GAAKya,GAAQ,EAC5C,CACX,CACA,SAASiC,EAAkBhI,EAAK2I,EAAe5iB,EAAOmW,GAClD,GAA6B,IAAzByM,EAActjB,OAEd,YADA2a,EAAIxb,KAAKuT,IAAIhS,EAAO,GAGxB,MAAO0G,KAAUmc,GAAUD,GACpBE,KAAgBnM,GAAUsD,EAAItD,OACrC,GAAqB,iBAAVjQ,EAGP,YADAub,EAAkB,CAAExjB,KADPwb,EAAIxb,KAAKijB,SAASoB,EAAcpc,EAAQyP,GAC3BQ,UAAUkM,EAAQ7iB,EAAOmW,GAGvD,MAAO5O,EAAMia,EAAIxB,GAAQtZ,EACnBqc,EAAMJ,EAAYpb,EAAMia,EAAIxB,GAClC,GAAsB,IAAlB6C,EAAOvjB,OAMX,IAAK,IAAID,EAAI,EAAGA,EAAI0jB,EAAK1jB,IAErB4iB,EAAkB,CAAExjB,KADPwb,EAAIxb,KAAKijB,SAASoB,GAAevb,EAAOyY,EAAO3gB,GAAK8W,GACvCQ,UAAUkM,EAAQ7iB,EAAOmW,QAPnD,IAAK,IAAI9W,EAAI,EAAGA,EAAI0jB,EAAK1jB,IACrB4a,EAAIxb,KAAKuT,IAAIhS,EAAO8iB,GAAevb,EAAOyY,EAAO3gB,GAAK8W,EAQlE,CACA,SAASmM,EAAsBN,EAAMlb,EAAKqP,EAAmBkM,GACzD,MAAOW,KAASC,GAASZ,GAClBa,KAAYC,GAAYnB,EAAKrL,QAC7ByM,KAAYC,GAAYvc,EAAI6P,OACnC,GAAkB,OAAdqM,EAAKzb,KACL,OAAqB,IAAjB0b,EAAM3jB,YACN0iB,EAAKvjB,KAAKuT,IAAIlL,EAAIrI,KAAKijB,SAAS,EAAGvL,GAAoB6M,EAAKxB,GAAKrL,QAGrEmM,EAAsB,CAClB7jB,KAAMujB,EAAKvjB,KAAKijB,SAASwB,EAAUF,EAAKxB,GAAKrL,GAC7CQ,OAAQwM,GACTrc,EAAKqP,EAAmB8M,GAG/B,GAAgB,OAAZD,EAAKxB,GAAa,CAClB,GAAqB,IAAjByB,EAAM3jB,OAAc,CACpB,IAAI8G,EAAS4c,EAAKzb,KAAO4O,EAEzB,YADA6L,EAAKvjB,KAAKuT,IAAIlL,EAAIrI,KAAKijB,SAAStb,EAAQA,EAAS+P,GAAoB,EAEzE,CAKA,YAJAmM,EAAsBN,EAAM,CACxBvjB,KAAMqI,EAAIrI,KAAKijB,SAAS0B,EAAUJ,EAAKzb,KAAO4O,GAC9CQ,OAAQ0M,GACTlN,EAAmB8M,EAE1B,CACA,MAAO1b,EAAMia,EAAIxB,GAAQgD,EAAKxB,IACvB8B,EAAO9b,EAAG+b,GAASP,EAAKzb,KACzBwb,EAAMJ,EAAYpb,EAAMia,EAAIxB,GAClC,GAAqB,IAAjBiD,EAAM3jB,OAgBV,IAAK,IAAID,EAAI,EAAGA,EAAI0jB,EAAK1jB,IACrBijB,EAAsB,CAClB7jB,KAAMujB,EAAKvjB,KAAKijB,SAASwB,GAAW3b,EAAOlI,EAAI2gB,GAAQ7J,GACvDQ,OAAQwM,GACT,CACC1kB,KAAMqI,EAAIrI,KAAKijB,SAAS0B,GAAWE,EAAQjkB,EAAIkkB,GAASpN,GACxDQ,OAAQ0M,GACTlN,EAAmB8M,OAvB1B,CAGI,GAAa,IAATjD,GAAwB,IAAVuD,GAA2B,IAAZL,GAA6B,IAAZE,EAAe,CAC7D,IAAIhd,EAASkd,EAAQnN,EACjBpD,EAAOgQ,EAAM5M,EAEjB,YADA6L,EAAKvjB,KAAKuT,IAAIlL,EAAIrI,KAAKijB,SAAStb,EAAQA,EAAS2M,GAAOxL,EAAO4O,EAEnE,CAEA,IAAK,IAAI9W,EAAI,EAAGA,EAAI0jB,EAAK1jB,IAAK,CAC1B,IAAI+G,EAASgd,GAAWE,EAAQC,EAAQlkB,GAAK8W,EAC7C6L,EAAKvjB,KAAKuT,IAAIlL,EAAIrI,KAAKijB,SAAStb,EAAQA,EAAS+P,GAAoB+M,GAAW3b,EAAOyY,EAAO3gB,GAAK8W,EACvG,CAEJ,CAUJ,C,iBEtLO,SAAUxH,EAAMpJ,EAAOwa,EAAMC,EAAO,QAC1B7W,IAAT4W,IACAA,EAAOxa,EACPA,EAAQ,GAEZ,IAAK,IAAIlG,EAAIkG,EAAOlG,EAAI0gB,EAAM1gB,GAAK2gB,QACzB3gB,CAEd,CAKO,SAAUmkB,KAAWC,GACxB,GAAyB,IAArBA,EAAUnkB,OACV,OAGJ,MAAMokB,EAAYD,EAAU5d,KAAK8d,GAAOA,EAAGhd,OAAOC,cAC5Cgd,EAAUF,EAAU7d,KAAK8d,GAAOA,EAAGE,SACzC,GAAID,EAAQ1e,MAAM4e,GAAMA,EAAEC,OACtB,MAAM,IAAI/V,MAAM,qCAEpB,IAAK,IAAI3O,EAAI,IAAK,CACd,GAAIukB,EAAQvkB,GAAG0kB,MAKX,GAHAL,EAAUrkB,GAAKokB,EAAUpkB,GAAGsH,OAAOC,YACnCgd,EAAQvkB,GAAKqkB,EAAUrkB,GAAGwkB,SAEpBxkB,GAAKqkB,EAAUpkB,OACjB,kBAKEskB,EAAQ/d,KAAI,EAAG7F,WAAYA,IACjCX,EAAI,EAERukB,EAAQvkB,GAAKqkB,EAAUrkB,GAAGwkB,MAC9B,CACJ,CAEO,SAASG,GAAc,MAAEze,EAAK,KAAEwa,EAAI,KAAEC,GAAQ1gB,GACjD,GAAa,IAAT0gB,EACA,MAAM,IAAIhS,MAAM,6BAGpB,MAAMiW,GADNjE,EAAOA,GAAQ,GACiB,GAEzBkE,EAAOC,GAASF,EAAmB,EAAE,EAAG3kB,EAAS,GAAK,CAAC,EAAGA,GA+BjE,OA7Bc,OAAViG,EACAA,EAAQ0e,EAAmBE,EAAQD,EAG/B3e,EAAQ,GACRA,GAASjG,GACG4kB,IACR3e,EAAQ2e,GAGP3e,EAAQ4e,IACb5e,EAAQ4e,GAIH,OAATpE,EACAA,EAAOkE,EAAmBC,EAAQC,EAG9BpE,EAAO,GACPA,GAAQzgB,GACG4kB,IACPnE,EAAOmE,GAGNnE,EAAOoE,IACZpE,EAAOoE,GAGR,CAAC5e,EAAOwa,EAAMC,EACzB,CACO,SAAStZ,EAAMnB,EAAOwa,EAAMC,EAAO,MAKtC,YAJa7W,IAAT4W,IACAA,EAAOxa,EACPA,EAAQ,MAEL,CACHA,QACAwa,OACAC,OAER,CAEO,SAASwC,IACZ,MAAM3P,EAAW,GACjB,MAAO,CACHK,IAAMkR,GAAOvR,EAAS5O,KAAKmgB,KAC3B3B,OAAQ,IAAM7Q,QAAQyS,IAAIxR,GAElC,C,yHClGA,IAAIyR,EACJ,WACI,IAAIC,EAAiB,IAAIC,QACzB,SAASC,EAAWlI,GAChB,IAAImI,EAASH,EAAehW,IAAIgO,IAAU,CAAEoI,GAAI,EAAGC,GAAI,GAEvD,OADAL,EAAevS,IAAIuK,EAAOmI,GACnBA,CACX,CACA,MAAO,CACH,SAAAG,CAAUtI,EAAOuI,GACbL,EAAWlI,GAAOuI,IAAY,CAClC,EACA,WAAAC,CAAYxI,GACR,IAAImI,EAASD,EAAWlI,GACxB,OAAOmI,EAAOE,GAAKF,EAAOC,GAAK,KAAO,IAC1C,EAER,CAjBsBK,GAsCtBtX,eAAeuX,EAAc9I,EAAUuB,GACnC,IAAI,KAAEvQ,GAASgP,EAASlP,QAAQ,WAC5BnB,QAAaqQ,EAASI,MAAMhO,IAAIpB,GACpC,IAAKrB,EACD,MAAM,IAAI,IAAkB,WAAY,CACpCoZ,MAAO,IAAI,IAAS/X,KAI5B,OADAmX,EAAgBO,UAAU1I,EAASI,MAAO,MACnC,IAAI,KAAMJ,EAASI,MAAOJ,EAAShP,MAAM,SAAwB,QAAmBrB,GAAO4R,GACtG,CACAhQ,eAAeyX,EAAchJ,EAAUuB,GACnC,IAAI,KAAEvQ,GAASgP,EAASlP,QAAQ,WAC5BnB,QAAaqQ,EAASI,MAAMhO,IAAIpB,GACpC,IAAKrB,EACD,MAAM,IAAI,IAAkB,WAAY,CACpCoZ,MAAO,IAAI,IAAS/X,KAI5B,OADAmX,EAAgBO,UAAU1I,EAASI,MAAO,MACnC,IAAI,KAAMJ,EAASI,MAAOJ,EAAShP,MAAM,SAAwB,QAAmBrB,GAAO4R,GACtG,CA8BOhQ,eAAe0X,EAAKjJ,EAAUjO,EAAU,CAAC,GAC5C,IAAIqO,EAAQ,UAAWJ,EAAWA,EAASI,MAAQJ,EAC/C4I,EAAcT,EAAgBS,YAAYxI,GAI1C8I,EAA+B,OAAhBN,EAAuBK,EAAKT,GAAKS,EAAKR,GACrDU,EAAiC,OAAhBP,EAAuBK,EAAKR,GAAKQ,EAAKT,GAC3D,OAAOU,EAAalJ,EAAUjO,GAASkG,OAAOmR,KAC1C,QAAeA,EAAK,KACbD,EAAenJ,EAAUjO,KAExC,CACAkX,EAAKT,GA9ELjX,eAAuByO,EAAUjO,EAAU,CAAC,GACxC,IAAIsX,EAAM,UAAWrJ,EAAWA,EAAW,IAAI,KAASA,GACpDuB,EAAQ,CAAC,EAGb,OAFIxP,EAAQwP,OAAS,KACjBA,QAVRhQ,eAA0ByO,GACtB,IAAIsJ,QAAmBtJ,EAASI,MAAMhO,IAAI4N,EAASlP,QAAQ,WAAWE,MACtE,OAAKsY,GAEE,QAAmBA,GADf,CAAC,CAEhB,CAKsBC,CAAWF,IACR,UAAjBtX,EAAQoH,KACD2P,EAAcO,EAAK9H,GACT,UAAjBxP,EAAQoH,KACD6P,EAAcK,EAAK9H,GACvBuH,EAAcO,EAAK9H,GAAOtJ,OAAOmR,KACpC,QAAeA,EAAK,KACbJ,EAAcK,EAAK9H,KAElC,EAkEA0H,EAAKR,GA3BLlX,eAAuByO,EAAUjO,EAAU,CAAC,GACxC,IAAIsX,EAAM,UAAWrJ,EAAWA,EAAW,IAAI,KAASA,GACpDwJ,QAlBRjY,eAAwByO,GACpB,IAAI,MAAEI,EAAK,KAAEpP,GAASgP,EAASlP,QAAQ,aACnCnB,QAAaqQ,EAASI,MAAMhO,IAAIpB,GACpC,IAAKrB,EACD,MAAM,IAAI,IAAkB,oBAAqB,CAC7CoZ,MAAO,IAAI,IAAS/X,KAG5B,IAAIyY,GAAW,QAAmB9Z,GAIlC,MAH2B,UAAvB8Z,EAASC,YACTD,EAAS5H,YAAa,QAAsB4H,IAElB,UAAvBA,EAASC,UACV,IAAI,KAAMtJ,EAAOJ,EAAShP,KAAMyY,GAChC,IAAI,KAAMrJ,EAAOJ,EAAShP,KAAMyY,EAC1C,CAGqBE,CAASN,GAE1B,GADAlB,EAAgBO,UAAUW,EAAIjJ,MAAO,WAChBpT,IAAjB+E,EAAQoH,KACR,OAAOqQ,EACX,GAAqB,UAAjBzX,EAAQoH,MAAoBqQ,aAAgB,KAC5C,OAAOA,EACX,GAAqB,UAAjBzX,EAAQoH,MAAoBqQ,aAAgB,KAC5C,OAAOA,EACX,IAAIrQ,EAAOqQ,aAAgB,KAAQ,QAAU,QAC7C,MAAM,IAAI3X,MAAM,yBAAyBE,EAAQoH,eAAeA,KACpE,C,qDCjFO,MAAMyQ,EACT,GACA,WAAAvnB,CAAY8C,EAAG0U,EAAY1W,GACN,iBAANgC,EACP5C,MAAK,EAAS,IAAIoP,WAAWxM,GAExBA,aAAa0kB,YAClBtnB,MAAK,EAAS,IAAIoP,WAAWxM,EAAG0U,EAAY1W,GAG5CZ,MAAK,EAAS,IAAIoP,WAAWxH,MAAMiB,KAAKjG,GAAIuC,GAAOA,EAAI,EAAI,IAEnE,CACA,qBAAIwS,GACA,OAAO,CACX,CACA,cAAIL,GACA,OAAOtX,MAAK,EAAOsX,UACvB,CACA,cAAIC,GACA,OAAOvX,MAAK,EAAOuX,UACvB,CACA,UAAIF,GACA,OAAOrX,MAAK,EAAOqX,MACvB,CACA,UAAIzW,GACA,OAAOZ,MAAK,EAAOY,MACvB,CACA,GAAAiP,CAAIrH,GACA,IAAIlH,EAAQtB,MAAK,EAAOwI,GACxB,MAAwB,iBAAVlH,EAA+B,IAAVA,EAAcA,CACrD,CACA,GAAAgS,CAAI9K,EAAKlH,GACLtB,MAAK,EAAOwI,GAAOlH,EAAQ,EAAI,CACnC,CACA,IAAAwB,CAAKxB,GACDtB,MAAK,EAAO8C,KAAKxB,EAAQ,EAAI,EACjC,CACA,EAAE2G,OAAOC,YACL,IAAK,IAAIvH,EAAI,EAAGA,EAAIX,KAAKY,OAAQD,UACvBX,KAAK6P,IAAIlP,EAEvB,EAOG,MAAM4mB,EACTC,MACAhM,MACA,GACA,WAAA1b,CAAY0b,EAAO5Y,EAAG0U,EAAY1W,GAG9B,GAFAZ,KAAKwb,MAAQA,EACbxb,MAAK,EAAW,IAAIya,YACH,iBAAN7X,EACP5C,KAAKwnB,MAAQ,IAAIpY,WAAWxM,EAAI4Y,QAE/B,GAAI5Y,aAAa0kB,YACd1mB,IACAA,GAAkB4a,GACtBxb,KAAKwnB,MAAQ,IAAIpY,WAAWxM,EAAG0U,EAAY1W,OAE1C,CACD,IAAI6mB,EAAS7f,MAAMiB,KAAKjG,GACxB5C,KAAKwnB,MAAQ,IAAIpY,WAAWqY,EAAO7mB,OAAS4a,GAC5C,IAAK,IAAI7a,EAAI,EAAGA,EAAI8mB,EAAO7mB,OAAQD,IAC/BX,KAAKsT,IAAI3S,EAAG8mB,EAAO9mB,GAE3B,CACJ,CACA,qBAAIgX,GACA,OAAO3X,KAAKwb,KAChB,CACA,cAAIlE,GACA,OAAOtX,KAAKwnB,MAAMlQ,UACtB,CACA,cAAIC,GACA,OAAOvX,KAAKwnB,MAAMjQ,UACtB,CACA,UAAIF,GACA,OAAOrX,KAAKwnB,MAAMnQ,MACtB,CACA,UAAIzW,GACA,OAAOZ,KAAKuX,WAAavX,KAAK2X,iBAClC,CACA,GAAA9H,CAAIrH,GACA,MAAM4T,EAAO,IAAIhN,WAAWpP,KAAKqX,OAAQrX,KAAKsX,WAAatX,KAAKwb,MAAQhT,EAAKxI,KAAKwb,OAElF,OAAO,IAAIW,aAAchF,OAAOiF,GAAMjC,QAAQ,QAAS,GAC3D,CACA,GAAA7G,CAAI9K,EAAKlH,GACL,MAAM8a,EAAO,IAAIhN,WAAWpP,KAAKqX,OAAQrX,KAAKsX,WAAatX,KAAKwb,MAAQhT,EAAKxI,KAAKwb,OAClFY,EAAKtZ,KAAK,GACVsZ,EAAK9I,IAAItT,MAAK,EAASiX,OAAO3V,GAClC,CACA,IAAAwB,CAAKxB,GACD,MAAMomB,EAAU1nB,MAAK,EAASiX,OAAO3V,GACrC,IAAK,IAAIX,EAAI,EAAGA,EAAIX,KAAKY,OAAQD,IAC7BX,KAAKwnB,MAAMlU,IAAIoU,EAAS/mB,EAAIX,KAAKwb,MAEzC,CACA,EAAEvT,OAAOC,YACL,IAAK,IAAIvH,EAAI,EAAGA,EAAIX,KAAKY,OAAQD,UACvBX,KAAK6P,IAAIlP,EAEvB,EAOG,MAAMgnB,EACT,GACAnM,MACA,WAAA1b,CAAY0b,EAAO5Y,EAAG0U,EAAY1W,GAE9B,GADAZ,KAAKwb,MAAQA,EACI,iBAAN5Y,EACP5C,MAAK,EAAQ,IAAI4nB,WAAWhlB,EAAI4Y,QAE/B,GAAI5Y,aAAa0kB,YACd1mB,IACAA,GAAU4a,GACdxb,MAAK,EAAQ,IAAI4nB,WAAWhlB,EAAG0U,EAAY1W,OAE1C,CACD,MAAM6mB,EAAS7kB,EACTqb,EAAI,IAAI0J,EAAmBnM,EAAO,GACxCxb,MAAK,EAAQ,IAAI4nB,WAAW,YACxB,IAAK,IAAIC,KAAOJ,EACZxJ,EAAE3K,IAAI,EAAGuU,SACF5J,GAAE,CAEhB,CAL2B,GAMhC,CACJ,CACA,qBAAItG,GACA,OAAO3X,MAAK,EAAM2X,kBAAoB3X,KAAKwb,KAC/C,CACA,cAAIjE,GACA,OAAOvX,MAAK,EAAMuX,UACtB,CACA,cAAID,GACA,OAAOtX,MAAK,EAAMsX,UACtB,CACA,UAAID,GACA,OAAOrX,MAAK,EAAMqX,MACtB,CACA,UAAIzW,GACA,OAAOZ,MAAK,EAAMY,OAASZ,KAAKwb,KACpC,CACA,GAAA3L,CAAIrH,GACA,MAAMd,EAAS1H,KAAKwb,MAAQhT,EAC5B,IAAIyB,EAAS,GACb,IAAK,IAAItJ,EAAI,EAAGA,EAAIX,KAAKwb,MAAO7a,IAC5BsJ,GAAU6d,OAAOC,cAAc/nB,MAAK,EAAM0H,EAAS/G,IAGvD,OAAOsJ,EAAOkQ,QAAQ,UAAW,GACrC,CACA,GAAA7G,CAAI9K,EAAKlH,GACL,MAAMoG,EAAS1H,KAAKwb,MAAQhT,EACtB4T,EAAOpc,MAAK,EAAMgjB,SAAStb,EAAQA,EAAS1H,KAAKwb,OACvDY,EAAKtZ,KAAK,GACV,IAAK,IAAInC,EAAI,EAAGA,EAAIX,KAAKwb,MAAO7a,IAC5Byb,EAAKzb,GAAKW,EAAM0mB,YAAYrnB,IAAM,CAE1C,CACA,IAAAmC,CAAKxB,GAEDtB,KAAKsT,IAAI,EAAGhS,GAEZ,IAAIomB,EAAU1nB,MAAK,EAAMgjB,SAAS,EAAGhjB,KAAKwb,OAC1C,IAAK,IAAI7a,EAAI,EAAGA,EAAIX,KAAKY,OAAQD,IAC7BX,MAAK,EAAMsT,IAAIoU,EAAS/mB,EAAIX,KAAKwb,MAEzC,CACA,EAAEvT,OAAOC,YACL,IAAK,IAAIvH,EAAI,EAAGA,EAAIX,KAAKY,OAAQD,UACvBX,KAAK6P,IAAIlP,EAEvB,E,4JC5LG,SAASsnB,EAAmBjQ,GAC/B,MAAM6P,GAAM,IAAI1L,aAAchF,OAAOa,GACrC,OAAOiC,KAAKiO,MAAML,EACtB,CACO,SAASM,EAAiB/L,EAAM3E,GACnC,MAAM2Q,EAAW3Q,EAAoB,EAC/B4Q,EAAe5Q,EAAoB,EACzC,IAAIzO,EAAI,EACR,IAAK,IAAIrI,EAAI,EAAGA,EAAIyb,EAAKxb,OAAQD,GAAK8W,EAClC,IAAK,IAAI6Q,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAC/Btf,EAAIoT,EAAKzb,EAAI2nB,GACblM,EAAKzb,EAAI2nB,GAAKlM,EAAKzb,EAAI0nB,EAAeC,GACtClM,EAAKzb,EAAI0nB,EAAeC,GAAKtf,CAGzC,CACO,SAASuf,EAAQzQ,GACpB,GAAkB,cAAdA,EACA,OAAOoL,WAAWtb,MAEtB,IAAI4gB,EAAQ1Q,EAAU0Q,MAAM,kBAC5B,GAAIA,EAAO,CACP,IAAK,CAAE5R,EAAM4E,GAASgN,EAEtB,OAAiB,MAAT5R,EAAe,KAAqB,MAAiBmH,KAAK,KAAMpY,OAAO6V,GACnF,CAEA,IAAIiN,EAAM,CACNC,KAAMC,UACNC,MAAOC,WACPC,MAAOlB,WACPmB,MAAO7F,WAAW8F,cAClBC,MAAO7Z,WACP8Z,OAAQC,YACRC,OAAQ/oB,YACRgpB,OAAQnG,WAAWoG,eACnBC,QAASrG,WAAWsG,aACpBC,QAASC,aACTC,QAASC,aACTC,KAAM,MACR/R,GAEF,OADAgS,EAAOrB,EAAK,qCAAqC3Q,KAC1C2Q,CACX,CAEO,SAAS9I,EAAYzc,EAAO2X,GAC/B,MAAMC,EAAO5X,EAAMtC,OACE,iBAAVia,IACPA,EACc,MAAVA,EACMjT,MAAMiB,KAAK,CAAEjI,OAAQka,IAAQ,CAAChS,EAAGnI,IAAMA,IACvCiH,MAAMiB,KAAK,CAAEjI,OAAQka,IAAQ,CAAChS,EAAGnI,IAAMma,EAAO,EAAIna,KAEhEmpB,EAAOhP,IAASD,EAAMja,OAAQ,qDAC9B,IAAI0gB,EAAO,EACPrJ,EAAS,IAAIrQ,MAAMkT,GACvB,IAAK,IAAIna,EAAIka,EAAMja,OAAS,EAAGD,GAAK,EAAGA,IACnCsX,EAAO4C,EAAMla,IAAM2gB,EACnBA,GAAQpe,EAAM2X,EAAMla,IAExB,OAAOsX,CACX,CAEO,SAAS8R,GAAyB,KAAE3mB,EAAI,cAAEyT,IAC7C,GAAa,YAATzT,EAAoB,CACpB,MAAM4mB,EAAYnT,GAAemT,WAAa,IAC9C,OAAQlK,GAAiB,CAAC,OAAQA,GAAczO,KAAK2Y,EACzD,CACA,GAAa,OAAT5mB,EAAe,CACf,MAAM4mB,EAAYnT,GAAemT,WAAa,IAC9C,OAAQlK,GAAiBA,EAAazO,KAAK2Y,IAAc,GAC7D,CACA,MAAM,IAAI1a,MAAM,+BAA+BlM,IACnD,CA6BO,SAAS6mB,EAAwB7c,EAAM6R,EAAa,CAAC,GACxD,IAAIlC,EAAS,GACTmD,EA9BR,SAAsBA,GAClB,GAAc,OAAVA,EACA,MAAO,CAAEpI,UAAW,aAExB,IAAI0Q,EAAQtI,EAAMsI,MAAM,iBACxBsB,EAAOtB,EAAO,kBAAkBtI,KAChC,IAAK,CAAErI,EAAQqS,GAAQ1B,EACnB1Q,EAAY,CACZqS,GAAI,OACJC,GAAI,OACJC,GAAI,QACJC,GAAI,QACJC,GAAI,SACJC,GAAI,QACJC,GAAI,SACJC,GAAI,QACJC,GAAI,SACJC,GAAI,UACJC,GAAI,UACJC,GAAI,WACNZ,KACGA,EAAK/X,WAAW,MAAQ+X,EAAK/X,WAAW,KAAO,MAAM+X,SAASzf,GAEnE,OADAqf,EAAOhS,EAAW,iCAAiCoI,KACpC,MAAXrI,EACO,CAAEC,aAEN,CAAEA,YAAWD,OAAmB,MAAXA,EAAiB,SAAW,MAC5D,CAGgBkT,CAAa3d,EAAK8S,OACX,MAAf9S,EAAKyN,OACLkC,EAAOxX,KAAK,CAAEnC,KAAM,YAAayT,cAAe,CAAEgE,MAAO,OAEzD,WAAYqF,GAA0B,QAAjBA,EAAMrI,QAC3BkF,EAAOxX,KAAK,CAAEnC,KAAM,QAASyT,cAAe,CAAEgB,OAAQ,SAE1D,IAAK,IAAI,GAAEmT,KAAOnU,KAAmBzJ,EAAK6d,SAAW,GACjDlO,EAAOxX,KAAK,CAAEnC,KAAM4nB,EAAInU,kBAE5B,GAAIzJ,EAAK8d,WAAY,CACjB,IAAI,GAAEF,KAAOnU,GAAkBzJ,EAAK8d,WACpCnO,EAAOxX,KAAK,CAAEnC,KAAM4nB,EAAInU,iBAC5B,CACA,MAAO,CACHsU,YAAa,EACbhE,UAAW,QACXjkB,MAAOkK,EAAKlK,MACZ4U,UAAWoI,EAAMpI,UACjB+H,WAAY,CACRzc,KAAM,UACNyT,cAAe,CACXqH,YAAa9Q,EAAKrH,SAG1B0Z,mBAAoB,CAChBrc,KAAM,KACNyT,cAAe,CACXmT,UAAW5c,EAAKge,qBAAuB,MAG/CrO,SACAuC,WAAYlS,EAAKkS,WACjBL,aAER,CACO,SAASoM,EAAwBvU,EAAOmI,EAAa,CAAC,GACzD,MAAO,CACHkM,YAAa,EACbhE,UAAW,QACXlI,aAER,CACO,SAASqM,EAASpL,EAAOI,GAC5B,GAAc,WAAVA,GACU,WAAVA,GACU,YAAVA,GACU,WAAVA,GACU,WAAVA,EACA,OAAOJ,IAAUI,EAErB,IAAIiL,EAAuB,SAAVrL,EACjB,GAAc,YAAVI,EACA,OAAOiL,EACX,IAAIC,EAAYtL,EAAM/N,WAAW,SAAW+N,EAAM/N,WAAW,QAC7D,GAAc,WAAVmO,EACA,OAAOkL,EACX,IAAIC,EAAsB,UAAVvL,GAA+B,WAAVA,EACrC,GAAc,WAAVI,EACA,OAAOmL,EACX,IAAIC,EAAsB,cAAVxL,EAChB,MAAc,WAAVI,EACOoL,IACHF,GAAcC,GAAcF,GAAeG,EACvD,CACO,SAASC,EAAkB1O,GAC9B,MAAuB,qBAAhBA,GAAO7Z,IAClB,CACO,SAASwoB,EAAsB7M,GAClC,MAA4B,WAAvBA,EAASjH,WAAiD,UAAvBiH,EAASjH,WACtB,MAAvBiH,EAASO,WAINP,EAASO,WAFLuM,OAAO9M,EAASO,WAG/B,CA0BO,SAASwM,EAAeC,KAAUC,GACrC,IAAKA,EAAOxlB,MAAMylB,GAAeF,aAAiBE,IAC9C,MAAMF,CAEd,CAgBO,SAASjC,EAAOoC,EAAY1L,EAAM,IACrC,IAAK0L,EACD,MAAM,IAAI5c,MAAMkR,EAExB,CASOxR,eAAemd,EAAWpsB,GAAM,OAAEsY,EAAM,OAAE+T,IAC7C,MAAMld,EAAWnP,aAAgBssB,SAAWtsB,EAAO,IAAIssB,SAAStsB,GAChE+pB,EAAO5a,EAASod,KAAM,mCACtB,IACI,MAAMC,EAAuB,IAAIF,SAASnd,EAASod,KAAKE,YAAY,IAAIC,oBAAoBpU,GAAS,CAAE+T,YAEvG,aADqBG,EAAqBld,aAE9C,CACA,MAEI,MADA+c,GAAQM,iBACF,IAAIpd,MAAM,oBAAoB+I,IACxC,CACJ,C","sources":["webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/Histogram.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/VolumeDims.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/ImageInfo.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/ChunkPrefetchIterator.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/utils.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/validation.js","webpack://@aics/vole-app/./node_modules/@zarrita/storage/dist/src/util.js","webpack://@aics/vole-app/./node_modules/@zarrita/storage/dist/src/fetch.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/wrappers.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/RequestQueue.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/SubscribableRequestQueue.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/workers/types.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/workers/util.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/bitround.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/bytes.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/crc32c.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/gzip.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/json2.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/transpose.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/vlen-utf8.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/zlib.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/sharding.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/hierarchy.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/indexer.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/ops.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/get.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/util.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/open.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/typedarray.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/util.js"],"sourcesContent":["const NBINS = 256;\n/**\n * Builds a histogram with 256 bins from a data array. Assume data is 8 bit single channel grayscale.\n * @class\n * @param {Array.<number>} data\n */\nexport default class Histogram {\n  // no more than 2^32 pixels of any one intensity in the data!?!?!\n\n  /** Min value in the original raw data. */\n\n  /** Max value in the original raw data. */\n\n  /** Size of each histogram bin in the scale of the original data. */\n\n  /** Index of the first bin (other than 0) with at least 1 value. */\n\n  /** Index of the last bin (other than 0) with at least 1 value. */\n\n  constructor(data) {\n    this.dataMinBin = 0;\n    this.dataMaxBin = 0;\n    this.maxBin = 0;\n    this.bins = new Uint32Array();\n    this.min = 0;\n    this.max = 0;\n    this.binSize = 0;\n\n    // build up the histogram\n    const hinfo = Histogram.calculateHistogram(data, NBINS);\n    this.bins = hinfo.bins;\n    this.min = hinfo.min;\n    this.max = hinfo.max;\n    this.binSize = hinfo.binSize;\n\n    // TODO: These should always return 0 and NBINS - 1, respectively. Test if these\n    // can be removed.\n    for (let i = 0; i < this.bins.length; i++) {\n      if (this.bins[i] > 0) {\n        this.dataMinBin = i;\n        break;\n      }\n    }\n    for (let i = this.bins.length - 1; i >= 0; i--) {\n      if (this.bins[i] > 0) {\n        this.dataMaxBin = i;\n        break;\n      }\n    }\n    this.pixelCount = data.length;\n\n    // get the bin with the most frequently occurring NONZERO value\n    this.maxBin = 1;\n    let max = this.bins[1];\n    for (let i = 1; i < this.bins.length; i++) {\n      if (this.bins[i] > max) {\n        this.maxBin = i;\n        max = this.bins[i];\n      }\n    }\n  }\n\n  // return the bin index of the given data value\n  static findBin(dataValue, dataMin, binSize, numBins) {\n    let binIndex = Math.floor((dataValue - dataMin) / binSize);\n    // for values that lie exactly on last bin we need to subtract one\n    if (binIndex === numBins) {\n      binIndex--;\n    }\n    return binIndex;\n  }\n\n  // return the bin index of the given data value\n  findBinOfValue(value) {\n    return Histogram.findBin(value, this.min, this.binSize, NBINS);\n  }\n\n  /**\n   * Return the min data value\n   * @return {number}\n   */\n  getDataMin() {\n    return this.min;\n  }\n\n  /**\n   * Return the max data value\n   * @return {number}\n   */\n  getDataMax() {\n    return this.max;\n  }\n\n  /**\n   * Returns the first bin index with at least 1 value, other than the 0th bin.\n   * @return {number}\n   */\n  getMin() {\n    return this.dataMinBin;\n  }\n\n  /**\n   * Returns the last bin index with at least 1 value, other than the 0th bin.\n   * @return {number}\n   */\n  getMax() {\n    // Note that this will always return `NBINS - 1`.\n    return this.dataMaxBin;\n  }\n  getNumBins() {\n    return this.bins.length;\n  }\n  getBin(i) {\n    return this.bins[i];\n  }\n  getBinRange(i) {\n    return [this.min + i * this.binSize, this.min + (i + 1) * this.binSize];\n  }\n\n  /**\n   * Find the bin that contains the percentage of pixels below it\n   * @return {number}\n   * @param {number} pct\n   */\n  findBinOfPercentile(pct) {\n    const limit = this.pixelCount * pct;\n    let i = 0;\n    let count = 0;\n    for (i = 0; i < this.bins.length; ++i) {\n      count += this.bins[i];\n      if (count > limit) {\n        break;\n      }\n    }\n    return i;\n  }\n\n  // Find bins at 10th / 90th percentile\n  findBestFitBins() {\n    const pixcount = this.pixelCount;\n    //const pixcount = this.imgData.data.length;\n    const limit = pixcount / 10;\n    let i = 0;\n    let count = 0;\n    for (i = 1; i < this.bins.length; ++i) {\n      count += this.bins[i];\n      if (count > limit) {\n        break;\n      }\n    }\n    const hmin = i;\n    count = 0;\n    for (i = this.bins.length - 1; i >= 1; --i) {\n      count += this.bins[i];\n      if (count > limit) {\n        break;\n      }\n    }\n    const hmax = i;\n    return [hmin, hmax];\n  }\n\n  // Find min and max bins attempting to replicate ImageJ's \"Auto\" button\n  findAutoIJBins() {\n    // note that consecutive applications of this should modify the auto threshold. see:\n    // https://github.com/imagej/ImageJ/blob/7746fcb0f5744a7a7758244c5dcd2193459e6e0e/ij/plugin/frame/ContrastAdjuster.java#L816\n    const AUTO_THRESHOLD = 5000;\n    const pixcount = this.pixelCount;\n    //  const pixcount = this.imgData.data.length;\n    const limit = pixcount / 10;\n    const threshold = pixcount / AUTO_THRESHOLD;\n\n    // this will skip the \"zero\" bin which contains pixels of zero intensity.\n    let hmin = this.bins.length - 1;\n    let hmax = 1;\n    for (let i = 1; i < this.bins.length; ++i) {\n      if (this.bins[i] > threshold && this.bins[i] <= limit) {\n        hmin = i;\n        break;\n      }\n    }\n    for (let i = this.bins.length - 1; i >= 1; --i) {\n      if (this.bins[i] > threshold && this.bins[i] <= limit) {\n        hmax = i;\n        break;\n      }\n    }\n    if (hmax < hmin) {\n      hmin = 0;\n      hmax = 255;\n    }\n    return [hmin, hmax];\n  }\n\n  // Find min and max bins using a percentile of the most commonly occurring value\n  findAutoMinMax() {\n    // simple linear mapping cutting elements with small appearence\n    // get 10% threshold\n    const PERCENTAGE = 0.1;\n    const th = Math.floor(this.bins[this.maxBin] * PERCENTAGE);\n    let b = 0;\n    let e = this.bins.length - 1;\n    for (let x = 1; x < this.bins.length; ++x) {\n      if (this.bins[x] > th) {\n        b = x;\n        break;\n      }\n    }\n    for (let x = this.bins.length - 1; x >= 1; --x) {\n      if (this.bins[x] > th) {\n        e = x;\n        break;\n      }\n    }\n    return [b, e];\n  }\n  static calculateHistogram(arr, numBins = 1) {\n    if (numBins < 1) {\n      numBins = 1;\n    }\n\n    // calculate min and max of arr\n    // TODO See convertChannel, which will also compute min and max!\n    // We could save a whole extra loop over the data, or have convertChannel compute the whole histogram.\n    // need to be careful about computing over chunks or whole ready-to-display volume\n\n    let min = arr[0];\n    let max = arr[0];\n    for (let i = 1; i < arr.length; i++) {\n      if (arr[i] < min) {\n        min = arr[i];\n      } else if (arr[i] > max) {\n        max = arr[i];\n      }\n    }\n    const bins = new Uint32Array(numBins).fill(0);\n    const binSize = (max - min) / numBins === 0 ? 1 : (max - min) / numBins;\n    for (let i = 0; i < arr.length; i++) {\n      const item = arr[i];\n      const binIndex = Histogram.findBin(item, min, binSize, numBins);\n      bins[binIndex]++;\n    }\n    return {\n      bins,\n      min,\n      max,\n      binSize\n    };\n  }\n}","import { Vector3 } from \"three\";\nexport function defaultVolumeDims() {\n  return {\n    shape: [0, 0, 0, 0, 0],\n    spacing: [1, 1, 1, 1, 1],\n    spaceUnit: \"μm\",\n    timeUnit: \"s\",\n    dataType: \"uint8\"\n  };\n}\nexport function volumeSize(volumeDims) {\n  return new Vector3(volumeDims.shape[4], volumeDims.shape[3], volumeDims.shape[2]);\n}\nexport function physicalPixelSize(volumeDims) {\n  return new Vector3(volumeDims.spacing[4], volumeDims.spacing[3], volumeDims.spacing[2]);\n}","import { volumeSize, physicalPixelSize } from \"./VolumeDims.js\";\nimport { Vector3, Vector2 } from \"three\";\nexport function defaultImageInfo() {\n  return {\n    name: \"\",\n    atlasTileDims: [1, 1],\n    subregionSize: [1, 1, 1],\n    subregionOffset: [0, 0, 0],\n    combinedNumChannels: 1,\n    channelNames: [\"0\"],\n    channelColors: [[255, 255, 255]],\n    multiscaleLevel: 0,\n    multiscaleLevelDims: [{\n      shape: [1, 1, 1, 1, 1],\n      spacing: [1, 1, 1, 1, 1],\n      spaceUnit: \"\",\n      timeUnit: \"\",\n      dataType: \"uint8\"\n    }],\n    transform: {\n      translation: [0, 0, 0],\n      rotation: [0, 0, 0],\n      scale: [1, 1, 1]\n    }\n  };\n}\nexport class CImageInfo {\n  constructor(imageInfo) {\n    this.imageInfo = imageInfo || defaultImageInfo();\n  }\n  get currentLevelDims() {\n    return this.imageInfo.multiscaleLevelDims[this.imageInfo.multiscaleLevel];\n  }\n\n  /** Number of channels in the image */\n  get numChannels() {\n    return this.imageInfo.combinedNumChannels;\n  }\n\n  /** XYZ size of the *original* (not downsampled) volume, in pixels */\n  get originalSize() {\n    return volumeSize(this.imageInfo.multiscaleLevelDims[0]);\n  }\n\n  /** Size of the volume, in pixels */\n  get volumeSize() {\n    return volumeSize(this.currentLevelDims);\n  }\n\n  /** Size of a single *original* (not downsampled) pixel, in spatial units */\n  get physicalPixelSize() {\n    return physicalPixelSize(this.imageInfo.multiscaleLevelDims[0]);\n  }\n\n  /** Symbol of physical spatial unit used by `physicalPixelSize` */\n  get spatialUnit() {\n    return this.imageInfo.multiscaleLevelDims[0].spaceUnit;\n  }\n\n  /** Number of timesteps in the time series, or 1 if the image is not a time series */\n  get times() {\n    // 0 is T\n    return this.currentLevelDims.shape[0];\n  }\n\n  /** Size of each timestep in temporal units */\n  get timeScale() {\n    // 0 is T\n    return this.currentLevelDims.spacing[0];\n  }\n\n  /** Symbol of physical time unit used by `timeScale` */\n  get timeUnit() {\n    return this.currentLevelDims.timeUnit;\n  }\n\n  /** Number of scale levels available for this volume */\n  get numMultiscaleLevels() {\n    return this.imageInfo.multiscaleLevelDims.length;\n  }\n\n  /** The names of each channel */\n  get channelNames() {\n    return this.imageInfo.channelNames;\n  }\n\n  /** Optional overrides to default channel colors, in 0-255 range */\n  get channelColors() {\n    return this.imageInfo.channelColors;\n  }\n\n  /** Size of the currently loaded subregion, in pixels */\n  get subregionSize() {\n    return new Vector3(...this.imageInfo.subregionSize);\n  }\n\n  /** Offset of the loaded subregion into the total volume, in pixels */\n  get subregionOffset() {\n    return new Vector3(...this.imageInfo.subregionOffset);\n  }\n  get multiscaleLevel() {\n    return this.imageInfo.multiscaleLevel;\n  }\n\n  /**\n   * XY dimensions of the texture atlas used by `RayMarchedAtlasVolume` and `Atlas2DSlice`, in number of z-slice\n   * tiles (not pixels). Chosen by the loader to lay out the 3D volume in the squarest possible 2D texture atlas.\n   */\n  get atlasTileDims() {\n    return new Vector2(...this.imageInfo.atlasTileDims);\n  }\n  get transform() {\n    return {\n      translation: new Vector3(...this.imageInfo.transform.translation),\n      rotation: new Vector3(...this.imageInfo.transform.rotation),\n      scale: new Vector3(...this.imageInfo.transform.scale)\n    };\n  }\n}\nexport function computeAtlasSize(imageInfo) {\n  const {\n    atlasTileDims\n  } = imageInfo;\n  const volDims = imageInfo.multiscaleLevelDims[imageInfo.multiscaleLevel];\n  // TCZYX: 4 = x, 3 = y\n  return [atlasTileDims[0] * volDims.shape[4], atlasTileDims[1] * volDims.shape[3]];\n}","const allEqual = arr => arr.every(v => v === arr[0]);\nconst pushN = (arr, val, n) => {\n  for (let i = 0; i < n; i++) {\n    arr.push(val);\n  }\n};\nconst directionToIndex = dir => {\n  const absDir = dir >> 1; // shave off sign bit to get index in TZYX\n  return absDir + Number(absDir !== 0); // convert TZYX -> TCZYX by skipping c (index 1)\n};\nfunction updateMinMax(val, minmax) {\n  if (val < minmax[0]) {\n    minmax[0] = val;\n  }\n  if (val > minmax[1]) {\n    minmax[1] = val;\n  }\n}\n\n/**\n * Since the user is most likely to want nearby data (in space or time) first, we should prefetch those chunks first.\n *\n * Given a list of just-loaded chunks and some bounds, `ChunkPrefetchIterator` iterates evenly outwards in T/Z/Y/X.\n */\n// NOTE: Assumes `chunks` form a rectangular prism! Will create gaps otherwise! (in practice they always should)\nexport default class ChunkPrefetchIterator {\n  constructor(chunks, tzyxMaxPrefetchOffset, tczyxChunksPerSource, priorityDirections, onlyPriorityDirections = false) {\n    // Get min and max chunk coordinates for T/Z/Y/X\n    const extrema = [[Infinity, -Infinity], [Infinity, -Infinity], [Infinity, -Infinity], [Infinity, -Infinity]];\n    for (const chunk of chunks) {\n      updateMinMax(chunk[0], extrema[0]);\n      updateMinMax(chunk[2], extrema[1]);\n      updateMinMax(chunk[3], extrema[2]);\n      updateMinMax(chunk[4], extrema[3]);\n    }\n\n    // Bail out if we have any non-finite values in the extrema (the iterator will be empty)\n    if (extrema.flat().some(val => !Number.isFinite(val))) {\n      this.directionStates = [];\n      this.priorityDirectionStates = [];\n      return;\n    }\n\n    // Create `PrefetchDirectionState`s for each direction\n    this.directionStates = [];\n    this.priorityDirectionStates = [];\n\n    // iterating like this: direction is the index in the flattened entries\n    // and corresponds to our +T, -T, +Z, -Z, +Y, -Y, +X, -X directions in order\n    // because extrema is in TZYX order.\n    for (const [direction, start] of extrema.flat().entries()) {\n      const dimension = direction >> 1; // shave off sign bit to get index in TZYX\n      const tczyxIndex = dimension + Number(dimension !== 0); // convert TZYX -> TCZYX by skipping c (index 1)\n      let end;\n      if (direction & 1) {\n        // Positive direction - end is either the max coordinate in the fetched set plus the max offset in this\n        // dimension, or the max chunk coordinate in this dimension, whichever comes first\n        const endsPerSource = tczyxChunksPerSource.map(chunkDims => {\n          return Math.min(start + tzyxMaxPrefetchOffset[dimension], chunkDims[tczyxIndex] - 1);\n        });\n\n        // Save some time: if all sources have the same end, we can just store that\n        if (allEqual(endsPerSource)) {\n          end = endsPerSource[0];\n        } else {\n          // Otherwise, expand our ends per source array to ends per channel\n          end = [];\n          for (const [i, sourceEnd] of endsPerSource.entries()) {\n            pushN(end, sourceEnd, tczyxChunksPerSource[i][1]);\n          }\n        }\n        // end = Math.min(start + tzyxMaxPrefetchOffset[dimension], tczyxChunksPerDimension[dimension] - 1);\n      } else {\n        // Negative direction - end is either the min coordinate in the fetched set minus the max offset in this\n        // dimension, or 0, whichever comes first\n        end = Math.max(start - tzyxMaxPrefetchOffset[dimension], 0);\n      }\n      const directionState = {\n        direction,\n        start,\n        end,\n        chunks: []\n      };\n      if (priorityDirections && priorityDirections.includes(direction)) {\n        this.priorityDirectionStates.push(directionState);\n      } else {\n        // we have an option setting that can let us ignore non-priority directions\n        if (!onlyPriorityDirections) {\n          this.directionStates.push(directionState);\n        }\n      }\n    }\n\n    // Fill each `PrefetchDirectionState` with chunks at the border of the fetched set\n    for (const chunk of chunks) {\n      for (const dir of this.directionStates) {\n        if (chunk[directionToIndex(dir.direction)] === dir.start) {\n          dir.chunks.push(chunk);\n        }\n      }\n      for (const dir of this.priorityDirectionStates) {\n        if (chunk[directionToIndex(dir.direction)] === dir.start) {\n          dir.chunks.push(chunk);\n        }\n      }\n    }\n  }\n  static *iterateDirections(directions) {\n    let offset = 1;\n    while (directions.length > 0) {\n      // Remove directions in which we have reached the end (or, if per-channel ends, the end for all channels)\n      directions = directions.filter(dir => {\n        const end = Array.isArray(dir.end) ? Math.max(...dir.end) : dir.end;\n        if (dir.direction & 1) {\n          return dir.start + offset <= end;\n        } else {\n          return dir.start - offset >= end;\n        }\n      });\n\n      // Yield chunks one chunk farther out in every remaining direction\n      for (const dir of directions) {\n        const offsetDir = offset * (dir.direction & 1 ? 1 : -1);\n        for (const chunk of dir.chunks) {\n          // Skip this chunk if this channel has a specific per-channel end and we've reached it\n          if (Array.isArray(dir.end) && chunk[directionToIndex(dir.direction)] + offsetDir > dir.end[chunk[1]]) {\n            continue;\n          }\n          const newChunk = chunk.slice();\n          newChunk[directionToIndex(dir.direction)] += offsetDir;\n          yield newChunk;\n        }\n      }\n      offset += 1;\n    }\n  }\n  *[Symbol.iterator]() {\n    // Yield all chunks in priority direction(s) first, if any\n    if (this.priorityDirectionStates.length > 0) {\n      for (const chunk of ChunkPrefetchIterator.iterateDirections(this.priorityDirectionStates)) {\n        yield chunk;\n      }\n    }\n\n    // Then yield all chunks in other directions\n    for (const chunk of ChunkPrefetchIterator.iterateDirections(this.directionStates)) {\n      yield chunk;\n    }\n  }\n}","import { VolumeLoadErrorType, VolumeLoadError } from \"../VolumeLoadError.js\";\n/** Extracts channel names from a `ZarrSource`. Handles missing `omeroMetadata`. Does *not* resolve name collisions. */\nexport function getSourceChannelNames(src) {\n  if (src.omeroMetadata?.channels) {\n    return src.omeroMetadata.channels.map(({\n      label\n    }, idx) => label ?? `Channel ${idx + src.channelOffset}`);\n  }\n  const cIdx = src.axesTCZYX[1];\n  const length = cIdx < 0 ? 1 : src.scaleLevels[0].shape[cIdx];\n  return Array.from({\n    length\n  }, (_, idx) => `Channel ${idx + src.channelOffset}`);\n}\n\n/** Turns `axesTCZYX` into the number of dimensions in the array */\nexport const getDimensionCount = ([t, c, z]) => 2 + Number(t > -1) + Number(c > -1) + Number(z > -1);\nexport function remapAxesToTCZYX(axes) {\n  const axesTCZYX = [-1, -1, -1, -1, -1];\n  const axisNames = [\"t\", \"c\", \"z\", \"y\", \"x\"];\n  axes.forEach((axis, idx) => {\n    const axisIdx = axisNames.indexOf(axis.name);\n    if (axisIdx > -1) {\n      axesTCZYX[axisIdx] = idx;\n    } else {\n      throw new VolumeLoadError(`Unrecognized axis in zarr: ${axis.name}`, {\n        type: VolumeLoadErrorType.INVALID_METADATA\n      });\n    }\n  });\n\n  // it is possible that Z might not exist but we require X and Y at least.\n  const noXAxis = axesTCZYX[4] === -1;\n  if (noXAxis || axesTCZYX[3] === -1) {\n    throw new VolumeLoadError(`Did not find ${noXAxis ? \"an X\" : \"a Y\"} axis in zarr`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n  return axesTCZYX;\n}\n\n/** Reorder an array of values [T, C, Z, Y, X] to the given dimension order */\nexport function orderByDimension(valsTCZYX, orderTCZYX) {\n  const specLen = getDimensionCount(orderTCZYX);\n  const result = Array(specLen);\n  orderTCZYX.forEach((val, idx) => {\n    if (val >= 0) {\n      if (val >= specLen) {\n        throw new VolumeLoadError(`Unexpected axis index in zarr: ${val}`, {\n          type: VolumeLoadErrorType.INVALID_METADATA\n        });\n      }\n      result[val] = valsTCZYX[idx];\n    }\n  });\n  return result;\n}\n\n/** Reorder an array of values in the given dimension order to [T, C, Z, Y, X] */\nexport function orderByTCZYX(valsDimension, orderTCZYX, defaultValue) {\n  const result = [defaultValue, defaultValue, defaultValue, defaultValue, defaultValue];\n  orderTCZYX.forEach((val, idx) => {\n    if (val >= 0) {\n      if (val >= valsDimension.length) {\n        throw new VolumeLoadError(`Unexpected axis index in zarr: ${val}`, {\n          type: VolumeLoadErrorType.INVALID_METADATA\n        });\n      }\n      result[idx] = valsDimension[val];\n    }\n  });\n  return result;\n}\n\n/** Select the scale transform from an OME metadata object with coordinate transforms, and return it in TCZYX order */\nexport function getScale(dataset, orderTCZYX) {\n  const transforms = dataset.coordinateTransformations;\n  if (transforms === undefined) {\n    console.warn(\"WARNING: OMEZarrLoader: no coordinate transformations for scale level.\");\n    return [1, 1, 1, 1, 1];\n  }\n\n  // this assumes we'll never encounter the \"path\" variant\n  const isScaleTransform = t => t.type === \"scale\";\n\n  // there can be any number of coordinateTransformations\n  // but there must be only one of type \"scale\".\n  const scaleTransform = transforms.find(isScaleTransform);\n  if (!scaleTransform) {\n    console.warn(`WARNING: OMEZarrLoader: no coordinate transformation of type \"scale\" for scale level.`);\n    return [1, 1, 1, 1, 1];\n  }\n  const scale = scaleTransform.scale.slice();\n  return orderByTCZYX(scale, orderTCZYX, 1);\n}\n\n/**\n * Defines a partial order of zarr arrays based on their size. Specifically:\n * - If array size x, y, z are all equal, the arrays are equal\n * - otherwise, if all xyz of `a` are less than or equal to those of `b`, `a` is less than `b` (and vice versa)\n * - if some xyz is less and some is greater, the arrays are uncomparable\n */\nfunction compareZarrArraySize(aArr, aTCZYX, bArr, bTCZYX) {\n  const aZ = aTCZYX[2] > -1 ? aArr.shape[aTCZYX[2]] : 1;\n  const bZ = bTCZYX[2] > -1 ? bArr.shape[bTCZYX[2]] : 1;\n  const diffZ = aZ - bZ;\n  const diffY = aArr.shape[aTCZYX[3]] - bArr.shape[bTCZYX[3]];\n  const diffX = aArr.shape[aTCZYX[4]] - bArr.shape[bTCZYX[4]];\n  if (diffZ === 0 && diffY === 0 && diffX === 0) {\n    return 0;\n  } else if (diffZ <= 0 && diffY <= 0 && diffX <= 0) {\n    return -1;\n  } else if (diffZ >= 0 && diffY >= 0 && diffX >= 0) {\n    return 1;\n  } else {\n    return undefined;\n  }\n}\nconst EPSILON = 0.00001;\nconst aboutEquals = (a, b) => Math.abs(a - b) < EPSILON;\nfunction scaleTransformsAreEqual(aSrc, aLevel, bSrc, bLevel) {\n  const aScale = getScale(aSrc.multiscaleMetadata.datasets[aLevel], aSrc.axesTCZYX);\n  const bScale = getScale(bSrc.multiscaleMetadata.datasets[bLevel], bSrc.axesTCZYX);\n  return aboutEquals(aScale[2], bScale[2]) && aboutEquals(aScale[3], bScale[3]) && aboutEquals(aScale[4], bScale[4]);\n}\n\n/**\n * Ensures that all scale levels in `sources` are matched up by size. More precisely: enforces that, for any scale\n * level `i`, the size of zarr array `s[i]` is equal for every source `s`. We accomplish this by removing any arrays\n * (and their associated OME dataset metadata) which don't match up in all sources.\n *\n * Note that this function modifies the input `sources` array rather than returning a new value.\n *\n * Assumes all sources have scale levels ordered by size from largest to smallest. (This should always be true for\n * compliant OME-Zarr data.)\n */\nexport function matchSourceScaleLevels(sources) {\n  if (sources.length < 2) {\n    return;\n  }\n\n  // Save matching scale levels and metadata here\n  const matchedLevels = Array.from({\n    length: sources.length\n  }, () => []);\n  const matchedMetas = Array.from({\n    length: sources.length\n  }, () => []);\n\n  // Start as many index counters as we have sources\n  const scaleIndexes = new Array(sources.length).fill(0);\n  while (scaleIndexes.every((val, idx) => val < sources[idx].scaleLevels.length)) {\n    // First pass: find the smallest source / determine if all sources are equal\n    let allEqual = true;\n    let smallestIdx = 0;\n    let smallestSrc = sources[0];\n    let smallestArr = smallestSrc.scaleLevels[scaleIndexes[0]];\n    for (let currentIdx = 1; currentIdx < sources.length; currentIdx++) {\n      const currentSrc = sources[currentIdx];\n      const currentArr = currentSrc.scaleLevels[scaleIndexes[currentIdx]];\n      const ordering = compareZarrArraySize(smallestArr, smallestSrc.axesTCZYX, currentArr, currentSrc.axesTCZYX);\n      if (!ordering) {\n        // Arrays are equal, or they are uncomparable\n        if (ordering === undefined) {\n          throw new VolumeLoadError(\"Incompatible zarr arrays: pixel dimensions are mismatched\", {\n            type: VolumeLoadErrorType.INVALID_MULTI_SOURCE_ZARR\n          });\n        }\n\n        // Now we know the arrays are equal, but they may still be invalid to match up because...\n        // ...they have different scale transformations\n        if (!scaleTransformsAreEqual(smallestSrc, scaleIndexes[smallestIdx], currentSrc, scaleIndexes[currentIdx])) {\n          // today we are going to treat this as a warning.\n          // For our implementation it is enough that the xyz pixel ranges are the same.\n          // Ideally scale*arraysize=physical size is really the quantity that should be equal, for combining two volume data sets as channels.\n          console.warn(\"Incompatible zarr arrays: scale levels of equal size have different scale transformations\");\n        }\n\n        // ...they have different numbers of timesteps\n        const largestT = smallestSrc.axesTCZYX[0] > -1 ? smallestArr.shape[smallestSrc.axesTCZYX[0]] : 1;\n        const currentT = currentSrc.axesTCZYX[0] > -1 ? currentArr.shape[currentSrc.axesTCZYX[0]] : 1;\n        if (largestT !== currentT) {\n          // we also treat this as a warning.\n          // In OmeZarrLoader we will take the minimum T size of all sources\n          console.warn(`Incompatible zarr arrays: different numbers of timesteps: ${largestT} vs ${currentT}`);\n        }\n      } else {\n        allEqual = false;\n        if (ordering > 0) {\n          smallestIdx = currentIdx;\n          smallestSrc = currentSrc;\n          smallestArr = currentArr;\n        }\n      }\n    }\n    if (allEqual) {\n      // We've found a matching set of scale levels! Save it and increment all indexes\n      for (let i = 0; i < scaleIndexes.length; i++) {\n        const currentSrc = sources[i];\n        const matchedScaleLevel = scaleIndexes[i];\n        matchedLevels[i].push(currentSrc.scaleLevels[matchedScaleLevel]);\n        matchedMetas[i].push(currentSrc.multiscaleMetadata.datasets[matchedScaleLevel]);\n        scaleIndexes[i] += 1;\n      }\n    } else {\n      // Increment the indexes of the sources which are larger than the smallest\n      for (const [idx, srcIdx] of scaleIndexes.entries()) {\n        const currentSrc = sources[idx];\n        const currentArr = currentSrc.scaleLevels[srcIdx];\n        const ordering = compareZarrArraySize(smallestArr, smallestSrc.axesTCZYX, currentArr, currentSrc.axesTCZYX);\n        if (ordering !== 0) {\n          scaleIndexes[idx] += 1;\n        }\n      }\n    }\n  }\n  if (sources[0].scaleLevels.length === 0) {\n    throw new VolumeLoadError(\"Incompatible zarr arrays: no sets of scale levels found that matched in all sources\", {\n      type: VolumeLoadErrorType.INVALID_MULTI_SOURCE_ZARR\n    });\n  }\n  for (let i = 0; i < sources.length; i++) {\n    sources[i].scaleLevels = matchedLevels[i];\n    sources[i].multiscaleMetadata.datasets = matchedMetas[i];\n  }\n}","import { VolumeLoadError, VolumeLoadErrorType } from \"../VolumeLoadError.js\";\n/**\n * If `meta` is the top-level metadata of a zarr node formatted according to the OME-Zarr spec version 0.5, returns\n * the object formatted according to v0.4 of the spec. For our purposes this just means flattening out the `ome` key.\n *\n * Return type is `unknown` because this does no actual validation; use `validateOMEZarrMetadata` for that.\n */\nexport const toOMEZarrMetaV4 = meta => meta.ome ?? meta;\nfunction isObjectWithProp(obj, prop) {\n  return typeof obj === \"object\" && obj !== null && prop in obj;\n}\nfunction assertMetadataHasProp(obj, prop, name = \"zarr\") {\n  if (!isObjectWithProp(obj, prop)) {\n    throw new VolumeLoadError(`${name} metadata is missing required entry \"${prop}\"`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n}\nfunction assertPropIsArray(obj, prop, name = \"zarr\") {\n  if (!Array.isArray(obj[prop])) {\n    throw new VolumeLoadError(`${name} metadata entry \"${prop}\" is not an array`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n}\n\n/** Intermediate stage of validation, before we've picked a single multiscale to validate */\n\nexport function assertMetadataHasMultiscales(meta, name = \"zarr\") {\n  // data is an object with a key \"multiscales\", which is a non-empty array\n  assertMetadataHasProp(meta, \"multiscales\", name);\n  assertPropIsArray(meta, \"multiscales\", name);\n}\n\n/**\n * Validates that the `OMEZarrMetadata` record `meta` has the minimal amount of data required to open a volume. Since\n * we only ever open one multiscale, we only validate the multiscale metadata record at index `multiscaleIdx` here.\n * `name` is used in error messages to identify the source of the metadata.\n */\nexport function validateOMEZarrMetadata(meta, multiscaleIdx = 0, name = \"zarr\") {\n  // check that a multiscale metadata entry exists at `multiscaleIdx`\n  const multiscaleMeta = meta.multiscales[multiscaleIdx];\n  if (!multiscaleMeta) {\n    throw new VolumeLoadError(`${name} metadata does not have requested multiscale level ${multiscaleIdx}`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n  const multiscaleMetaName = isObjectWithProp(multiscaleMeta, \"name\") ? ` (\"${multiscaleMeta.name})` : \"\";\n  const multiscaleName = `${name} multiscale ${multiscaleIdx}${multiscaleMetaName}`;\n\n  // multiscale has a key \"axes\", which is an array. Each axis has a \"name\".\n  assertMetadataHasProp(multiscaleMeta, \"axes\", multiscaleName);\n  assertPropIsArray(multiscaleMeta, \"axes\", multiscaleName);\n  multiscaleMeta.axes.forEach((axis, i) => assertMetadataHasProp(axis, \"name\", `${multiscaleName} axis ${i}`));\n\n  // multiscale has a key \"datasets\", which is an array. Each dataset has a \"path\".\n  assertMetadataHasProp(multiscaleMeta, \"datasets\", name);\n  assertPropIsArray(multiscaleMeta, \"datasets\", name);\n  multiscaleMeta.datasets.forEach((data, i) => assertMetadataHasProp(data, \"path\", `${multiscaleName} dataset ${i}`));\n}","export function strip_prefix(path) {\n    // @ts-expect-error - TS can't infer this type correctly\n    return path.slice(1);\n}\nexport function uri2href(url) {\n    let [protocol, rest] = (typeof url === \"string\" ? url : url.href).split(\"://\");\n    if (protocol === \"https\" || protocol === \"http\") {\n        return url;\n    }\n    if (protocol === \"gc\") {\n        return `https://storage.googleapis.com/${rest}`;\n    }\n    if (protocol === \"s3\") {\n        return `https://s3.amazonaws.com/${rest}`;\n    }\n    throw Error(`Protocol not supported, got: ${JSON.stringify(protocol)}`);\n}\nexport function fetch_range(url, offset, length, opts = {}) {\n    if (offset !== undefined && length !== undefined) {\n        // merge request opts\n        opts = {\n            ...opts,\n            headers: {\n                ...opts.headers,\n                Range: `bytes=${offset}-${offset + length - 1}`,\n            },\n        };\n    }\n    return fetch(url, opts);\n}\nexport function merge_init(storeOverrides, requestOverrides) {\n    // Request overrides take precedence over storeOverrides.\n    return {\n        ...storeOverrides,\n        ...requestOverrides,\n        headers: {\n            ...storeOverrides.headers,\n            ...requestOverrides.headers,\n        },\n    };\n}\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(expression, msg = \"\") {\n    if (!expression)\n        throw new Error(msg);\n}\n//# sourceMappingURL=util.js.map","import { fetch_range, merge_init } from \"./util.js\";\nfunction resolve(root, path) {\n    const base = typeof root === \"string\" ? new URL(root) : root;\n    if (!base.pathname.endsWith(\"/\")) {\n        // ensure trailing slash so that base is resolved as _directory_\n        base.pathname += \"/\";\n    }\n    const resolved = new URL(path.slice(1), base);\n    // copy search params to new URL\n    resolved.search = base.search;\n    return resolved;\n}\nasync function handle_response(response) {\n    if (response.status === 404) {\n        return undefined;\n    }\n    if (response.status === 200 || response.status === 206) {\n        return new Uint8Array(await response.arrayBuffer());\n    }\n    throw new Error(`Unexpected response status ${response.status} ${response.statusText}`);\n}\nasync function fetch_suffix(url, suffix_length, init, use_suffix_request) {\n    if (use_suffix_request) {\n        return fetch(url, {\n            ...init,\n            headers: { ...init.headers, Range: `bytes=-${suffix_length}` },\n        });\n    }\n    let response = await fetch(url, { ...init, method: \"HEAD\" });\n    if (!response.ok) {\n        // will be picked up by handle_response\n        return response;\n    }\n    let content_length = response.headers.get(\"Content-Length\");\n    let length = Number(content_length);\n    return fetch_range(url, length - suffix_length, length, init);\n}\n/**\n * Readonly store based in the [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n * Must polyfill `fetch` for use in Node.js.\n *\n * ```typescript\n * import * as zarr from \"zarrita\";\n * const store = new FetchStore(\"http://localhost:8080/data.zarr\");\n * const arr = await zarr.get(store, { kind: \"array\" });\n * ```\n */\nclass FetchStore {\n    url;\n    #overrides;\n    #use_suffix_request;\n    constructor(url, options = {}) {\n        this.url = url;\n        this.#overrides = options.overrides ?? {};\n        this.#use_suffix_request = options.useSuffixRequest ?? false;\n    }\n    #merge_init(overrides) {\n        return merge_init(this.#overrides, overrides);\n    }\n    async get(key, options = {}) {\n        let href = resolve(this.url, key).href;\n        let response = await fetch(href, this.#merge_init(options));\n        return handle_response(response);\n    }\n    async getRange(key, range, options = {}) {\n        let url = resolve(this.url, key);\n        let init = this.#merge_init(options);\n        let response;\n        if (\"suffixLength\" in range) {\n            response = await fetch_suffix(url, range.suffixLength, init, this.#use_suffix_request);\n        }\n        else {\n            response = await fetch_range(url, range.offset, range.length, init);\n        }\n        return handle_response(response);\n    }\n}\nexport default FetchStore;\n//# sourceMappingURL=fetch.js.map","import { FetchStore } from \"zarrita\";\nimport { isChunk } from \"../../VolumeCache.js\";\nexport default function wrapArray(array, basePath, cache, queue) {\n  const path = basePath.endsWith(\"/\") ? basePath.slice(0, -1) : basePath;\n  const keyBase = path + array.path + (array.path.endsWith(\"/\") ? \"\" : \"/\");\n  const getChunk = async (coords, opts) => {\n    if (opts?.subscriber && opts.reportChunk) {\n      opts.reportChunk(coords, opts.subscriber);\n    }\n    const fullKey = keyBase + coords.join(\",\");\n    const cacheResult = cache?.get(fullKey);\n    if (cacheResult && isChunk(cacheResult)) {\n      return cacheResult;\n    }\n    let result;\n    if (queue && opts?.subscriber) {\n      result = await queue.addRequest(fullKey, opts?.subscriber, () => array.getChunk(coords, opts), opts.isPrefetch);\n    } else {\n      result = await array.getChunk(coords, opts);\n    }\n    cache?.insert(fullKey, result);\n    return result;\n  };\n  return new Proxy(array, {\n    get: (target, prop) => {\n      if (prop === \"getChunk\") {\n        return getChunk;\n      }\n\n      // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy#no_private_property_forwarding\n      const value = target[prop];\n      if (value instanceof Function) {\n        return function (...args) {\n          return value.apply(target, args);\n        };\n      }\n      return value;\n    }\n  });\n}\nexport class RelaxedFetchStore extends FetchStore {\n  constructor(baseUrl, options) {\n    super(baseUrl, options);\n  }\n\n  // Solution for https://github.com/manzt/zarrita.js/pull/212\n  // taken from https://github.com/vitessce/vitessce/pull/2069\n  async get(key, options = {}) {\n    try {\n      return await super.get(key, options);\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    } catch (e) {\n      if (e?.message?.startsWith(\"Unexpected response status 403\")) {\n        return undefined;\n      }\n      throw e;\n    }\n  }\n}","/** Object format used when passing multiple requests to RequestQueue at once. */\n\nexport const DEFAULT_REQUEST_CANCEL_REASON = \"request cancelled\";\n\n/**\n * Internal object interface used by RequestQueue to store request metadata and callbacks.\n */\n\n/**\n * Manages a queue of asynchronous requests with unique string keys, which can be added to or cancelled.\n * If redundant requests with the same key are issued, the request action will only be run once per key\n * while the original request is still in the queue.\n */\nexport default class RequestQueue {\n  /**\n   * The maximum number of requests that can be handled concurrently.\n   * Once reached, additional requests will be queued up to run once a running request completes.\n   */\n\n  /**\n   * The maximum number of requests that can be handled concurrently if only low-priority requests are waiting. Set\n   * lower than `concurrencyLimit` to always leave space for high-priority requests. Cannot be set higher than\n   * `concurrencyLimit`.\n   */\n\n  /** A queue of requests that are ready to be executed, in order of request time. */\n\n  /** A queue of low-priority tasks that are ready to be executed. `queue` must be empty before any of these tasks run. */\n\n  /** Stores all requests, even those that are currently active. */\n\n  /** Stores requests whose actions are currently being run. */\n\n  /**\n   * Creates a new RequestQueue.\n   * @param maxActiveRequests The maximum number of requests that will be handled concurrently. This is 10 by default.\n   * @param maxLowPriorityRequests The maximum number of low-priority requests that will be handled concurrently. Equal\n   *    to `maxActiveRequests` by default, but may be set lower to always leave space for new high-priority requests.\n   */\n  constructor(maxActiveRequests = 10, maxLowPriorityRequests = 5) {\n    this.allRequests = new Map();\n    this.activeRequests = new Set();\n    this.queue = [];\n    this.queueLowPriority = [];\n    this.maxActiveRequests = maxActiveRequests;\n    this.maxLowPriorityRequests = Math.min(maxActiveRequests, maxLowPriorityRequests);\n  }\n\n  /**\n   * Stores request metadata to the internal map of all pending requests.\n   * @param key string identifier of the request.\n   * @param requestAction callable function action of the request.\n   * @returns a reference to the new, registered RequestItem.\n   */\n  registerRequest(key, requestAction) {\n    // Create a new promise and store the resolve and reject callbacks for later.\n    // This lets us perform the actual action at a later point, when the request is at the\n    // front of the processing queue.\n    let promiseResolve, promiseReject;\n    const promise = new Promise((resolve, reject) => {\n      promiseResolve = resolve;\n      promiseReject = reject;\n    });\n    // Store the request data.\n    const requestItem = {\n      key: key,\n      action: requestAction,\n      resolve: promiseResolve,\n      reject: promiseReject,\n      promise\n    };\n    this.allRequests.set(key, requestItem);\n    return requestItem;\n  }\n\n  /**\n   * Moves a registered request into the processing queue, clearing any timeouts on the request.\n   * @param key string identifier of the request.\n   * @param lowPriority Whether this request should be added with low priority. False by default.\n   */\n  addRequestToQueue(key, lowPriority) {\n    // Check that this request is not cancelled.\n    if (this.allRequests.has(key)) {\n      // Clear the request timeout, if it has one, since it is being added to the queue.\n      const requestItem = this.allRequests.get(key);\n      if (requestItem && requestItem.timeoutId) {\n        clearTimeout(requestItem.timeoutId);\n        requestItem.timeoutId = undefined;\n      }\n      if (!this.queue.includes(key) && !this.queueLowPriority.includes(key)) {\n        // Add to queue and check if the request can be processed right away.\n        if (lowPriority) {\n          this.queueLowPriority.push(key);\n        } else {\n          this.queue.push(key);\n        }\n        this.dequeue();\n      }\n    }\n  }\n\n  /**\n   * Adds a request with a unique key to the queue, if it doesn't already exist.\n   * @param key The key used to track the request.\n   * @param requestAction Function that will be called to complete the request. The function\n   *  will be run only once per unique key while the request exists, and may be deferred by the\n   *  queue at any time.\n   * @param lowPriority Whether this request should be added with low priority. False by default.\n   * @param delayMs Minimum delay, in milliseconds, before this request should be executed.\n   *\n   * NOTE: Cancelling a request while the action is running WILL NOT stop the action. If this behavior is desired,\n   * actions must be responsible for checking the RequestQueue, determining if the request is still valid (e.g.\n   * using `.hasRequest()`), and stopping or returning early.\n   *\n   * @returns A promise that will resolve on completion of the request, or reject if the request is cancelled.\n   *  If multiple requests are issued with the same key, a promise for the first request will be returned\n   *  until the request is resolved or cancelled.\n   *  Note that the return type of the promise will match that of the first request's instance.\n   */\n  addRequest(key, requestAction, lowPriority = false, delayMs = 0) {\n    if (!this.allRequests.has(key)) {\n      // New request!\n      const requestItem = this.registerRequest(key, requestAction);\n      // If a delay is set, wait to add this to the queue.\n      if (delayMs > 0) {\n        const timeoutId = setTimeout(() => this.addRequestToQueue(key, lowPriority), delayMs);\n        // Save timeout information to request metadata\n        requestItem.timeoutId = timeoutId;\n      } else {\n        // No delay, add immediately\n        this.addRequestToQueue(key, lowPriority);\n      }\n    } else {\n      const lowPriorityIndex = this.queueLowPriority.indexOf(key);\n      if (lowPriorityIndex > -1 && !lowPriority) {\n        // This request is registered and queued, but is now being requested with high priority.\n        // Promote it to high priority.\n        this.queueLowPriority.splice(lowPriorityIndex, 1);\n        this.addRequestToQueue(key);\n      } else if (delayMs <= 0) {\n        // This request is registered, but is now being requested without a delay.\n        // Move into queue immediately if it's not already added, and clear any timeouts it may have.\n        this.addRequestToQueue(key, lowPriority);\n      }\n    }\n    const promise = this.allRequests.get(key)?.promise;\n    if (!promise) {\n      throw new Error(\"Found no promise to return when getting stored request data.\");\n    }\n    return promise;\n  }\n\n  /**\n   * Adds multiple requests to the queue, with an optional delay between each.\n   * @param requests An array of RequestItems, which include a key and a request action.\n   * @param lowPriority Whether these requests should be added with low priority. False by default.\n   * @param delayMs An optional minimum delay in milliseconds to be added between each request.\n   *  For example, a delay of 10 ms will cause the second request to be added to the processing queue\n   *  after 10 ms, the third to added after 20 ms, and so on. Set to 10 ms by default.\n   * @returns An array of promises corresponding to the provided requests. (i.e., the `i`th value\n   * of the returned array will be a Promise for the resolution of `requests[i]`). If a request\n   *  with a matching key is already pending, returns the promise for the initial request.\n   */\n  addRequests(requests, lowPriority = false, delayMs = 10) {\n    const promises = [];\n    for (let i = 0; i < requests.length; i++) {\n      const item = requests[i];\n      const promise = this.addRequest(item.key, item.requestAction, lowPriority, delayMs * i);\n      promises.push(promise);\n    }\n    return promises;\n  }\n\n  /**\n   * Attempts to remove and run the next queued request item, if resources are available.\n   * @returns true if a request was started, or false if there are too many\n   * requests already active.\n   */\n  async dequeue() {\n    const numRequests = this.activeRequests.size;\n    if (numRequests >= this.maxActiveRequests || this.queue.length === 0 && (numRequests >= this.maxLowPriorityRequests || this.queueLowPriority.length === 0)) {\n      return;\n    }\n    const requestKey = this.queue.shift() ?? this.queueLowPriority.shift();\n    if (!requestKey) {\n      return;\n    }\n    if (this.activeRequests.has(requestKey)) {\n      // This request is already active, try the next one instead. (this shouldn't happen)\n      this.dequeue();\n      return;\n    }\n    const requestItem = this.allRequests.get(requestKey);\n    if (!requestItem) {\n      return;\n    }\n    const key = requestItem.key;\n    // Mark that this request is active\n    this.activeRequests.add(key);\n    await requestItem.action().then(requestItem.resolve, requestItem.reject);\n    this.activeRequests.delete(key);\n    this.allRequests.delete(key);\n    this.dequeue();\n  }\n\n  /**\n   * Removes any request matching the provided key from the queue and rejects its promise.\n   * @param key The key that should be matched against.\n   * @param cancelReason A message or object that will be used as the promise rejection.\n   */\n  cancelRequest(key, cancelReason = DEFAULT_REQUEST_CANCEL_REASON) {\n    if (!this.allRequests.has(key)) {\n      return;\n    }\n    const requestItem = this.allRequests.get(key);\n    if (requestItem) {\n      if (requestItem.timeoutId) {\n        // Cancel requests that have not been queued yet.\n        clearTimeout(requestItem.timeoutId);\n      }\n      // Reject the request, then clear from the queue and known requests.\n      requestItem.reject(cancelReason);\n    }\n    const queueIndex = this.queue.indexOf(key);\n    if (queueIndex > -1) {\n      this.queue.splice(queueIndex, 1);\n    } else {\n      const lowPriorityIndex = this.queueLowPriority.indexOf(key);\n      if (lowPriorityIndex > -1) {\n        this.queueLowPriority.splice(lowPriorityIndex, 1);\n      }\n    }\n    this.allRequests.delete(key);\n    this.activeRequests.delete(key);\n  }\n\n  /**\n   * Rejects all request promises and clears the queue.\n   * @param cancelReason A message or object that will be used as the promise rejection.\n   */\n  cancelAllRequests(cancelReason = DEFAULT_REQUEST_CANCEL_REASON) {\n    // Clear the queue so we don't do extra work while filtering it\n    this.queue = [];\n    this.queueLowPriority = [];\n    for (const key of this.allRequests.keys()) {\n      this.cancelRequest(key, cancelReason);\n    }\n  }\n\n  /**\n   * Returns whether a request with the given key exists in the RequestQueue and is not cancelled.\n   * @param key the key to search for.\n   * @returns true if the request is in the RequestQueue.\n   */\n  hasRequest(key) {\n    return this.allRequests.has(key);\n  }\n\n  /**\n   * Returns whether the request with the given key is currently running (not waiting in the queue).\n   * @param key the key to search for.\n   * @returns true if the request is actively running.\n   */\n  requestRunning(key) {\n    return this.activeRequests.has(key);\n  }\n}","import RequestQueue from \"./RequestQueue.js\";\n\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n/**\n * An extension of `RequestQueue` that adds a concept of \"subscribers,\" which may share references to a single request\n * or cancel their subscription without disrupting the request for other subscribers.\n */\nexport default class SubscribableRequestQueue {\n  /** The next unused subscriber ID. Increments whenever a subscriber is added. */\n\n  /**\n   * Map of subscribers keyed by ID. Subscribers store a map to all their subscriptions by request key.\n   * Subscribers are only useful as handles to cancel subscriptions early, so we only need to store rejecters here.\n   */\n\n  /** Map from \"inner\" request (managed by `queue`) to \"outer\" promises generated per-subscriber. */\n\n  /**\n   * Since `SubscribableRequestQueue` wraps `RequestQueue`, its constructor may either take the same arguments as the\n   * `RequestQueue` constructor and create a new `RequestQueue`, or it may take an existing `RequestQueue` to wrap.\n   */\n\n  constructor(maxActiveRequests, maxLowPriorityRequests) {\n    if (typeof maxActiveRequests === \"number\" || maxActiveRequests === undefined) {\n      this.queue = new RequestQueue(maxActiveRequests, maxLowPriorityRequests);\n    } else {\n      this.queue = maxActiveRequests;\n    }\n    this.nextSubscriberId = 0;\n    this.subscribers = new Map();\n    this.requests = new Map();\n  }\n\n  /** Resolves all subscriptions to request `key` with `value` */\n  resolveAll(key, value) {\n    const requests = this.requests.get(key);\n    if (requests) {\n      for (const {\n        resolve,\n        subscriberId\n      } of requests) {\n        resolve(value);\n        this.subscribers.get(subscriberId)?.delete(key);\n      }\n      this.requests.delete(key);\n    }\n  }\n\n  /** Rejects all subscriptions to request `key` with `reason` */\n  rejectAll(key, reason) {\n    const requests = this.requests.get(key);\n    if (requests) {\n      for (const {\n        reject,\n        subscriberId\n      } of requests) {\n        reject(reason);\n        this.subscribers.get(subscriberId)?.delete(key);\n      }\n      this.requests.delete(key);\n    }\n  }\n\n  /** Adds a new request subscriber. Returns a unique ID to identify this subscriber. */\n  addSubscriber() {\n    const subscriberId = this.nextSubscriberId;\n    this.nextSubscriberId++;\n    this.subscribers.set(subscriberId, new Map());\n    return subscriberId;\n  }\n\n  /**\n   * Queues a new request, or adds a subscription if the request is already queued/running.\n   *\n   * If `subscriberId` is already subscribed to the request, this rejects the existing promise and returns a new one.\n   */\n  addRequest(key, subscriberId, requestAction, lowPriority, delayMs) {\n    // Create single underlying request if it does not yet exist\n    this.queue.addRequest(key, requestAction, lowPriority, delayMs).then(value => this.resolveAll(key, value)).catch(reason => this.rejectAll(key, reason));\n    if (!this.requests.has(key)) {\n      this.requests.set(key, []);\n    }\n\n    // Validate subscriber\n    if (subscriberId >= this.nextSubscriberId || subscriberId < 0) {\n      throw new Error(`SubscribableRequestQueue: subscriber id ${subscriberId} has not been registered`);\n    }\n    const subscriber = this.subscribers.get(subscriberId);\n    if (!subscriber) {\n      throw new Error(`SubscribableRequestQueue: subscriber id ${subscriberId} has been removed`);\n    }\n\n    // Create promise and add to list of requests\n    return new Promise((resolve, reject) => {\n      this.requests.get(key)?.push({\n        resolve,\n        reject,\n        subscriberId\n      });\n      const subscriber = this.subscribers.get(subscriberId);\n      const existingRequest = subscriber?.get(key);\n      if (existingRequest) {\n        existingRequest.push(reject);\n      } else {\n        subscriber?.set(key, [reject]);\n      }\n    });\n  }\n\n  /**\n   * Rejects a subscription and removes it from the list of subscriptions for a request, then cancels the underlying\n   * request if it is no longer subscribed and is not running already.\n   */\n  rejectSubscription(key, reject, cancelReason) {\n    // Reject the outer \"subscription\" promise\n    reject(cancelReason);\n\n    // Get the list of subscriptions for this request\n    const subscriptions = this.requests.get(key);\n    if (!subscriptions) {\n      // This should never happen\n      return;\n    }\n    // Remove this request subscription by ref equality to `reject`\n    const idx = subscriptions.findIndex(sub => sub.reject === reject);\n    if (idx >= 0) {\n      subscriptions.splice(idx, 1);\n    }\n\n    // Remove the underlying request if there are no more subscribers and the request is not already running\n    if (subscriptions.length < 1 && !this.queue.requestRunning(key)) {\n      this.queue.cancelRequest(key, cancelReason);\n      this.requests.delete(key);\n    }\n  }\n\n  /** Cancels a request subscription, and cancels the underlying request if it is no longer subscribed or running. */\n  cancelRequest(key, subscriberId, cancelReason) {\n    const subscriber = this.subscribers.get(subscriberId);\n    if (!subscriber) {\n      return false;\n    }\n    const rejecters = subscriber.get(key);\n    if (!rejecters || !rejecters.length) {\n      return false;\n    }\n    for (const reject of rejecters) {\n      this.rejectSubscription(key, reject, cancelReason);\n    }\n    subscriber.delete(key);\n    return true;\n  }\n\n  /** Removes a subscriber and cancels its remaining subscriptions. */\n  removeSubscriber(subscriberId, cancelReason) {\n    const subscriptions = this.subscribers.get(subscriberId);\n    if (subscriptions) {\n      for (const [key, rejecters] of subscriptions.entries()) {\n        for (const reject of rejecters) {\n          this.rejectSubscription(key, reject, cancelReason);\n        }\n      }\n      this.subscribers.delete(subscriberId);\n    }\n  }\n\n  /** Returns whether a request with the given `key` is running or waiting in the queue */\n  hasRequest(key) {\n    return this.queue.hasRequest(key);\n  }\n\n  /** Returns whether a request with the given `key` is running */\n  requestRunning(key) {\n    return this.queue.requestRunning(key);\n  }\n\n  /** Returns whether a subscriber with the given `subscriberId` exists */\n  hasSubscriber(subscriberId) {\n    return this.subscribers.has(subscriberId);\n  }\n\n  /** Returns whether a subscriber with the given `subscriberId` is subscribed to the request with the given `key` */\n  isSubscribed(subscriberId, key) {\n    return this.subscribers.get(subscriberId)?.has(key) ?? false;\n  }\n}","/** The types of requests that can be made to the worker. Mostly corresponds to methods on `IVolumeLoader`. */\nexport let WorkerMsgType = /*#__PURE__*/function (WorkerMsgType) {\n  WorkerMsgType[WorkerMsgType[\"INIT\"] = 0] = \"INIT\";\n  WorkerMsgType[WorkerMsgType[\"CREATE_LOADER\"] = 1] = \"CREATE_LOADER\";\n  WorkerMsgType[WorkerMsgType[\"CLOSE_LOADER\"] = 2] = \"CLOSE_LOADER\";\n  WorkerMsgType[WorkerMsgType[\"CREATE_VOLUME\"] = 3] = \"CREATE_VOLUME\";\n  WorkerMsgType[WorkerMsgType[\"LOAD_DIMS\"] = 4] = \"LOAD_DIMS\";\n  WorkerMsgType[WorkerMsgType[\"LOAD_VOLUME_DATA\"] = 5] = \"LOAD_VOLUME_DATA\";\n  WorkerMsgType[WorkerMsgType[\"SET_PREFETCH_PRIORITY_DIRECTIONS\"] = 6] = \"SET_PREFETCH_PRIORITY_DIRECTIONS\";\n  WorkerMsgType[WorkerMsgType[\"SYNCHRONIZE_MULTICHANNEL_LOADING\"] = 7] = \"SYNCHRONIZE_MULTICHANNEL_LOADING\";\n  WorkerMsgType[WorkerMsgType[\"UPDATE_FETCH_OPTIONS\"] = 8] = \"UPDATE_FETCH_OPTIONS\";\n  return WorkerMsgType;\n}({});\n\n/** The variants of `WorkerMessageType` which represent \"global\" actions that don't require a specific loader */\n\n/** The variants of `WorkerMessageType` which represent actions on a specific loader */\n\n/** The kind of response a worker can return - `SUCCESS`, `ERROR`, or `EVENT`. */\nexport let WorkerResponseResult = /*#__PURE__*/function (WorkerResponseResult) {\n  WorkerResponseResult[WorkerResponseResult[\"SUCCESS\"] = 0] = \"SUCCESS\";\n  WorkerResponseResult[WorkerResponseResult[\"ERROR\"] = 1] = \"ERROR\";\n  WorkerResponseResult[WorkerResponseResult[\"EVENT\"] = 2] = \"EVENT\";\n  return WorkerResponseResult;\n}({});\n\n/** The kind of events that can occur when loading */\nexport let WorkerEventType = /*#__PURE__*/function (WorkerEventType) {\n  /** Fired to update a `Volume`'s `imageInfo` and/or `loadSpec` based on loaded data (time, channels, region, etc.) */\n  WorkerEventType[WorkerEventType[\"METADATA_UPDATE\"] = 0] = \"METADATA_UPDATE\";\n  /** Fired when data for a channel (or batch of channels) is loaded */\n  WorkerEventType[WorkerEventType[\"CHANNEL_LOAD\"] = 1] = \"CHANNEL_LOAD\";\n  return WorkerEventType;\n}({});\n\n/**\n * All messages to/from a worker carry a `msgId`, a `type`, and a `payload` (whose type is determined by `type`).\n * Messages which operate on a specific loader also require a `loaderId`.\n */\n\n/** Maps each `WorkerMsgType` to the type of the payload of requests of that type. */\n\n/** Maps each `WorkerMsgType` to the type of the payload of responses of that type. */\n\n/** Event for when a batch of channel data loads. */\n\n/** Event for when metadata updates. */\n\n/** All valid types of worker requests, with some `WorkerMsgType` and a matching payload type. */\n\n/** All valid types of worker responses: `SUCCESS` with a matching payload, `ERROR` with a message, or an `EVENT`. */","import { Box3, Vector3 } from \"three\";\n/** Recreates a `LoadSpec` that has just been sent to/from a worker to restore three.js object prototypes */\nexport function rebuildLoadSpec(spec) {\n  return {\n    ...spec,\n    subregion: new Box3(new Vector3().copy(spec.subregion.min), new Vector3().copy(spec.subregion.max))\n  };\n}","import { assert } from \"../util.js\";\n/**\n * A codec for bit-rounding.\n *\n * Reduces floating-point precision by truncating mantissa bits during encoding.\n * Decoding is a no-op as the process is lossy and precision cannot be restored.\n *\n * Note: {@link BitroundCodec.encode} is not yet implemented since Zarrita is\n * primarily used in read-only contexts (web browser). If you need encoding support,\n * please open an issue at {@link https://github.com/manzt/zarrita.js/issues}.\n *\n * @see {@link https://github.com/zarr-developers/numcodecs/blob/main/numcodecs/bitround.py}\n * for the original Python implementation.\n *\n * @remarks\n * Data types are not validated, and `float16` arrays are not supported (reflecting browser support).\n */\nexport class BitroundCodec {\n    kind = \"array_to_array\";\n    constructor(configuration, _meta) {\n        assert(configuration.keepbits >= 0, \"keepbits must be zero or positive\");\n    }\n    static fromConfig(configuration, meta) {\n        return new BitroundCodec(configuration, meta);\n    }\n    /**\n     * Encode a chunk of data with bit-rounding.\n     * @param _arr - The chunk to encode\n     */\n    encode(_arr) {\n        throw new Error(\"`BitroundCodec.encode` is not implemented. Please open an issue at https://github.com/manzt/zarrita.js/issues.\");\n    }\n    /**\n     * Decode a chunk of data (no-op).\n     * @param arr - The chunk to decode\n     * @returns The decoded chunk\n     */\n    decode(arr) {\n        return arr; // No-op as bit-rounding is lossy\n    }\n}\n//# sourceMappingURL=bitround.js.map","import { byteswap_inplace, get_ctr, get_strides } from \"../util.js\";\nconst LITTLE_ENDIAN_OS = system_is_little_endian();\nfunction system_is_little_endian() {\n    const a = new Uint32Array([0x12345678]);\n    const b = new Uint8Array(a.buffer, a.byteOffset, a.byteLength);\n    return !(b[0] === 0x12);\n}\nfunction bytes_per_element(TypedArray) {\n    if (\"BYTES_PER_ELEMENT\" in TypedArray) {\n        return TypedArray.BYTES_PER_ELEMENT;\n    }\n    // Unicode string array is backed by a Int32Array.\n    return 4;\n}\nexport class BytesCodec {\n    kind = \"array_to_bytes\";\n    #stride;\n    #TypedArray;\n    #BYTES_PER_ELEMENT;\n    #shape;\n    #endian;\n    constructor(configuration, meta) {\n        this.#endian = configuration?.endian;\n        this.#TypedArray = get_ctr(meta.data_type);\n        this.#shape = meta.shape;\n        this.#stride = get_strides(meta.shape, \"C\");\n        // TODO: fix me.\n        // hack to get bytes per element since it's dynamic for string types.\n        const sample = new this.#TypedArray(0);\n        this.#BYTES_PER_ELEMENT = sample.BYTES_PER_ELEMENT;\n    }\n    static fromConfig(configuration, meta) {\n        return new BytesCodec(configuration, meta);\n    }\n    encode(arr) {\n        let bytes = new Uint8Array(arr.data.buffer);\n        if (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n            byteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n        }\n        return bytes;\n    }\n    decode(bytes) {\n        if (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n            byteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n        }\n        return {\n            data: new this.#TypedArray(bytes.buffer, bytes.byteOffset, bytes.byteLength / this.#BYTES_PER_ELEMENT),\n            shape: this.#shape,\n            stride: this.#stride,\n        };\n    }\n}\n//# sourceMappingURL=bytes.js.map","export class Crc32cCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig() {\n        return new Crc32cCodec();\n    }\n    encode(_) {\n        throw new Error(\"Not implemented\");\n    }\n    decode(arr) {\n        return new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength - 4);\n    }\n}\n//# sourceMappingURL=crc32c.js.map","import { decompress } from \"../util.js\";\nexport class GzipCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig(_) {\n        return new GzipCodec();\n    }\n    encode(_bytes) {\n        throw new Error(\"Gzip encoding is not enabled by default. Please register a custom codec with `numcodecs/gzip`.\");\n    }\n    async decode(bytes) {\n        const buffer = await decompress(bytes, { format: \"gzip\" });\n        return new Uint8Array(buffer);\n    }\n}\n//# sourceMappingURL=gzip.js.map","import { assert, get_strides, json_decode_object } from \"../util.js\";\n// Reference: https://stackoverflow.com/a/21897413\nfunction throw_on_nan_replacer(_key, value) {\n    assert(!Number.isNaN(value), \"JsonCodec allow_nan is false but NaN was encountered during encoding.\");\n    assert(value !== Number.POSITIVE_INFINITY, \"JsonCodec allow_nan is false but Infinity was encountered during encoding.\");\n    assert(value !== Number.NEGATIVE_INFINITY, \"JsonCodec allow_nan is false but -Infinity was encountered during encoding.\");\n    return value;\n}\n// Reference: https://gist.github.com/davidfurlong/463a83a33b70a3b6618e97ec9679e490\nfunction sort_keys_replacer(_key, value) {\n    return value instanceof Object && !Array.isArray(value)\n        ? Object.keys(value)\n            .sort()\n            .reduce((sorted, key) => {\n            sorted[key] = value[key];\n            return sorted;\n        }, {})\n        : value;\n}\nexport class JsonCodec {\n    configuration;\n    kind = \"array_to_bytes\";\n    #encoder_config;\n    #decoder_config;\n    constructor(configuration = {}) {\n        this.configuration = configuration;\n        // Reference: https://github.com/zarr-developers/numcodecs/blob/0878717a3613d91a453fe3d3716aa9c67c023a8b/numcodecs/json.py#L36\n        const { encoding = \"utf-8\", skipkeys = false, ensure_ascii = true, check_circular = true, allow_nan = true, sort_keys = true, indent, strict = true, } = configuration;\n        let separators = configuration.separators;\n        if (!separators) {\n            // ensure separators are explicitly specified, and consistent behaviour across\n            // Python versions, and most compact representation if indent is None\n            if (!indent) {\n                separators = [\",\", \":\"];\n            }\n            else {\n                separators = [\", \", \": \"];\n            }\n        }\n        this.#encoder_config = {\n            encoding,\n            skipkeys,\n            ensure_ascii,\n            check_circular,\n            allow_nan,\n            indent,\n            separators,\n            sort_keys,\n        };\n        this.#decoder_config = { strict };\n    }\n    static fromConfig(configuration) {\n        return new JsonCodec(configuration);\n    }\n    encode(buf) {\n        const { indent, encoding, ensure_ascii, check_circular, allow_nan, sort_keys, } = this.#encoder_config;\n        assert(encoding === \"utf-8\", \"JsonCodec does not yet support non-utf-8 encoding.\");\n        const replacer_functions = [];\n        // By default, for JSON.stringify,\n        // a TypeError will be thrown if one attempts to encode an object with circular references\n        assert(check_circular, \"JsonCodec does not yet support skipping the check for circular references during encoding.\");\n        if (!allow_nan) {\n            // Throw if NaN/Infinity/-Infinity are encountered during encoding.\n            replacer_functions.push(throw_on_nan_replacer);\n        }\n        if (sort_keys) {\n            // We can ensure keys are sorted but not really the opposite since\n            // there is no guarantee of key ordering in JS.\n            replacer_functions.push(sort_keys_replacer);\n        }\n        const items = Array.from(buf.data);\n        items.push(\"|O\");\n        items.push(buf.shape);\n        let replacer = undefined;\n        if (replacer_functions.length) {\n            replacer = (key, value) => {\n                let new_value = value;\n                for (let sub_replacer of replacer_functions) {\n                    new_value = sub_replacer(key, new_value);\n                }\n                return new_value;\n            };\n        }\n        let json_str = JSON.stringify(items, replacer, indent);\n        if (ensure_ascii) {\n            // If ensure_ascii is true (the default), the output is guaranteed\n            // to have all incoming non-ASCII characters escaped.\n            // If ensure_ascii is false, these characters will be output as-is.\n            // Reference: https://stackoverflow.com/a/31652607\n            json_str = json_str.replace(/[\\u007F-\\uFFFF]/g, (chr) => {\n                const full_str = `0000${chr.charCodeAt(0).toString(16)}`;\n                const sub_str = full_str.substring(full_str.length - 4);\n                return `\\\\u${sub_str}`;\n            });\n        }\n        return new TextEncoder().encode(json_str);\n    }\n    decode(bytes) {\n        const { strict } = this.#decoder_config;\n        // (i.e., allowing control characters inside strings)\n        assert(strict, \"JsonCodec does not yet support non-strict decoding.\");\n        const items = json_decode_object(bytes);\n        const shape = items.pop();\n        items.pop(); // Pop off dtype (unused)\n        // O-d case\n        assert(shape, \"0D not implemented for JsonCodec.\");\n        const stride = get_strides(shape, \"C\");\n        const data = items;\n        return { data, shape, stride };\n    }\n}\n//# sourceMappingURL=json2.js.map","import { BoolArray, ByteStringArray, UnicodeStringArray, } from \"../typedarray.js\";\nimport { assert, get_strides } from \"../util.js\";\nfunction proxy(arr) {\n    if (arr instanceof BoolArray ||\n        arr instanceof ByteStringArray ||\n        arr instanceof UnicodeStringArray) {\n        // @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n        const arrp = new Proxy(arr, {\n            get(target, prop) {\n                return target.get(Number(prop));\n            },\n            set(target, prop, value) {\n                // @ts-expect-error - value is OK\n                target.set(Number(prop), value);\n                return true;\n            },\n        });\n        return arrp;\n    }\n    // @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n    return arr;\n}\nfunction empty_like(chunk, order) {\n    let data;\n    if (chunk.data instanceof ByteStringArray ||\n        chunk.data instanceof UnicodeStringArray) {\n        data = new chunk.constructor(\n        // @ts-expect-error\n        chunk.data.length, chunk.data.chars);\n    }\n    else {\n        data = new chunk.constructor(chunk.data.length);\n    }\n    return {\n        data,\n        shape: chunk.shape,\n        stride: get_strides(chunk.shape, order),\n    };\n}\nfunction convert_array_order(src, target) {\n    let out = empty_like(src, target);\n    let n_dims = src.shape.length;\n    let size = src.data.length;\n    let index = Array(n_dims).fill(0);\n    let src_data = proxy(src.data);\n    let out_data = proxy(out.data);\n    for (let src_idx = 0; src_idx < size; src_idx++) {\n        let out_idx = 0;\n        for (let dim = 0; dim < n_dims; dim++) {\n            out_idx += index[dim] * out.stride[dim];\n        }\n        out_data[out_idx] = src_data[src_idx];\n        index[0] += 1;\n        for (let dim = 0; dim < n_dims; dim++) {\n            if (index[dim] === src.shape[dim]) {\n                if (dim + 1 === n_dims) {\n                    break;\n                }\n                index[dim] = 0;\n                index[dim + 1] += 1;\n            }\n        }\n    }\n    return out;\n}\n/** Determine the memory order (axis permutation) for a chunk */\nfunction get_order(chunk) {\n    let rank = chunk.shape.length;\n    assert(rank === chunk.stride.length, \"Shape and stride must have the same length.\");\n    return chunk.stride\n        .map((s, i) => ({ stride: s, index: i }))\n        .sort((a, b) => b.stride - a.stride)\n        .map((entry) => entry.index);\n}\nfunction matches_order(chunk, target) {\n    let source = get_order(chunk);\n    assert(source.length === target.length, \"Orders must match\");\n    return source.every((dim, i) => dim === target[i]);\n}\nexport class TransposeCodec {\n    kind = \"array_to_array\";\n    #order;\n    #inverseOrder;\n    constructor(configuration, meta) {\n        let value = configuration.order ?? \"C\";\n        let rank = meta.shape.length;\n        let order = new Array(rank);\n        let inverseOrder = new Array(rank);\n        if (value === \"C\") {\n            for (let i = 0; i < rank; ++i) {\n                order[i] = i;\n                inverseOrder[i] = i;\n            }\n        }\n        else if (value === \"F\") {\n            for (let i = 0; i < rank; ++i) {\n                order[i] = rank - i - 1;\n                inverseOrder[i] = rank - i - 1;\n            }\n        }\n        else {\n            order = value;\n            order.forEach((x, i) => {\n                assert(inverseOrder[x] === undefined, `Invalid permutation: ${JSON.stringify(value)}`);\n                inverseOrder[x] = i;\n            });\n        }\n        this.#order = order;\n        this.#inverseOrder = inverseOrder;\n    }\n    static fromConfig(configuration, meta) {\n        return new TransposeCodec(configuration, meta);\n    }\n    encode(arr) {\n        if (matches_order(arr, this.#inverseOrder)) {\n            // can skip making a copy\n            return arr;\n        }\n        return convert_array_order(arr, this.#inverseOrder);\n    }\n    decode(arr) {\n        return {\n            data: arr.data,\n            shape: arr.shape,\n            stride: get_strides(arr.shape, this.#order),\n        };\n    }\n}\n//# sourceMappingURL=transpose.js.map","import { get_strides } from \"../util.js\";\nexport class VLenUTF8 {\n    kind = \"array_to_bytes\";\n    #shape;\n    #strides;\n    constructor(shape) {\n        this.#shape = shape;\n        this.#strides = get_strides(shape, \"C\");\n    }\n    static fromConfig(_, meta) {\n        return new VLenUTF8(meta.shape);\n    }\n    encode(_chunk) {\n        throw new Error(\"Method not implemented.\");\n    }\n    decode(bytes) {\n        let decoder = new TextDecoder();\n        let view = new DataView(bytes.buffer);\n        let data = Array(view.getUint32(0, true));\n        let pos = 4;\n        for (let i = 0; i < data.length; i++) {\n            let item_length = view.getUint32(pos, true);\n            pos += 4;\n            data[i] = decoder.decode(bytes.buffer.slice(pos, pos + item_length));\n            pos += item_length;\n        }\n        return { data, shape: this.#shape, stride: this.#strides };\n    }\n}\n//# sourceMappingURL=vlen-utf8.js.map","import { decompress } from \"../util.js\";\nexport class ZlibCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig(_) {\n        return new ZlibCodec();\n    }\n    encode(_bytes) {\n        throw new Error(\"Zlib encoding is not enabled by default. Please register a codec with `numcodecs/zlib`.\");\n    }\n    async decode(bytes) {\n        const buffer = await decompress(bytes, { format: \"deflate\" });\n        return new Uint8Array(buffer);\n    }\n}\n//# sourceMappingURL=zlib.js.map","import { BitroundCodec } from \"./codecs/bitround.js\";\nimport { BytesCodec } from \"./codecs/bytes.js\";\nimport { Crc32cCodec } from \"./codecs/crc32c.js\";\nimport { GzipCodec } from \"./codecs/gzip.js\";\nimport { JsonCodec } from \"./codecs/json2.js\";\nimport { TransposeCodec } from \"./codecs/transpose.js\";\nimport { VLenUTF8 } from \"./codecs/vlen-utf8.js\";\nimport { ZlibCodec } from \"./codecs/zlib.js\";\nimport { assert } from \"./util.js\";\nfunction create_default_registry() {\n    return new Map()\n        .set(\"blosc\", () => import(\"numcodecs/blosc\").then((m) => m.default))\n        .set(\"lz4\", () => import(\"numcodecs/lz4\").then((m) => m.default))\n        .set(\"zstd\", () => import(\"numcodecs/zstd\").then((m) => m.default))\n        .set(\"gzip\", () => GzipCodec)\n        .set(\"zlib\", () => ZlibCodec)\n        .set(\"transpose\", () => TransposeCodec)\n        .set(\"bytes\", () => BytesCodec)\n        .set(\"crc32c\", () => Crc32cCodec)\n        .set(\"vlen-utf8\", () => VLenUTF8)\n        .set(\"json2\", () => JsonCodec)\n        .set(\"bitround\", () => BitroundCodec);\n}\nexport const registry = create_default_registry();\nexport function create_codec_pipeline(chunk_metadata) {\n    let codecs;\n    return {\n        async encode(chunk) {\n            if (!codecs)\n                codecs = await load_codecs(chunk_metadata);\n            for (const codec of codecs.array_to_array) {\n                chunk = await codec.encode(chunk);\n            }\n            let bytes = await codecs.array_to_bytes.encode(chunk);\n            for (const codec of codecs.bytes_to_bytes) {\n                bytes = await codec.encode(bytes);\n            }\n            return bytes;\n        },\n        async decode(bytes) {\n            if (!codecs)\n                codecs = await load_codecs(chunk_metadata);\n            for (let i = codecs.bytes_to_bytes.length - 1; i >= 0; i--) {\n                bytes = await codecs.bytes_to_bytes[i].decode(bytes);\n            }\n            let chunk = await codecs.array_to_bytes.decode(bytes);\n            for (let i = codecs.array_to_array.length - 1; i >= 0; i--) {\n                chunk = await codecs.array_to_array[i].decode(chunk);\n            }\n            return chunk;\n        },\n    };\n}\nasync function load_codecs(chunk_meta) {\n    let promises = chunk_meta.codecs.map(async (meta) => {\n        let Codec = await registry.get(meta.name)?.();\n        assert(Codec, `Unknown codec: ${meta.name}`);\n        return { Codec, meta };\n    });\n    let array_to_array = [];\n    let array_to_bytes;\n    let bytes_to_bytes = [];\n    for await (let { Codec, meta } of promises) {\n        let codec = Codec.fromConfig(meta.configuration, chunk_meta);\n        switch (codec.kind) {\n            case \"array_to_array\":\n                array_to_array.push(codec);\n                break;\n            case \"array_to_bytes\":\n                array_to_bytes = codec;\n                break;\n            default:\n                bytes_to_bytes.push(codec);\n        }\n    }\n    if (!array_to_bytes) {\n        assert(is_typed_array_like_meta(chunk_meta), `Cannot encode ${chunk_meta.data_type} to bytes without a codec`);\n        array_to_bytes = BytesCodec.fromConfig({ endian: \"little\" }, chunk_meta);\n    }\n    return { array_to_array, array_to_bytes, bytes_to_bytes };\n}\nfunction is_typed_array_like_meta(meta) {\n    return meta.data_type !== \"v2:object\";\n}\n//# sourceMappingURL=codecs.js.map","import { assert } from \"../util.js\";\nimport { create_codec_pipeline } from \"../codecs.js\";\nconst MAX_BIG_UINT = 18446744073709551615n;\nexport function create_sharded_chunk_getter(location, shard_shape, encode_shard_key, sharding_config) {\n    assert(location.store.getRange, \"Store does not support range requests\");\n    let get_range = location.store.getRange.bind(location.store);\n    let index_shape = shard_shape.map((d, i) => d / sharding_config.chunk_shape[i]);\n    let index_codec = create_codec_pipeline({\n        data_type: \"uint64\",\n        shape: [...index_shape, 2],\n        codecs: sharding_config.index_codecs,\n    });\n    let cache = {};\n    return async (chunk_coord) => {\n        let shard_coord = chunk_coord.map((d, i) => Math.floor(d / index_shape[i]));\n        let shard_path = location.resolve(encode_shard_key(shard_coord)).path;\n        let index;\n        if (shard_path in cache) {\n            index = cache[shard_path];\n        }\n        else {\n            let checksum_size = 4;\n            let index_size = 16 * index_shape.reduce((a, b) => a * b, 1);\n            let bytes = await get_range(shard_path, {\n                suffixLength: index_size + checksum_size,\n            });\n            index = cache[shard_path] = bytes\n                ? await index_codec.decode(bytes)\n                : null;\n        }\n        if (index === null) {\n            return undefined;\n        }\n        let { data, shape, stride } = index;\n        let linear_offset = chunk_coord\n            .map((d, i) => d % shape[i])\n            .reduce((acc, sel, idx) => acc + sel * stride[idx], 0);\n        let offset = data[linear_offset];\n        let length = data[linear_offset + 1];\n        // write null chunk when 2^64-1 indicates fill value\n        if (offset === MAX_BIG_UINT && length === MAX_BIG_UINT) {\n            return undefined;\n        }\n        return get_range(shard_path, {\n            offset: Number(offset),\n            length: Number(length),\n        });\n    };\n}\n//# sourceMappingURL=sharding.js.map","import { create_codec_pipeline } from \"./codecs.js\";\nimport { create_sharded_chunk_getter } from \"./codecs/sharding.js\";\nimport { is_dtype, is_sharding_codec, } from \"./util.js\";\nimport { create_chunk_key_encoder, ensure_correct_scalar, get_ctr, get_strides, } from \"./util.js\";\nexport class Location {\n    store;\n    path;\n    constructor(store, path = \"/\") {\n        this.store = store;\n        this.path = path;\n    }\n    resolve(path) {\n        // reuse URL resolution logic built into the browser\n        // handles relative paths, absolute paths, etc.\n        let root = new URL(`file://${this.path.endsWith(\"/\") ? this.path : `${this.path}/`}`);\n        return new Location(this.store, new URL(path, root).pathname);\n    }\n}\nexport function root(store) {\n    return new Location(store ?? new Map());\n}\nexport class Group extends Location {\n    kind = \"group\";\n    #metadata;\n    constructor(store, path, metadata) {\n        super(store, path);\n        this.#metadata = metadata;\n    }\n    get attrs() {\n        return this.#metadata.attributes;\n    }\n}\nfunction get_array_order(codecs) {\n    const maybe_transpose_codec = codecs.find((c) => c.name === \"transpose\");\n    // @ts-expect-error - TODO: Should validate?\n    return maybe_transpose_codec?.configuration?.order ?? \"C\";\n}\nconst CONTEXT_MARKER = Symbol(\"zarrita.context\");\nexport function get_context(obj) {\n    return obj[CONTEXT_MARKER];\n}\nfunction create_context(location, metadata) {\n    let { configuration } = metadata.codecs.find(is_sharding_codec) ?? {};\n    let shared_context = {\n        encode_chunk_key: create_chunk_key_encoder(metadata.chunk_key_encoding),\n        TypedArray: get_ctr(metadata.data_type),\n        fill_value: metadata.fill_value,\n    };\n    if (configuration) {\n        let native_order = get_array_order(configuration.codecs);\n        return {\n            ...shared_context,\n            kind: \"sharded\",\n            chunk_shape: configuration.chunk_shape,\n            codec: create_codec_pipeline({\n                data_type: metadata.data_type,\n                shape: configuration.chunk_shape,\n                codecs: configuration.codecs,\n            }),\n            get_strides(shape) {\n                return get_strides(shape, native_order);\n            },\n            get_chunk_bytes: create_sharded_chunk_getter(location, metadata.chunk_grid.configuration.chunk_shape, shared_context.encode_chunk_key, configuration),\n        };\n    }\n    let native_order = get_array_order(metadata.codecs);\n    return {\n        ...shared_context,\n        kind: \"regular\",\n        chunk_shape: metadata.chunk_grid.configuration.chunk_shape,\n        codec: create_codec_pipeline({\n            data_type: metadata.data_type,\n            shape: metadata.chunk_grid.configuration.chunk_shape,\n            codecs: metadata.codecs,\n        }),\n        get_strides(shape) {\n            return get_strides(shape, native_order);\n        },\n        async get_chunk_bytes(chunk_coords, options) {\n            let chunk_key = shared_context.encode_chunk_key(chunk_coords);\n            let chunk_path = location.resolve(chunk_key).path;\n            return location.store.get(chunk_path, options);\n        },\n    };\n}\nexport class Array extends Location {\n    kind = \"array\";\n    #metadata;\n    [CONTEXT_MARKER];\n    constructor(store, path, metadata) {\n        super(store, path);\n        this.#metadata = {\n            ...metadata,\n            fill_value: ensure_correct_scalar(metadata),\n        };\n        this[CONTEXT_MARKER] = create_context(this, metadata);\n    }\n    get attrs() {\n        return this.#metadata.attributes;\n    }\n    get shape() {\n        return this.#metadata.shape;\n    }\n    get chunks() {\n        return this[CONTEXT_MARKER].chunk_shape;\n    }\n    get dtype() {\n        return this.#metadata.data_type;\n    }\n    async getChunk(chunk_coords, options) {\n        let context = this[CONTEXT_MARKER];\n        let maybe_bytes = await context.get_chunk_bytes(chunk_coords, options);\n        if (!maybe_bytes) {\n            let size = context.chunk_shape.reduce((a, b) => a * b, 1);\n            let data = new context.TypedArray(size);\n            // @ts-expect-error: TS can't infer that `fill_value` is union (assumes never) but this is ok\n            data.fill(context.fill_value);\n            return {\n                data,\n                shape: context.chunk_shape,\n                stride: context.get_strides(context.chunk_shape),\n            };\n        }\n        return context.codec.decode(maybe_bytes);\n    }\n    /**\n     * A helper method to narrow `zarr.Array` Dtype.\n     *\n     * ```typescript\n     * let arr: zarr.Array<DataType, FetchStore> = zarr.open(store, { kind: \"array\" });\n     *\n     * // Option 1: narrow by scalar type (e.g. \"bool\", \"raw\", \"bigint\", \"number\")\n     * if (arr.is(\"bigint\")) {\n     *   // zarr.Array<\"int64\" | \"uint64\", FetchStore>\n     * }\n     *\n     * // Option 3: exact match\n     * if (arr.is(\"float32\")) {\n     *   // zarr.Array<\"float32\", FetchStore, \"/\">\n     * }\n     * ```\n     */\n    is(query) {\n        return is_dtype(this.dtype, query);\n    }\n}\n//# sourceMappingURL=hierarchy.js.map","import { product, range, slice, slice_indices } from \"./util.js\";\nexport class IndexError extends Error {\n    constructor(msg) {\n        super(msg);\n        this.name = \"IndexError\";\n    }\n}\nfunction err_too_many_indices(selection, shape) {\n    throw new IndexError(`too many indicies for array; expected ${shape.length}, got ${selection.length}`);\n}\nfunction err_boundscheck(dim_len) {\n    throw new IndexError(`index out of bounds for dimension with length ${dim_len}`);\n}\nfunction err_negative_step() {\n    throw new IndexError(\"only slices with step >= 1 are supported\");\n}\nfunction check_selection_length(selection, shape) {\n    if (selection.length > shape.length) {\n        err_too_many_indices(selection, shape);\n    }\n}\nexport function normalize_integer_selection(dim_sel, dim_len) {\n    // normalize type to int\n    dim_sel = Math.trunc(dim_sel);\n    // handle wraparound\n    if (dim_sel < 0) {\n        dim_sel = dim_len + dim_sel;\n    }\n    // handle out of bounds\n    if (dim_sel >= dim_len || dim_sel < 0) {\n        err_boundscheck(dim_len);\n    }\n    return dim_sel;\n}\nclass IntDimIndexer {\n    dim_sel;\n    dim_len;\n    dim_chunk_len;\n    nitems;\n    constructor({ dim_sel, dim_len, dim_chunk_len }) {\n        // normalize\n        dim_sel = normalize_integer_selection(dim_sel, dim_len);\n        // store properties\n        this.dim_sel = dim_sel;\n        this.dim_len = dim_len;\n        this.dim_chunk_len = dim_chunk_len;\n        this.nitems = 1;\n    }\n    *[Symbol.iterator]() {\n        const dim_chunk_ix = Math.floor(this.dim_sel / this.dim_chunk_len);\n        const dim_offset = dim_chunk_ix * this.dim_chunk_len;\n        const dim_chunk_sel = this.dim_sel - dim_offset;\n        yield { dim_chunk_ix, dim_chunk_sel };\n    }\n}\nclass SliceDimIndexer {\n    start;\n    stop;\n    step;\n    dim_len;\n    dim_chunk_len;\n    nitems;\n    nchunks;\n    constructor({ dim_sel, dim_len, dim_chunk_len }) {\n        // normalize\n        const [start, stop, step] = slice_indices(dim_sel, dim_len);\n        this.start = start;\n        this.stop = stop;\n        this.step = step;\n        if (this.step < 1)\n            err_negative_step();\n        // store properties\n        this.dim_len = dim_len;\n        this.dim_chunk_len = dim_chunk_len;\n        this.nitems = Math.max(0, Math.ceil((this.stop - this.start) / this.step));\n        this.nchunks = Math.ceil(this.dim_len / this.dim_chunk_len);\n    }\n    *[Symbol.iterator]() {\n        // figure out the range of chunks we need to visit\n        const dim_chunk_ix_from = Math.floor(this.start / this.dim_chunk_len);\n        const dim_chunk_ix_to = Math.ceil(this.stop / this.dim_chunk_len);\n        for (const dim_chunk_ix of range(dim_chunk_ix_from, dim_chunk_ix_to)) {\n            // compute offsets for chunk within overall array\n            const dim_offset = dim_chunk_ix * this.dim_chunk_len;\n            const dim_limit = Math.min(this.dim_len, (dim_chunk_ix + 1) * this.dim_chunk_len);\n            // determine chunk length, accounting for trailing chunk\n            const dim_chunk_len = dim_limit - dim_offset;\n            let dim_out_offset = 0;\n            let dim_chunk_sel_start = 0;\n            if (this.start < dim_offset) {\n                // selection start before current chunk\n                const remainder = (dim_offset - this.start) % this.step;\n                if (remainder)\n                    dim_chunk_sel_start += this.step - remainder;\n                // compute number of previous items, provides offset into output array\n                dim_out_offset = Math.ceil((dim_offset - this.start) / this.step);\n            }\n            else {\n                // selection starts within current chunk\n                dim_chunk_sel_start = this.start - dim_offset;\n            }\n            // selection starts within current chunk if true,\n            // otherwise selection ends after current chunk.\n            const dim_chunk_sel_stop = this.stop > dim_limit ? dim_chunk_len : this.stop - dim_offset;\n            const dim_chunk_sel = [\n                dim_chunk_sel_start,\n                dim_chunk_sel_stop,\n                this.step,\n            ];\n            const dim_chunk_nitems = Math.ceil((dim_chunk_sel_stop - dim_chunk_sel_start) / this.step);\n            const dim_out_sel = [\n                dim_out_offset,\n                dim_out_offset + dim_chunk_nitems,\n                1,\n            ];\n            yield { dim_chunk_ix, dim_chunk_sel, dim_out_sel };\n        }\n    }\n}\nexport function normalize_selection(selection, shape) {\n    let normalized = [];\n    if (selection === null) {\n        normalized = shape.map((_) => slice(null));\n    }\n    else if (Array.isArray(selection)) {\n        normalized = selection.map((s) => s ?? slice(null));\n    }\n    check_selection_length(normalized, shape);\n    return normalized;\n}\nexport class BasicIndexer {\n    dim_indexers;\n    shape;\n    constructor({ selection, shape, chunk_shape }) {\n        // setup per-dimension indexers\n        this.dim_indexers = normalize_selection(selection, shape).map((dim_sel, i) => {\n            return new (typeof dim_sel === \"number\" ? IntDimIndexer : SliceDimIndexer)({\n                // @ts-expect-error ts inference not strong enough to know correct chunk\n                dim_sel: dim_sel,\n                dim_len: shape[i],\n                dim_chunk_len: chunk_shape[i],\n            });\n        });\n        this.shape = this.dim_indexers\n            .filter((ixr) => ixr instanceof SliceDimIndexer)\n            .map((sixr) => sixr.nitems);\n    }\n    *[Symbol.iterator]() {\n        for (const dim_projections of product(...this.dim_indexers)) {\n            const chunk_coords = dim_projections.map((p) => p.dim_chunk_ix);\n            const mapping = dim_projections.map((p) => {\n                if (\"dim_out_sel\" in p) {\n                    return { from: p.dim_chunk_sel, to: p.dim_out_sel };\n                }\n                return { from: p.dim_chunk_sel, to: null };\n            });\n            yield { chunk_coords, mapping };\n        }\n    }\n}\n//# sourceMappingURL=indexer.js.map","import { get as get_with_setter } from \"./get.js\";\nimport { set as set_with_setter } from \"./set.js\";\n/** A 1D \"view\" of an array that can be used to set values in the array. */\nfunction object_array_view(arr, offset = 0, size) {\n    let length = size ?? arr.length - offset;\n    return {\n        length,\n        subarray(from, to = length) {\n            return object_array_view(arr, offset + from, to - from);\n        },\n        set(data, start = 0) {\n            for (let i = 0; i < data.length; i++) {\n                arr[offset + start + i] = data.get(i);\n            }\n        },\n        get(index) {\n            return arr[offset + index];\n        },\n    };\n}\n/**\n * Convert a chunk to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more than\n * just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the underlying, which is supported by our binary set functions.\n */\nfunction compat_chunk(arr) {\n    if (globalThis.Array.isArray(arr.data)) {\n        return {\n            // @ts-expect-error\n            data: object_array_view(arr.data),\n            stride: arr.stride,\n            bytes_per_element: 1,\n        };\n    }\n    return {\n        data: new Uint8Array(arr.data.buffer, arr.data.byteOffset, arr.data.byteLength),\n        stride: arr.stride,\n        bytes_per_element: arr.data.BYTES_PER_ELEMENT,\n    };\n}\n/** Hack to get the constructor of a typed array constructor from an existing TypedArray. */\nfunction get_typed_array_constructor(arr) {\n    if (\"chars\" in arr) {\n        // our custom TypedArray needs to bind the number of characters per\n        // element to the constructor.\n        return arr.constructor.bind(null, arr.chars);\n    }\n    return arr.constructor;\n}\n/**\n * Convert a scalar to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more\n * than just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the scalar, which is supported by our binary set functions.\n */\nfunction compat_scalar(arr, value) {\n    if (globalThis.Array.isArray(arr.data)) {\n        // @ts-expect-error\n        return object_array_view([value]);\n    }\n    let TypedArray = get_typed_array_constructor(arr.data);\n    // @ts-expect-error - value is a scalar and matches\n    let data = new TypedArray([value]);\n    return new Uint8Array(data.buffer, data.byteOffset, data.byteLength);\n}\nexport const setter = {\n    prepare(data, shape, stride) {\n        return { data, shape, stride };\n    },\n    set_scalar(dest, sel, value) {\n        let view = compat_chunk(dest);\n        set_scalar_binary(view, sel, compat_scalar(dest, value), view.bytes_per_element);\n    },\n    set_from_chunk(dest, src, projections) {\n        let view = compat_chunk(dest);\n        set_from_chunk_binary(view, compat_chunk(src), view.bytes_per_element, projections);\n    },\n};\n/** @category Utility */\nexport async function get(arr, selection = null, opts = {}) {\n    return get_with_setter(arr, selection, opts, setter);\n}\n/** @category Utility */\nexport async function set(arr, selection, value, opts = {}) {\n    return set_with_setter(arr, selection, value, opts, setter);\n}\nfunction indices_len(start, stop, step) {\n    if (step < 0 && stop < start) {\n        return Math.floor((start - stop - 1) / -step) + 1;\n    }\n    if (start < stop)\n        return Math.floor((stop - start - 1) / step) + 1;\n    return 0;\n}\nfunction set_scalar_binary(out, out_selection, value, bytes_per_element) {\n    if (out_selection.length === 0) {\n        out.data.set(value, 0);\n        return;\n    }\n    const [slice, ...slices] = out_selection;\n    const [curr_stride, ...stride] = out.stride;\n    if (typeof slice === \"number\") {\n        const data = out.data.subarray(curr_stride * slice * bytes_per_element);\n        set_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n        return;\n    }\n    const [from, to, step] = slice;\n    const len = indices_len(from, to, step);\n    if (slices.length === 0) {\n        for (let i = 0; i < len; i++) {\n            out.data.set(value, curr_stride * (from + step * i) * bytes_per_element);\n        }\n        return;\n    }\n    for (let i = 0; i < len; i++) {\n        const data = out.data.subarray(curr_stride * (from + step * i) * bytes_per_element);\n        set_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n    }\n}\nfunction set_from_chunk_binary(dest, src, bytes_per_element, projections) {\n    const [proj, ...projs] = projections;\n    const [dstride, ...dstrides] = dest.stride;\n    const [sstride, ...sstrides] = src.stride;\n    if (proj.from === null) {\n        if (projs.length === 0) {\n            dest.data.set(src.data.subarray(0, bytes_per_element), proj.to * bytes_per_element);\n            return;\n        }\n        set_from_chunk_binary({\n            data: dest.data.subarray(dstride * proj.to * bytes_per_element),\n            stride: dstrides,\n        }, src, bytes_per_element, projs);\n        return;\n    }\n    if (proj.to === null) {\n        if (projs.length === 0) {\n            let offset = proj.from * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + bytes_per_element), 0);\n            return;\n        }\n        set_from_chunk_binary(dest, {\n            data: src.data.subarray(sstride * proj.from * bytes_per_element),\n            stride: sstrides,\n        }, bytes_per_element, projs);\n        return;\n    }\n    const [from, to, step] = proj.to;\n    const [sfrom, _, sstep] = proj.from;\n    const len = indices_len(from, to, step);\n    if (projs.length === 0) {\n        // NB: we have a contiguous block of memory\n        // so we can just copy over all the data at once.\n        if (step === 1 && sstep === 1 && dstride === 1 && sstride === 1) {\n            let offset = sfrom * bytes_per_element;\n            let size = len * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + size), from * bytes_per_element);\n            return;\n        }\n        // Otherwise, we have to copy over each element individually.\n        for (let i = 0; i < len; i++) {\n            let offset = sstride * (sfrom + sstep * i) * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + bytes_per_element), dstride * (from + step * i) * bytes_per_element);\n        }\n        return;\n    }\n    for (let i = 0; i < len; i++) {\n        set_from_chunk_binary({\n            data: dest.data.subarray(dstride * (from + i * step) * bytes_per_element),\n            stride: dstrides,\n        }, {\n            data: src.data.subarray(sstride * (sfrom + i * sstep) * bytes_per_element),\n            stride: sstrides,\n        }, bytes_per_element, projs);\n    }\n}\n//# sourceMappingURL=ops.js.map","import { get_context } from \"../hierarchy.js\";\nimport { BasicIndexer } from \"./indexer.js\";\nimport { create_queue } from \"./util.js\";\nfunction unwrap(arr, idx) {\n    return (\"get\" in arr ? arr.get(idx) : arr[idx]);\n}\nexport async function get(arr, selection, opts, setter) {\n    let context = get_context(arr);\n    let indexer = new BasicIndexer({\n        selection,\n        shape: arr.shape,\n        chunk_shape: arr.chunks,\n    });\n    let out = setter.prepare(new context.TypedArray(indexer.shape.reduce((a, b) => a * b, 1)), indexer.shape, context.get_strides(indexer.shape));\n    let queue = opts.create_queue?.() ?? create_queue();\n    for (const { chunk_coords, mapping } of indexer) {\n        queue.add(async () => {\n            let { data, shape, stride } = await arr.getChunk(chunk_coords, opts.opts);\n            let chunk = setter.prepare(data, shape, stride);\n            setter.set_from_chunk(out, chunk, mapping);\n        });\n    }\n    await queue.onIdle();\n    // If the final out shape is empty, we just return a scalar.\n    // @ts-expect-error - TS can't narrow this conditional type\n    return indexer.shape.length === 0 ? unwrap(out.data, 0) : out;\n}\n//# sourceMappingURL=get.js.map","/** Similar to python's `range` function. Supports positive ranges only. */\nexport function* range(start, stop, step = 1) {\n    if (stop === undefined) {\n        stop = start;\n        start = 0;\n    }\n    for (let i = start; i < stop; i += step) {\n        yield i;\n    }\n}\n/**\n * python-like itertools.product generator\n * https://gist.github.com/cybercase/db7dde901d7070c98c48\n */\nexport function* product(...iterables) {\n    if (iterables.length === 0) {\n        return;\n    }\n    // make a list of iterators from the iterables\n    const iterators = iterables.map((it) => it[Symbol.iterator]());\n    const results = iterators.map((it) => it.next());\n    if (results.some((r) => r.done)) {\n        throw new Error(\"Input contains an empty iterator.\");\n    }\n    for (let i = 0;;) {\n        if (results[i].done) {\n            // reset the current iterator\n            iterators[i] = iterables[i][Symbol.iterator]();\n            results[i] = iterators[i].next();\n            // advance, and exit if we've reached the end\n            if (++i >= iterators.length) {\n                return;\n            }\n        }\n        else {\n            // @ts-expect-error - TS can't infer this\n            yield results.map(({ value }) => value);\n            i = 0;\n        }\n        results[i] = iterators[i].next();\n    }\n}\n// https://github.com/python/cpython/blob/263c0dd16017613c5ea2fbfc270be4de2b41b5ad/Objects/sliceobject.c#L376-L519\nexport function slice_indices({ start, stop, step }, length) {\n    if (step === 0) {\n        throw new Error(\"slice step cannot be zero\");\n    }\n    step = step ?? 1;\n    const step_is_negative = step < 0;\n    /* Find lower and upper bounds for start and stop. */\n    const [lower, upper] = step_is_negative ? [-1, length - 1] : [0, length];\n    /* Compute start. */\n    if (start === null) {\n        start = step_is_negative ? upper : lower;\n    }\n    else {\n        if (start < 0) {\n            start += length;\n            if (start < lower) {\n                start = lower;\n            }\n        }\n        else if (start > upper) {\n            start = upper;\n        }\n    }\n    /* Compute stop. */\n    if (stop === null) {\n        stop = step_is_negative ? lower : upper;\n    }\n    else {\n        if (stop < 0) {\n            stop += length;\n            if (stop < lower) {\n                stop = lower;\n            }\n        }\n        else if (stop > upper) {\n            stop = upper;\n        }\n    }\n    return [start, stop, step];\n}\nexport function slice(start, stop, step = null) {\n    if (stop === undefined) {\n        stop = start;\n        start = null;\n    }\n    return {\n        start,\n        stop,\n        step,\n    };\n}\n/** Built-in \"queue\" for awaiting promises. */\nexport function create_queue() {\n    const promises = [];\n    return {\n        add: (fn) => promises.push(fn()),\n        onIdle: () => Promise.all(promises),\n    };\n}\n//# sourceMappingURL=util.js.map","import { KeyError, NodeNotFoundError } from \"./errors.js\";\nimport { Array, Group, Location } from \"./hierarchy.js\";\nimport { ensure_correct_scalar, json_decode_object, rethrow_unless, v2_to_v3_array_metadata, v2_to_v3_group_metadata, } from \"./util.js\";\nlet VERSION_COUNTER = create_version_counter();\nfunction create_version_counter() {\n    let version_counts = new WeakMap();\n    function get_counts(store) {\n        let counts = version_counts.get(store) ?? { v2: 0, v3: 0 };\n        version_counts.set(store, counts);\n        return counts;\n    }\n    return {\n        increment(store, version) {\n            get_counts(store)[version] += 1;\n        },\n        version_max(store) {\n            let counts = get_counts(store);\n            return counts.v3 > counts.v2 ? \"v3\" : \"v2\";\n        },\n    };\n}\nasync function load_attrs(location) {\n    let meta_bytes = await location.store.get(location.resolve(\".zattrs\").path);\n    if (!meta_bytes)\n        return {};\n    return json_decode_object(meta_bytes);\n}\nasync function open_v2(location, options = {}) {\n    let loc = \"store\" in location ? location : new Location(location);\n    let attrs = {};\n    if (options.attrs ?? true)\n        attrs = await load_attrs(loc);\n    if (options.kind === \"array\")\n        return open_array_v2(loc, attrs);\n    if (options.kind === \"group\")\n        return open_group_v2(loc, attrs);\n    return open_array_v2(loc, attrs).catch((err) => {\n        rethrow_unless(err, NodeNotFoundError);\n        return open_group_v2(loc, attrs);\n    });\n}\nasync function open_array_v2(location, attrs) {\n    let { path } = location.resolve(\".zarray\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v2 array\", {\n            cause: new KeyError(path),\n        });\n    }\n    VERSION_COUNTER.increment(location.store, \"v2\");\n    return new Array(location.store, location.path, v2_to_v3_array_metadata(json_decode_object(meta), attrs));\n}\nasync function open_group_v2(location, attrs) {\n    let { path } = location.resolve(\".zgroup\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v2 group\", {\n            cause: new KeyError(path),\n        });\n    }\n    VERSION_COUNTER.increment(location.store, \"v2\");\n    return new Group(location.store, location.path, v2_to_v3_group_metadata(json_decode_object(meta), attrs));\n}\nasync function _open_v3(location) {\n    let { store, path } = location.resolve(\"zarr.json\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v3 array or group\", {\n            cause: new KeyError(path),\n        });\n    }\n    let meta_doc = json_decode_object(meta);\n    if (meta_doc.node_type === \"array\") {\n        meta_doc.fill_value = ensure_correct_scalar(meta_doc);\n    }\n    return meta_doc.node_type === \"array\"\n        ? new Array(store, location.path, meta_doc)\n        : new Group(store, location.path, meta_doc);\n}\nasync function open_v3(location, options = {}) {\n    let loc = \"store\" in location ? location : new Location(location);\n    let node = await _open_v3(loc);\n    VERSION_COUNTER.increment(loc.store, \"v3\");\n    if (options.kind === undefined)\n        return node;\n    if (options.kind === \"array\" && node instanceof Array)\n        return node;\n    if (options.kind === \"group\" && node instanceof Group)\n        return node;\n    let kind = node instanceof Array ? \"array\" : \"group\";\n    throw new Error(`Expected node of kind ${options.kind}, found ${kind}.`);\n}\nexport async function open(location, options = {}) {\n    let store = \"store\" in location ? location.store : location;\n    let version_max = VERSION_COUNTER.version_max(store);\n    // Use the open function for the version with the most successful opens.\n    // Note that here we use the dot syntax to access the open functions\n    // because this enables us to use vi.spyOn during testing.\n    let open_primary = version_max === \"v2\" ? open.v2 : open.v3;\n    let open_secondary = version_max === \"v2\" ? open.v3 : open.v2;\n    return open_primary(location, options).catch((err) => {\n        rethrow_unless(err, NodeNotFoundError);\n        return open_secondary(location, options);\n    });\n}\nopen.v2 = open_v2;\nopen.v3 = open_v3;\n//# sourceMappingURL=open.js.map","/**\n * Custom array-like views (i.e., TypedArrays) for Zarr binary data buffers.\n *\n * @module\n */\n/**\n * An array-like view of a fixed-length boolean buffer.\n *\n * Encoded as 1 byte per value.\n */\nexport class BoolArray {\n    #bytes;\n    constructor(x, byteOffset, length) {\n        if (typeof x === \"number\") {\n            this.#bytes = new Uint8Array(x);\n        }\n        else if (x instanceof ArrayBuffer) {\n            this.#bytes = new Uint8Array(x, byteOffset, length);\n        }\n        else {\n            this.#bytes = new Uint8Array(Array.from(x, (v) => (v ? 1 : 0)));\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return 1;\n    }\n    get byteOffset() {\n        return this.#bytes.byteOffset;\n    }\n    get byteLength() {\n        return this.#bytes.byteLength;\n    }\n    get buffer() {\n        return this.#bytes.buffer;\n    }\n    get length() {\n        return this.#bytes.length;\n    }\n    get(idx) {\n        let value = this.#bytes[idx];\n        return typeof value === \"number\" ? value !== 0 : value;\n    }\n    set(idx, value) {\n        this.#bytes[idx] = value ? 1 : 0;\n    }\n    fill(value) {\n        this.#bytes.fill(value ? 1 : 0);\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n/**\n * An array-like view of a fixed-length byte buffer.\n *\n * Encodes a raw byte sequences without enforced encoding.\n */\nexport class ByteStringArray {\n    _data;\n    chars;\n    #encoder;\n    constructor(chars, x, byteOffset, length) {\n        this.chars = chars;\n        this.#encoder = new TextEncoder();\n        if (typeof x === \"number\") {\n            this._data = new Uint8Array(x * chars);\n        }\n        else if (x instanceof ArrayBuffer) {\n            if (length)\n                length = length * chars;\n            this._data = new Uint8Array(x, byteOffset, length);\n        }\n        else {\n            let values = Array.from(x);\n            this._data = new Uint8Array(values.length * chars);\n            for (let i = 0; i < values.length; i++) {\n                this.set(i, values[i]);\n            }\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return this.chars;\n    }\n    get byteOffset() {\n        return this._data.byteOffset;\n    }\n    get byteLength() {\n        return this._data.byteLength;\n    }\n    get buffer() {\n        return this._data.buffer;\n    }\n    get length() {\n        return this.byteLength / this.BYTES_PER_ELEMENT;\n    }\n    get(idx) {\n        const view = new Uint8Array(this.buffer, this.byteOffset + this.chars * idx, this.chars);\n        // biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n        return new TextDecoder().decode(view).replace(/\\x00/g, \"\");\n    }\n    set(idx, value) {\n        const view = new Uint8Array(this.buffer, this.byteOffset + this.chars * idx, this.chars);\n        view.fill(0); // clear current\n        view.set(this.#encoder.encode(value));\n    }\n    fill(value) {\n        const encoded = this.#encoder.encode(value);\n        for (let i = 0; i < this.length; i++) {\n            this._data.set(encoded, i * this.chars);\n        }\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n/**\n * An array-like view of a fixed-length Unicode string buffer.\n *\n * Encoded as UTF-32 code points.\n */\nexport class UnicodeStringArray {\n    #data;\n    chars;\n    constructor(chars, x, byteOffset, length) {\n        this.chars = chars;\n        if (typeof x === \"number\") {\n            this.#data = new Int32Array(x * chars);\n        }\n        else if (x instanceof ArrayBuffer) {\n            if (length)\n                length *= chars;\n            this.#data = new Int32Array(x, byteOffset, length);\n        }\n        else {\n            const values = x;\n            const d = new UnicodeStringArray(chars, 1);\n            this.#data = new Int32Array((function* () {\n                for (let str of values) {\n                    d.set(0, str);\n                    yield* d.#data;\n                }\n            })());\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return this.#data.BYTES_PER_ELEMENT * this.chars;\n    }\n    get byteLength() {\n        return this.#data.byteLength;\n    }\n    get byteOffset() {\n        return this.#data.byteOffset;\n    }\n    get buffer() {\n        return this.#data.buffer;\n    }\n    get length() {\n        return this.#data.length / this.chars;\n    }\n    get(idx) {\n        const offset = this.chars * idx;\n        let result = \"\";\n        for (let i = 0; i < this.chars; i++) {\n            result += String.fromCodePoint(this.#data[offset + i]);\n        }\n        // biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n        return result.replace(/\\u0000/g, \"\");\n    }\n    set(idx, value) {\n        const offset = this.chars * idx;\n        const view = this.#data.subarray(offset, offset + this.chars);\n        view.fill(0); // clear current\n        for (let i = 0; i < this.chars; i++) {\n            view[i] = value.codePointAt(i) ?? 0;\n        }\n    }\n    fill(value) {\n        // encode once\n        this.set(0, value);\n        // copy the encoded values to all other elements\n        let encoded = this.#data.subarray(0, this.chars);\n        for (let i = 1; i < this.length; i++) {\n            this.#data.set(encoded, i * this.chars);\n        }\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n//# sourceMappingURL=typedarray.js.map","import { BoolArray, ByteStringArray, UnicodeStringArray, } from \"./typedarray.js\";\nexport function json_encode_object(o) {\n    const str = JSON.stringify(o, null, 2);\n    return new TextEncoder().encode(str);\n}\nexport function json_decode_object(bytes) {\n    const str = new TextDecoder().decode(bytes);\n    return JSON.parse(str);\n}\nexport function byteswap_inplace(view, bytes_per_element) {\n    const numFlips = bytes_per_element / 2;\n    const endByteIndex = bytes_per_element - 1;\n    let t = 0;\n    for (let i = 0; i < view.length; i += bytes_per_element) {\n        for (let j = 0; j < numFlips; j += 1) {\n            t = view[i + j];\n            view[i + j] = view[i + endByteIndex - j];\n            view[i + endByteIndex - j] = t;\n        }\n    }\n}\nexport function get_ctr(data_type) {\n    if (data_type === \"v2:object\") {\n        return globalThis.Array;\n    }\n    let match = data_type.match(/v2:([US])(\\d+)/);\n    if (match) {\n        let [, kind, chars] = match;\n        // @ts-expect-error\n        return (kind === \"U\" ? UnicodeStringArray : ByteStringArray).bind(null, Number(chars));\n    }\n    // @ts-expect-error - We've checked that the key exists\n    let ctr = {\n        int8: Int8Array,\n        int16: Int16Array,\n        int32: Int32Array,\n        int64: globalThis.BigInt64Array,\n        uint8: Uint8Array,\n        uint16: Uint16Array,\n        uint32: Uint32Array,\n        uint64: globalThis.BigUint64Array,\n        float16: globalThis.Float16Array,\n        float32: Float32Array,\n        float64: Float64Array,\n        bool: BoolArray,\n    }[data_type];\n    assert(ctr, `Unknown or unsupported data_type: ${data_type}`);\n    return ctr;\n}\n/** Compute strides for 'C' or 'F' ordered array from shape */\nexport function get_strides(shape, order) {\n    const rank = shape.length;\n    if (typeof order === \"string\") {\n        order =\n            order === \"C\"\n                ? Array.from({ length: rank }, (_, i) => i) // Row-major (identity order)\n                : Array.from({ length: rank }, (_, i) => rank - 1 - i); // Column-major (reverse order)\n    }\n    assert(rank === order.length, \"Order length must match the number of dimensions.\");\n    let step = 1;\n    let stride = new Array(rank);\n    for (let i = order.length - 1; i >= 0; i--) {\n        stride[order[i]] = step;\n        step *= shape[order[i]];\n    }\n    return stride;\n}\n// https://zarr-specs.readthedocs.io/en/latest/v3/core/v3.0.html#chunk-key-encoding\nexport function create_chunk_key_encoder({ name, configuration, }) {\n    if (name === \"default\") {\n        const separator = configuration?.separator ?? \"/\";\n        return (chunk_coords) => [\"c\", ...chunk_coords].join(separator);\n    }\n    if (name === \"v2\") {\n        const separator = configuration?.separator ?? \".\";\n        return (chunk_coords) => chunk_coords.join(separator) || \"0\";\n    }\n    throw new Error(`Unknown chunk key encoding: ${name}`);\n}\nfunction coerce_dtype(dtype) {\n    if (dtype === \"|O\") {\n        return { data_type: \"v2:object\" };\n    }\n    let match = dtype.match(/^([<|>])(.*)$/);\n    assert(match, `Invalid dtype: ${dtype}`);\n    let [, endian, rest] = match;\n    let data_type = {\n        b1: \"bool\",\n        i1: \"int8\",\n        u1: \"uint8\",\n        i2: \"int16\",\n        u2: \"uint16\",\n        i4: \"int32\",\n        u4: \"uint32\",\n        i8: \"int64\",\n        u8: \"uint64\",\n        f2: \"float16\",\n        f4: \"float32\",\n        f8: \"float64\",\n    }[rest] ??\n        (rest.startsWith(\"S\") || rest.startsWith(\"U\") ? `v2:${rest}` : undefined);\n    assert(data_type, `Unsupported or unknown dtype: ${dtype}`);\n    if (endian === \"|\") {\n        return { data_type };\n    }\n    return { data_type, endian: endian === \"<\" ? \"little\" : \"big\" };\n}\nexport function v2_to_v3_array_metadata(meta, attributes = {}) {\n    let codecs = [];\n    let dtype = coerce_dtype(meta.dtype);\n    if (meta.order === \"F\") {\n        codecs.push({ name: \"transpose\", configuration: { order: \"F\" } });\n    }\n    if (\"endian\" in dtype && dtype.endian === \"big\") {\n        codecs.push({ name: \"bytes\", configuration: { endian: \"big\" } });\n    }\n    for (let { id, ...configuration } of meta.filters ?? []) {\n        codecs.push({ name: id, configuration });\n    }\n    if (meta.compressor) {\n        let { id, ...configuration } = meta.compressor;\n        codecs.push({ name: id, configuration });\n    }\n    return {\n        zarr_format: 3,\n        node_type: \"array\",\n        shape: meta.shape,\n        data_type: dtype.data_type,\n        chunk_grid: {\n            name: \"regular\",\n            configuration: {\n                chunk_shape: meta.chunks,\n            },\n        },\n        chunk_key_encoding: {\n            name: \"v2\",\n            configuration: {\n                separator: meta.dimension_separator ?? \".\",\n            },\n        },\n        codecs,\n        fill_value: meta.fill_value,\n        attributes,\n    };\n}\nexport function v2_to_v3_group_metadata(_meta, attributes = {}) {\n    return {\n        zarr_format: 3,\n        node_type: \"group\",\n        attributes,\n    };\n}\nexport function is_dtype(dtype, query) {\n    if (query !== \"number\" &&\n        query !== \"bigint\" &&\n        query !== \"boolean\" &&\n        query !== \"object\" &&\n        query !== \"string\") {\n        return dtype === query;\n    }\n    let is_boolean = dtype === \"bool\";\n    if (query === \"boolean\")\n        return is_boolean;\n    let is_string = dtype.startsWith(\"v2:U\") || dtype.startsWith(\"v2:S\");\n    if (query === \"string\")\n        return is_string;\n    let is_bigint = dtype === \"int64\" || dtype === \"uint64\";\n    if (query === \"bigint\")\n        return is_bigint;\n    let is_object = dtype === \"v2:object\";\n    if (query === \"object\")\n        return is_object;\n    return !is_string && !is_bigint && !is_boolean && !is_object;\n}\nexport function is_sharding_codec(codec) {\n    return codec?.name === \"sharding_indexed\";\n}\nexport function ensure_correct_scalar(metadata) {\n    if ((metadata.data_type === \"uint64\" || metadata.data_type === \"int64\") &&\n        metadata.fill_value != null) {\n        // @ts-expect-error - We've narrowed the type of fill_value correctly\n        return BigInt(metadata.fill_value);\n    }\n    return metadata.fill_value;\n}\n/**\n * Ensures an error matches expected type(s), otherwise rethrows.\n *\n * Unmatched errors bubble up, like Python's `except`. Narrows error types for\n * type-safe property access.\n *\n * @see {@link https://gist.github.com/manzt/3702f19abb714e21c22ce48851c75abf}\n *\n * @example\n * ```ts\n * class DatabaseError extends Error { }\n * class NetworkError extends Error { }\n *\n * try {\n *   await db.query();\n * } catch (err) {\n *   rethrow_unless(err, DatabaseError, NetworkError);\n *   err // DatabaseError | NetworkError\n * }\n * ```\n *\n * @param error - The error to check\n * @param errors - Expected error type(s)\n * @throws The original error if it doesn't match expected type(s)\n */\nexport function rethrow_unless(error, ...errors) {\n    if (!errors.some((ErrorClass) => error instanceof ErrorClass)) {\n        throw error;\n    }\n}\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(expression, msg = \"\") {\n    if (!expression) {\n        throw new Error(msg);\n    }\n}\n/**\n * @param {ArrayBuffer |ArrayBufferView | Response} data\n * @param {Object} options\n * @param {CompressionFormat} options.format\n * @param {AbortSignal} [options.signal]\n *\n * @returns {Promise<ArrayBuffer>}\n */\nexport async function decompress(data, { format, signal }) {\n    const response = data instanceof Response ? data : new Response(data);\n    assert(response.body, \"Response does not contain body.\");\n    try {\n        const decompressedResponse = new Response(response.body.pipeThrough(new DecompressionStream(format), { signal }));\n        const buffer = await decompressedResponse.arrayBuffer();\n        return buffer;\n    }\n    catch {\n        signal?.throwIfAborted();\n        throw new Error(`Failed to decode ${format}`);\n    }\n}\n//# sourceMappingURL=util.js.map"],"names":["Histogram","constructor","data","this","dataMinBin","dataMaxBin","maxBin","bins","Uint32Array","min","max","binSize","hinfo","calculateHistogram","i","length","pixelCount","findBin","dataValue","dataMin","numBins","binIndex","Math","floor","findBinOfValue","value","getDataMin","getDataMax","getMin","getMax","getNumBins","getBin","getBinRange","findBinOfPercentile","pct","limit","count","findBestFitBins","hmin","findAutoIJBins","pixcount","threshold","hmax","findAutoMinMax","th","b","e","x","arr","fill","item","volumeSize","volumeDims","shape","defaultImageInfo","name","atlasTileDims","subregionSize","subregionOffset","combinedNumChannels","channelNames","channelColors","multiscaleLevel","multiscaleLevelDims","spacing","spaceUnit","timeUnit","dataType","transform","translation","rotation","scale","CImageInfo","imageInfo","currentLevelDims","numChannels","originalSize","physicalPixelSize","spatialUnit","times","timeScale","numMultiscaleLevels","computeAtlasSize","volDims","allEqual","every","v","pushN","val","n","push","directionToIndex","dir","absDir","Number","updateMinMax","minmax","ChunkPrefetchIterator","chunks","tzyxMaxPrefetchOffset","tczyxChunksPerSource","priorityDirections","onlyPriorityDirections","extrema","Infinity","chunk","flat","some","isFinite","directionStates","priorityDirectionStates","direction","start","entries","dimension","tczyxIndex","end","endsPerSource","map","chunkDims","sourceEnd","directionState","includes","iterateDirections","directions","offset","filter","Array","isArray","offsetDir","newChunk","slice","Symbol","iterator","getSourceChannelNames","src","omeroMetadata","channels","label","idx","channelOffset","cIdx","axesTCZYX","scaleLevels","from","_","getDimensionCount","t","c","z","remapAxesToTCZYX","axes","axisNames","forEach","axis","axisIdx","indexOf","type","INVALID_METADATA","noXAxis","orderByDimension","valsTCZYX","orderTCZYX","specLen","result","orderByTCZYX","valsDimension","defaultValue","getScale","dataset","transforms","coordinateTransformations","undefined","console","warn","scaleTransform","find","compareZarrArraySize","aArr","aTCZYX","bArr","bTCZYX","diffZ","diffY","diffX","aboutEquals","a","abs","scaleTransformsAreEqual","aSrc","aLevel","bSrc","bLevel","aScale","multiscaleMetadata","datasets","bScale","matchSourceScaleLevels","sources","matchedLevels","matchedMetas","scaleIndexes","smallestIdx","smallestSrc","smallestArr","currentIdx","currentSrc","currentArr","ordering","INVALID_MULTI_SOURCE_ZARR","largestT","currentT","matchedScaleLevel","srcIdx","toOMEZarrMetaV4","meta","ome","isObjectWithProp","obj","prop","assertMetadataHasProp","assertPropIsArray","assertMetadataHasMultiscales","validateOMEZarrMetadata","multiscaleIdx","multiscaleMeta","multiscales","multiscaleName","fetch_range","url","opts","headers","Range","fetch","resolve","root","path","base","URL","pathname","endsWith","resolved","search","async","handle_response","response","status","Uint8Array","arrayBuffer","Error","statusText","options","overrides","useSuffixRequest","storeOverrides","requestOverrides","get","key","href","getRange","range","init","suffix_length","use_suffix_request","method","ok","content_length","fetch_suffix","suffixLength","wrapArray","array","basePath","cache","queue","keyBase","getChunk","coords","subscriber","reportChunk","fullKey","join","cacheResult","addRequest","isPrefetch","insert","Proxy","target","Function","args","apply","RelaxedFetchStore","baseUrl","super","message","startsWith","DEFAULT_REQUEST_CANCEL_REASON","RequestQueue","maxActiveRequests","maxLowPriorityRequests","allRequests","Map","activeRequests","Set","queueLowPriority","registerRequest","requestAction","promiseResolve","promiseReject","promise","Promise","reject","requestItem","action","set","addRequestToQueue","lowPriority","has","timeoutId","clearTimeout","dequeue","delayMs","lowPriorityIndex","splice","setTimeout","addRequests","requests","promises","numRequests","size","requestKey","shift","add","then","delete","cancelRequest","cancelReason","queueIndex","cancelAllRequests","keys","hasRequest","requestRunning","SubscribableRequestQueue","nextSubscriberId","subscribers","resolveAll","subscriberId","rejectAll","reason","addSubscriber","catch","existingRequest","rejectSubscription","subscriptions","findIndex","sub","rejecters","removeSubscriber","hasSubscriber","isSubscribed","WorkerMsgType","WorkerResponseResult","WorkerEventType","rebuildLoadSpec","spec","subregion","copy","BitroundCodec","kind","configuration","_meta","keepbits","fromConfig","encode","_arr","decode","LITTLE_ENDIAN_OS","buffer","byteOffset","byteLength","system_is_little_endian","bytes_per_element","TypedArray","BYTES_PER_ELEMENT","BytesCodec","endian","data_type","sample","bytes","stride","Crc32cCodec","GzipCodec","_bytes","format","throw_on_nan_replacer","_key","isNaN","POSITIVE_INFINITY","NEGATIVE_INFINITY","sort_keys_replacer","Object","sort","reduce","sorted","JsonCodec","encoding","skipkeys","ensure_ascii","check_circular","allow_nan","sort_keys","indent","strict","separators","buf","replacer_functions","items","replacer","new_value","sub_replacer","json_str","JSON","stringify","replace","chr","full_str","charCodeAt","toString","substring","TextEncoder","pop","proxy","TransposeCodec","order","rank","inverseOrder","source","s","index","entry","get_order","dim","matches_order","out","chars","empty_like","n_dims","src_data","out_data","src_idx","out_idx","convert_array_order","VLenUTF8","_chunk","decoder","TextDecoder","view","DataView","getUint32","pos","item_length","ZlibCodec","registry","m","default","create_codec_pipeline","chunk_metadata","codecs","load_codecs","codec","array_to_array","array_to_bytes","bytes_to_bytes","chunk_meta","Codec","MAX_BIG_UINT","create_sharded_chunk_getter","location","shard_shape","encode_shard_key","sharding_config","store","get_range","bind","index_shape","d","chunk_shape","index_codec","index_codecs","chunk_coord","shard_coord","shard_path","checksum_size","index_size","linear_offset","acc","sel","Location","Group","metadata","attrs","attributes","get_array_order","maybe_transpose_codec","CONTEXT_MARKER","get_context","fill_value","shared_context","encode_chunk_key","chunk_key_encoding","native_order","get_strides","get_chunk_bytes","chunk_grid","chunk_coords","chunk_key","chunk_path","create_context","dtype","context","maybe_bytes","is","query","IndexError","msg","IntDimIndexer","dim_sel","dim_len","dim_chunk_len","nitems","trunc","err_boundscheck","normalize_integer_selection","dim_chunk_ix","dim_offset","dim_chunk_sel","SliceDimIndexer","stop","step","nchunks","err_negative_step","ceil","dim_chunk_ix_from","dim_chunk_ix_to","dim_limit","dim_out_offset","dim_chunk_sel_start","remainder","dim_chunk_sel_stop","dim_out_sel","BasicIndexer","dim_indexers","selection","normalized","err_too_many_indices","check_selection_length","normalize_selection","ixr","sixr","dim_projections","p","mapping","to","object_array_view","subarray","compat_chunk","globalThis","setter","prepare","set_scalar","dest","set_scalar_binary","get_typed_array_constructor","compat_scalar","set_from_chunk","projections","set_from_chunk_binary","indexer","create_queue","onIdle","unwrap","indices_len","out_selection","slices","curr_stride","len","proj","projs","dstride","dstrides","sstride","sstrides","sfrom","sstep","product","iterables","iterators","it","results","next","r","done","slice_indices","step_is_negative","lower","upper","fn","all","VERSION_COUNTER","version_counts","WeakMap","get_counts","counts","v2","v3","increment","version","version_max","create_version_counter","open_array_v2","cause","open_group_v2","open","open_primary","open_secondary","err","loc","meta_bytes","load_attrs","node","meta_doc","node_type","_open_v3","BoolArray","ArrayBuffer","ByteStringArray","_data","values","encoded","UnicodeStringArray","Int32Array","str","String","fromCodePoint","codePointAt","json_decode_object","parse","byteswap_inplace","numFlips","endByteIndex","j","get_ctr","match","ctr","int8","Int8Array","int16","Int16Array","int32","int64","BigInt64Array","uint8","uint16","Uint16Array","uint32","uint64","BigUint64Array","float16","Float16Array","float32","Float32Array","float64","Float64Array","bool","assert","create_chunk_key_encoder","separator","v2_to_v3_array_metadata","rest","b1","i1","u1","i2","u2","i4","u4","i8","u8","f2","f4","f8","coerce_dtype","id","filters","compressor","zarr_format","dimension_separator","v2_to_v3_group_metadata","is_dtype","is_boolean","is_string","is_bigint","is_object","is_sharding_codec","ensure_correct_scalar","BigInt","rethrow_unless","error","errors","ErrorClass","expression","decompress","signal","Response","body","decompressedResponse","pipeThrough","DecompressionStream","throwIfAborted"],"sourceRoot":""}