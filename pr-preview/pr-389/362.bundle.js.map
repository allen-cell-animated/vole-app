{"version":3,"file":"362.bundle.js","mappings":"gIAMe,MAAMA,EAanB,WAAAC,CAAYC,GACVC,KAAKC,WAAa,EAClBD,KAAKE,WAAa,EAClBF,KAAKG,OAAS,EACdH,KAAKI,KAAO,IAAIC,YAChBL,KAAKM,IAAM,EACXN,KAAKO,IAAM,EACXP,KAAKQ,QAAU,EAGf,MAAMC,EAAQZ,EAAUa,mBAAmBX,EA7BjC,KA8BVC,KAAKI,KAAOK,EAAML,KAClBJ,KAAKM,IAAMG,EAAMH,IACjBN,KAAKO,IAAME,EAAMF,IACjBP,KAAKQ,QAAUC,EAAMD,QAIrB,IAAK,IAAIG,EAAI,EAAGA,EAAIX,KAAKI,KAAKQ,OAAQD,IACpC,GAAIX,KAAKI,KAAKO,GAAK,EAAG,CACpBX,KAAKC,WAAaU,EAClB,KACF,CAEF,IAAK,IAAIA,EAAIX,KAAKI,KAAKQ,OAAS,EAAGD,GAAK,EAAGA,IACzC,GAAIX,KAAKI,KAAKO,GAAK,EAAG,CACpBX,KAAKE,WAAaS,EAClB,KACF,CAEFX,KAAKa,WAAad,EAAKa,OAGvBZ,KAAKG,OAAS,EACd,IAAII,EAAMP,KAAKI,KAAK,GACpB,IAAK,IAAIO,EAAI,EAAGA,EAAIX,KAAKI,KAAKQ,OAAQD,IAChCX,KAAKI,KAAKO,GAAKJ,IACjBP,KAAKG,OAASQ,EACdJ,EAAMP,KAAKI,KAAKO,GAGtB,CAGA,cAAOG,CAAQC,EAAWC,EAASR,EAASS,GAC1C,IAAIC,EAAWC,KAAKC,OAAOL,EAAYC,GAAWR,GAKlD,OAHIU,IAAaD,GACfC,IAEKA,CACT,CAGA,cAAAG,CAAeC,GACb,OAAOzB,EAAUiB,QAAQQ,EAAOtB,KAAKM,IAAKN,KAAKQ,QA1ErC,IA2EZ,CAMA,UAAAe,GACE,OAAOvB,KAAKM,GACd,CAMA,UAAAkB,GACE,OAAOxB,KAAKO,GACd,CAMA,MAAAkB,GACE,OAAOzB,KAAKC,UACd,CAMA,MAAAyB,GAEE,OAAO1B,KAAKE,UACd,CACA,UAAAyB,GACE,OAAO3B,KAAKI,KAAKQ,MACnB,CACA,MAAAgB,CAAOjB,GACL,OAAOX,KAAKI,KAAKO,EACnB,CACA,WAAAkB,CAAYlB,GACV,MAAO,CAACX,KAAKM,IAAMK,EAAIX,KAAKQ,QAASR,KAAKM,KAAOK,EAAI,GAAKX,KAAKQ,QACjE,CAOA,mBAAAsB,CAAoBC,GAClB,MAAMC,EAAQhC,KAAKa,WAAakB,EAChC,IAAIpB,EAAI,EACJsB,EAAQ,EACZ,IAAKtB,EAAI,EAAGA,EAAIX,KAAKI,KAAKQ,SACxBqB,GAASjC,KAAKI,KAAKO,KACfsB,EAAQD,MAFsBrB,GAMpC,OAAOA,CACT,CAGA,eAAAuB,GACE,MAEMF,EAFWhC,KAAKa,WAEG,GACzB,IAAIF,EAAI,EACJsB,EAAQ,EACZ,IAAKtB,EAAI,EAAGA,EAAIX,KAAKI,KAAKQ,SACxBqB,GAASjC,KAAKI,KAAKO,KACfsB,EAAQD,MAFsBrB,GAMpC,MAAMwB,EAAOxB,EAEb,IADAsB,EAAQ,EACHtB,EAAIX,KAAKI,KAAKQ,OAAS,EAAGD,GAAK,IAClCsB,GAASjC,KAAKI,KAAKO,KACfsB,EAAQD,MAF2BrB,GAOzC,MAAO,CAACwB,EADKxB,EAEf,CAGA,cAAAyB,GAGE,MACMC,EAAWrC,KAAKa,WAEhBmB,EAAQK,EAAW,GACnBC,EAAYD,EAJK,IAOvB,IAAIF,EAAOnC,KAAKI,KAAKQ,OAAS,EAC1B2B,EAAO,EACX,IAAK,IAAI5B,EAAI,EAAGA,EAAIX,KAAKI,KAAKQ,SAAUD,EACtC,GAAIX,KAAKI,KAAKO,GAAK2B,GAAatC,KAAKI,KAAKO,IAAMqB,EAAO,CACrDG,EAAOxB,EACP,KACF,CAEF,IAAK,IAAIA,EAAIX,KAAKI,KAAKQ,OAAS,EAAGD,GAAK,IAAKA,EAC3C,GAAIX,KAAKI,KAAKO,GAAK2B,GAAatC,KAAKI,KAAKO,IAAMqB,EAAO,CACrDO,EAAO5B,EACP,KACF,CAMF,OAJI4B,EAAOJ,IACTA,EAAO,EACPI,EAAO,KAEF,CAACJ,EAAMI,EAChB,CAGA,cAAAC,GAGE,MACMC,EAAKtB,KAAKC,MADG,GACGpB,KAAKI,KAAKJ,KAAKG,SACrC,IAAIuC,EAAI,EACJC,EAAI3C,KAAKI,KAAKQ,OAAS,EAC3B,IAAK,IAAIgC,EAAI,EAAGA,EAAI5C,KAAKI,KAAKQ,SAAUgC,EACtC,GAAI5C,KAAKI,KAAKwC,GAAKH,EAAI,CACrBC,EAAIE,EACJ,KACF,CAEF,IAAK,IAAIA,EAAI5C,KAAKI,KAAKQ,OAAS,EAAGgC,GAAK,IAAKA,EAC3C,GAAI5C,KAAKI,KAAKwC,GAAKH,EAAI,CACrBE,EAAIC,EACJ,KACF,CAEF,MAAO,CAACF,EAAGC,EACb,CACA,yBAAOjC,CAAmBmC,EAAK5B,EAAU,GACnCA,EAAU,IACZA,EAAU,GAQZ,IAAIX,EAAMuC,EAAI,GACVtC,EAAMsC,EAAI,GACd,IAAK,IAAIlC,EAAI,EAAGA,EAAIkC,EAAIjC,OAAQD,IAC1BkC,EAAIlC,GAAKL,EACXA,EAAMuC,EAAIlC,GACDkC,EAAIlC,GAAKJ,IAClBA,EAAMsC,EAAIlC,IAGd,MAAMP,EAAO,IAAIC,YAAYY,GAAS6B,KAAK,GACrCtC,GAAWD,EAAMD,GAAOW,GAAY,EAAI,GAAKV,EAAMD,GAAOW,EAChE,IAAK,IAAIN,EAAI,EAAGA,EAAIkC,EAAIjC,OAAQD,IAAK,CACnC,MAAMoC,EAAOF,EAAIlC,GAEjBP,EADiBP,EAAUiB,QAAQiC,EAAMzC,EAAKE,EAASS,KAEzD,CACA,MAAO,CACLb,OACAE,MACAC,MACAC,UAEJ,E,mEC9OK,SAASwC,EAAWC,GACzB,OAAO,IAAI,MAAQA,EAAWC,MAAM,GAAID,EAAWC,MAAM,GAAID,EAAWC,MAAM,GAChF,CCVO,SAASC,IACd,MAAO,CACLC,KAAM,GACNC,cAAe,CAAC,EAAG,GACnBC,cAAe,CAAC,EAAG,EAAG,GACtBC,gBAAiB,CAAC,EAAG,EAAG,GACxBC,oBAAqB,EACrBC,aAAc,CAAC,KACfC,cAAe,CAAC,CAAC,IAAK,IAAK,MAC3BC,gBAAiB,EACjBC,oBAAqB,CAAC,CACpBV,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBW,QAAS,CAAC,EAAG,EAAG,EAAG,EAAG,GACtBC,UAAW,GACXC,SAAU,GACVC,SAAU,UAEZC,UAAW,CACTC,YAAa,CAAC,EAAG,EAAG,GACpBC,SAAU,CAAC,EAAG,EAAG,GACjBC,MAAO,CAAC,EAAG,EAAG,IAGpB,CACO,MAAMC,EACX,WAAAvE,CAAYwE,GACVtE,KAAKsE,UAAYA,GAzBZ,CACLlB,KAAM,GACNC,cAAe,CAAC,EAAG,GACnBC,cAAe,CAAC,EAAG,EAAG,GACtBC,gBAAiB,CAAC,EAAG,EAAG,GACxBC,oBAAqB,EACrBC,aAAc,CAAC,KACfC,cAAe,CAAC,CAAC,IAAK,IAAK,MAC3BC,gBAAiB,EACjBC,oBAAqB,CAAC,CACpBV,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBW,QAAS,CAAC,EAAG,EAAG,EAAG,EAAG,GACtBC,UAAW,GACXC,SAAU,GACVC,SAAU,UAEZC,UAAW,CACTC,YAAa,CAAC,EAAG,EAAG,GACpBC,SAAU,CAAC,EAAG,EAAG,GACjBC,MAAO,CAAC,EAAG,EAAG,IAOlB,CACA,oBAAIG,GACF,OAAOvE,KAAKsE,UAAUV,oBAAoB5D,KAAKsE,UAAUX,gBAC3D,CAGA,eAAIa,GACF,OAAOxE,KAAKsE,UAAUd,mBACxB,CAGA,gBAAIiB,GACF,OAAOzB,EAAWhD,KAAKsE,UAAUV,oBAAoB,GACvD,CAGA,cAAIZ,GACF,OAAOA,EAAWhD,KAAKuE,iBACzB,CAGA,qBAAIG,GACF,ODtC8BzB,ECsCLjD,KAAKsE,UAAUV,oBAAoB,GDrCvD,IAAI,MAAQX,EAAWY,QAAQ,GAAIZ,EAAWY,QAAQ,GAAIZ,EAAWY,QAAQ,IAD/E,IAA2BZ,CCuChC,CAGA,eAAI0B,GACF,OAAO3E,KAAKsE,UAAUV,oBAAoB,GAAGE,SAC/C,CAGA,SAAIc,GAEF,OAAO5E,KAAKuE,iBAAiBrB,MAAM,EACrC,CAGA,aAAI2B,GAEF,OAAO7E,KAAKuE,iBAAiBV,QAAQ,EACvC,CAGA,YAAIE,GACF,OAAO/D,KAAKuE,iBAAiBR,QAC/B,CAGA,uBAAIe,GACF,OAAO9E,KAAKsE,UAAUV,oBAAoBhD,MAC5C,CAGA,gBAAI6C,GACF,OAAOzD,KAAKsE,UAAUb,YACxB,CAGA,iBAAIC,GACF,OAAO1D,KAAKsE,UAAUZ,aACxB,CAGA,iBAAIJ,GACF,OAAO,IAAI,SAAWtD,KAAKsE,UAAUhB,cACvC,CAGA,mBAAIC,GACF,OAAO,IAAI,SAAWvD,KAAKsE,UAAUf,gBACvC,CACA,mBAAII,GACF,OAAO3D,KAAKsE,UAAUX,eACxB,CAMA,iBAAIN,GACF,OAAO,IAAI,SAAWrD,KAAKsE,UAAUjB,cACvC,CACA,aAAIY,GACF,MAAO,CACLC,YAAa,IAAI,SAAWlE,KAAKsE,UAAUL,UAAUC,aACrDC,SAAU,IAAI,SAAWnE,KAAKsE,UAAUL,UAAUE,UAClDC,MAAO,IAAI,SAAWpE,KAAKsE,UAAUL,UAAUG,OAEnD,EAEK,SAASW,EAAiBT,GAC/B,MAAM,cACJjB,GACEiB,EACEU,EAAUV,EAAUV,oBAAoBU,EAAUX,iBAExD,MAAO,CAACN,EAAc,GAAK2B,EAAQ9B,MAAM,GAAIG,EAAc,GAAK2B,EAAQ9B,MAAM,GAChF,C,kCC9HA,MAAM+B,EAAWpC,GAAOA,EAAIqC,OAAMC,GAAKA,IAAMtC,EAAI,KAC3CuC,EAAQ,CAACvC,EAAKwC,EAAKC,KACvB,IAAK,IAAI3E,EAAI,EAAGA,EAAI2E,EAAG3E,IACrBkC,EAAI0C,KAAKF,EACX,EAEIG,EAAmBC,IACvB,MAAMC,EAASD,GAAO,EACtB,OAAOC,EAASC,OAAkB,IAAXD,EAAa,EAEtC,SAASE,EAAaP,EAAKQ,GACrBR,EAAMQ,EAAO,KACfA,EAAO,GAAKR,GAEVA,EAAMQ,EAAO,KACfA,EAAO,GAAKR,EAEhB,CAQe,MAAMS,EACnB,WAAAhG,CAAYiG,EAAQC,EAAuBC,EAAsBC,EAAoBC,GAAyB,GAE5G,MAAMC,EAAU,CAAC,CAACC,KAAU,KAAY,CAACA,KAAU,KAAY,CAACA,KAAU,KAAY,CAACA,KAAU,MACjG,IAAK,MAAMC,KAASP,EAClBH,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAIjC,GAAIA,EAAQG,OAAOC,MAAKnB,IAAQM,OAAOc,SAASpB,KAG9C,OAFArF,KAAK0G,gBAAkB,QACvB1G,KAAK2G,wBAA0B,IAKjC3G,KAAK0G,gBAAkB,GACvB1G,KAAK2G,wBAA0B,GAK/B,IAAK,MAAOC,EAAWC,KAAUT,EAAQG,OAAOO,UAAW,CACzD,MAAMC,EAAYH,GAAa,EACzBI,EAAaD,EAAYpB,OAAqB,IAAdoB,GACtC,IAAIE,EACJ,GAAgB,EAAZL,EAAe,CAGjB,MAAMM,EAAgBjB,EAAqBkB,KAAIC,GACtCjG,KAAKb,IAAIuG,EAAQb,EAAsBe,GAAYK,EAAUJ,GAAc,KAIpF,GAAI/B,EAASiC,GACXD,EAAMC,EAAc,OACf,CAELD,EAAM,GACN,IAAK,MAAOtG,EAAG0G,KAAcH,EAAcJ,UACzC1B,EAAM6B,EAAKI,EAAWpB,EAAqBtF,GAAG,GAElD,CAEF,MAGEsG,EAAM9F,KAAKZ,IAAIsG,EAAQb,EAAsBe,GAAY,GAE3D,MAAMO,EAAiB,CACrBV,YACAC,QACAI,MACAlB,OAAQ,IAENG,GAAsBA,EAAmBqB,SAASX,GACpD5G,KAAK2G,wBAAwBpB,KAAK+B,GAG7BnB,GACHnG,KAAK0G,gBAAgBnB,KAAK+B,EAGhC,CAGA,IAAK,MAAMhB,KAASP,EAAQ,CAC1B,IAAK,MAAMN,KAAOzF,KAAK0G,gBACjBJ,EAAMd,EAAiBC,EAAImB,cAAgBnB,EAAIoB,OACjDpB,EAAIM,OAAOR,KAAKe,GAGpB,IAAK,MAAMb,KAAOzF,KAAK2G,wBACjBL,EAAMd,EAAiBC,EAAImB,cAAgBnB,EAAIoB,OACjDpB,EAAIM,OAAOR,KAAKe,EAGtB,CACF,CACA,wBAAQkB,CAAkBC,GACxB,IAAIC,EAAS,EACb,KAAOD,EAAW7G,OAAS,GAAG,CAE5B6G,EAAaA,EAAWE,QAAOlC,IAC7B,MAAMwB,EAAMW,MAAMC,QAAQpC,EAAIwB,KAAO9F,KAAKZ,OAAOkF,EAAIwB,KAAOxB,EAAIwB,IAChE,OAAoB,EAAhBxB,EAAImB,UACCnB,EAAIoB,MAAQa,GAAUT,EAEtBxB,EAAIoB,MAAQa,GAAUT,CAC/B,IAIF,IAAK,MAAMxB,KAAOgC,EAAY,CAC5B,MAAMK,EAAYJ,GAA0B,EAAhBjC,EAAImB,UAAgB,GAAK,GACrD,IAAK,MAAMN,KAASb,EAAIM,OAAQ,CAE9B,GAAI6B,MAAMC,QAAQpC,EAAIwB,MAAQX,EAAMd,EAAiBC,EAAImB,YAAckB,EAAYrC,EAAIwB,IAAIX,EAAM,IAC/F,SAEF,MAAMyB,EAAWzB,EAAM0B,QACvBD,EAASvC,EAAiBC,EAAImB,aAAekB,QACvCC,CACR,CACF,CACAL,GAAU,CACZ,CACF,CACA,EAAEO,OAAOC,YAEP,GAAIlI,KAAK2G,wBAAwB/F,OAAS,EACxC,IAAK,MAAM0F,KAASR,EAAsB0B,kBAAkBxH,KAAK2G,+BACzDL,EAKV,IAAK,MAAMA,KAASR,EAAsB0B,kBAAkBxH,KAAK0G,uBACzDJ,CAEV,E,6FClJK,SAAS6B,EAAsBC,GACpC,GAAIA,EAAIC,eAAeC,SACrB,OAAOF,EAAIC,cAAcC,SAASnB,KAAI,EACpCoB,SACCC,IAAQD,GAAS,WAAWC,EAAMJ,EAAIK,kBAE3C,MAAMC,EAAON,EAAIO,UAAU,GACrB/H,EAAS8H,EAAO,EAAI,EAAIN,EAAIQ,YAAY,GAAG1F,MAAMwF,GACvD,OAAOd,MAAMiB,KAAK,CAChBjI,WACC,CAACkI,EAAGN,IAAQ,WAAWA,EAAMJ,EAAIK,iBACtC,CAGO,MAAMM,EAAoB,EAAEC,EAAGC,EAAGC,KAAO,EAAIvD,OAAOqD,GAAK,GAAKrD,OAAOsD,GAAK,GAAKtD,OAAOuD,GAAK,GAC3F,SAASC,EAAiBC,GAC/B,MAAMT,EAAY,EAAE,GAAI,GAAI,GAAI,GAAI,GAC9BU,EAAY,CAAC,IAAK,IAAK,IAAK,IAAK,KACvCD,EAAKE,SAAQ,CAACC,EAAMf,KAClB,MAAMgB,EAAUH,EAAUI,QAAQF,EAAKnG,MACvC,KAAIoG,GAAW,GAGb,MAAM,IAAI,KAAgB,8BAA8BD,EAAKnG,OAAQ,CACnEsG,KAAM,KAAoBC,mBAH5BhB,EAAUa,GAAWhB,CAKvB,IAIF,MAAMoB,GAA4B,IAAlBjB,EAAU,GAC1B,GAAIiB,IAA6B,IAAlBjB,EAAU,GACvB,MAAM,IAAI,KAAgB,gBAAgBiB,EAAU,OAAS,qBAAsB,CACjFF,KAAM,KAAoBC,mBAG9B,OAAOhB,CACT,CAGO,SAASkB,EAAiBC,EAAWC,GAC1C,MAAMC,EAAUjB,EAAkBgB,GAC5BE,EAASrC,MAAMoC,GAWrB,OAVAD,EAAWT,SAAQ,CAACjE,EAAKmD,KACvB,GAAInD,GAAO,EAAG,CACZ,GAAIA,GAAO2E,EACT,MAAM,IAAI,KAAgB,kCAAkC3E,IAAO,CACjEqE,KAAM,KAAoBC,mBAG9BM,EAAO5E,GAAOyE,EAAUtB,EAC1B,KAEKyB,CACT,CAGO,SAASC,EAAaC,EAAeJ,EAAYK,GACtD,MAAMH,EAAS,CAACG,EAAcA,EAAcA,EAAcA,EAAcA,GAWxE,OAVAL,EAAWT,SAAQ,CAACjE,EAAKmD,KACvB,GAAInD,GAAO,EAAG,CACZ,GAAIA,GAAO8E,EAAcvJ,OACvB,MAAM,IAAI,KAAgB,kCAAkCyE,IAAO,CACjEqE,KAAM,KAAoBC,mBAG9BM,EAAOzB,GAAO2B,EAAc9E,EAC9B,KAEK4E,CACT,CAGO,SAASI,EAASC,EAASP,GAChC,MAAMQ,EAAaD,EAAQE,0BAC3B,QAAmBC,IAAfF,EAEF,OADAG,QAAQC,KAAK,0EACN,CAAC,EAAG,EAAG,EAAG,EAAG,GAItB,MAIMC,EAAiBL,EAAWM,MAJT7B,GAAgB,UAAXA,EAAEU,OAKhC,OAAKkB,EAKEV,EADOU,EAAexG,MAAM4D,QACR+B,EAAY,IAJrCW,QAAQC,KAAK,yFACN,CAAC,EAAG,EAAG,EAAG,EAAG,GAIxB,CAQA,SAASG,EAAqBC,EAAMC,EAAQC,EAAMC,GAChD,MAEMC,GAFKH,EAAO,IAAM,EAAID,EAAK7H,MAAM8H,EAAO,IAAM,IACzCE,EAAO,IAAM,EAAID,EAAK/H,MAAMgI,EAAO,IAAM,GAE9CE,EAAQL,EAAK7H,MAAM8H,EAAO,IAAMC,EAAK/H,MAAMgI,EAAO,IAClDG,EAAQN,EAAK7H,MAAM8H,EAAO,IAAMC,EAAK/H,MAAMgI,EAAO,IACxD,OAAc,IAAVC,GAAyB,IAAVC,GAAyB,IAAVC,EACzB,EACEF,GAAS,GAAKC,GAAS,GAAKC,GAAS,GACtC,EACCF,GAAS,GAAKC,GAAS,GAAKC,GAAS,EACvC,OAEP,CAEJ,CACA,MACMC,EAAc,CAACC,EAAG7I,IAAMvB,KAAKqK,IAAID,EAAI7I,GAD3B,KAEhB,SAAS+I,EAAwBC,EAAMC,EAAQC,EAAMC,GACnD,MAAMC,EAASzB,EAASqB,EAAKK,mBAAmBC,SAASL,GAASD,EAAK/C,WACjEsD,EAAS5B,EAASuB,EAAKG,mBAAmBC,SAASH,GAASD,EAAKjD,WACvE,OAAO2C,EAAYQ,EAAO,GAAIG,EAAO,KAAOX,EAAYQ,EAAO,GAAIG,EAAO,KAAOX,EAAYQ,EAAO,GAAIG,EAAO,GACjH,CAYO,SAASC,EAAuBC,GACrC,GAAIA,EAAQvL,OAAS,EACnB,OAIF,MAAMwL,EAAgBxE,MAAMiB,KAAK,CAC/BjI,OAAQuL,EAAQvL,SACf,IAAM,KACHyL,EAAezE,MAAMiB,KAAK,CAC9BjI,OAAQuL,EAAQvL,SACf,IAAM,KAGH0L,EAAe,IAAI1E,MAAMuE,EAAQvL,QAAQkC,KAAK,GACpD,KAAOwJ,EAAapH,OAAM,CAACG,EAAKmD,IAAQnD,EAAM8G,EAAQ3D,GAAKI,YAAYhI,UAAS,CAE9E,IAAIqE,GAAW,EACXsH,EAAc,EACdC,EAAcL,EAAQ,GACtBM,EAAcD,EAAY5D,YAAY0D,EAAa,IACvD,IAAK,IAAII,EAAa,EAAGA,EAAaP,EAAQvL,OAAQ8L,IAAc,CAClE,MAAMC,EAAaR,EAAQO,GACrBE,EAAaD,EAAW/D,YAAY0D,EAAaI,IACjDG,EAAW/B,EAAqB2B,EAAaD,EAAY7D,UAAWiE,EAAYD,EAAWhE,WACjG,GAAKkE,EA0BH5H,GAAW,EACP4H,EAAW,IACbN,EAAcG,EACdF,EAAcG,EACdF,EAAcG,OA9BH,CAEb,QAAiBnC,IAAboC,EACF,MAAM,IAAI,KAAgB,4DAA6D,CACrFnD,KAAM,KAAoBoD,4BAMzBrB,EAAwBe,EAAaF,EAAaC,GAAcI,EAAYL,EAAaI,KAI5FhC,QAAQC,KAAK,6FAIf,MAAMoC,EAAWP,EAAY7D,UAAU,IAAM,EAAI8D,EAAYvJ,MAAMsJ,EAAY7D,UAAU,IAAM,EACzFqE,EAAWL,EAAWhE,UAAU,IAAM,EAAIiE,EAAW1J,MAAMyJ,EAAWhE,UAAU,IAAM,EACxFoE,IAAaC,GAGftC,QAAQC,KAAK,6DAA6DoC,QAAeC,IAE7F,CAQF,CACA,GAAI/H,EAEF,IAAK,IAAItE,EAAI,EAAGA,EAAI2L,EAAa1L,OAAQD,IAAK,CAC5C,MAAMgM,EAAaR,EAAQxL,GACrBsM,EAAoBX,EAAa3L,GACvCyL,EAAczL,GAAG4E,KAAKoH,EAAW/D,YAAYqE,IAC7CZ,EAAa1L,GAAG4E,KAAKoH,EAAWZ,mBAAmBC,SAASiB,IAC5DX,EAAa3L,IAAM,CACrB,MAGA,IAAK,MAAO6H,EAAK0E,KAAWZ,EAAaxF,UAAW,CAClD,MAAM6F,EAAaR,EAAQ3D,GACrBoE,EAAaD,EAAW/D,YAAYsE,GAEzB,IADApC,EAAqB2B,EAAaD,EAAY7D,UAAWiE,EAAYD,EAAWhE,aAE/F2D,EAAa9D,IAAQ,EAEzB,CAEJ,CACA,GAAsC,IAAlC2D,EAAQ,GAAGvD,YAAYhI,OACzB,MAAM,IAAI,KAAgB,sFAAuF,CAC/G8I,KAAM,KAAoBoD,4BAG9B,IAAK,IAAInM,EAAI,EAAGA,EAAIwL,EAAQvL,OAAQD,IAClCwL,EAAQxL,GAAGiI,YAAcwD,EAAczL,GACvCwL,EAAQxL,GAAGoL,mBAAmBC,SAAWK,EAAa1L,EAE1D,C,kEC1NO,MAAMwM,EAAkBC,GAAQA,EAAKC,KAAOD,EACnD,SAASE,EAAiBC,EAAKC,GAC7B,MAAsB,iBAARD,GAA4B,OAARA,GAAgBC,KAAQD,CAC5D,CACA,SAASE,EAAsBF,EAAKC,EAAMpK,EAAO,QAC/C,IAAKkK,EAAiBC,EAAKC,GACzB,MAAM,IAAI,KAAgB,GAAGpK,yCAA4CoK,KAAS,CAChF9D,KAAM,KAAoBC,kBAGhC,CACA,SAAS+D,EAAkBH,EAAKC,EAAMpK,EAAO,QAC3C,IAAKwE,MAAMC,QAAQ0F,EAAIC,IACrB,MAAM,IAAI,KAAgB,GAAGpK,qBAAwBoK,qBAAyB,CAC5E9D,KAAM,KAAoBC,kBAGhC,CAIO,SAASgE,EAA6BP,EAAMhK,EAAO,QAExDqK,EAAsBL,EAAM,cAAehK,GAC3CsK,EAAkBN,EAAM,cAAehK,EACzC,CAOO,SAASwK,EAAwBR,EAAMS,EAAgB,EAAGzK,EAAO,QAEtE,MAAM0K,EAAiBV,EAAKW,YAAYF,GACxC,IAAKC,EACH,MAAM,IAAI,KAAgB,GAAG1K,uDAA0DyK,IAAiB,CACtGnE,KAAM,KAAoBC,mBAG9B,MACMqE,EAAiB,GAAG5K,gBAAmByK,IADlBP,EAAiBQ,EAAgB,QAAU,MAAMA,EAAe1K,QAAU,KAIrGqK,EAAsBK,EAAgB,OAAQE,GAC9CN,EAAkBI,EAAgB,OAAQE,GAC1CF,EAAe1E,KAAKE,SAAQ,CAACC,EAAM5I,IAAM8M,EAAsBlE,EAAM,OAAQ,GAAGyE,UAAuBrN,OAGvG8M,EAAsBK,EAAgB,WAAY1K,GAClDsK,EAAkBI,EAAgB,WAAY1K,GAC9C0K,EAAe9B,SAAS1C,SAAQ,CAACvJ,EAAMY,IAAM8M,EAAsB1N,EAAM,OAAQ,GAAGiO,aAA0BrN,MAChH,C,+CC1De,SAASsN,EAAUC,EAAOC,EAAUC,EAAOC,GACxD,MACMC,GADOH,EAASI,SAAS,KAAOJ,EAASnG,MAAM,GAAI,GAAKmG,GACvCD,EAAMM,MAAQN,EAAMM,KAAKD,SAAS,KAAO,GAAK,KAC/DE,EAAWC,MAAOC,EAAQC,KAC1BA,GAAMC,YAAcD,EAAKE,aAC3BF,EAAKE,YAAYH,EAAQC,EAAKC,YAEhC,MAAME,EAAUT,EAAUK,EAAOK,KAAK,KAChCC,EAAcb,GAAOc,IAAIH,GAC/B,GAAIE,IAAe,OAAQA,GACzB,OAAOA,EAET,IAAIhF,EAOJ,OALEA,EADEoE,GAASO,GAAMC,iBACFR,EAAMc,WAAWJ,EAASH,GAAMC,YAAY,IAAMX,EAAMO,SAASE,EAAQC,IAAOA,EAAKQ,kBAErFlB,EAAMO,SAASE,EAAQC,GAExCR,GAAOiB,OAAON,EAAS9E,GAChBA,CAAM,EAEf,OAAO,IAAIqF,MAAMpB,EAAO,CACtBgB,IAAK,CAACK,EAAQ/B,KACZ,GAAa,aAATA,EACF,OAAOiB,EAIT,MAAMnN,EAAQiO,EAAO/B,GACrB,OAAIlM,aAAiBkO,SACZ,YAAaC,GAClB,OAAOnO,EAAMoO,MAAMH,EAAQE,EAC7B,EAEKnO,CAAK,GAGlB,C,kCCpCO,MAAMqO,EAAgC,oBAW9B,MAAMC,EA0BnB,WAAA9P,CAAY+P,EAAoB,GAAIC,EAAyB,GAC3D9P,KAAK+P,YAAc,IAAIC,IACvBhQ,KAAKiQ,eAAiB,IAAIC,IAC1BlQ,KAAKqO,MAAQ,GACbrO,KAAKmQ,iBAAmB,GACxBnQ,KAAK6P,kBAAoBA,EACzB7P,KAAK8P,uBAAyB3O,KAAKb,IAAIuP,EAAmBC,EAC5D,CAQA,eAAAM,CAAgBC,EAAKC,GAInB,IAAIC,EAAgBC,EACpB,MAAMC,EAAU,IAAIC,SAAQ,CAACC,EAASC,KACpCL,EAAiBI,EACjBH,EAAgBI,CAAM,IAGlBC,EAAc,CAClBR,IAAKA,EACLS,OAAQR,EACRK,QAASJ,EACTK,OAAQJ,EACRC,WAGF,OADAzQ,KAAK+P,YAAYgB,IAAIV,EAAKQ,GACnBA,CACT,CAOA,iBAAAG,CAAkBX,EAAKY,GAErB,GAAIjR,KAAK+P,YAAYmB,IAAIb,GAAM,CAE7B,MAAMQ,EAAc7Q,KAAK+P,YAAYb,IAAImB,GACrCQ,GAAeA,EAAYM,YAC7BC,aAAaP,EAAYM,WACzBN,EAAYM,eAAY1G,GAErBzK,KAAKqO,MAAM9G,SAAS8I,IAASrQ,KAAKmQ,iBAAiB5I,SAAS8I,KAE3DY,EACFjR,KAAKmQ,iBAAiB5K,KAAK8K,GAE3BrQ,KAAKqO,MAAM9I,KAAK8K,GAElBrQ,KAAKqR,UAET,CACF,CAoBA,UAAAlC,CAAWkB,EAAKC,EAAeW,GAAc,EAAOK,EAAU,GAC5D,GAAKtR,KAAK+P,YAAYmB,IAAIb,GAYnB,CACL,MAAMkB,EAAmBvR,KAAKmQ,iBAAiB1G,QAAQ4G,GACnDkB,GAAoB,IAAMN,GAG5BjR,KAAKmQ,iBAAiBqB,OAAOD,EAAkB,GAC/CvR,KAAKgR,kBAAkBX,IACdiB,GAAW,GAGpBtR,KAAKgR,kBAAkBX,EAAKY,EAEhC,KAxBgC,CAE9B,MAAMJ,EAAc7Q,KAAKoQ,gBAAgBC,EAAKC,GAE9C,GAAIgB,EAAU,EAAG,CACf,MAAMH,EAAYM,YAAW,IAAMzR,KAAKgR,kBAAkBX,EAAKY,IAAcK,GAE7ET,EAAYM,UAAYA,CAC1B,MAEEnR,KAAKgR,kBAAkBX,EAAKY,EAEhC,CAaA,MAAMR,EAAUzQ,KAAK+P,YAAYb,IAAImB,IAAMI,QAC3C,IAAKA,EACH,MAAM,IAAIiB,MAAM,gEAElB,OAAOjB,CACT,CAaA,WAAAkB,CAAYC,EAAUX,GAAc,EAAOK,EAAU,IACnD,MAAMO,EAAW,GACjB,IAAK,IAAIlR,EAAI,EAAGA,EAAIiR,EAAShR,OAAQD,IAAK,CACxC,MAAMoC,EAAO6O,EAASjR,GAChB8P,EAAUzQ,KAAKmP,WAAWpM,EAAKsN,IAAKtN,EAAKuN,cAAeW,EAAaK,EAAU3Q,GACrFkR,EAAStM,KAAKkL,EAChB,CACA,OAAOoB,CACT,CAOA,aAAMR,GACJ,MAAMS,EAAc9R,KAAKiQ,eAAe8B,KACxC,GAAID,GAAe9R,KAAK6P,mBAA2C,IAAtB7P,KAAKqO,MAAMzN,SAAiBkR,GAAe9R,KAAK8P,wBAA2D,IAAjC9P,KAAKmQ,iBAAiBvP,QAC3I,OAEF,MAAMoR,EAAahS,KAAKqO,MAAM4D,SAAWjS,KAAKmQ,iBAAiB8B,QAC/D,IAAKD,EACH,OAEF,GAAIhS,KAAKiQ,eAAeiB,IAAIc,GAG1B,YADAhS,KAAKqR,UAGP,MAAMR,EAAc7Q,KAAK+P,YAAYb,IAAI8C,GACzC,IAAKnB,EACH,OAEF,MAAMR,EAAMQ,EAAYR,IAExBrQ,KAAKiQ,eAAeiC,IAAI7B,SAClBQ,EAAYC,SAASqB,KAAKtB,EAAYF,QAASE,EAAYD,QACjE5Q,KAAKiQ,eAAemC,OAAO/B,GAC3BrQ,KAAK+P,YAAYqC,OAAO/B,GACxBrQ,KAAKqR,SACP,CAOA,aAAAgB,CAAchC,EAAKiC,EAAe3C,GAChC,IAAK3P,KAAK+P,YAAYmB,IAAIb,GACxB,OAEF,MAAMQ,EAAc7Q,KAAK+P,YAAYb,IAAImB,GACrCQ,IACEA,EAAYM,WAEdC,aAAaP,EAAYM,WAG3BN,EAAYD,OAAO0B,IAErB,MAAMC,EAAavS,KAAKqO,MAAM5E,QAAQ4G,GACtC,GAAIkC,GAAc,EAChBvS,KAAKqO,MAAMmD,OAAOe,EAAY,OACzB,CACL,MAAMhB,EAAmBvR,KAAKmQ,iBAAiB1G,QAAQ4G,GACnDkB,GAAoB,GACtBvR,KAAKmQ,iBAAiBqB,OAAOD,EAAkB,EAEnD,CACAvR,KAAK+P,YAAYqC,OAAO/B,GACxBrQ,KAAKiQ,eAAemC,OAAO/B,EAC7B,CAMA,iBAAAmC,CAAkBF,EAAe3C,GAE/B3P,KAAKqO,MAAQ,GACbrO,KAAKmQ,iBAAmB,GACxB,IAAK,MAAME,KAAOrQ,KAAK+P,YAAY0C,OACjCzS,KAAKqS,cAAchC,EAAKiC,EAE5B,CAOA,UAAAI,CAAWrC,GACT,OAAOrQ,KAAK+P,YAAYmB,IAAIb,EAC9B,CAOA,cAAAsC,CAAetC,GACb,OAAOrQ,KAAKiQ,eAAeiB,IAAIb,EACjC,E,gDCjQa,MAAMuC,EAenB,WAAA9S,CAAY+P,EAAmBC,GAE3B9P,KAAKqO,MAD0B,iBAAtBwB,QAAwDpF,IAAtBoF,EAC9B,IAAI,IAAaA,EAAmBC,GAEpCD,EAEf7P,KAAK6S,iBAAmB,EACxB7S,KAAK8S,YAAc,IAAI9C,IACvBhQ,KAAK4R,SAAW,IAAI5B,GACtB,CAGA,UAAA+C,CAAW1C,EAAK/O,GACd,MAAMsQ,EAAW5R,KAAK4R,SAAS1C,IAAImB,GACnC,GAAIuB,EAAU,CACZ,IAAK,MAAM,QACTjB,EAAO,aACPqC,KACGpB,EACHjB,EAAQrP,GACRtB,KAAK8S,YAAY5D,IAAI8D,IAAeZ,OAAO/B,GAE7CrQ,KAAK4R,SAASQ,OAAO/B,EACvB,CACF,CAGA,SAAA4C,CAAU5C,EAAK6C,GACb,MAAMtB,EAAW5R,KAAK4R,SAAS1C,IAAImB,GACnC,GAAIuB,EAAU,CACZ,IAAK,MAAM,OACThB,EAAM,aACNoC,KACGpB,EACHhB,EAAOsC,GACPlT,KAAK8S,YAAY5D,IAAI8D,IAAeZ,OAAO/B,GAE7CrQ,KAAK4R,SAASQ,OAAO/B,EACvB,CACF,CAGA,aAAA8C,GACE,MAAMH,EAAehT,KAAK6S,iBAG1B,OAFA7S,KAAK6S,mBACL7S,KAAK8S,YAAY/B,IAAIiC,EAAc,IAAIhD,KAChCgD,CACT,CAOA,UAAA7D,CAAWkB,EAAK2C,EAAc1C,EAAeW,EAAaK,GAQxD,GANAtR,KAAKqO,MAAMc,WAAWkB,EAAKC,EAAeW,EAAaK,GAASa,MAAK7Q,GAAStB,KAAK+S,WAAW1C,EAAK/O,KAAQ8R,OAAMF,GAAUlT,KAAKiT,UAAU5C,EAAK6C,KAC1IlT,KAAK4R,SAASV,IAAIb,IACrBrQ,KAAK4R,SAASb,IAAIV,EAAK,IAIrB2C,GAAgBhT,KAAK6S,kBAAoBG,EAAe,EAC1D,MAAM,IAAItB,MAAM,2CAA2CsB,6BAG7D,IADmBhT,KAAK8S,YAAY5D,IAAI8D,GAEtC,MAAM,IAAItB,MAAM,2CAA2CsB,sBAI7D,OAAO,IAAItC,SAAQ,CAACC,EAASC,KAC3B5Q,KAAK4R,SAAS1C,IAAImB,IAAM9K,KAAK,CAC3BoL,UACAC,SACAoC,iBAEF,MAAMnE,EAAa7O,KAAK8S,YAAY5D,IAAI8D,GAClCK,EAAkBxE,GAAYK,IAAImB,GACpCgD,EACFA,EAAgB9N,KAAKqL,GAErB/B,GAAYkC,IAAIV,EAAK,CAACO,GACxB,GAEJ,CAMA,kBAAA0C,CAAmBjD,EAAKO,EAAQ0B,GAE9B1B,EAAO0B,GAGP,MAAMiB,EAAgBvT,KAAK4R,SAAS1C,IAAImB,GACxC,IAAKkD,EAEH,OAGF,MAAM/K,EAAM+K,EAAcC,WAAUC,GAAOA,EAAI7C,SAAWA,IACtDpI,GAAO,GACT+K,EAAc/B,OAAOhJ,EAAK,GAIxB+K,EAAc3S,OAAS,IAAMZ,KAAKqO,MAAMsE,eAAetC,KACzDrQ,KAAKqO,MAAMgE,cAAchC,EAAKiC,GAC9BtS,KAAK4R,SAASQ,OAAO/B,GAEzB,CAGA,aAAAgC,CAAchC,EAAK2C,EAAcV,GAC/B,MAAMzD,EAAa7O,KAAK8S,YAAY5D,IAAI8D,GACxC,IAAKnE,EACH,OAAO,EAET,MAAM6E,EAAY7E,EAAWK,IAAImB,GACjC,IAAKqD,IAAcA,EAAU9S,OAC3B,OAAO,EAET,IAAK,MAAMgQ,KAAU8C,EACnB1T,KAAKsT,mBAAmBjD,EAAKO,EAAQ0B,GAGvC,OADAzD,EAAWuD,OAAO/B,IACX,CACT,CAGA,gBAAAsD,CAAiBX,EAAcV,GAC7B,MAAMiB,EAAgBvT,KAAK8S,YAAY5D,IAAI8D,GAC3C,GAAIO,EAAe,CACjB,IAAK,MAAOlD,EAAKqD,KAAcH,EAAczM,UAC3C,IAAK,MAAM8J,KAAU8C,EACnB1T,KAAKsT,mBAAmBjD,EAAKO,EAAQ0B,GAGzCtS,KAAK8S,YAAYV,OAAOY,EAC1B,CACF,CAGA,UAAAN,CAAWrC,GACT,OAAOrQ,KAAKqO,MAAMqE,WAAWrC,EAC/B,CAGA,cAAAsC,CAAetC,GACb,OAAOrQ,KAAKqO,MAAMsE,eAAetC,EACnC,CAGA,aAAAuD,CAAcZ,GACZ,OAAOhT,KAAK8S,YAAY5B,IAAI8B,EAC9B,CAGA,YAAAa,CAAab,EAAc3C,GACzB,OAAOrQ,KAAK8S,YAAY5D,IAAI8D,IAAe9B,IAAIb,KAAQ,CACzD,E,qDCxLK,IAAIyD,EAA6B,SAAUA,GAUhD,OATAA,EAAcA,EAAoB,KAAI,GAAK,OAC3CA,EAAcA,EAA6B,cAAI,GAAK,gBACpDA,EAAcA,EAA4B,aAAI,GAAK,eACnDA,EAAcA,EAA6B,cAAI,GAAK,gBACpDA,EAAcA,EAAyB,UAAI,GAAK,YAChDA,EAAcA,EAAgC,iBAAI,GAAK,mBACvDA,EAAcA,EAAgD,iCAAI,GAAK,mCACvEA,EAAcA,EAAgD,iCAAI,GAAK,mCACvEA,EAAcA,EAAoC,qBAAI,GAAK,uBACpDA,CACT,CAXwC,CAWtC,CAAC,GAOQC,EAAoC,SAAUA,GAIvD,OAHAA,EAAqBA,EAA8B,QAAI,GAAK,UAC5DA,EAAqBA,EAA4B,MAAI,GAAK,QAC1DA,EAAqBA,EAA4B,MAAI,GAAK,QACnDA,CACT,CAL+C,CAK7C,CAAC,GAGQC,EAA+B,SAAUA,GAKlD,OAHAA,EAAgBA,EAAiC,gBAAI,GAAK,kBAE1DA,EAAgBA,EAA8B,aAAI,GAAK,eAChDA,CACT,CAN0C,CAMxC,CAAC,E,gDC/BI,SAASC,EAAgBC,GAC9B,MAAO,IACFA,EACHC,UAAW,IAAI,OAAK,IAAI,OAAUC,KAAKF,EAAKC,UAAU7T,MAAM,IAAI,OAAU8T,KAAKF,EAAKC,UAAU5T,MAElG,C,iBCUO,SAAS8T,EAAYC,EAAK5M,EAAQ9G,EAAQgO,EAAO,CAAC,GAWrD,YAVenE,IAAX/C,QAAmC+C,IAAX7J,IAExBgO,EAAO,IACAA,EACH2F,QAAS,IACF3F,EAAK2F,QACRC,MAAO,SAAS9M,KAAUA,EAAS9G,EAAS,OAIjD6T,MAAMH,EAAK1F,EACtB,CC5BA,SAAS+B,EAAQ+D,EAAMlG,GACnB,MAAMmG,EAAuB,iBAATD,EAAoB,IAAIE,IAAIF,GAAQA,EACnDC,EAAKE,SAAStG,SAAS,OAExBoG,EAAKE,UAAY,KAErB,MAAMC,EAAW,IAAIF,IAAIpG,EAAKxG,MAAM,GAAI2M,GAGxC,OADAG,EAASC,OAASJ,EAAKI,OAChBD,CACX,CACApG,eAAesG,EAAgBC,GAC3B,GAAwB,MAApBA,EAASC,OAAb,CAGA,GAAwB,MAApBD,EAASC,QAAsC,MAApBD,EAASC,OACpC,OAAO,IAAIC,iBAAiBF,EAASG,eAEzC,MAAM,IAAI1D,MAAM,8BAA8BuD,EAASC,UAAUD,EAASI,aAJ1E,CAKJ,C,iBAyDA,QA9BA,MACIf,IACA,GACA,GACA,WAAAxU,CAAYwU,EAAKgB,EAAU,CAAC,GACxBtV,KAAKsU,IAAMA,EACXtU,MAAK,EAAasV,EAAQC,WAAa,CAAC,EACxCvV,MAAK,EAAsBsV,EAAQE,mBAAoB,CAC3D,CACA,GAAYD,GACR,OD3BmBE,EC2BDzV,MAAK,ED3BY0V,EC2BAH,EDzBhC,IACAE,KACAC,EACHnB,QAAS,IACFkB,EAAelB,WACfmB,EAAiBnB,UAPzB,IAAoBkB,EAAgBC,CC4BvC,CACA,SAAMxG,CAAImB,EAAKiF,EAAU,CAAC,GACtB,IAAIK,EAAOhF,EAAQ3Q,KAAKsU,IAAKjE,GAAKsF,KAElC,OAAOX,QADcP,MAAMkB,EAAM3V,MAAK,EAAYsV,IAEtD,CACA,cAAMM,CAASvF,EAAKwF,EAAOP,EAAU,CAAC,GAClC,IAEIL,EAFAX,EAAM3D,EAAQ3Q,KAAKsU,IAAKjE,GACxByF,EAAO9V,MAAK,EAAYsV,GAQ5B,OALIL,EADA,iBAAkBY,QA/C9BnH,eAA4B4F,EAAKyB,EAAeD,EAAME,GAClD,GAAIA,EACA,OAAOvB,MAAMH,EAAK,IACXwB,EACHvB,QAAS,IAAKuB,EAAKvB,QAASC,MAAO,UAAUuB,OAGrD,IAAId,QAAiBR,MAAMH,EAAK,IAAKwB,EAAMG,OAAQ,SACnD,IAAKhB,EAASiB,GAEV,OAAOjB,EAEX,IAAIkB,EAAiBlB,EAASV,QAAQrF,IAAI,kBACtCtO,EAAS+E,OAAOwQ,GACpB,OAAO9B,EAAYC,EAAK1T,EAASmV,EAAenV,EAAQkV,EAC5D,CAiC6BM,CAAa9B,EAAKuB,EAAMQ,aAAcP,EAAM9V,MAAK,SAGjDqU,EAAYC,EAAKuB,EAAMnO,OAAQmO,EAAMjV,OAAQkV,GAE3Dd,EAAgBC,EAC3B,E,qFC1DG,MAAMqB,EACTC,KAAO,iBACP,WAAAzW,CAAY0W,EAAeC,IACvB,QAAOD,EAAcE,UAAY,EAAG,oCACxC,CACA,iBAAOC,CAAWH,EAAepJ,GAC7B,OAAO,IAAIkJ,EAAcE,EAAepJ,EAC5C,CAKA,MAAAwJ,CAAOC,GACH,MAAM,IAAInF,MAAM,iHACpB,CAMA,MAAAoF,CAAOjU,GACH,OAAOA,CACX,ECtCJ,MAAMkU,EACN,WACI,MAAMxL,EAAI,IAAIlL,YAAY,CAAC,YAE3B,QAAkB,KADR,IAAI8U,WAAW5J,EAAEyL,OAAQzL,EAAE0L,WAAY1L,EAAE2L,YACxC,GACf,CALyBC,GAMzB,SAASC,EAAkBC,GACvB,MAAI,sBAAuBA,EAChBA,EAAWC,kBAGf,CACX,CACO,MAAMC,EACThB,KAAO,iBACP,GACA,GACA,GACA,GACA,GACA,WAAAzW,CAAY0W,EAAepJ,GACvBpN,MAAK,EAAUwW,GAAegB,OAC9BxX,MAAK,GAAc,QAAQoN,EAAKqK,WAChCzX,MAAK,EAASoN,EAAKlK,MACnBlD,MAAK,GAAU,QAAYoN,EAAKlK,MAAO,KAGvC,MAAMwU,EAAS,IAAI1X,MAAK,EAAY,GACpCA,MAAK,EAAqB0X,EAAOJ,iBACrC,CACA,iBAAOX,CAAWH,EAAepJ,GAC7B,OAAO,IAAImK,EAAWf,EAAepJ,EACzC,CACA,MAAAwJ,CAAO/T,GACH,IAAI8U,EAAQ,IAAIxC,WAAWtS,EAAI9C,KAAKiX,QAIpC,OAHID,GAAqC,QAAjB/W,MAAK,IACzB,QAAiB2X,EAAOP,EAAkBpX,MAAK,IAE5C2X,CACX,CACA,MAAAb,CAAOa,GAIH,OAHIZ,GAAqC,QAAjB/W,MAAK,IACzB,QAAiB2X,EAAOP,EAAkBpX,MAAK,IAE5C,CACHD,KAAM,IAAIC,MAAK,EAAY2X,EAAMX,OAAQW,EAAMV,WAAYU,EAAMT,WAAalX,MAAK,GACnFkD,MAAOlD,MAAK,EACZ4X,OAAQ5X,MAAK,EAErB,EClDG,MAAM6X,EACTtB,KAAO,iBACP,iBAAOI,GACH,OAAO,IAAIkB,CACf,CACA,MAAAjB,CAAO9N,GACH,MAAM,IAAI4I,MAAM,kBACpB,CACA,MAAAoF,CAAOjU,GACH,OAAO,IAAIsS,WAAWtS,EAAImU,OAAQnU,EAAIoU,WAAYpU,EAAIqU,WAAa,EACvE,ECRJ,SAASY,EAAsBC,EAAMzW,GAIjC,OAHA,SAAQqE,OAAOqS,MAAM1W,GAAQ,0EAC7B,QAAOA,IAAUqE,OAAOsS,kBAAmB,+EAC3C,QAAO3W,IAAUqE,OAAOuS,kBAAmB,+EACpC5W,CACX,CAEA,SAAS6W,EAAmBJ,EAAMzW,GAC9B,OAAOA,aAAiB8W,SAAWxQ,MAAMC,QAAQvG,GAC3C8W,OAAO3F,KAAKnR,GACT+W,OACAC,QAAO,CAACC,EAAQlI,KACjBkI,EAAOlI,GAAO/O,EAAM+O,GACbkI,IACR,CAAC,GACFjX,CACV,CACO,MAAMkX,EACThC,cACAD,KAAO,iBACP,GACA,GACA,WAAAzW,CAAY0W,EAAgB,CAAC,GACzBxW,KAAKwW,cAAgBA,EAErB,MAAM,SAAEiC,EAAW,QAAO,SAAEC,GAAW,EAAK,aAAEC,GAAe,EAAI,eAAEC,GAAiB,EAAI,UAAEC,GAAY,EAAI,UAAEC,GAAY,EAAI,OAAEC,EAAM,OAAEC,GAAS,GAAUxC,EACzJ,IAAIyC,EAAazC,EAAcyC,WAC1BA,IAOGA,EAJCF,EAIY,CAAC,KAAM,MAHP,CAAC,IAAK,MAM3B/Y,MAAK,EAAkB,CACnByY,WACAC,WACAC,eACAC,iBACAC,YACAE,SACAE,aACAH,aAEJ9Y,MAAK,EAAkB,CAAEgZ,SAC7B,CACA,iBAAOrC,CAAWH,GACd,OAAO,IAAIgC,EAAUhC,EACzB,CACA,MAAAI,CAAOsC,GACH,MAAM,OAAEH,EAAM,SAAEN,EAAQ,aAAEE,EAAY,eAAEC,EAAc,UAAEC,EAAS,UAAEC,GAAe9Y,MAAK,GACvF,QAAoB,UAAbyY,EAAsB,sDAC7B,MAAMU,EAAqB,IAG3B,QAAOP,EAAgB,8FAClBC,GAEDM,EAAmB5T,KAAKuS,GAExBgB,GAGAK,EAAmB5T,KAAK4S,GAE5B,MAAMiB,EAAQxR,MAAMiB,KAAKqQ,EAAInZ,MAG7B,IAAIsZ,EAFJD,EAAM7T,KAAK,MACX6T,EAAM7T,KAAK2T,EAAIhW,OAEXiW,EAAmBvY,SACnByY,EAAW,CAAChJ,EAAK/O,KACb,IAAIgY,EAAYhY,EAChB,IAAK,IAAIiY,KAAgBJ,EACrBG,EAAYC,EAAalJ,EAAKiJ,GAElC,OAAOA,CAAS,GAGxB,IAAIE,EAAWC,KAAKC,UAAUN,EAAOC,EAAUN,GAY/C,OAXIJ,IAKAa,EAAWA,EAASG,QAAQ,oBAAqBC,IAC7C,MAAMC,EAAW,OAAOD,EAAIE,WAAW,GAAGC,SAAS,MAEnD,MAAO,MADSF,EAASG,UAAUH,EAASjZ,OAAS,IAC/B,MAGvB,IAAIqZ,aAAcrD,OAAO4C,EACpC,CACA,MAAA1C,CAAOa,GACH,MAAM,OAAEqB,GAAWhZ,MAAK,GAExB,QAAOgZ,EAAQ,uDACf,MAAMI,GAAQ,QAAmBzB,GAC3BzU,EAAQkW,EAAMc,MAMpB,OALAd,EAAMc,OAEN,QAAOhX,EAAO,qCAGP,CAAEnD,KADIqZ,EACElW,QAAO0U,QAFP,QAAY1U,EAAO,KAGtC,E,cC3GJ,SAASiX,EAAMtX,GACX,OAAIA,aAAe,MACfA,aAAe,MACfA,aAAe,KAEF,IAAIyM,MAAMzM,EAAK,CACxBqM,IAAG,CAACK,EAAQ/B,IACD+B,EAAOL,IAAIvJ,OAAO6H,IAE7BuD,IAAG,CAACxB,EAAQ/B,EAAMlM,KAEdiO,EAAOwB,IAAIpL,OAAO6H,GAAOlM,IAClB,KAMZuB,CACX,CA0DO,MAAMuX,EACT7D,KAAO,iBACP,GACA,GACA,WAAAzW,CAAY0W,EAAepJ,GACvB,IAAI9L,EAAQkV,EAAc6D,OAAS,IAC/BC,EAAOlN,EAAKlK,MAAMtC,OAClByZ,EAAQ,IAAIzS,MAAM0S,GAClBC,EAAe,IAAI3S,MAAM0S,GAC7B,GAAc,MAAVhZ,EACA,IAAK,IAAIX,EAAI,EAAGA,EAAI2Z,IAAQ3Z,EACxB0Z,EAAM1Z,GAAKA,EACX4Z,EAAa5Z,GAAKA,OAGrB,GAAc,MAAVW,EACL,IAAK,IAAIX,EAAI,EAAGA,EAAI2Z,IAAQ3Z,EACxB0Z,EAAM1Z,GAAK2Z,EAAO3Z,EAAI,EACtB4Z,EAAa5Z,GAAK2Z,EAAO3Z,EAAI,OAIjC0Z,EAAQ/Y,EACR+Y,EAAM/Q,SAAQ,CAAC1G,EAAGjC,MACd,aAA2B8J,IAApB8P,EAAa3X,GAAkB,wBAAwB6W,KAAKC,UAAUpY,MAC7EiZ,EAAa3X,GAAKjC,CAAC,IAG3BX,MAAK,EAASqa,EACdra,MAAK,EAAgBua,CACzB,CACA,iBAAO5D,CAAWH,EAAepJ,GAC7B,OAAO,IAAIgN,EAAe5D,EAAepJ,EAC7C,CACA,MAAAwJ,CAAO/T,GACH,OAxCR,SAAuByD,EAAOiJ,GAC1B,IAAIiL,EATR,SAAmBlU,GACf,IAAIgU,EAAOhU,EAAMpD,MAAMtC,OAEvB,OADA,QAAO0Z,IAAShU,EAAMsR,OAAOhX,OAAQ,+CAC9B0F,EAAMsR,OACRzQ,KAAI,CAACsT,EAAG9Z,KAAM,CAAGiX,OAAQ6C,EAAGC,MAAO/Z,MACnC0X,MAAK,CAAC9M,EAAG7I,IAAMA,EAAEkV,OAASrM,EAAEqM,SAC5BzQ,KAAKwT,GAAUA,EAAMD,OAC9B,CAEiBE,CAAUtU,GAEvB,OADA,QAAOkU,EAAO5Z,SAAW2O,EAAO3O,OAAQ,qBACjC4Z,EAAOtV,OAAM,CAAC2V,EAAKla,IAAMka,IAAQtL,EAAO5O,IACnD,CAoCYma,CAAcjY,EAAK7C,MAAK,GAEjB6C,EA7EnB,SAA6BuF,EAAKmH,GAC9B,IAAIwL,EAlBR,SAAoBzU,EAAO+T,GACvB,IAAIta,EAUJ,OAPIA,EAFAuG,EAAMvG,gBAAgB,MACtBuG,EAAMvG,gBAAgB,KACf,IAAIuG,EAAMxG,YAEjBwG,EAAMvG,KAAKa,OAAQ0F,EAAMvG,KAAKib,OAGvB,IAAI1U,EAAMxG,YAAYwG,EAAMvG,KAAKa,QAErC,CACHb,OACAmD,MAAOoD,EAAMpD,MACb0U,QAAQ,QAAYtR,EAAMpD,MAAOmX,GAEzC,CAEcY,CAAW7S,EAAKmH,GACtB2L,EAAS9S,EAAIlF,MAAMtC,OACnBmR,EAAO3J,EAAIrI,KAAKa,OAChB8Z,EAAQ9S,MAAMsT,GAAQpY,KAAK,GAC3BqY,EAAWhB,EAAM/R,EAAIrI,MACrBqb,EAAWjB,EAAMY,EAAIhb,MACzB,IAAK,IAAIsb,EAAU,EAAGA,EAAUtJ,EAAMsJ,IAAW,CAC7C,IAAIC,EAAU,EACd,IAAK,IAAIT,EAAM,EAAGA,EAAMK,EAAQL,IAC5BS,GAAWZ,EAAMG,GAAOE,EAAInD,OAAOiD,GAEvCO,EAASE,GAAWH,EAASE,GAC7BX,EAAM,IAAM,EACZ,IAAK,IAAIG,EAAM,EAAGA,EAAMK,EAAQL,IAC5B,GAAIH,EAAMG,KAASzS,EAAIlF,MAAM2X,GAAM,CAC/B,GAAIA,EAAM,IAAMK,EACZ,MAEJR,EAAMG,GAAO,EACbH,EAAMG,EAAM,IAAM,CACtB,CAER,CACA,OAAOE,CACX,CAsDeQ,CAAoB1Y,EAAK7C,MAAK,EACzC,CACA,MAAA8W,CAAOjU,GACH,MAAO,CACH9C,KAAM8C,EAAI9C,KACVmD,MAAOL,EAAIK,MACX0U,QAAQ,QAAY/U,EAAIK,MAAOlD,MAAK,GAE5C,EC7HG,MAAMwb,EACTjF,KAAO,iBACP,GACA,GACA,WAAAzW,CAAYoD,GACRlD,MAAK,EAASkD,EACdlD,MAAK,GAAW,QAAYkD,EAAO,IACvC,CACA,iBAAOyT,CAAW7N,EAAGsE,GACjB,OAAO,IAAIoO,EAASpO,EAAKlK,MAC7B,CACA,MAAA0T,CAAO6E,GACH,MAAM,IAAI/J,MAAM,0BACpB,CACA,MAAAoF,CAAOa,GACH,IAAI+D,EAAU,IAAIC,YACdC,EAAO,IAAIC,SAASlE,EAAMX,QAC1BjX,EAAO6H,MAAMgU,EAAKE,UAAU,GAAG,IAC/BC,EAAM,EACV,IAAK,IAAIpb,EAAI,EAAGA,EAAIZ,EAAKa,OAAQD,IAAK,CAClC,IAAIqb,EAAcJ,EAAKE,UAAUC,GAAK,GACtCA,GAAO,EACPhc,EAAKY,GAAK+a,EAAQ5E,OAAOa,EAAMX,OAAOhP,MAAM+T,EAAKA,EAAMC,IACvDD,GAAOC,CACX,CACA,MAAO,CAAEjc,OAAMmD,MAAOlD,MAAK,EAAQ4X,OAAQ5X,MAAK,EACpD,ECNG,MAAMic,GAbF,IAAIjM,KACNe,IAAI,SAAS,IAAM,8BAA0BoB,MAAM+J,GAAMA,EAAEC,YAC3DpL,IAAI,QAAQ,IAAM,sDAAyBoB,MAAM+J,GAAMA,EAAEC,YACzDpL,IAAI,OAAO,IAAM,8BAAwBoB,MAAM+J,GAAMA,EAAEC,YACvDpL,IAAI,QAAQ,IAAM,qDAAyBoB,MAAM+J,GAAMA,EAAEC,YACzDpL,IAAI,QAAQ,IAAM,8BAAyBoB,MAAM+J,GAAMA,EAAEC,YACzDpL,IAAI,aAAa,IAAMqJ,IACvBrJ,IAAI,SAAS,IAAMwG,IACnBxG,IAAI,UAAU,IAAM8G,IACpB9G,IAAI,aAAa,IAAMyK,IACvBzK,IAAI,SAAS,IAAMyH,IACnBzH,IAAI,YAAY,IAAMuF,IAGxB,SAAS8F,EAAsBC,GAClC,IAAIC,EACJ,MAAO,CACH,YAAM1F,CAAOtQ,GACJgW,IACDA,QAAeC,EAAYF,IAC/B,IAAK,MAAMG,KAASF,EAAOG,eACvBnW,QAAckW,EAAM5F,OAAOtQ,GAE/B,IAAIqR,QAAc2E,EAAOI,eAAe9F,OAAOtQ,GAC/C,IAAK,MAAMkW,KAASF,EAAOK,eACvBhF,QAAc6E,EAAM5F,OAAOe,GAE/B,OAAOA,CACX,EACA,YAAMb,CAAOa,GACJ2E,IACDA,QAAeC,EAAYF,IAC/B,IAAK,IAAI1b,EAAI2b,EAAOK,eAAe/b,OAAS,EAAGD,GAAK,EAAGA,IACnDgX,QAAc2E,EAAOK,eAAehc,GAAGmW,OAAOa,GAElD,IAAIrR,QAAcgW,EAAOI,eAAe5F,OAAOa,GAC/C,IAAK,IAAIhX,EAAI2b,EAAOG,eAAe7b,OAAS,EAAGD,GAAK,EAAGA,IACnD2F,QAAcgW,EAAOG,eAAe9b,GAAGmW,OAAOxQ,GAElD,OAAOA,CACX,EAER,CACAoI,eAAe6N,EAAYK,GACvB,IAMIF,EANA7K,EAAW+K,EAAWN,OAAOnV,KAAIuH,MAAOtB,IACxC,IAAIyP,QAAcZ,EAAS/M,IAAI9B,EAAKhK,KAAlB6Y,MAElB,OADA,QAAOY,EAAO,kBAAkBzP,EAAKhK,QAC9B,CAAEyZ,QAAOzP,OAAM,IAEtBqP,EAAiB,GAEjBE,EAAiB,GACrB,UAAW,IAAI,MAAEE,EAAK,KAAEzP,KAAUyE,EAAU,CACxC,IAAI2K,EAAQK,EAAMlG,WAAWvJ,EAAKoJ,cAAeoG,GACjD,OAAQJ,EAAMjG,MACV,IAAK,iBACDkG,EAAelX,KAAKiX,GACpB,MACJ,IAAK,iBACDE,EAAiBF,EACjB,MACJ,QACIG,EAAepX,KAAKiX,GAEhC,CAKA,OAJKE,KACD,QAMsB,cANUE,EAMxBnF,UANqC,iBAAiBmF,EAAWnF,sCACzEiF,EAAiBnF,EAAWZ,WAAW,CAAEa,OAAQ,UAAYoF,IAE1D,CAAEH,iBAAgBC,iBAAgBC,iBAC7C,CC5EA,MAAMG,EAAe,sBACd,SAASC,EAA4BC,EAAUC,EAAaC,EAAkBC,IACjF,QAAOH,EAASI,MAAMxH,SAAU,yCAChC,IAAIyH,EAAYL,EAASI,MAAMxH,SAAS0H,KAAKN,EAASI,OAClDG,EAAcN,EAAY9V,KAAI,CAACqW,EAAG7c,IAAM6c,EAAIL,EAAgBM,YAAY9c,KACxE+c,EAActB,EAAsB,CACpC3E,UAAW,SACXvU,MAAO,IAAIqa,EAAa,GACxBjB,OAAQa,EAAgBQ,eAExBvP,EAAQ,CAAC,EACb,OAAOM,MAAOkP,IACV,IAEIlD,EAFAmD,EAAcD,EAAYzW,KAAI,CAACqW,EAAG7c,IAAMQ,KAAKC,MAAMoc,EAAID,EAAY5c,MACnEmd,EAAad,EAASrM,QAAQuM,EAAiBW,IAAcrP,KAEjE,GAAIsP,KAAc1P,EACdsM,EAAQtM,EAAM0P,OAEb,CACD,IAAIC,EAAgB,EAChBC,EAAa,GAAKT,EAAYjF,QAAO,CAAC/M,EAAG7I,IAAM6I,EAAI7I,GAAG,GACtDiV,QAAc0F,EAAUS,EAAY,CACpCzH,aAAc2H,EAAaD,IAE/BrD,EAAQtM,EAAM0P,GAAcnG,QAChB+F,EAAY5G,OAAOa,GACzB,IACV,CACA,GAAc,OAAV+C,EACA,OAEJ,IAAI,KAAE3a,EAAI,MAAEmD,EAAK,OAAE0U,GAAW8C,EAC1BuD,EAAgBL,EACfzW,KAAI,CAACqW,EAAG7c,IAAM6c,EAAIta,EAAMvC,KACxB2X,QAAO,CAAC4F,EAAKC,EAAK3V,IAAQ0V,EAAMC,EAAMvG,EAAOpP,IAAM,GACpDd,EAAS3H,EAAKke,GACdrd,EAASb,EAAKke,EAAgB,GAElC,OAAIvW,IAAWoV,GAAgBlc,IAAWkc,EAGnCO,EAAUS,EAAY,CACzBpW,OAAQ/B,OAAO+B,GACf9G,OAAQ+E,OAAO/E,UALnB,CAME,CAEV,CC5CO,MAAMwd,EACThB,MACA5O,KACA,WAAA1O,CAAYsd,EAAO5O,EAAO,KACtBxO,KAAKod,MAAQA,EACbpd,KAAKwO,KAAOA,CAChB,CACA,OAAAmC,CAAQnC,GAGJ,IAAIkG,EAAO,IAAIE,IAAI,UAAU5U,KAAKwO,KAAKD,SAAS,KAAOvO,KAAKwO,KAAO,GAAGxO,KAAKwO,WAC3E,OAAO,IAAI4P,EAASpe,KAAKod,MAAO,IAAIxI,IAAIpG,EAAMkG,GAAMG,SACxD,EAEG,SAASH,EAAK0I,GACjB,OAAO,IAAIgB,EAAShB,GAAS,IAAIpN,IACrC,CACO,MAAMqO,UAAcD,EACvB7H,KAAO,QACP,GACA,WAAAzW,CAAYsd,EAAO5O,EAAM8P,GACrBC,MAAMnB,EAAO5O,GACbxO,MAAK,EAAYse,CACrB,CACA,SAAIE,GACA,OAAOxe,MAAK,EAAUye,UAC1B,EAEJ,SAASC,EAAgBpC,GACrB,MAAMqC,EAAwBrC,EAAOzR,MAAM5B,GAAiB,cAAXA,EAAE7F,OAEnD,OAAOub,GAAuBnI,eAAe6D,OAAS,GAC1D,CACA,MAAMuE,EAAiB3W,OAAO,mBACvB,SAAS4W,EAAYtR,GACxB,OAAOA,EAAIqR,EACf,CA6CO,MAAM,UAAcR,EACvB7H,KAAO,QACP,GACA,CAACqI,GACD,WAAA9e,CAAYsd,EAAO5O,EAAM8P,GACrBC,MAAMnB,EAAO5O,GACbxO,MAAK,EAAY,IACVse,EACHQ,YAAY,QAAsBR,IAEtCte,KAAK4e,GAtDb,SAAwB5B,EAAUsB,GAC9B,IAAI,cAAE9H,GAAkB8H,EAAShC,OAAOzR,KAAK,MAAsB,CAAC,EAChEkU,EAAiB,CACjBC,kBAAkB,QAAyBV,EAASW,oBACpD5H,YAAY,QAAQiH,EAAS7G,WAC7BqH,WAAYR,EAASQ,YAEzB,GAAItI,EAAe,CACf,IAAI0I,EAAeR,EAAgBlI,EAAc8F,QACjD,MAAO,IACAyC,EACHxI,KAAM,UACNkH,YAAajH,EAAciH,YAC3BjB,MAAOJ,EAAsB,CACzB3E,UAAW6G,EAAS7G,UACpBvU,MAAOsT,EAAciH,YACrBnB,OAAQ9F,EAAc8F,SAE1B6C,YAAYjc,IACD,QAAYA,EAAOgc,GAE9BE,gBAAiBrC,EAA4BC,EAAUsB,EAASe,WAAW7I,cAAciH,YAAasB,EAAeC,iBAAkBxI,GAE/I,CACA,IAAI0I,EAAeR,EAAgBJ,EAAShC,QAC5C,MAAO,IACAyC,EACHxI,KAAM,UACNkH,YAAaa,EAASe,WAAW7I,cAAciH,YAC/CjB,MAAOJ,EAAsB,CACzB3E,UAAW6G,EAAS7G,UACpBvU,MAAOob,EAASe,WAAW7I,cAAciH,YACzCnB,OAAQgC,EAAShC,SAErB6C,YAAYjc,IACD,QAAYA,EAAOgc,GAE9B,qBAAME,CAAgBE,EAAchK,GAChC,IAAIiK,EAAYR,EAAeC,iBAAiBM,GAC5CE,EAAaxC,EAASrM,QAAQ4O,GAAW/Q,KAC7C,OAAOwO,EAASI,MAAMlO,IAAIsQ,EAAYlK,EAC1C,EAER,CAW+BmK,CAAezf,KAAMse,EAChD,CACA,SAAIE,GACA,OAAOxe,MAAK,EAAUye,UAC1B,CACA,SAAIvb,GACA,OAAOlD,MAAK,EAAUkD,KAC1B,CACA,UAAI6C,GACA,OAAO/F,KAAK4e,GAAgBnB,WAChC,CACA,SAAIiC,GACA,OAAO1f,MAAK,EAAUyX,SAC1B,CACA,cAAMhJ,CAAS6Q,EAAchK,GACzB,IAAIqK,EAAU3f,KAAK4e,GACfgB,QAAoBD,EAAQP,gBAAgBE,EAAchK,GAC9D,IAAKsK,EAAa,CACd,IAAI7N,EAAO4N,EAAQlC,YAAYnF,QAAO,CAAC/M,EAAG7I,IAAM6I,EAAI7I,GAAG,GACnD3C,EAAO,IAAI4f,EAAQtI,WAAWtF,GAGlC,OADAhS,EAAK+C,KAAK6c,EAAQb,YACX,CACH/e,OACAmD,MAAOyc,EAAQlC,YACf7F,OAAQ+H,EAAQR,YAAYQ,EAAQlC,aAE5C,CACA,OAAOkC,EAAQnD,MAAM1F,OAAO8I,EAChC,CAkBA,EAAAC,CAAGC,GACC,OAAO,QAAS9f,KAAK0f,MAAOI,EAChC,E,8GC/IG,MAAMC,UAAmBrO,MAC5B,WAAA5R,CAAYkgB,GACRzB,MAAMyB,GACNhgB,KAAKoD,KAAO,YAChB,EA6BJ,MAAM6c,EACFC,QACAC,QACAC,cACAC,OACA,WAAAvgB,EAAY,QAAEogB,EAAO,QAAEC,EAAO,cAAEC,IAE5BF,EApBD,SAAqCA,EAASC,GAWjD,OATAD,EAAU/e,KAAKmf,MAAMJ,IAEP,IACVA,EAAUC,EAAUD,IAGpBA,GAAWC,GAAWD,EAAU,IAnBxC,SAAyBC,GACrB,MAAM,IAAIJ,EAAW,iDAAiDI,IAC1E,CAkBQI,CAAgBJ,GAEbD,CACX,CAQkBM,CAA4BN,EAASC,GAE/CngB,KAAKkgB,QAAUA,EACflgB,KAAKmgB,QAAUA,EACfngB,KAAKogB,cAAgBA,EACrBpgB,KAAKqgB,OAAS,CAClB,CACA,EAAEpY,OAAOC,YACL,MAAMuY,EAAetf,KAAKC,MAAMpB,KAAKkgB,QAAUlgB,KAAKogB,eAC9CM,EAAaD,EAAezgB,KAAKogB,cACjCO,EAAgB3gB,KAAKkgB,QAAUQ,OAC/B,CAAED,eAAcE,gBAC1B,EAEJ,MAAMC,EACF/Z,MACAga,KACAC,KACAX,QACAC,cACAC,OACAU,QACA,WAAAjhB,EAAY,QAAEogB,EAAO,QAAEC,EAAO,cAAEC,IAE5B,MAAOvZ,EAAOga,EAAMC,IAAQ,QAAcZ,EAASC,GACnDngB,KAAK6G,MAAQA,EACb7G,KAAK6gB,KAAOA,EACZ7gB,KAAK8gB,KAAOA,EACR9gB,KAAK8gB,KAAO,GAxDxB,WACI,MAAM,IAAIf,EAAW,2CACzB,CAuDYiB,GAEJhhB,KAAKmgB,QAAUA,EACfngB,KAAKogB,cAAgBA,EACrBpgB,KAAKqgB,OAASlf,KAAKZ,IAAI,EAAGY,KAAK8f,MAAMjhB,KAAK6gB,KAAO7gB,KAAK6G,OAAS7G,KAAK8gB,OACpE9gB,KAAK+gB,QAAU5f,KAAK8f,KAAKjhB,KAAKmgB,QAAUngB,KAAKogB,cACjD,CACA,EAAEnY,OAAOC,YAEL,MAAMgZ,EAAoB/f,KAAKC,MAAMpB,KAAK6G,MAAQ7G,KAAKogB,eACjDe,EAAkBhgB,KAAK8f,KAAKjhB,KAAK6gB,KAAO7gB,KAAKogB,eACnD,IAAK,MAAMK,KAAgB,QAAMS,EAAmBC,GAAkB,CAElE,MAAMT,EAAaD,EAAezgB,KAAKogB,cACjCgB,EAAYjgB,KAAKb,IAAIN,KAAKmgB,SAAUM,EAAe,GAAKzgB,KAAKogB,eAE7DA,EAAgBgB,EAAYV,EAClC,IAAIW,EAAiB,EACjBC,EAAsB,EAC1B,GAAIthB,KAAK6G,MAAQ6Z,EAAY,CAEzB,MAAMa,GAAab,EAAa1gB,KAAK6G,OAAS7G,KAAK8gB,KAC/CS,IACAD,GAAuBthB,KAAK8gB,KAAOS,GAEvCF,EAAiBlgB,KAAK8f,MAAMP,EAAa1gB,KAAK6G,OAAS7G,KAAK8gB,KAChE,MAGIQ,EAAsBthB,KAAK6G,MAAQ6Z,EAIvC,MAAMc,EAAqBxhB,KAAK6gB,KAAOO,EAAYhB,EAAgBpgB,KAAK6gB,KAAOH,EACzEC,EAAgB,CAClBW,EACAE,EACAxhB,KAAK8gB,MAGHW,EAAc,CAChBJ,EACAA,EAHqBlgB,KAAK8f,MAAMO,EAAqBF,GAAuBthB,KAAK8gB,MAIjF,QAEE,CAAEL,eAAcE,gBAAec,cACzC,CACJ,EAaG,MAAMC,EACTC,aACAze,MACA,WAAApD,EAAY,UAAE8hB,EAAS,MAAE1e,EAAK,YAAEua,IAE5Bzd,KAAK2hB,aAhBN,SAA6BC,EAAW1e,GAC3C,IAAI2e,EAAa,GAQjB,OAPkB,OAAdD,EACAC,EAAa3e,EAAMiE,KAAK2B,IAAM,QAAM,QAE/BlB,MAAMC,QAAQ+Z,KACnBC,EAAaD,EAAUza,KAAKsT,GAAMA,IAAK,QAAM,SA7GrD,SAAgCmH,EAAW1e,GACnC0e,EAAUhhB,OAASsC,EAAMtC,QAVjC,SAA8BghB,EAAW1e,GACrC,MAAM,IAAI6c,EAAW,yCAAyC7c,EAAMtC,eAAeghB,EAAUhhB,SACjG,CASQkhB,CAAqBF,EAAW1e,EAExC,CA2GI6e,CAAuBF,EAAY3e,GAC5B2e,CACX,CAM4BG,CAAoBJ,EAAW1e,GAAOiE,KAAI,CAAC+Y,EAASvf,IAC7D,IAAwB,iBAAZuf,EAAuBD,EAAgBW,GAAiB,CAEvEV,QAASA,EACTC,QAASjd,EAAMvC,GACfyf,cAAe3C,EAAY9c,OAGnCX,KAAKkD,MAAQlD,KAAK2hB,aACbha,QAAQsa,GAAQA,aAAerB,IAC/BzZ,KAAK+a,GAASA,EAAK7B,QAC5B,CACA,EAAEpY,OAAOC,YACL,IAAK,MAAMia,KAAmB,WAAWniB,KAAK2hB,cAAe,CACzD,MAAMrC,EAAe6C,EAAgBhb,KAAKib,GAAMA,EAAE3B,eAC5C4B,EAAUF,EAAgBhb,KAAKib,GAC7B,gBAAiBA,EACV,CAAEvZ,KAAMuZ,EAAEzB,cAAe2B,GAAIF,EAAEX,aAEnC,CAAE5Y,KAAMuZ,EAAEzB,cAAe2B,GAAI,aAElC,CAAEhD,eAAc+C,UAC1B,CACJ,EC3JJ,SAASE,EAAkB1f,EAAK6E,EAAS,EAAGqK,GACxC,IAAInR,EAASmR,GAAQlP,EAAIjC,OAAS8G,EAClC,MAAO,CACH9G,SACA4hB,SAAQ,CAAC3Z,EAAMyZ,EAAK1hB,IACT2hB,EAAkB1f,EAAK6E,EAASmB,EAAMyZ,EAAKzZ,GAEtD,GAAAkI,CAAIhR,EAAM8G,EAAQ,GACd,IAAK,IAAIlG,EAAI,EAAGA,EAAIZ,EAAKa,OAAQD,IAC7BkC,EAAI6E,EAASb,EAAQlG,GAAKZ,EAAKmP,IAAIvO,EAE3C,EACAuO,IAAIwL,GACO7X,EAAI6E,EAASgT,GAGhC,CAWA,SAAS+H,EAAa5f,GAClB,OAAI6f,WAAW9a,MAAMC,QAAQhF,EAAI9C,MACtB,CAEHA,KAAMwiB,EAAkB1f,EAAI9C,MAC5B6X,OAAQ/U,EAAI+U,OACZR,kBAAmB,GAGpB,CACHrX,KAAM,IAAIoV,WAAWtS,EAAI9C,KAAKiX,OAAQnU,EAAI9C,KAAKkX,WAAYpU,EAAI9C,KAAKmX,YACpEU,OAAQ/U,EAAI+U,OACZR,kBAAmBvU,EAAI9C,KAAKuX,kBAEpC,CA8BO,MAAMqL,EAAS,CAClBC,QAAO,CAAC7iB,EAAMmD,EAAO0U,KACV,CAAE7X,OAAMmD,QAAO0U,WAE1B,UAAAiL,CAAWC,EAAM3E,EAAK7c,GAClB,IAAIsa,EAAO6G,EAAaK,GACxBC,EAAkBnH,EAAMuC,EAhBhC,SAAuBtb,EAAKvB,GACxB,GAAIohB,WAAW9a,MAAMC,QAAQhF,EAAI9C,MAE7B,OAAOwiB,EAAkB,CAACjhB,IAE9B,IAEIvB,EAAO,IAzBf,SAAqC8C,GACjC,MAAI,UAAWA,EAGJA,EAAI/C,YAAYwd,KAAK,KAAMza,EAAImY,OAEnCnY,EAAI/C,WACf,CAgBqBkjB,CAA4BngB,EAAI9C,MAEtC,CAAe,CAACuB,IAC3B,OAAO,IAAI6T,WAAWpV,EAAKiX,OAAQjX,EAAKkX,WAAYlX,EAAKmX,WAC7D,CAOqC+L,CAAcH,EAAMxhB,GAAQsa,EAAKxE,kBAClE,EACA,cAAA8L,CAAeJ,EAAM1a,EAAK+a,GACtB,IAAIvH,EAAO6G,EAAaK,GACxBM,EAAsBxH,EAAM6G,EAAara,GAAMwT,EAAKxE,kBAAmB+L,EAC3E,GAGGzU,eAAe,EAAI7L,EAAK+e,EAAY,KAAMhT,EAAO,CAAC,GACrD,OCnFGF,eAAmB7L,EAAK+e,EAAWhT,EAAM+T,GAC5C,IAAIhD,GAAU,QAAY9c,GACtBwgB,EAAU,IAAI3B,EAAa,CAC3BE,YACA1e,MAAOL,EAAIK,MACXua,YAAa5a,EAAIkD,SAEjBgV,EAAM4H,EAAOC,QAAQ,IAAIjD,EAAQtI,WAAWgM,EAAQngB,MAAMoV,QAAO,CAAC/M,EAAG7I,IAAM6I,EAAI7I,GAAG,IAAK2gB,EAAQngB,MAAOyc,EAAQR,YAAYkE,EAAQngB,QAClImL,EAAQO,EAAK0U,mBAAoB,UACrC,IAAK,MAAM,aAAEhE,EAAY,QAAE+C,KAAagB,EACpChV,EAAM6D,KAAIxD,UACN,IAAI,KAAE3O,EAAI,MAAEmD,EAAK,OAAE0U,SAAiB/U,EAAI4L,SAAS6Q,EAAc1Q,EAAKA,MAChEtI,EAAQqc,EAAOC,QAAQ7iB,EAAMmD,EAAO0U,GACxC+K,EAAOO,eAAenI,EAAKzU,EAAO+b,EAAQ,IAMlD,aAHMhU,EAAMkV,SAGoB,IAAzBF,EAAQngB,MAAMtC,OAtBzB,SAAgBiC,GACZ,MAAQ,QAASA,EAAMA,EAAIqM,IAqB0B,GArBfrM,EAqBe,EApBzD,CAoBwC2gB,CAAOzI,EAAIhb,MAAWgb,CAC9D,CD+DW7L,CAAgBrM,EAAK+e,EAAWhT,EAAM+T,EACjD,CAKA,SAASc,EAAY5c,EAAOga,EAAMC,GAC9B,OAAIA,EAAO,GAAKD,EAAOha,EACZ1F,KAAKC,OAAOyF,EAAQga,EAAO,IAAMC,GAAQ,EAEhDja,EAAQga,EACD1f,KAAKC,OAAOyf,EAAOha,EAAQ,GAAKia,GAAQ,EAC5C,CACX,CACA,SAASiC,EAAkBhI,EAAK2I,EAAepiB,EAAO8V,GAClD,GAA6B,IAAzBsM,EAAc9iB,OAEd,YADAma,EAAIhb,KAAKgR,IAAIzP,EAAO,GAGxB,MAAO0G,KAAU2b,GAAUD,GACpBE,KAAgBhM,GAAUmD,EAAInD,OACrC,GAAqB,iBAAV5P,EAGP,YADA+a,EAAkB,CAAEhjB,KADPgb,EAAIhb,KAAKyiB,SAASoB,EAAc5b,EAAQoP,GAC3BQ,UAAU+L,EAAQriB,EAAO8V,GAGvD,MAAOvO,EAAMyZ,EAAIxB,GAAQ9Y,EACnB6b,EAAMJ,EAAY5a,EAAMyZ,EAAIxB,GAClC,GAAsB,IAAlB6C,EAAO/iB,OAMX,IAAK,IAAID,EAAI,EAAGA,EAAIkjB,EAAKljB,IAErBoiB,EAAkB,CAAEhjB,KADPgb,EAAIhb,KAAKyiB,SAASoB,GAAe/a,EAAOiY,EAAOngB,GAAKyW,GACvCQ,UAAU+L,EAAQriB,EAAO8V,QAPnD,IAAK,IAAIzW,EAAI,EAAGA,EAAIkjB,EAAKljB,IACrBoa,EAAIhb,KAAKgR,IAAIzP,EAAOsiB,GAAe/a,EAAOiY,EAAOngB,GAAKyW,EAQlE,CACA,SAASgM,EAAsBN,EAAM1a,EAAKgP,EAAmB+L,GACzD,MAAOW,KAASC,GAASZ,GAClBa,KAAYC,GAAYnB,EAAKlL,QAC7BsM,KAAYC,GAAY/b,EAAIwP,OACnC,GAAkB,OAAdkM,EAAKjb,KACL,OAAqB,IAAjBkb,EAAMnjB,YACNkiB,EAAK/iB,KAAKgR,IAAI3I,EAAIrI,KAAKyiB,SAAS,EAAGpL,GAAoB0M,EAAKxB,GAAKlL,QAGrEgM,EAAsB,CAClBrjB,KAAM+iB,EAAK/iB,KAAKyiB,SAASwB,EAAUF,EAAKxB,GAAKlL,GAC7CQ,OAAQqM,GACT7b,EAAKgP,EAAmB2M,GAG/B,GAAgB,OAAZD,EAAKxB,GAAa,CAClB,GAAqB,IAAjByB,EAAMnjB,OAAc,CACpB,IAAI8G,EAASoc,EAAKjb,KAAOuO,EAEzB,YADA0L,EAAK/iB,KAAKgR,IAAI3I,EAAIrI,KAAKyiB,SAAS9a,EAAQA,EAAS0P,GAAoB,EAEzE,CAKA,YAJAgM,EAAsBN,EAAM,CACxB/iB,KAAMqI,EAAIrI,KAAKyiB,SAAS0B,EAAUJ,EAAKjb,KAAOuO,GAC9CQ,OAAQuM,GACT/M,EAAmB2M,EAE1B,CACA,MAAOlb,EAAMyZ,EAAIxB,GAAQgD,EAAKxB,IACvB8B,EAAOtb,EAAGub,GAASP,EAAKjb,KACzBgb,EAAMJ,EAAY5a,EAAMyZ,EAAIxB,GAClC,GAAqB,IAAjBiD,EAAMnjB,OAgBV,IAAK,IAAID,EAAI,EAAGA,EAAIkjB,EAAKljB,IACrByiB,EAAsB,CAClBrjB,KAAM+iB,EAAK/iB,KAAKyiB,SAASwB,GAAWnb,EAAOlI,EAAImgB,GAAQ1J,GACvDQ,OAAQqM,GACT,CACClkB,KAAMqI,EAAIrI,KAAKyiB,SAAS0B,GAAWE,EAAQzjB,EAAI0jB,GAASjN,GACxDQ,OAAQuM,GACT/M,EAAmB2M,OAvB1B,CAGI,GAAa,IAATjD,GAAwB,IAAVuD,GAA2B,IAAZL,GAA6B,IAAZE,EAAe,CAC7D,IAAIxc,EAAS0c,EAAQhN,EACjBrF,EAAO8R,EAAMzM,EAEjB,YADA0L,EAAK/iB,KAAKgR,IAAI3I,EAAIrI,KAAKyiB,SAAS9a,EAAQA,EAASqK,GAAOlJ,EAAOuO,EAEnE,CAEA,IAAK,IAAIzW,EAAI,EAAGA,EAAIkjB,EAAKljB,IAAK,CAC1B,IAAI+G,EAASwc,GAAWE,EAAQC,EAAQ1jB,GAAKyW,EAC7C0L,EAAK/iB,KAAKgR,IAAI3I,EAAIrI,KAAKyiB,SAAS9a,EAAQA,EAAS0P,GAAoB4M,GAAWnb,EAAOiY,EAAOngB,GAAKyW,EACvG,CAEJ,CAUJ,C,iBEtLO,SAAUvB,EAAMhP,EAAOga,EAAMC,EAAO,QAC1BrW,IAAToW,IACAA,EAAOha,EACPA,EAAQ,GAEZ,IAAK,IAAIlG,EAAIkG,EAAOlG,EAAIkgB,EAAMlgB,GAAKmgB,QACzBngB,CAEd,CAKO,SAAU2jB,KAAWC,GACxB,GAAyB,IAArBA,EAAU3jB,OACV,OAGJ,MAAM4jB,EAAYD,EAAUpd,KAAKsd,GAAOA,EAAGxc,OAAOC,cAC5Cwc,EAAUF,EAAUrd,KAAKsd,GAAOA,EAAGE,SACzC,GAAID,EAAQle,MAAMoe,GAAMA,EAAEC,OACtB,MAAM,IAAInT,MAAM,qCAEpB,IAAK,IAAI/Q,EAAI,IAAK,CACd,GAAI+jB,EAAQ/jB,GAAGkkB,MAKX,GAHAL,EAAU7jB,GAAK4jB,EAAU5jB,GAAGsH,OAAOC,YACnCwc,EAAQ/jB,GAAK6jB,EAAU7jB,GAAGgkB,SAEpBhkB,GAAK6jB,EAAU5jB,OACjB,kBAKE8jB,EAAQvd,KAAI,EAAG7F,WAAYA,IACjCX,EAAI,EAER+jB,EAAQ/jB,GAAK6jB,EAAU7jB,GAAGgkB,MAC9B,CACJ,CAEO,SAASG,GAAc,MAAEje,EAAK,KAAEga,EAAI,KAAEC,GAAQlgB,GACjD,GAAa,IAATkgB,EACA,MAAM,IAAIpP,MAAM,6BAGpB,MAAMqT,GADNjE,EAAOA,GAAQ,GACiB,GAEzBkE,EAAOC,GAASF,EAAmB,EAAE,EAAGnkB,EAAS,GAAK,CAAC,EAAGA,GA+BjE,OA7Bc,OAAViG,EACAA,EAAQke,EAAmBE,EAAQD,EAG/Bne,EAAQ,GACRA,GAASjG,GACGokB,IACRne,EAAQme,GAGPne,EAAQoe,IACbpe,EAAQoe,GAIH,OAATpE,EACAA,EAAOkE,EAAmBC,EAAQC,EAG9BpE,EAAO,GACPA,GAAQjgB,GACGokB,IACPnE,EAAOmE,GAGNnE,EAAOoE,IACZpE,EAAOoE,GAGR,CAACpe,EAAOga,EAAMC,EACzB,CACO,SAAS9Y,EAAMnB,EAAOga,EAAMC,EAAO,MAKtC,YAJarW,IAAToW,IACAA,EAAOha,EACPA,EAAQ,MAEL,CACHA,QACAga,OACAC,OAER,CAEO,SAASwC,IACZ,MAAMzR,EAAW,GACjB,MAAO,CACHK,IAAMgT,GAAOrT,EAAStM,KAAK2f,KAC3B3B,OAAQ,IAAM7S,QAAQyU,IAAItT,GAElC,C,yHClGA,IAAIuT,EACJ,WACI,IAAIC,EAAiB,IAAIC,QACzB,SAASC,EAAWnI,GAChB,IAAIoI,EAASH,EAAenW,IAAIkO,IAAU,CAAEqI,GAAI,EAAGC,GAAI,GAEvD,OADAL,EAAetU,IAAIqM,EAAOoI,GACnBA,CACX,CACA,MAAO,CACH,SAAAG,CAAUvI,EAAOwI,GACbL,EAAWnI,GAAOwI,IAAY,CAClC,EACA,WAAAC,CAAYzI,GACR,IAAIoI,EAASD,EAAWnI,GACxB,OAAOoI,EAAOE,GAAKF,EAAOC,GAAK,KAAO,IAC1C,EAER,CAjBsBK,GAsCtBpX,eAAeqX,EAAc/I,EAAUwB,GACnC,IAAI,KAAEhQ,GAASwO,EAASrM,QAAQ,WAC5BvD,QAAa4P,EAASI,MAAMlO,IAAIV,GACpC,IAAKpB,EACD,MAAM,IAAI,IAAkB,WAAY,CACpC4Y,MAAO,IAAI,IAASxX,KAI5B,OADA4W,EAAgBO,UAAU3I,EAASI,MAAO,MACnC,IAAI,KAAMJ,EAASI,MAAOJ,EAASxO,MAAM,SAAwB,QAAmBpB,GAAOoR,GACtG,CACA9P,eAAeuX,EAAcjJ,EAAUwB,GACnC,IAAI,KAAEhQ,GAASwO,EAASrM,QAAQ,WAC5BvD,QAAa4P,EAASI,MAAMlO,IAAIV,GACpC,IAAKpB,EACD,MAAM,IAAI,IAAkB,WAAY,CACpC4Y,MAAO,IAAI,IAASxX,KAI5B,OADA4W,EAAgBO,UAAU3I,EAASI,MAAO,MACnC,IAAI,KAAMJ,EAASI,MAAOJ,EAASxO,MAAM,SAAwB,QAAmBpB,GAAOoR,GACtG,CA8BO9P,eAAewX,EAAKlJ,EAAU1H,EAAU,CAAC,GAC5C,IAAI8H,EAAQ,UAAWJ,EAAWA,EAASI,MAAQJ,EAC/C6I,EAAcT,EAAgBS,YAAYzI,GAI1C+I,EAA+B,OAAhBN,EAAuBK,EAAKT,GAAKS,EAAKR,GACrDU,EAAiC,OAAhBP,EAAuBK,EAAKR,GAAKQ,EAAKT,GAC3D,OAAOU,EAAanJ,EAAU1H,GAASlC,OAAOiT,KAC1C,QAAeA,EAAK,KACbD,EAAepJ,EAAU1H,KAExC,CACA4Q,EAAKT,GA9EL/W,eAAuBsO,EAAU1H,EAAU,CAAC,GACxC,IAAIgR,EAAM,UAAWtJ,EAAWA,EAAW,IAAI,KAASA,GACpDwB,EAAQ,CAAC,EAGb,OAFIlJ,EAAQkJ,OAAS,KACjBA,QAVR9P,eAA0BsO,GACtB,IAAIuJ,QAAmBvJ,EAASI,MAAMlO,IAAI8N,EAASrM,QAAQ,WAAWnC,MACtE,OAAK+X,GAEE,QAAmBA,GADf,CAAC,CAEhB,CAKsBC,CAAWF,IACR,UAAjBhR,EAAQiB,KACDwP,EAAcO,EAAK9H,GACT,UAAjBlJ,EAAQiB,KACD0P,EAAcK,EAAK9H,GACvBuH,EAAcO,EAAK9H,GAAOpL,OAAOiT,KACpC,QAAeA,EAAK,KACbJ,EAAcK,EAAK9H,KAElC,EAkEA0H,EAAKR,GA3BLhX,eAAuBsO,EAAU1H,EAAU,CAAC,GACxC,IAAIgR,EAAM,UAAWtJ,EAAWA,EAAW,IAAI,KAASA,GACpDyJ,QAlBR/X,eAAwBsO,GACpB,IAAI,MAAEI,EAAK,KAAE5O,GAASwO,EAASrM,QAAQ,aACnCvD,QAAa4P,EAASI,MAAMlO,IAAIV,GACpC,IAAKpB,EACD,MAAM,IAAI,IAAkB,oBAAqB,CAC7C4Y,MAAO,IAAI,IAASxX,KAG5B,IAAIkY,GAAW,QAAmBtZ,GAIlC,MAH2B,UAAvBsZ,EAASC,YACTD,EAAS5H,YAAa,QAAsB4H,IAElB,UAAvBA,EAASC,UACV,IAAI,KAAMvJ,EAAOJ,EAASxO,KAAMkY,GAChC,IAAI,KAAMtJ,EAAOJ,EAASxO,KAAMkY,EAC1C,CAGqBE,CAASN,GAE1B,GADAlB,EAAgBO,UAAUW,EAAIlJ,MAAO,WAChB3S,IAAjB6K,EAAQiB,KACR,OAAOkQ,EACX,GAAqB,UAAjBnR,EAAQiB,MAAoBkQ,aAAgB,KAC5C,OAAOA,EACX,GAAqB,UAAjBnR,EAAQiB,MAAoBkQ,aAAgB,KAC5C,OAAOA,EACX,IAAIlQ,EAAOkQ,aAAgB,KAAQ,QAAU,QAC7C,MAAM,IAAI/U,MAAM,yBAAyB4D,EAAQiB,eAAeA,KACpE,C,qDCjFO,MAAMsQ,EACT,GACA,WAAA/mB,CAAY8C,EAAGqU,EAAYrW,GACN,iBAANgC,EACP5C,MAAK,EAAS,IAAImV,WAAWvS,GAExBA,aAAakkB,YAClB9mB,MAAK,EAAS,IAAImV,WAAWvS,EAAGqU,EAAYrW,GAG5CZ,MAAK,EAAS,IAAImV,WAAWvN,MAAMiB,KAAKjG,GAAIuC,GAAOA,EAAI,EAAI,IAEnE,CACA,qBAAImS,GACA,OAAO,CACX,CACA,cAAIL,GACA,OAAOjX,MAAK,EAAOiX,UACvB,CACA,cAAIC,GACA,OAAOlX,MAAK,EAAOkX,UACvB,CACA,UAAIF,GACA,OAAOhX,MAAK,EAAOgX,MACvB,CACA,UAAIpW,GACA,OAAOZ,MAAK,EAAOY,MACvB,CACA,GAAAsO,CAAI1G,GACA,IAAIlH,EAAQtB,MAAK,EAAOwI,GACxB,MAAwB,iBAAVlH,EAA+B,IAAVA,EAAcA,CACrD,CACA,GAAAyP,CAAIvI,EAAKlH,GACLtB,MAAK,EAAOwI,GAAOlH,EAAQ,EAAI,CACnC,CACA,IAAAwB,CAAKxB,GACDtB,MAAK,EAAO8C,KAAKxB,EAAQ,EAAI,EACjC,CACA,EAAE2G,OAAOC,YACL,IAAK,IAAIvH,EAAI,EAAGA,EAAIX,KAAKY,OAAQD,UACvBX,KAAKkP,IAAIvO,EAEvB,EAOG,MAAMomB,EACTC,MACAhM,MACA,GACA,WAAAlb,CAAYkb,EAAOpY,EAAGqU,EAAYrW,GAG9B,GAFAZ,KAAKgb,MAAQA,EACbhb,MAAK,EAAW,IAAIia,YACH,iBAANrX,EACP5C,KAAKgnB,MAAQ,IAAI7R,WAAWvS,EAAIoY,QAE/B,GAAIpY,aAAakkB,YACdlmB,IACAA,GAAkBoa,GACtBhb,KAAKgnB,MAAQ,IAAI7R,WAAWvS,EAAGqU,EAAYrW,OAE1C,CACD,IAAIqmB,EAASrf,MAAMiB,KAAKjG,GACxB5C,KAAKgnB,MAAQ,IAAI7R,WAAW8R,EAAOrmB,OAASoa,GAC5C,IAAK,IAAIra,EAAI,EAAGA,EAAIsmB,EAAOrmB,OAAQD,IAC/BX,KAAK+Q,IAAIpQ,EAAGsmB,EAAOtmB,GAE3B,CACJ,CACA,qBAAI2W,GACA,OAAOtX,KAAKgb,KAChB,CACA,cAAI/D,GACA,OAAOjX,KAAKgnB,MAAM/P,UACtB,CACA,cAAIC,GACA,OAAOlX,KAAKgnB,MAAM9P,UACtB,CACA,UAAIF,GACA,OAAOhX,KAAKgnB,MAAMhQ,MACtB,CACA,UAAIpW,GACA,OAAOZ,KAAKkX,WAAalX,KAAKsX,iBAClC,CACA,GAAApI,CAAI1G,GACA,MAAMoT,EAAO,IAAIzG,WAAWnV,KAAKgX,OAAQhX,KAAKiX,WAAajX,KAAKgb,MAAQxS,EAAKxI,KAAKgb,OAElF,OAAO,IAAIW,aAAc7E,OAAO8E,GAAMjC,QAAQ,QAAS,GAC3D,CACA,GAAA5I,CAAIvI,EAAKlH,GACL,MAAMsa,EAAO,IAAIzG,WAAWnV,KAAKgX,OAAQhX,KAAKiX,WAAajX,KAAKgb,MAAQxS,EAAKxI,KAAKgb,OAClFY,EAAK9Y,KAAK,GACV8Y,EAAK7K,IAAI/Q,MAAK,EAAS4W,OAAOtV,GAClC,CACA,IAAAwB,CAAKxB,GACD,MAAM4lB,EAAUlnB,MAAK,EAAS4W,OAAOtV,GACrC,IAAK,IAAIX,EAAI,EAAGA,EAAIX,KAAKY,OAAQD,IAC7BX,KAAKgnB,MAAMjW,IAAImW,EAASvmB,EAAIX,KAAKgb,MAEzC,CACA,EAAE/S,OAAOC,YACL,IAAK,IAAIvH,EAAI,EAAGA,EAAIX,KAAKY,OAAQD,UACvBX,KAAKkP,IAAIvO,EAEvB,EAOG,MAAMwmB,EACT,GACAnM,MACA,WAAAlb,CAAYkb,EAAOpY,EAAGqU,EAAYrW,GAE9B,GADAZ,KAAKgb,MAAQA,EACI,iBAANpY,EACP5C,MAAK,EAAQ,IAAIonB,WAAWxkB,EAAIoY,QAE/B,GAAIpY,aAAakkB,YACdlmB,IACAA,GAAUoa,GACdhb,MAAK,EAAQ,IAAIonB,WAAWxkB,EAAGqU,EAAYrW,OAE1C,CACD,MAAMqmB,EAASrkB,EACT4a,EAAI,IAAI2J,EAAmBnM,EAAO,GACxChb,MAAK,EAAQ,IAAIonB,WAAW,YACxB,IAAK,IAAIC,KAAOJ,EACZzJ,EAAEzM,IAAI,EAAGsW,SACF7J,GAAE,CAEhB,CAL2B,GAMhC,CACJ,CACA,qBAAIlG,GACA,OAAOtX,MAAK,EAAMsX,kBAAoBtX,KAAKgb,KAC/C,CACA,cAAI9D,GACA,OAAOlX,MAAK,EAAMkX,UACtB,CACA,cAAID,GACA,OAAOjX,MAAK,EAAMiX,UACtB,CACA,UAAID,GACA,OAAOhX,MAAK,EAAMgX,MACtB,CACA,UAAIpW,GACA,OAAOZ,MAAK,EAAMY,OAASZ,KAAKgb,KACpC,CACA,GAAA9L,CAAI1G,GACA,MAAMd,EAAS1H,KAAKgb,MAAQxS,EAC5B,IAAIyB,EAAS,GACb,IAAK,IAAItJ,EAAI,EAAGA,EAAIX,KAAKgb,MAAOra,IAC5BsJ,GAAUqd,OAAOC,cAAcvnB,MAAK,EAAM0H,EAAS/G,IAGvD,OAAOsJ,EAAO0P,QAAQ,UAAW,GACrC,CACA,GAAA5I,CAAIvI,EAAKlH,GACL,MAAMoG,EAAS1H,KAAKgb,MAAQxS,EACtBoT,EAAO5b,MAAK,EAAMwiB,SAAS9a,EAAQA,EAAS1H,KAAKgb,OACvDY,EAAK9Y,KAAK,GACV,IAAK,IAAInC,EAAI,EAAGA,EAAIX,KAAKgb,MAAOra,IAC5Bib,EAAKjb,GAAKW,EAAMkmB,YAAY7mB,IAAM,CAE1C,CACA,IAAAmC,CAAKxB,GAEDtB,KAAK+Q,IAAI,EAAGzP,GAEZ,IAAI4lB,EAAUlnB,MAAK,EAAMwiB,SAAS,EAAGxiB,KAAKgb,OAC1C,IAAK,IAAIra,EAAI,EAAGA,EAAIX,KAAKY,OAAQD,IAC7BX,MAAK,EAAM+Q,IAAImW,EAASvmB,EAAIX,KAAKgb,MAEzC,CACA,EAAE/S,OAAOC,YACL,IAAK,IAAIvH,EAAI,EAAGA,EAAIX,KAAKY,OAAQD,UACvBX,KAAKkP,IAAIvO,EAEvB,E,mJC5LG,SAAS8mB,EAAmB9P,GAC/B,MAAM0P,GAAM,IAAI1L,aAAc7E,OAAOa,GACrC,OAAO8B,KAAKiO,MAAML,EACtB,CACO,SAASM,EAAiB/L,EAAMxE,GACnC,MAAMwQ,EAAWxQ,EAAoB,EAC/ByQ,EAAezQ,EAAoB,EACzC,IAAIpO,EAAI,EACR,IAAK,IAAIrI,EAAI,EAAGA,EAAIib,EAAKhb,OAAQD,GAAKyW,EAClC,IAAK,IAAI0Q,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAC/B9e,EAAI4S,EAAKjb,EAAImnB,GACblM,EAAKjb,EAAImnB,GAAKlM,EAAKjb,EAAIknB,EAAeC,GACtClM,EAAKjb,EAAIknB,EAAeC,GAAK9e,CAGzC,CACO,SAAS+e,EAAQtQ,GACpB,GAAkB,cAAdA,EACA,OAAOiL,WAAW9a,MAEtB,IAAIogB,EAAQvQ,EAAUuQ,MAAM,kBAC5B,GAAIA,EAAO,CACP,IAAK,CAAEzR,EAAMyE,GAASgN,EAEtB,OAAiB,MAATzR,EAAe,KAAqB,MAAiB+G,KAAK,KAAM3X,OAAOqV,GACnF,CAEA,IAAIiN,EAAM,CACNC,KAAMC,UACNC,MAAOC,WACPC,MAAOlB,WACPmB,MAAO7F,WAAW8F,cAClBC,MAAOtT,WACPuT,OAAQC,YACRC,OAAQvoB,YACRwoB,OAAQnG,WAAWoG,eACnBC,QAASrG,WAAWsG,aACpBC,QAASC,aACTC,QAASC,aACTC,KAAM,MACR5R,GAEF,OADA6R,EAAOrB,EAAK,qCAAqCxQ,KAC1CwQ,CACX,CAEO,SAAS9I,EAAYjc,EAAOmX,GAC/B,MAAMC,EAAOpX,EAAMtC,OACE,iBAAVyZ,IACPA,EACc,MAAVA,EACMzS,MAAMiB,KAAK,CAAEjI,OAAQ0Z,IAAQ,CAACxR,EAAGnI,IAAMA,IACvCiH,MAAMiB,KAAK,CAAEjI,OAAQ0Z,IAAQ,CAACxR,EAAGnI,IAAM2Z,EAAO,EAAI3Z,KAEhE2oB,EAAOhP,IAASD,EAAMzZ,OAAQ,qDAC9B,IAAIkgB,EAAO,EACPlJ,EAAS,IAAIhQ,MAAM0S,GACvB,IAAK,IAAI3Z,EAAI0Z,EAAMzZ,OAAS,EAAGD,GAAK,EAAGA,IACnCiX,EAAOyC,EAAM1Z,IAAMmgB,EACnBA,GAAQ5d,EAAMmX,EAAM1Z,IAExB,OAAOiX,CACX,CAEO,SAAS2R,GAAyB,KAAEnmB,EAAI,cAAEoT,IAC7C,GAAa,YAATpT,EAAoB,CACpB,MAAMomB,EAAYhT,GAAegT,WAAa,IAC9C,OAAQlK,GAAiB,CAAC,OAAQA,GAActQ,KAAKwa,EACzD,CACA,GAAa,OAATpmB,EAAe,CACf,MAAMomB,EAAYhT,GAAegT,WAAa,IAC9C,OAAQlK,GAAiBA,EAAatQ,KAAKwa,IAAc,GAC7D,CACA,MAAM,IAAI9X,MAAM,+BAA+BtO,IACnD,CA6BO,SAASqmB,EAAwBrc,EAAMqR,EAAa,CAAC,GACxD,IAAInC,EAAS,GACToD,EA9BR,SAAsBA,GAClB,GAAc,OAAVA,EACA,MAAO,CAAEjI,UAAW,aAExB,IAAIuQ,EAAQtI,EAAMsI,MAAM,iBACxBsB,EAAOtB,EAAO,kBAAkBtI,KAChC,IAAK,CAAElI,EAAQkS,GAAQ1B,EACnBvQ,EAAY,CACZkS,GAAI,OACJC,GAAI,OACJC,GAAI,QACJC,GAAI,QACJC,GAAI,SACJC,GAAI,QACJC,GAAI,SACJC,GAAI,QACJC,GAAI,SACJC,GAAI,UACJC,GAAI,UACJC,GAAI,WACNZ,KACGA,EAAKa,WAAW,MAAQb,EAAKa,WAAW,KAAO,MAAMb,SAASjf,GAEnE,OADA6e,EAAO7R,EAAW,iCAAiCiI,KACpC,MAAXlI,EACO,CAAEC,aAEN,CAAEA,YAAWD,OAAmB,MAAXA,EAAiB,SAAW,MAC5D,CAGgBgT,CAAapd,EAAKsS,OACX,MAAftS,EAAKiN,OACLiC,EAAO/W,KAAK,CAAEnC,KAAM,YAAaoT,cAAe,CAAE6D,MAAO,OAEzD,WAAYqF,GAA0B,QAAjBA,EAAMlI,QAC3B8E,EAAO/W,KAAK,CAAEnC,KAAM,QAASoT,cAAe,CAAEgB,OAAQ,SAE1D,IAAK,IAAI,GAAEiT,KAAOjU,KAAmBpJ,EAAKsd,SAAW,GACjDpO,EAAO/W,KAAK,CAAEnC,KAAMqnB,EAAIjU,kBAE5B,GAAIpJ,EAAKud,WAAY,CACjB,IAAI,GAAEF,KAAOjU,GAAkBpJ,EAAKud,WACpCrO,EAAO/W,KAAK,CAAEnC,KAAMqnB,EAAIjU,iBAC5B,CACA,MAAO,CACHoU,YAAa,EACbjE,UAAW,QACXzjB,MAAOkK,EAAKlK,MACZuU,UAAWiI,EAAMjI,UACjB4H,WAAY,CACRjc,KAAM,UACNoT,cAAe,CACXiH,YAAarQ,EAAKrH,SAG1BkZ,mBAAoB,CAChB7b,KAAM,KACNoT,cAAe,CACXgT,UAAWpc,EAAKyd,qBAAuB,MAG/CvO,SACAwC,WAAY1R,EAAK0R,WACjBL,aAER,CACO,SAASqM,EAAwBrU,EAAOgI,EAAa,CAAC,GACzD,MAAO,CACHmM,YAAa,EACbjE,UAAW,QACXlI,aAER,CACO,SAASsM,EAASrL,EAAOI,GAC5B,GAAc,WAAVA,GACU,WAAVA,GACU,YAAVA,GACU,WAAVA,GACU,WAAVA,EACA,OAAOJ,IAAUI,EAErB,IAAIkL,EAAuB,SAAVtL,EACjB,GAAc,YAAVI,EACA,OAAOkL,EACX,IAAIC,EAAYvL,EAAM6K,WAAW,SAAW7K,EAAM6K,WAAW,QAC7D,GAAc,WAAVzK,EACA,OAAOmL,EACX,IAAIC,EAAsB,UAAVxL,GAA+B,WAAVA,EACrC,GAAc,WAAVI,EACA,OAAOoL,EACX,IAAIC,EAAsB,cAAVzL,EAChB,MAAc,WAAVI,EACOqL,IACHF,GAAcC,GAAcF,GAAeG,EACvD,CACO,SAASC,EAAkB5O,GAC9B,MAAuB,qBAAhBA,GAAOpZ,IAClB,CACO,SAASioB,EAAsB/M,GAClC,MAA4B,WAAvBA,EAAS7G,WAAiD,UAAvB6G,EAAS7G,WACtB,MAAvB6G,EAASQ,WAINR,EAASQ,WAFLwM,OAAOhN,EAASQ,WAG/B,CA0BO,SAASyM,EAAeC,KAAUC,GACrC,IAAKA,EAAOjlB,MAAMklB,GAAeF,aAAiBE,IAC9C,MAAMF,CAEd,CAgBO,SAASlC,EAAOqC,EAAY3L,EAAM,IACrC,IAAK2L,EACD,MAAM,IAAIja,MAAMsO,EAExB,C","sources":["webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/Histogram.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/VolumeDims.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/ImageInfo.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/ChunkPrefetchIterator.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/utils.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/validation.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/wrapArray.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/RequestQueue.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/SubscribableRequestQueue.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/workers/types.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/workers/util.js","webpack://@aics/vole-app/./node_modules/@zarrita/storage/dist/src/util.js","webpack://@aics/vole-app/./node_modules/@zarrita/storage/dist/src/fetch.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/bitround.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/bytes.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/crc32c.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/json2.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/transpose.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/vlen-utf8.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/sharding.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/hierarchy.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/indexer.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/ops.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/get.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/util.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/open.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/typedarray.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/util.js"],"sourcesContent":["const NBINS = 256;\n/**\n * Builds a histogram with 256 bins from a data array. Assume data is 8 bit single channel grayscale.\n * @class\n * @param {Array.<number>} data\n */\nexport default class Histogram {\n  // no more than 2^32 pixels of any one intensity in the data!?!?!\n\n  /** Min value in the original raw data. */\n\n  /** Max value in the original raw data. */\n\n  /** Size of each histogram bin in the scale of the original data. */\n\n  /** Index of the first bin (other than 0) with at least 1 value. */\n\n  /** Index of the last bin (other than 0) with at least 1 value. */\n\n  constructor(data) {\n    this.dataMinBin = 0;\n    this.dataMaxBin = 0;\n    this.maxBin = 0;\n    this.bins = new Uint32Array();\n    this.min = 0;\n    this.max = 0;\n    this.binSize = 0;\n\n    // build up the histogram\n    const hinfo = Histogram.calculateHistogram(data, NBINS);\n    this.bins = hinfo.bins;\n    this.min = hinfo.min;\n    this.max = hinfo.max;\n    this.binSize = hinfo.binSize;\n\n    // TODO: These should always return 0 and NBINS - 1, respectively. Test if these\n    // can be removed.\n    for (let i = 0; i < this.bins.length; i++) {\n      if (this.bins[i] > 0) {\n        this.dataMinBin = i;\n        break;\n      }\n    }\n    for (let i = this.bins.length - 1; i >= 0; i--) {\n      if (this.bins[i] > 0) {\n        this.dataMaxBin = i;\n        break;\n      }\n    }\n    this.pixelCount = data.length;\n\n    // get the bin with the most frequently occurring NONZERO value\n    this.maxBin = 1;\n    let max = this.bins[1];\n    for (let i = 1; i < this.bins.length; i++) {\n      if (this.bins[i] > max) {\n        this.maxBin = i;\n        max = this.bins[i];\n      }\n    }\n  }\n\n  // return the bin index of the given data value\n  static findBin(dataValue, dataMin, binSize, numBins) {\n    let binIndex = Math.floor((dataValue - dataMin) / binSize);\n    // for values that lie exactly on last bin we need to subtract one\n    if (binIndex === numBins) {\n      binIndex--;\n    }\n    return binIndex;\n  }\n\n  // return the bin index of the given data value\n  findBinOfValue(value) {\n    return Histogram.findBin(value, this.min, this.binSize, NBINS);\n  }\n\n  /**\n   * Return the min data value\n   * @return {number}\n   */\n  getDataMin() {\n    return this.min;\n  }\n\n  /**\n   * Return the max data value\n   * @return {number}\n   */\n  getDataMax() {\n    return this.max;\n  }\n\n  /**\n   * Returns the first bin index with at least 1 value, other than the 0th bin.\n   * @return {number}\n   */\n  getMin() {\n    return this.dataMinBin;\n  }\n\n  /**\n   * Returns the last bin index with at least 1 value, other than the 0th bin.\n   * @return {number}\n   */\n  getMax() {\n    // Note that this will always return `NBINS - 1`.\n    return this.dataMaxBin;\n  }\n  getNumBins() {\n    return this.bins.length;\n  }\n  getBin(i) {\n    return this.bins[i];\n  }\n  getBinRange(i) {\n    return [this.min + i * this.binSize, this.min + (i + 1) * this.binSize];\n  }\n\n  /**\n   * Find the bin that contains the percentage of pixels below it\n   * @return {number}\n   * @param {number} pct\n   */\n  findBinOfPercentile(pct) {\n    const limit = this.pixelCount * pct;\n    let i = 0;\n    let count = 0;\n    for (i = 0; i < this.bins.length; ++i) {\n      count += this.bins[i];\n      if (count > limit) {\n        break;\n      }\n    }\n    return i;\n  }\n\n  // Find bins at 10th / 90th percentile\n  findBestFitBins() {\n    const pixcount = this.pixelCount;\n    //const pixcount = this.imgData.data.length;\n    const limit = pixcount / 10;\n    let i = 0;\n    let count = 0;\n    for (i = 1; i < this.bins.length; ++i) {\n      count += this.bins[i];\n      if (count > limit) {\n        break;\n      }\n    }\n    const hmin = i;\n    count = 0;\n    for (i = this.bins.length - 1; i >= 1; --i) {\n      count += this.bins[i];\n      if (count > limit) {\n        break;\n      }\n    }\n    const hmax = i;\n    return [hmin, hmax];\n  }\n\n  // Find min and max bins attempting to replicate ImageJ's \"Auto\" button\n  findAutoIJBins() {\n    // note that consecutive applications of this should modify the auto threshold. see:\n    // https://github.com/imagej/ImageJ/blob/7746fcb0f5744a7a7758244c5dcd2193459e6e0e/ij/plugin/frame/ContrastAdjuster.java#L816\n    const AUTO_THRESHOLD = 5000;\n    const pixcount = this.pixelCount;\n    //  const pixcount = this.imgData.data.length;\n    const limit = pixcount / 10;\n    const threshold = pixcount / AUTO_THRESHOLD;\n\n    // this will skip the \"zero\" bin which contains pixels of zero intensity.\n    let hmin = this.bins.length - 1;\n    let hmax = 1;\n    for (let i = 1; i < this.bins.length; ++i) {\n      if (this.bins[i] > threshold && this.bins[i] <= limit) {\n        hmin = i;\n        break;\n      }\n    }\n    for (let i = this.bins.length - 1; i >= 1; --i) {\n      if (this.bins[i] > threshold && this.bins[i] <= limit) {\n        hmax = i;\n        break;\n      }\n    }\n    if (hmax < hmin) {\n      hmin = 0;\n      hmax = 255;\n    }\n    return [hmin, hmax];\n  }\n\n  // Find min and max bins using a percentile of the most commonly occurring value\n  findAutoMinMax() {\n    // simple linear mapping cutting elements with small appearence\n    // get 10% threshold\n    const PERCENTAGE = 0.1;\n    const th = Math.floor(this.bins[this.maxBin] * PERCENTAGE);\n    let b = 0;\n    let e = this.bins.length - 1;\n    for (let x = 1; x < this.bins.length; ++x) {\n      if (this.bins[x] > th) {\n        b = x;\n        break;\n      }\n    }\n    for (let x = this.bins.length - 1; x >= 1; --x) {\n      if (this.bins[x] > th) {\n        e = x;\n        break;\n      }\n    }\n    return [b, e];\n  }\n  static calculateHistogram(arr, numBins = 1) {\n    if (numBins < 1) {\n      numBins = 1;\n    }\n\n    // calculate min and max of arr\n    // TODO See convertChannel, which will also compute min and max!\n    // We could save a whole extra loop over the data, or have convertChannel compute the whole histogram.\n    // need to be careful about computing over chunks or whole ready-to-display volume\n\n    let min = arr[0];\n    let max = arr[0];\n    for (let i = 1; i < arr.length; i++) {\n      if (arr[i] < min) {\n        min = arr[i];\n      } else if (arr[i] > max) {\n        max = arr[i];\n      }\n    }\n    const bins = new Uint32Array(numBins).fill(0);\n    const binSize = (max - min) / numBins === 0 ? 1 : (max - min) / numBins;\n    for (let i = 0; i < arr.length; i++) {\n      const item = arr[i];\n      const binIndex = Histogram.findBin(item, min, binSize, numBins);\n      bins[binIndex]++;\n    }\n    return {\n      bins,\n      min,\n      max,\n      binSize\n    };\n  }\n}","import { Vector3 } from \"three\";\nexport function defaultVolumeDims() {\n  return {\n    shape: [0, 0, 0, 0, 0],\n    spacing: [1, 1, 1, 1, 1],\n    spaceUnit: \"m\",\n    timeUnit: \"s\",\n    dataType: \"uint8\"\n  };\n}\nexport function volumeSize(volumeDims) {\n  return new Vector3(volumeDims.shape[4], volumeDims.shape[3], volumeDims.shape[2]);\n}\nexport function physicalPixelSize(volumeDims) {\n  return new Vector3(volumeDims.spacing[4], volumeDims.spacing[3], volumeDims.spacing[2]);\n}","import { volumeSize, physicalPixelSize } from \"./VolumeDims.js\";\nimport { Vector3, Vector2 } from \"three\";\nexport function defaultImageInfo() {\n  return {\n    name: \"\",\n    atlasTileDims: [1, 1],\n    subregionSize: [1, 1, 1],\n    subregionOffset: [0, 0, 0],\n    combinedNumChannels: 1,\n    channelNames: [\"0\"],\n    channelColors: [[255, 255, 255]],\n    multiscaleLevel: 0,\n    multiscaleLevelDims: [{\n      shape: [1, 1, 1, 1, 1],\n      spacing: [1, 1, 1, 1, 1],\n      spaceUnit: \"\",\n      timeUnit: \"\",\n      dataType: \"uint8\"\n    }],\n    transform: {\n      translation: [0, 0, 0],\n      rotation: [0, 0, 0],\n      scale: [1, 1, 1]\n    }\n  };\n}\nexport class CImageInfo {\n  constructor(imageInfo) {\n    this.imageInfo = imageInfo || defaultImageInfo();\n  }\n  get currentLevelDims() {\n    return this.imageInfo.multiscaleLevelDims[this.imageInfo.multiscaleLevel];\n  }\n\n  /** Number of channels in the image */\n  get numChannels() {\n    return this.imageInfo.combinedNumChannels;\n  }\n\n  /** XYZ size of the *original* (not downsampled) volume, in pixels */\n  get originalSize() {\n    return volumeSize(this.imageInfo.multiscaleLevelDims[0]);\n  }\n\n  /** Size of the volume, in pixels */\n  get volumeSize() {\n    return volumeSize(this.currentLevelDims);\n  }\n\n  /** Size of a single *original* (not downsampled) pixel, in spatial units */\n  get physicalPixelSize() {\n    return physicalPixelSize(this.imageInfo.multiscaleLevelDims[0]);\n  }\n\n  /** Symbol of physical spatial unit used by `physicalPixelSize` */\n  get spatialUnit() {\n    return this.imageInfo.multiscaleLevelDims[0].spaceUnit;\n  }\n\n  /** Number of timesteps in the time series, or 1 if the image is not a time series */\n  get times() {\n    // 0 is T\n    return this.currentLevelDims.shape[0];\n  }\n\n  /** Size of each timestep in temporal units */\n  get timeScale() {\n    // 0 is T\n    return this.currentLevelDims.spacing[0];\n  }\n\n  /** Symbol of physical time unit used by `timeScale` */\n  get timeUnit() {\n    return this.currentLevelDims.timeUnit;\n  }\n\n  /** Number of scale levels available for this volume */\n  get numMultiscaleLevels() {\n    return this.imageInfo.multiscaleLevelDims.length;\n  }\n\n  /** The names of each channel */\n  get channelNames() {\n    return this.imageInfo.channelNames;\n  }\n\n  /** Optional overrides to default channel colors, in 0-255 range */\n  get channelColors() {\n    return this.imageInfo.channelColors;\n  }\n\n  /** Size of the currently loaded subregion, in pixels */\n  get subregionSize() {\n    return new Vector3(...this.imageInfo.subregionSize);\n  }\n\n  /** Offset of the loaded subregion into the total volume, in pixels */\n  get subregionOffset() {\n    return new Vector3(...this.imageInfo.subregionOffset);\n  }\n  get multiscaleLevel() {\n    return this.imageInfo.multiscaleLevel;\n  }\n\n  /**\n   * XY dimensions of the texture atlas used by `RayMarchedAtlasVolume` and `Atlas2DSlice`, in number of z-slice\n   * tiles (not pixels). Chosen by the loader to lay out the 3D volume in the squarest possible 2D texture atlas.\n   */\n  get atlasTileDims() {\n    return new Vector2(...this.imageInfo.atlasTileDims);\n  }\n  get transform() {\n    return {\n      translation: new Vector3(...this.imageInfo.transform.translation),\n      rotation: new Vector3(...this.imageInfo.transform.rotation),\n      scale: new Vector3(...this.imageInfo.transform.scale)\n    };\n  }\n}\nexport function computeAtlasSize(imageInfo) {\n  const {\n    atlasTileDims\n  } = imageInfo;\n  const volDims = imageInfo.multiscaleLevelDims[imageInfo.multiscaleLevel];\n  // TCZYX: 4 = x, 3 = y\n  return [atlasTileDims[0] * volDims.shape[4], atlasTileDims[1] * volDims.shape[3]];\n}","const allEqual = arr => arr.every(v => v === arr[0]);\nconst pushN = (arr, val, n) => {\n  for (let i = 0; i < n; i++) {\n    arr.push(val);\n  }\n};\nconst directionToIndex = dir => {\n  const absDir = dir >> 1; // shave off sign bit to get index in TZYX\n  return absDir + Number(absDir !== 0); // convert TZYX -> TCZYX by skipping c (index 1)\n};\nfunction updateMinMax(val, minmax) {\n  if (val < minmax[0]) {\n    minmax[0] = val;\n  }\n  if (val > minmax[1]) {\n    minmax[1] = val;\n  }\n}\n\n/**\n * Since the user is most likely to want nearby data (in space or time) first, we should prefetch those chunks first.\n *\n * Given a list of just-loaded chunks and some bounds, `ChunkPrefetchIterator` iterates evenly outwards in T/Z/Y/X.\n */\n// NOTE: Assumes `chunks` form a rectangular prism! Will create gaps otherwise! (in practice they always should)\nexport default class ChunkPrefetchIterator {\n  constructor(chunks, tzyxMaxPrefetchOffset, tczyxChunksPerSource, priorityDirections, onlyPriorityDirections = false) {\n    // Get min and max chunk coordinates for T/Z/Y/X\n    const extrema = [[Infinity, -Infinity], [Infinity, -Infinity], [Infinity, -Infinity], [Infinity, -Infinity]];\n    for (const chunk of chunks) {\n      updateMinMax(chunk[0], extrema[0]);\n      updateMinMax(chunk[2], extrema[1]);\n      updateMinMax(chunk[3], extrema[2]);\n      updateMinMax(chunk[4], extrema[3]);\n    }\n\n    // Bail out if we have any non-finite values in the extrema (the iterator will be empty)\n    if (extrema.flat().some(val => !Number.isFinite(val))) {\n      this.directionStates = [];\n      this.priorityDirectionStates = [];\n      return;\n    }\n\n    // Create `PrefetchDirectionState`s for each direction\n    this.directionStates = [];\n    this.priorityDirectionStates = [];\n\n    // iterating like this: direction is the index in the flattened entries\n    // and corresponds to our +T, -T, +Z, -Z, +Y, -Y, +X, -X directions in order\n    // because extrema is in TZYX order.\n    for (const [direction, start] of extrema.flat().entries()) {\n      const dimension = direction >> 1; // shave off sign bit to get index in TZYX\n      const tczyxIndex = dimension + Number(dimension !== 0); // convert TZYX -> TCZYX by skipping c (index 1)\n      let end;\n      if (direction & 1) {\n        // Positive direction - end is either the max coordinate in the fetched set plus the max offset in this\n        // dimension, or the max chunk coordinate in this dimension, whichever comes first\n        const endsPerSource = tczyxChunksPerSource.map(chunkDims => {\n          return Math.min(start + tzyxMaxPrefetchOffset[dimension], chunkDims[tczyxIndex] - 1);\n        });\n\n        // Save some time: if all sources have the same end, we can just store that\n        if (allEqual(endsPerSource)) {\n          end = endsPerSource[0];\n        } else {\n          // Otherwise, expand our ends per source array to ends per channel\n          end = [];\n          for (const [i, sourceEnd] of endsPerSource.entries()) {\n            pushN(end, sourceEnd, tczyxChunksPerSource[i][1]);\n          }\n        }\n        // end = Math.min(start + tzyxMaxPrefetchOffset[dimension], tczyxChunksPerDimension[dimension] - 1);\n      } else {\n        // Negative direction - end is either the min coordinate in the fetched set minus the max offset in this\n        // dimension, or 0, whichever comes first\n        end = Math.max(start - tzyxMaxPrefetchOffset[dimension], 0);\n      }\n      const directionState = {\n        direction,\n        start,\n        end,\n        chunks: []\n      };\n      if (priorityDirections && priorityDirections.includes(direction)) {\n        this.priorityDirectionStates.push(directionState);\n      } else {\n        // we have an option setting that can let us ignore non-priority directions\n        if (!onlyPriorityDirections) {\n          this.directionStates.push(directionState);\n        }\n      }\n    }\n\n    // Fill each `PrefetchDirectionState` with chunks at the border of the fetched set\n    for (const chunk of chunks) {\n      for (const dir of this.directionStates) {\n        if (chunk[directionToIndex(dir.direction)] === dir.start) {\n          dir.chunks.push(chunk);\n        }\n      }\n      for (const dir of this.priorityDirectionStates) {\n        if (chunk[directionToIndex(dir.direction)] === dir.start) {\n          dir.chunks.push(chunk);\n        }\n      }\n    }\n  }\n  static *iterateDirections(directions) {\n    let offset = 1;\n    while (directions.length > 0) {\n      // Remove directions in which we have reached the end (or, if per-channel ends, the end for all channels)\n      directions = directions.filter(dir => {\n        const end = Array.isArray(dir.end) ? Math.max(...dir.end) : dir.end;\n        if (dir.direction & 1) {\n          return dir.start + offset <= end;\n        } else {\n          return dir.start - offset >= end;\n        }\n      });\n\n      // Yield chunks one chunk farther out in every remaining direction\n      for (const dir of directions) {\n        const offsetDir = offset * (dir.direction & 1 ? 1 : -1);\n        for (const chunk of dir.chunks) {\n          // Skip this chunk if this channel has a specific per-channel end and we've reached it\n          if (Array.isArray(dir.end) && chunk[directionToIndex(dir.direction)] + offsetDir > dir.end[chunk[1]]) {\n            continue;\n          }\n          const newChunk = chunk.slice();\n          newChunk[directionToIndex(dir.direction)] += offsetDir;\n          yield newChunk;\n        }\n      }\n      offset += 1;\n    }\n  }\n  *[Symbol.iterator]() {\n    // Yield all chunks in priority direction(s) first, if any\n    if (this.priorityDirectionStates.length > 0) {\n      for (const chunk of ChunkPrefetchIterator.iterateDirections(this.priorityDirectionStates)) {\n        yield chunk;\n      }\n    }\n\n    // Then yield all chunks in other directions\n    for (const chunk of ChunkPrefetchIterator.iterateDirections(this.directionStates)) {\n      yield chunk;\n    }\n  }\n}","import { VolumeLoadErrorType, VolumeLoadError } from \"../VolumeLoadError.js\";\n/** Extracts channel names from a `ZarrSource`. Handles missing `omeroMetadata`. Does *not* resolve name collisions. */\nexport function getSourceChannelNames(src) {\n  if (src.omeroMetadata?.channels) {\n    return src.omeroMetadata.channels.map(({\n      label\n    }, idx) => label ?? `Channel ${idx + src.channelOffset}`);\n  }\n  const cIdx = src.axesTCZYX[1];\n  const length = cIdx < 0 ? 1 : src.scaleLevels[0].shape[cIdx];\n  return Array.from({\n    length\n  }, (_, idx) => `Channel ${idx + src.channelOffset}`);\n}\n\n/** Turns `axesTCZYX` into the number of dimensions in the array */\nexport const getDimensionCount = ([t, c, z]) => 2 + Number(t > -1) + Number(c > -1) + Number(z > -1);\nexport function remapAxesToTCZYX(axes) {\n  const axesTCZYX = [-1, -1, -1, -1, -1];\n  const axisNames = [\"t\", \"c\", \"z\", \"y\", \"x\"];\n  axes.forEach((axis, idx) => {\n    const axisIdx = axisNames.indexOf(axis.name);\n    if (axisIdx > -1) {\n      axesTCZYX[axisIdx] = idx;\n    } else {\n      throw new VolumeLoadError(`Unrecognized axis in zarr: ${axis.name}`, {\n        type: VolumeLoadErrorType.INVALID_METADATA\n      });\n    }\n  });\n\n  // it is possible that Z might not exist but we require X and Y at least.\n  const noXAxis = axesTCZYX[4] === -1;\n  if (noXAxis || axesTCZYX[3] === -1) {\n    throw new VolumeLoadError(`Did not find ${noXAxis ? \"an X\" : \"a Y\"} axis in zarr`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n  return axesTCZYX;\n}\n\n/** Reorder an array of values [T, C, Z, Y, X] to the given dimension order */\nexport function orderByDimension(valsTCZYX, orderTCZYX) {\n  const specLen = getDimensionCount(orderTCZYX);\n  const result = Array(specLen);\n  orderTCZYX.forEach((val, idx) => {\n    if (val >= 0) {\n      if (val >= specLen) {\n        throw new VolumeLoadError(`Unexpected axis index in zarr: ${val}`, {\n          type: VolumeLoadErrorType.INVALID_METADATA\n        });\n      }\n      result[val] = valsTCZYX[idx];\n    }\n  });\n  return result;\n}\n\n/** Reorder an array of values in the given dimension order to [T, C, Z, Y, X] */\nexport function orderByTCZYX(valsDimension, orderTCZYX, defaultValue) {\n  const result = [defaultValue, defaultValue, defaultValue, defaultValue, defaultValue];\n  orderTCZYX.forEach((val, idx) => {\n    if (val >= 0) {\n      if (val >= valsDimension.length) {\n        throw new VolumeLoadError(`Unexpected axis index in zarr: ${val}`, {\n          type: VolumeLoadErrorType.INVALID_METADATA\n        });\n      }\n      result[idx] = valsDimension[val];\n    }\n  });\n  return result;\n}\n\n/** Select the scale transform from an OME metadata object with coordinate transforms, and return it in TCZYX order */\nexport function getScale(dataset, orderTCZYX) {\n  const transforms = dataset.coordinateTransformations;\n  if (transforms === undefined) {\n    console.warn(\"WARNING: OMEZarrLoader: no coordinate transformations for scale level.\");\n    return [1, 1, 1, 1, 1];\n  }\n\n  // this assumes we'll never encounter the \"path\" variant\n  const isScaleTransform = t => t.type === \"scale\";\n\n  // there can be any number of coordinateTransformations\n  // but there must be only one of type \"scale\".\n  const scaleTransform = transforms.find(isScaleTransform);\n  if (!scaleTransform) {\n    console.warn(`WARNING: OMEZarrLoader: no coordinate transformation of type \"scale\" for scale level.`);\n    return [1, 1, 1, 1, 1];\n  }\n  const scale = scaleTransform.scale.slice();\n  return orderByTCZYX(scale, orderTCZYX, 1);\n}\n\n/**\n * Defines a partial order of zarr arrays based on their size. Specifically:\n * - If array size x, y, z are all equal, the arrays are equal\n * - otherwise, if all xyz of `a` are less than or equal to those of `b`, `a` is less than `b` (and vice versa)\n * - if some xyz is less and some is greater, the arrays are uncomparable\n */\nfunction compareZarrArraySize(aArr, aTCZYX, bArr, bTCZYX) {\n  const aZ = aTCZYX[2] > -1 ? aArr.shape[aTCZYX[2]] : 1;\n  const bZ = bTCZYX[2] > -1 ? bArr.shape[bTCZYX[2]] : 1;\n  const diffZ = aZ - bZ;\n  const diffY = aArr.shape[aTCZYX[3]] - bArr.shape[bTCZYX[3]];\n  const diffX = aArr.shape[aTCZYX[4]] - bArr.shape[bTCZYX[4]];\n  if (diffZ === 0 && diffY === 0 && diffX === 0) {\n    return 0;\n  } else if (diffZ <= 0 && diffY <= 0 && diffX <= 0) {\n    return -1;\n  } else if (diffZ >= 0 && diffY >= 0 && diffX >= 0) {\n    return 1;\n  } else {\n    return undefined;\n  }\n}\nconst EPSILON = 0.00001;\nconst aboutEquals = (a, b) => Math.abs(a - b) < EPSILON;\nfunction scaleTransformsAreEqual(aSrc, aLevel, bSrc, bLevel) {\n  const aScale = getScale(aSrc.multiscaleMetadata.datasets[aLevel], aSrc.axesTCZYX);\n  const bScale = getScale(bSrc.multiscaleMetadata.datasets[bLevel], bSrc.axesTCZYX);\n  return aboutEquals(aScale[2], bScale[2]) && aboutEquals(aScale[3], bScale[3]) && aboutEquals(aScale[4], bScale[4]);\n}\n\n/**\n * Ensures that all scale levels in `sources` are matched up by size. More precisely: enforces that, for any scale\n * level `i`, the size of zarr array `s[i]` is equal for every source `s`. We accomplish this by removing any arrays\n * (and their associated OME dataset metadata) which don't match up in all sources.\n *\n * Note that this function modifies the input `sources` array rather than returning a new value.\n *\n * Assumes all sources have scale levels ordered by size from largest to smallest. (This should always be true for\n * compliant OME-Zarr data.)\n */\nexport function matchSourceScaleLevels(sources) {\n  if (sources.length < 2) {\n    return;\n  }\n\n  // Save matching scale levels and metadata here\n  const matchedLevels = Array.from({\n    length: sources.length\n  }, () => []);\n  const matchedMetas = Array.from({\n    length: sources.length\n  }, () => []);\n\n  // Start as many index counters as we have sources\n  const scaleIndexes = new Array(sources.length).fill(0);\n  while (scaleIndexes.every((val, idx) => val < sources[idx].scaleLevels.length)) {\n    // First pass: find the smallest source / determine if all sources are equal\n    let allEqual = true;\n    let smallestIdx = 0;\n    let smallestSrc = sources[0];\n    let smallestArr = smallestSrc.scaleLevels[scaleIndexes[0]];\n    for (let currentIdx = 1; currentIdx < sources.length; currentIdx++) {\n      const currentSrc = sources[currentIdx];\n      const currentArr = currentSrc.scaleLevels[scaleIndexes[currentIdx]];\n      const ordering = compareZarrArraySize(smallestArr, smallestSrc.axesTCZYX, currentArr, currentSrc.axesTCZYX);\n      if (!ordering) {\n        // Arrays are equal, or they are uncomparable\n        if (ordering === undefined) {\n          throw new VolumeLoadError(\"Incompatible zarr arrays: pixel dimensions are mismatched\", {\n            type: VolumeLoadErrorType.INVALID_MULTI_SOURCE_ZARR\n          });\n        }\n\n        // Now we know the arrays are equal, but they may still be invalid to match up because...\n        // ...they have different scale transformations\n        if (!scaleTransformsAreEqual(smallestSrc, scaleIndexes[smallestIdx], currentSrc, scaleIndexes[currentIdx])) {\n          // today we are going to treat this as a warning.\n          // For our implementation it is enough that the xyz pixel ranges are the same.\n          // Ideally scale*arraysize=physical size is really the quantity that should be equal, for combining two volume data sets as channels.\n          console.warn(\"Incompatible zarr arrays: scale levels of equal size have different scale transformations\");\n        }\n\n        // ...they have different numbers of timesteps\n        const largestT = smallestSrc.axesTCZYX[0] > -1 ? smallestArr.shape[smallestSrc.axesTCZYX[0]] : 1;\n        const currentT = currentSrc.axesTCZYX[0] > -1 ? currentArr.shape[currentSrc.axesTCZYX[0]] : 1;\n        if (largestT !== currentT) {\n          // we also treat this as a warning.\n          // In OmeZarrLoader we will take the minimum T size of all sources\n          console.warn(`Incompatible zarr arrays: different numbers of timesteps: ${largestT} vs ${currentT}`);\n        }\n      } else {\n        allEqual = false;\n        if (ordering > 0) {\n          smallestIdx = currentIdx;\n          smallestSrc = currentSrc;\n          smallestArr = currentArr;\n        }\n      }\n    }\n    if (allEqual) {\n      // We've found a matching set of scale levels! Save it and increment all indexes\n      for (let i = 0; i < scaleIndexes.length; i++) {\n        const currentSrc = sources[i];\n        const matchedScaleLevel = scaleIndexes[i];\n        matchedLevels[i].push(currentSrc.scaleLevels[matchedScaleLevel]);\n        matchedMetas[i].push(currentSrc.multiscaleMetadata.datasets[matchedScaleLevel]);\n        scaleIndexes[i] += 1;\n      }\n    } else {\n      // Increment the indexes of the sources which are larger than the smallest\n      for (const [idx, srcIdx] of scaleIndexes.entries()) {\n        const currentSrc = sources[idx];\n        const currentArr = currentSrc.scaleLevels[srcIdx];\n        const ordering = compareZarrArraySize(smallestArr, smallestSrc.axesTCZYX, currentArr, currentSrc.axesTCZYX);\n        if (ordering !== 0) {\n          scaleIndexes[idx] += 1;\n        }\n      }\n    }\n  }\n  if (sources[0].scaleLevels.length === 0) {\n    throw new VolumeLoadError(\"Incompatible zarr arrays: no sets of scale levels found that matched in all sources\", {\n      type: VolumeLoadErrorType.INVALID_MULTI_SOURCE_ZARR\n    });\n  }\n  for (let i = 0; i < sources.length; i++) {\n    sources[i].scaleLevels = matchedLevels[i];\n    sources[i].multiscaleMetadata.datasets = matchedMetas[i];\n  }\n}","import { VolumeLoadError, VolumeLoadErrorType } from \"../VolumeLoadError.js\";\n/**\n * If `meta` is the top-level metadata of a zarr node formatted according to the OME-Zarr spec version 0.5, returns\n * the object formatted according to v0.4 of the spec. For our purposes this just means flattening out the `ome` key.\n *\n * Return type is `unknown` because this does no actual validation; use `validateOMEZarrMetadata` for that.\n */\nexport const toOMEZarrMetaV4 = meta => meta.ome ?? meta;\nfunction isObjectWithProp(obj, prop) {\n  return typeof obj === \"object\" && obj !== null && prop in obj;\n}\nfunction assertMetadataHasProp(obj, prop, name = \"zarr\") {\n  if (!isObjectWithProp(obj, prop)) {\n    throw new VolumeLoadError(`${name} metadata is missing required entry \"${prop}\"`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n}\nfunction assertPropIsArray(obj, prop, name = \"zarr\") {\n  if (!Array.isArray(obj[prop])) {\n    throw new VolumeLoadError(`${name} metadata entry \"${prop}\" is not an array`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n}\n\n/** Intermediate stage of validation, before we've picked a single multiscale to validate */\n\nexport function assertMetadataHasMultiscales(meta, name = \"zarr\") {\n  // data is an object with a key \"multiscales\", which is a non-empty array\n  assertMetadataHasProp(meta, \"multiscales\", name);\n  assertPropIsArray(meta, \"multiscales\", name);\n}\n\n/**\n * Validates that the `OMEZarrMetadata` record `meta` has the minimal amount of data required to open a volume. Since\n * we only ever open one multiscale, we only validate the multiscale metadata record at index `multiscaleIdx` here.\n * `name` is used in error messages to identify the source of the metadata.\n */\nexport function validateOMEZarrMetadata(meta, multiscaleIdx = 0, name = \"zarr\") {\n  // check that a multiscale metadata entry exists at `multiscaleIdx`\n  const multiscaleMeta = meta.multiscales[multiscaleIdx];\n  if (!multiscaleMeta) {\n    throw new VolumeLoadError(`${name} metadata does not have requested multiscale level ${multiscaleIdx}`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n  const multiscaleMetaName = isObjectWithProp(multiscaleMeta, \"name\") ? ` (\"${multiscaleMeta.name})` : \"\";\n  const multiscaleName = `${name} multiscale ${multiscaleIdx}${multiscaleMetaName}`;\n\n  // multiscale has a key \"axes\", which is an array. Each axis has a \"name\".\n  assertMetadataHasProp(multiscaleMeta, \"axes\", multiscaleName);\n  assertPropIsArray(multiscaleMeta, \"axes\", multiscaleName);\n  multiscaleMeta.axes.forEach((axis, i) => assertMetadataHasProp(axis, \"name\", `${multiscaleName} axis ${i}`));\n\n  // multiscale has a key \"datasets\", which is an array. Each dataset has a \"path\".\n  assertMetadataHasProp(multiscaleMeta, \"datasets\", name);\n  assertPropIsArray(multiscaleMeta, \"datasets\", name);\n  multiscaleMeta.datasets.forEach((data, i) => assertMetadataHasProp(data, \"path\", `${multiscaleName} dataset ${i}`));\n}","import { isChunk } from \"../../VolumeCache.js\";\nexport default function wrapArray(array, basePath, cache, queue) {\n  const path = basePath.endsWith(\"/\") ? basePath.slice(0, -1) : basePath;\n  const keyBase = path + array.path + (array.path.endsWith(\"/\") ? \"\" : \"/\");\n  const getChunk = async (coords, opts) => {\n    if (opts?.subscriber && opts.reportChunk) {\n      opts.reportChunk(coords, opts.subscriber);\n    }\n    const fullKey = keyBase + coords.join(\",\");\n    const cacheResult = cache?.get(fullKey);\n    if (cacheResult && isChunk(cacheResult)) {\n      return cacheResult;\n    }\n    let result;\n    if (queue && opts?.subscriber) {\n      result = await queue.addRequest(fullKey, opts?.subscriber, () => array.getChunk(coords, opts), opts.isPrefetch);\n    } else {\n      result = await array.getChunk(coords, opts);\n    }\n    cache?.insert(fullKey, result);\n    return result;\n  };\n  return new Proxy(array, {\n    get: (target, prop) => {\n      if (prop === \"getChunk\") {\n        return getChunk;\n      }\n\n      // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy#no_private_property_forwarding\n      const value = target[prop];\n      if (value instanceof Function) {\n        return function (...args) {\n          return value.apply(target, args);\n        };\n      }\n      return value;\n    }\n  });\n}","/** Object format used when passing multiple requests to RequestQueue at once. */\n\nexport const DEFAULT_REQUEST_CANCEL_REASON = \"request cancelled\";\n\n/**\n * Internal object interface used by RequestQueue to store request metadata and callbacks.\n */\n\n/**\n * Manages a queue of asynchronous requests with unique string keys, which can be added to or cancelled.\n * If redundant requests with the same key are issued, the request action will only be run once per key\n * while the original request is still in the queue.\n */\nexport default class RequestQueue {\n  /**\n   * The maximum number of requests that can be handled concurrently.\n   * Once reached, additional requests will be queued up to run once a running request completes.\n   */\n\n  /**\n   * The maximum number of requests that can be handled concurrently if only low-priority requests are waiting. Set\n   * lower than `concurrencyLimit` to always leave space for high-priority requests. Cannot be set higher than\n   * `concurrencyLimit`.\n   */\n\n  /** A queue of requests that are ready to be executed, in order of request time. */\n\n  /** A queue of low-priority tasks that are ready to be executed. `queue` must be empty before any of these tasks run. */\n\n  /** Stores all requests, even those that are currently active. */\n\n  /** Stores requests whose actions are currently being run. */\n\n  /**\n   * Creates a new RequestQueue.\n   * @param maxActiveRequests The maximum number of requests that will be handled concurrently. This is 10 by default.\n   * @param maxLowPriorityRequests The maximum number of low-priority requests that will be handled concurrently. Equal\n   *    to `maxActiveRequests` by default, but may be set lower to always leave space for new high-priority requests.\n   */\n  constructor(maxActiveRequests = 10, maxLowPriorityRequests = 5) {\n    this.allRequests = new Map();\n    this.activeRequests = new Set();\n    this.queue = [];\n    this.queueLowPriority = [];\n    this.maxActiveRequests = maxActiveRequests;\n    this.maxLowPriorityRequests = Math.min(maxActiveRequests, maxLowPriorityRequests);\n  }\n\n  /**\n   * Stores request metadata to the internal map of all pending requests.\n   * @param key string identifier of the request.\n   * @param requestAction callable function action of the request.\n   * @returns a reference to the new, registered RequestItem.\n   */\n  registerRequest(key, requestAction) {\n    // Create a new promise and store the resolve and reject callbacks for later.\n    // This lets us perform the actual action at a later point, when the request is at the\n    // front of the processing queue.\n    let promiseResolve, promiseReject;\n    const promise = new Promise((resolve, reject) => {\n      promiseResolve = resolve;\n      promiseReject = reject;\n    });\n    // Store the request data.\n    const requestItem = {\n      key: key,\n      action: requestAction,\n      resolve: promiseResolve,\n      reject: promiseReject,\n      promise\n    };\n    this.allRequests.set(key, requestItem);\n    return requestItem;\n  }\n\n  /**\n   * Moves a registered request into the processing queue, clearing any timeouts on the request.\n   * @param key string identifier of the request.\n   * @param lowPriority Whether this request should be added with low priority. False by default.\n   */\n  addRequestToQueue(key, lowPriority) {\n    // Check that this request is not cancelled.\n    if (this.allRequests.has(key)) {\n      // Clear the request timeout, if it has one, since it is being added to the queue.\n      const requestItem = this.allRequests.get(key);\n      if (requestItem && requestItem.timeoutId) {\n        clearTimeout(requestItem.timeoutId);\n        requestItem.timeoutId = undefined;\n      }\n      if (!this.queue.includes(key) && !this.queueLowPriority.includes(key)) {\n        // Add to queue and check if the request can be processed right away.\n        if (lowPriority) {\n          this.queueLowPriority.push(key);\n        } else {\n          this.queue.push(key);\n        }\n        this.dequeue();\n      }\n    }\n  }\n\n  /**\n   * Adds a request with a unique key to the queue, if it doesn't already exist.\n   * @param key The key used to track the request.\n   * @param requestAction Function that will be called to complete the request. The function\n   *  will be run only once per unique key while the request exists, and may be deferred by the\n   *  queue at any time.\n   * @param lowPriority Whether this request should be added with low priority. False by default.\n   * @param delayMs Minimum delay, in milliseconds, before this request should be executed.\n   *\n   * NOTE: Cancelling a request while the action is running WILL NOT stop the action. If this behavior is desired,\n   * actions must be responsible for checking the RequestQueue, determining if the request is still valid (e.g.\n   * using `.hasRequest()`), and stopping or returning early.\n   *\n   * @returns A promise that will resolve on completion of the request, or reject if the request is cancelled.\n   *  If multiple requests are issued with the same key, a promise for the first request will be returned\n   *  until the request is resolved or cancelled.\n   *  Note that the return type of the promise will match that of the first request's instance.\n   */\n  addRequest(key, requestAction, lowPriority = false, delayMs = 0) {\n    if (!this.allRequests.has(key)) {\n      // New request!\n      const requestItem = this.registerRequest(key, requestAction);\n      // If a delay is set, wait to add this to the queue.\n      if (delayMs > 0) {\n        const timeoutId = setTimeout(() => this.addRequestToQueue(key, lowPriority), delayMs);\n        // Save timeout information to request metadata\n        requestItem.timeoutId = timeoutId;\n      } else {\n        // No delay, add immediately\n        this.addRequestToQueue(key, lowPriority);\n      }\n    } else {\n      const lowPriorityIndex = this.queueLowPriority.indexOf(key);\n      if (lowPriorityIndex > -1 && !lowPriority) {\n        // This request is registered and queued, but is now being requested with high priority.\n        // Promote it to high priority.\n        this.queueLowPriority.splice(lowPriorityIndex, 1);\n        this.addRequestToQueue(key);\n      } else if (delayMs <= 0) {\n        // This request is registered, but is now being requested without a delay.\n        // Move into queue immediately if it's not already added, and clear any timeouts it may have.\n        this.addRequestToQueue(key, lowPriority);\n      }\n    }\n    const promise = this.allRequests.get(key)?.promise;\n    if (!promise) {\n      throw new Error(\"Found no promise to return when getting stored request data.\");\n    }\n    return promise;\n  }\n\n  /**\n   * Adds multiple requests to the queue, with an optional delay between each.\n   * @param requests An array of RequestItems, which include a key and a request action.\n   * @param lowPriority Whether these requests should be added with low priority. False by default.\n   * @param delayMs An optional minimum delay in milliseconds to be added between each request.\n   *  For example, a delay of 10 ms will cause the second request to be added to the processing queue\n   *  after 10 ms, the third to added after 20 ms, and so on. Set to 10 ms by default.\n   * @returns An array of promises corresponding to the provided requests. (i.e., the `i`th value\n   * of the returned array will be a Promise for the resolution of `requests[i]`). If a request\n   *  with a matching key is already pending, returns the promise for the initial request.\n   */\n  addRequests(requests, lowPriority = false, delayMs = 10) {\n    const promises = [];\n    for (let i = 0; i < requests.length; i++) {\n      const item = requests[i];\n      const promise = this.addRequest(item.key, item.requestAction, lowPriority, delayMs * i);\n      promises.push(promise);\n    }\n    return promises;\n  }\n\n  /**\n   * Attempts to remove and run the next queued request item, if resources are available.\n   * @returns true if a request was started, or false if there are too many\n   * requests already active.\n   */\n  async dequeue() {\n    const numRequests = this.activeRequests.size;\n    if (numRequests >= this.maxActiveRequests || this.queue.length === 0 && (numRequests >= this.maxLowPriorityRequests || this.queueLowPriority.length === 0)) {\n      return;\n    }\n    const requestKey = this.queue.shift() ?? this.queueLowPriority.shift();\n    if (!requestKey) {\n      return;\n    }\n    if (this.activeRequests.has(requestKey)) {\n      // This request is already active, try the next one instead. (this shouldn't happen)\n      this.dequeue();\n      return;\n    }\n    const requestItem = this.allRequests.get(requestKey);\n    if (!requestItem) {\n      return;\n    }\n    const key = requestItem.key;\n    // Mark that this request is active\n    this.activeRequests.add(key);\n    await requestItem.action().then(requestItem.resolve, requestItem.reject);\n    this.activeRequests.delete(key);\n    this.allRequests.delete(key);\n    this.dequeue();\n  }\n\n  /**\n   * Removes any request matching the provided key from the queue and rejects its promise.\n   * @param key The key that should be matched against.\n   * @param cancelReason A message or object that will be used as the promise rejection.\n   */\n  cancelRequest(key, cancelReason = DEFAULT_REQUEST_CANCEL_REASON) {\n    if (!this.allRequests.has(key)) {\n      return;\n    }\n    const requestItem = this.allRequests.get(key);\n    if (requestItem) {\n      if (requestItem.timeoutId) {\n        // Cancel requests that have not been queued yet.\n        clearTimeout(requestItem.timeoutId);\n      }\n      // Reject the request, then clear from the queue and known requests.\n      requestItem.reject(cancelReason);\n    }\n    const queueIndex = this.queue.indexOf(key);\n    if (queueIndex > -1) {\n      this.queue.splice(queueIndex, 1);\n    } else {\n      const lowPriorityIndex = this.queueLowPriority.indexOf(key);\n      if (lowPriorityIndex > -1) {\n        this.queueLowPriority.splice(lowPriorityIndex, 1);\n      }\n    }\n    this.allRequests.delete(key);\n    this.activeRequests.delete(key);\n  }\n\n  /**\n   * Rejects all request promises and clears the queue.\n   * @param cancelReason A message or object that will be used as the promise rejection.\n   */\n  cancelAllRequests(cancelReason = DEFAULT_REQUEST_CANCEL_REASON) {\n    // Clear the queue so we don't do extra work while filtering it\n    this.queue = [];\n    this.queueLowPriority = [];\n    for (const key of this.allRequests.keys()) {\n      this.cancelRequest(key, cancelReason);\n    }\n  }\n\n  /**\n   * Returns whether a request with the given key exists in the RequestQueue and is not cancelled.\n   * @param key the key to search for.\n   * @returns true if the request is in the RequestQueue.\n   */\n  hasRequest(key) {\n    return this.allRequests.has(key);\n  }\n\n  /**\n   * Returns whether the request with the given key is currently running (not waiting in the queue).\n   * @param key the key to search for.\n   * @returns true if the request is actively running.\n   */\n  requestRunning(key) {\n    return this.activeRequests.has(key);\n  }\n}","import RequestQueue from \"./RequestQueue.js\";\n\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n/**\n * An extension of `RequestQueue` that adds a concept of \"subscribers,\" which may share references to a single request\n * or cancel their subscription without disrupting the request for other subscribers.\n */\nexport default class SubscribableRequestQueue {\n  /** The next unused subscriber ID. Increments whenever a subscriber is added. */\n\n  /**\n   * Map of subscribers keyed by ID. Subscribers store a map to all their subscriptions by request key.\n   * Subscribers are only useful as handles to cancel subscriptions early, so we only need to store rejecters here.\n   */\n\n  /** Map from \"inner\" request (managed by `queue`) to \"outer\" promises generated per-subscriber. */\n\n  /**\n   * Since `SubscribableRequestQueue` wraps `RequestQueue`, its constructor may either take the same arguments as the\n   * `RequestQueue` constructor and create a new `RequestQueue`, or it may take an existing `RequestQueue` to wrap.\n   */\n\n  constructor(maxActiveRequests, maxLowPriorityRequests) {\n    if (typeof maxActiveRequests === \"number\" || maxActiveRequests === undefined) {\n      this.queue = new RequestQueue(maxActiveRequests, maxLowPriorityRequests);\n    } else {\n      this.queue = maxActiveRequests;\n    }\n    this.nextSubscriberId = 0;\n    this.subscribers = new Map();\n    this.requests = new Map();\n  }\n\n  /** Resolves all subscriptions to request `key` with `value` */\n  resolveAll(key, value) {\n    const requests = this.requests.get(key);\n    if (requests) {\n      for (const {\n        resolve,\n        subscriberId\n      } of requests) {\n        resolve(value);\n        this.subscribers.get(subscriberId)?.delete(key);\n      }\n      this.requests.delete(key);\n    }\n  }\n\n  /** Rejects all subscriptions to request `key` with `reason` */\n  rejectAll(key, reason) {\n    const requests = this.requests.get(key);\n    if (requests) {\n      for (const {\n        reject,\n        subscriberId\n      } of requests) {\n        reject(reason);\n        this.subscribers.get(subscriberId)?.delete(key);\n      }\n      this.requests.delete(key);\n    }\n  }\n\n  /** Adds a new request subscriber. Returns a unique ID to identify this subscriber. */\n  addSubscriber() {\n    const subscriberId = this.nextSubscriberId;\n    this.nextSubscriberId++;\n    this.subscribers.set(subscriberId, new Map());\n    return subscriberId;\n  }\n\n  /**\n   * Queues a new request, or adds a subscription if the request is already queued/running.\n   *\n   * If `subscriberId` is already subscribed to the request, this rejects the existing promise and returns a new one.\n   */\n  addRequest(key, subscriberId, requestAction, lowPriority, delayMs) {\n    // Create single underlying request if it does not yet exist\n    this.queue.addRequest(key, requestAction, lowPriority, delayMs).then(value => this.resolveAll(key, value)).catch(reason => this.rejectAll(key, reason));\n    if (!this.requests.has(key)) {\n      this.requests.set(key, []);\n    }\n\n    // Validate subscriber\n    if (subscriberId >= this.nextSubscriberId || subscriberId < 0) {\n      throw new Error(`SubscribableRequestQueue: subscriber id ${subscriberId} has not been registered`);\n    }\n    const subscriber = this.subscribers.get(subscriberId);\n    if (!subscriber) {\n      throw new Error(`SubscribableRequestQueue: subscriber id ${subscriberId} has been removed`);\n    }\n\n    // Create promise and add to list of requests\n    return new Promise((resolve, reject) => {\n      this.requests.get(key)?.push({\n        resolve,\n        reject,\n        subscriberId\n      });\n      const subscriber = this.subscribers.get(subscriberId);\n      const existingRequest = subscriber?.get(key);\n      if (existingRequest) {\n        existingRequest.push(reject);\n      } else {\n        subscriber?.set(key, [reject]);\n      }\n    });\n  }\n\n  /**\n   * Rejects a subscription and removes it from the list of subscriptions for a request, then cancels the underlying\n   * request if it is no longer subscribed and is not running already.\n   */\n  rejectSubscription(key, reject, cancelReason) {\n    // Reject the outer \"subscription\" promise\n    reject(cancelReason);\n\n    // Get the list of subscriptions for this request\n    const subscriptions = this.requests.get(key);\n    if (!subscriptions) {\n      // This should never happen\n      return;\n    }\n    // Remove this request subscription by ref equality to `reject`\n    const idx = subscriptions.findIndex(sub => sub.reject === reject);\n    if (idx >= 0) {\n      subscriptions.splice(idx, 1);\n    }\n\n    // Remove the underlying request if there are no more subscribers and the request is not already running\n    if (subscriptions.length < 1 && !this.queue.requestRunning(key)) {\n      this.queue.cancelRequest(key, cancelReason);\n      this.requests.delete(key);\n    }\n  }\n\n  /** Cancels a request subscription, and cancels the underlying request if it is no longer subscribed or running. */\n  cancelRequest(key, subscriberId, cancelReason) {\n    const subscriber = this.subscribers.get(subscriberId);\n    if (!subscriber) {\n      return false;\n    }\n    const rejecters = subscriber.get(key);\n    if (!rejecters || !rejecters.length) {\n      return false;\n    }\n    for (const reject of rejecters) {\n      this.rejectSubscription(key, reject, cancelReason);\n    }\n    subscriber.delete(key);\n    return true;\n  }\n\n  /** Removes a subscriber and cancels its remaining subscriptions. */\n  removeSubscriber(subscriberId, cancelReason) {\n    const subscriptions = this.subscribers.get(subscriberId);\n    if (subscriptions) {\n      for (const [key, rejecters] of subscriptions.entries()) {\n        for (const reject of rejecters) {\n          this.rejectSubscription(key, reject, cancelReason);\n        }\n      }\n      this.subscribers.delete(subscriberId);\n    }\n  }\n\n  /** Returns whether a request with the given `key` is running or waiting in the queue */\n  hasRequest(key) {\n    return this.queue.hasRequest(key);\n  }\n\n  /** Returns whether a request with the given `key` is running */\n  requestRunning(key) {\n    return this.queue.requestRunning(key);\n  }\n\n  /** Returns whether a subscriber with the given `subscriberId` exists */\n  hasSubscriber(subscriberId) {\n    return this.subscribers.has(subscriberId);\n  }\n\n  /** Returns whether a subscriber with the given `subscriberId` is subscribed to the request with the given `key` */\n  isSubscribed(subscriberId, key) {\n    return this.subscribers.get(subscriberId)?.has(key) ?? false;\n  }\n}","/** The types of requests that can be made to the worker. Mostly corresponds to methods on `IVolumeLoader`. */\nexport let WorkerMsgType = /*#__PURE__*/function (WorkerMsgType) {\n  WorkerMsgType[WorkerMsgType[\"INIT\"] = 0] = \"INIT\";\n  WorkerMsgType[WorkerMsgType[\"CREATE_LOADER\"] = 1] = \"CREATE_LOADER\";\n  WorkerMsgType[WorkerMsgType[\"CLOSE_LOADER\"] = 2] = \"CLOSE_LOADER\";\n  WorkerMsgType[WorkerMsgType[\"CREATE_VOLUME\"] = 3] = \"CREATE_VOLUME\";\n  WorkerMsgType[WorkerMsgType[\"LOAD_DIMS\"] = 4] = \"LOAD_DIMS\";\n  WorkerMsgType[WorkerMsgType[\"LOAD_VOLUME_DATA\"] = 5] = \"LOAD_VOLUME_DATA\";\n  WorkerMsgType[WorkerMsgType[\"SET_PREFETCH_PRIORITY_DIRECTIONS\"] = 6] = \"SET_PREFETCH_PRIORITY_DIRECTIONS\";\n  WorkerMsgType[WorkerMsgType[\"SYNCHRONIZE_MULTICHANNEL_LOADING\"] = 7] = \"SYNCHRONIZE_MULTICHANNEL_LOADING\";\n  WorkerMsgType[WorkerMsgType[\"UPDATE_FETCH_OPTIONS\"] = 8] = \"UPDATE_FETCH_OPTIONS\";\n  return WorkerMsgType;\n}({});\n\n/** The variants of `WorkerMessageType` which represent \"global\" actions that don't require a specific loader */\n\n/** The variants of `WorkerMessageType` which represent actions on a specific loader */\n\n/** The kind of response a worker can return - `SUCCESS`, `ERROR`, or `EVENT`. */\nexport let WorkerResponseResult = /*#__PURE__*/function (WorkerResponseResult) {\n  WorkerResponseResult[WorkerResponseResult[\"SUCCESS\"] = 0] = \"SUCCESS\";\n  WorkerResponseResult[WorkerResponseResult[\"ERROR\"] = 1] = \"ERROR\";\n  WorkerResponseResult[WorkerResponseResult[\"EVENT\"] = 2] = \"EVENT\";\n  return WorkerResponseResult;\n}({});\n\n/** The kind of events that can occur when loading */\nexport let WorkerEventType = /*#__PURE__*/function (WorkerEventType) {\n  /** Fired to update a `Volume`'s `imageInfo` and/or `loadSpec` based on loaded data (time, channels, region, etc.) */\n  WorkerEventType[WorkerEventType[\"METADATA_UPDATE\"] = 0] = \"METADATA_UPDATE\";\n  /** Fired when data for a channel (or batch of channels) is loaded */\n  WorkerEventType[WorkerEventType[\"CHANNEL_LOAD\"] = 1] = \"CHANNEL_LOAD\";\n  return WorkerEventType;\n}({});\n\n/**\n * All messages to/from a worker carry a `msgId`, a `type`, and a `payload` (whose type is determined by `type`).\n * Messages which operate on a specific loader also require a `loaderId`.\n */\n\n/** Maps each `WorkerMsgType` to the type of the payload of requests of that type. */\n\n/** Maps each `WorkerMsgType` to the type of the payload of responses of that type. */\n\n/** Event for when a batch of channel data loads. */\n\n/** Event for when metadata updates. */\n\n/** All valid types of worker requests, with some `WorkerMsgType` and a matching payload type. */\n\n/** All valid types of worker responses: `SUCCESS` with a matching payload, `ERROR` with a message, or an `EVENT`. */","import { Box3, Vector3 } from \"three\";\n/** Recreates a `LoadSpec` that has just been sent to/from a worker to restore three.js object prototypes */\nexport function rebuildLoadSpec(spec) {\n  return {\n    ...spec,\n    subregion: new Box3(new Vector3().copy(spec.subregion.min), new Vector3().copy(spec.subregion.max))\n  };\n}","export function strip_prefix(path) {\n    // @ts-expect-error - TS can't infer this type correctly\n    return path.slice(1);\n}\nexport function uri2href(url) {\n    let [protocol, rest] = (typeof url === \"string\" ? url : url.href).split(\"://\");\n    if (protocol === \"https\" || protocol === \"http\") {\n        return url;\n    }\n    if (protocol === \"gc\") {\n        return `https://storage.googleapis.com/${rest}`;\n    }\n    if (protocol === \"s3\") {\n        return `https://s3.amazonaws.com/${rest}`;\n    }\n    throw Error(`Protocol not supported, got: ${JSON.stringify(protocol)}`);\n}\nexport function fetch_range(url, offset, length, opts = {}) {\n    if (offset !== undefined && length !== undefined) {\n        // merge request opts\n        opts = {\n            ...opts,\n            headers: {\n                ...opts.headers,\n                Range: `bytes=${offset}-${offset + length - 1}`,\n            },\n        };\n    }\n    return fetch(url, opts);\n}\nexport function merge_init(storeOverrides, requestOverrides) {\n    // Request overrides take precedence over storeOverrides.\n    return {\n        ...storeOverrides,\n        ...requestOverrides,\n        headers: {\n            ...storeOverrides.headers,\n            ...requestOverrides.headers,\n        },\n    };\n}\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(expression, msg = \"\") {\n    if (!expression)\n        throw new Error(msg);\n}\n//# sourceMappingURL=util.js.map","import { fetch_range, merge_init } from \"./util.js\";\nfunction resolve(root, path) {\n    const base = typeof root === \"string\" ? new URL(root) : root;\n    if (!base.pathname.endsWith(\"/\")) {\n        // ensure trailing slash so that base is resolved as _directory_\n        base.pathname += \"/\";\n    }\n    const resolved = new URL(path.slice(1), base);\n    // copy search params to new URL\n    resolved.search = base.search;\n    return resolved;\n}\nasync function handle_response(response) {\n    if (response.status === 404) {\n        return undefined;\n    }\n    if (response.status === 200 || response.status === 206) {\n        return new Uint8Array(await response.arrayBuffer());\n    }\n    throw new Error(`Unexpected response status ${response.status} ${response.statusText}`);\n}\nasync function fetch_suffix(url, suffix_length, init, use_suffix_request) {\n    if (use_suffix_request) {\n        return fetch(url, {\n            ...init,\n            headers: { ...init.headers, Range: `bytes=-${suffix_length}` },\n        });\n    }\n    let response = await fetch(url, { ...init, method: \"HEAD\" });\n    if (!response.ok) {\n        // will be picked up by handle_response\n        return response;\n    }\n    let content_length = response.headers.get(\"Content-Length\");\n    let length = Number(content_length);\n    return fetch_range(url, length - suffix_length, length, init);\n}\n/**\n * Readonly store based in the [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n * Must polyfill `fetch` for use in Node.js.\n *\n * ```typescript\n * import * as zarr from \"zarrita\";\n * const store = new FetchStore(\"http://localhost:8080/data.zarr\");\n * const arr = await zarr.get(store, { kind: \"array\" });\n * ```\n */\nclass FetchStore {\n    url;\n    #overrides;\n    #use_suffix_request;\n    constructor(url, options = {}) {\n        this.url = url;\n        this.#overrides = options.overrides ?? {};\n        this.#use_suffix_request = options.useSuffixRequest ?? false;\n    }\n    #merge_init(overrides) {\n        return merge_init(this.#overrides, overrides);\n    }\n    async get(key, options = {}) {\n        let href = resolve(this.url, key).href;\n        let response = await fetch(href, this.#merge_init(options));\n        return handle_response(response);\n    }\n    async getRange(key, range, options = {}) {\n        let url = resolve(this.url, key);\n        let init = this.#merge_init(options);\n        let response;\n        if (\"suffixLength\" in range) {\n            response = await fetch_suffix(url, range.suffixLength, init, this.#use_suffix_request);\n        }\n        else {\n            response = await fetch_range(url, range.offset, range.length, init);\n        }\n        return handle_response(response);\n    }\n}\nexport default FetchStore;\n//# sourceMappingURL=fetch.js.map","import { assert } from \"../util.js\";\n/**\n * A codec for bit-rounding.\n *\n * Reduces floating-point precision by truncating mantissa bits during encoding.\n * Decoding is a no-op as the process is lossy and precision cannot be restored.\n *\n * Note: {@link BitroundCodec.encode} is not yet implemented since Zarrita is\n * primarily used in read-only contexts (web browser). If you need encoding support,\n * please open an issue at {@link https://github.com/manzt/zarrita.js/issues}.\n *\n * @see {@link https://github.com/zarr-developers/numcodecs/blob/main/numcodecs/bitround.py}\n * for the original Python implementation.\n *\n * @remarks\n * Data types are not validated, and `float16` arrays are not supported (reflecting browser support).\n */\nexport class BitroundCodec {\n    kind = \"array_to_array\";\n    constructor(configuration, _meta) {\n        assert(configuration.keepbits >= 0, \"keepbits must be zero or positive\");\n    }\n    static fromConfig(configuration, meta) {\n        return new BitroundCodec(configuration, meta);\n    }\n    /**\n     * Encode a chunk of data with bit-rounding.\n     * @param _arr - The chunk to encode\n     */\n    encode(_arr) {\n        throw new Error(\"`BitroundCodec.encode` is not implemented. Please open an issue at https://github.com/manzt/zarrita.js/issues.\");\n    }\n    /**\n     * Decode a chunk of data (no-op).\n     * @param arr - The chunk to decode\n     * @returns The decoded chunk\n     */\n    decode(arr) {\n        return arr; // No-op as bit-rounding is lossy\n    }\n}\n","import { byteswap_inplace, get_ctr, get_strides } from \"../util.js\";\nconst LITTLE_ENDIAN_OS = system_is_little_endian();\nfunction system_is_little_endian() {\n    const a = new Uint32Array([0x12345678]);\n    const b = new Uint8Array(a.buffer, a.byteOffset, a.byteLength);\n    return !(b[0] === 0x12);\n}\nfunction bytes_per_element(TypedArray) {\n    if (\"BYTES_PER_ELEMENT\" in TypedArray) {\n        return TypedArray.BYTES_PER_ELEMENT;\n    }\n    // Unicode string array is backed by a Int32Array.\n    return 4;\n}\nexport class BytesCodec {\n    kind = \"array_to_bytes\";\n    #stride;\n    #TypedArray;\n    #BYTES_PER_ELEMENT;\n    #shape;\n    #endian;\n    constructor(configuration, meta) {\n        this.#endian = configuration?.endian;\n        this.#TypedArray = get_ctr(meta.data_type);\n        this.#shape = meta.shape;\n        this.#stride = get_strides(meta.shape, \"C\");\n        // TODO: fix me.\n        // hack to get bytes per element since it's dynamic for string types.\n        const sample = new this.#TypedArray(0);\n        this.#BYTES_PER_ELEMENT = sample.BYTES_PER_ELEMENT;\n    }\n    static fromConfig(configuration, meta) {\n        return new BytesCodec(configuration, meta);\n    }\n    encode(arr) {\n        let bytes = new Uint8Array(arr.data.buffer);\n        if (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n            byteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n        }\n        return bytes;\n    }\n    decode(bytes) {\n        if (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n            byteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n        }\n        return {\n            data: new this.#TypedArray(bytes.buffer, bytes.byteOffset, bytes.byteLength / this.#BYTES_PER_ELEMENT),\n            shape: this.#shape,\n            stride: this.#stride,\n        };\n    }\n}\n","export class Crc32cCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig() {\n        return new Crc32cCodec();\n    }\n    encode(_) {\n        throw new Error(\"Not implemented\");\n    }\n    decode(arr) {\n        return new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength - 4);\n    }\n}\n","import { assert, get_strides, json_decode_object } from \"../util.js\";\n// Reference: https://stackoverflow.com/a/21897413\nfunction throw_on_nan_replacer(_key, value) {\n    assert(!Number.isNaN(value), \"JsonCodec allow_nan is false but NaN was encountered during encoding.\");\n    assert(value !== Number.POSITIVE_INFINITY, \"JsonCodec allow_nan is false but Infinity was encountered during encoding.\");\n    assert(value !== Number.NEGATIVE_INFINITY, \"JsonCodec allow_nan is false but -Infinity was encountered during encoding.\");\n    return value;\n}\n// Reference: https://gist.github.com/davidfurlong/463a83a33b70a3b6618e97ec9679e490\nfunction sort_keys_replacer(_key, value) {\n    return value instanceof Object && !Array.isArray(value)\n        ? Object.keys(value)\n            .sort()\n            .reduce((sorted, key) => {\n            sorted[key] = value[key];\n            return sorted;\n        }, {})\n        : value;\n}\nexport class JsonCodec {\n    configuration;\n    kind = \"array_to_bytes\";\n    #encoder_config;\n    #decoder_config;\n    constructor(configuration = {}) {\n        this.configuration = configuration;\n        // Reference: https://github.com/zarr-developers/numcodecs/blob/0878717a3613d91a453fe3d3716aa9c67c023a8b/numcodecs/json.py#L36\n        const { encoding = \"utf-8\", skipkeys = false, ensure_ascii = true, check_circular = true, allow_nan = true, sort_keys = true, indent, strict = true, } = configuration;\n        let separators = configuration.separators;\n        if (!separators) {\n            // ensure separators are explicitly specified, and consistent behaviour across\n            // Python versions, and most compact representation if indent is None\n            if (!indent) {\n                separators = [\",\", \":\"];\n            }\n            else {\n                separators = [\", \", \": \"];\n            }\n        }\n        this.#encoder_config = {\n            encoding,\n            skipkeys,\n            ensure_ascii,\n            check_circular,\n            allow_nan,\n            indent,\n            separators,\n            sort_keys,\n        };\n        this.#decoder_config = { strict };\n    }\n    static fromConfig(configuration) {\n        return new JsonCodec(configuration);\n    }\n    encode(buf) {\n        const { indent, encoding, ensure_ascii, check_circular, allow_nan, sort_keys, } = this.#encoder_config;\n        assert(encoding === \"utf-8\", \"JsonCodec does not yet support non-utf-8 encoding.\");\n        const replacer_functions = [];\n        // By default, for JSON.stringify,\n        // a TypeError will be thrown if one attempts to encode an object with circular references\n        assert(check_circular, \"JsonCodec does not yet support skipping the check for circular references during encoding.\");\n        if (!allow_nan) {\n            // Throw if NaN/Infinity/-Infinity are encountered during encoding.\n            replacer_functions.push(throw_on_nan_replacer);\n        }\n        if (sort_keys) {\n            // We can ensure keys are sorted but not really the opposite since\n            // there is no guarantee of key ordering in JS.\n            replacer_functions.push(sort_keys_replacer);\n        }\n        const items = Array.from(buf.data);\n        items.push(\"|O\");\n        items.push(buf.shape);\n        let replacer = undefined;\n        if (replacer_functions.length) {\n            replacer = (key, value) => {\n                let new_value = value;\n                for (let sub_replacer of replacer_functions) {\n                    new_value = sub_replacer(key, new_value);\n                }\n                return new_value;\n            };\n        }\n        let json_str = JSON.stringify(items, replacer, indent);\n        if (ensure_ascii) {\n            // If ensure_ascii is true (the default), the output is guaranteed\n            // to have all incoming non-ASCII characters escaped.\n            // If ensure_ascii is false, these characters will be output as-is.\n            // Reference: https://stackoverflow.com/a/31652607\n            json_str = json_str.replace(/[\\u007F-\\uFFFF]/g, (chr) => {\n                const full_str = `0000${chr.charCodeAt(0).toString(16)}`;\n                const sub_str = full_str.substring(full_str.length - 4);\n                return `\\\\u${sub_str}`;\n            });\n        }\n        return new TextEncoder().encode(json_str);\n    }\n    decode(bytes) {\n        const { strict } = this.#decoder_config;\n        // (i.e., allowing control characters inside strings)\n        assert(strict, \"JsonCodec does not yet support non-strict decoding.\");\n        const items = json_decode_object(bytes);\n        const shape = items.pop();\n        items.pop(); // Pop off dtype (unused)\n        // O-d case\n        assert(shape, \"0D not implemented for JsonCodec.\");\n        const stride = get_strides(shape, \"C\");\n        const data = items;\n        return { data, shape, stride };\n    }\n}\n","import { BoolArray, ByteStringArray, UnicodeStringArray, } from \"../typedarray.js\";\nimport { assert, get_strides } from \"../util.js\";\nfunction proxy(arr) {\n    if (arr instanceof BoolArray ||\n        arr instanceof ByteStringArray ||\n        arr instanceof UnicodeStringArray) {\n        // @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n        const arrp = new Proxy(arr, {\n            get(target, prop) {\n                return target.get(Number(prop));\n            },\n            set(target, prop, value) {\n                // @ts-expect-error - value is OK\n                target.set(Number(prop), value);\n                return true;\n            },\n        });\n        return arrp;\n    }\n    // @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n    return arr;\n}\nfunction empty_like(chunk, order) {\n    let data;\n    if (chunk.data instanceof ByteStringArray ||\n        chunk.data instanceof UnicodeStringArray) {\n        data = new chunk.constructor(\n        // @ts-expect-error\n        chunk.data.length, chunk.data.chars);\n    }\n    else {\n        data = new chunk.constructor(chunk.data.length);\n    }\n    return {\n        data,\n        shape: chunk.shape,\n        stride: get_strides(chunk.shape, order),\n    };\n}\nfunction convert_array_order(src, target) {\n    let out = empty_like(src, target);\n    let n_dims = src.shape.length;\n    let size = src.data.length;\n    let index = Array(n_dims).fill(0);\n    let src_data = proxy(src.data);\n    let out_data = proxy(out.data);\n    for (let src_idx = 0; src_idx < size; src_idx++) {\n        let out_idx = 0;\n        for (let dim = 0; dim < n_dims; dim++) {\n            out_idx += index[dim] * out.stride[dim];\n        }\n        out_data[out_idx] = src_data[src_idx];\n        index[0] += 1;\n        for (let dim = 0; dim < n_dims; dim++) {\n            if (index[dim] === src.shape[dim]) {\n                if (dim + 1 === n_dims) {\n                    break;\n                }\n                index[dim] = 0;\n                index[dim + 1] += 1;\n            }\n        }\n    }\n    return out;\n}\n/** Determine the memory order (axis permutation) for a chunk */\nfunction get_order(chunk) {\n    let rank = chunk.shape.length;\n    assert(rank === chunk.stride.length, \"Shape and stride must have the same length.\");\n    return chunk.stride\n        .map((s, i) => ({ stride: s, index: i }))\n        .sort((a, b) => b.stride - a.stride)\n        .map((entry) => entry.index);\n}\nfunction matches_order(chunk, target) {\n    let source = get_order(chunk);\n    assert(source.length === target.length, \"Orders must match\");\n    return source.every((dim, i) => dim === target[i]);\n}\nexport class TransposeCodec {\n    kind = \"array_to_array\";\n    #order;\n    #inverseOrder;\n    constructor(configuration, meta) {\n        let value = configuration.order ?? \"C\";\n        let rank = meta.shape.length;\n        let order = new Array(rank);\n        let inverseOrder = new Array(rank);\n        if (value === \"C\") {\n            for (let i = 0; i < rank; ++i) {\n                order[i] = i;\n                inverseOrder[i] = i;\n            }\n        }\n        else if (value === \"F\") {\n            for (let i = 0; i < rank; ++i) {\n                order[i] = rank - i - 1;\n                inverseOrder[i] = rank - i - 1;\n            }\n        }\n        else {\n            order = value;\n            order.forEach((x, i) => {\n                assert(inverseOrder[x] === undefined, `Invalid permutation: ${JSON.stringify(value)}`);\n                inverseOrder[x] = i;\n            });\n        }\n        this.#order = order;\n        this.#inverseOrder = inverseOrder;\n    }\n    static fromConfig(configuration, meta) {\n        return new TransposeCodec(configuration, meta);\n    }\n    encode(arr) {\n        if (matches_order(arr, this.#inverseOrder)) {\n            // can skip making a copy\n            return arr;\n        }\n        return convert_array_order(arr, this.#inverseOrder);\n    }\n    decode(arr) {\n        return {\n            data: arr.data,\n            shape: arr.shape,\n            stride: get_strides(arr.shape, this.#order),\n        };\n    }\n}\n","import { get_strides } from \"../util.js\";\nexport class VLenUTF8 {\n    kind = \"array_to_bytes\";\n    #shape;\n    #strides;\n    constructor(shape) {\n        this.#shape = shape;\n        this.#strides = get_strides(shape, \"C\");\n    }\n    static fromConfig(_, meta) {\n        return new VLenUTF8(meta.shape);\n    }\n    encode(_chunk) {\n        throw new Error(\"Method not implemented.\");\n    }\n    decode(bytes) {\n        let decoder = new TextDecoder();\n        let view = new DataView(bytes.buffer);\n        let data = Array(view.getUint32(0, true));\n        let pos = 4;\n        for (let i = 0; i < data.length; i++) {\n            let item_length = view.getUint32(pos, true);\n            pos += 4;\n            data[i] = decoder.decode(bytes.buffer.slice(pos, pos + item_length));\n            pos += item_length;\n        }\n        return { data, shape: this.#shape, stride: this.#strides };\n    }\n}\n","import { BitroundCodec } from \"./codecs/bitround.js\";\nimport { BytesCodec } from \"./codecs/bytes.js\";\nimport { Crc32cCodec } from \"./codecs/crc32c.js\";\nimport { JsonCodec } from \"./codecs/json2.js\";\nimport { TransposeCodec } from \"./codecs/transpose.js\";\nimport { VLenUTF8 } from \"./codecs/vlen-utf8.js\";\nimport { assert } from \"./util.js\";\nfunction create_default_registry() {\n    return new Map()\n        .set(\"blosc\", () => import(\"numcodecs/blosc\").then((m) => m.default))\n        .set(\"gzip\", () => import(\"numcodecs/gzip\").then((m) => m.default))\n        .set(\"lz4\", () => import(\"numcodecs/lz4\").then((m) => m.default))\n        .set(\"zlib\", () => import(\"numcodecs/zlib\").then((m) => m.default))\n        .set(\"zstd\", () => import(\"numcodecs/zstd\").then((m) => m.default))\n        .set(\"transpose\", () => TransposeCodec)\n        .set(\"bytes\", () => BytesCodec)\n        .set(\"crc32c\", () => Crc32cCodec)\n        .set(\"vlen-utf8\", () => VLenUTF8)\n        .set(\"json2\", () => JsonCodec)\n        .set(\"bitround\", () => BitroundCodec);\n}\nexport const registry = create_default_registry();\nexport function create_codec_pipeline(chunk_metadata) {\n    let codecs;\n    return {\n        async encode(chunk) {\n            if (!codecs)\n                codecs = await load_codecs(chunk_metadata);\n            for (const codec of codecs.array_to_array) {\n                chunk = await codec.encode(chunk);\n            }\n            let bytes = await codecs.array_to_bytes.encode(chunk);\n            for (const codec of codecs.bytes_to_bytes) {\n                bytes = await codec.encode(bytes);\n            }\n            return bytes;\n        },\n        async decode(bytes) {\n            if (!codecs)\n                codecs = await load_codecs(chunk_metadata);\n            for (let i = codecs.bytes_to_bytes.length - 1; i >= 0; i--) {\n                bytes = await codecs.bytes_to_bytes[i].decode(bytes);\n            }\n            let chunk = await codecs.array_to_bytes.decode(bytes);\n            for (let i = codecs.array_to_array.length - 1; i >= 0; i--) {\n                chunk = await codecs.array_to_array[i].decode(chunk);\n            }\n            return chunk;\n        },\n    };\n}\nasync function load_codecs(chunk_meta) {\n    let promises = chunk_meta.codecs.map(async (meta) => {\n        let Codec = await registry.get(meta.name)?.();\n        assert(Codec, `Unknown codec: ${meta.name}`);\n        return { Codec, meta };\n    });\n    let array_to_array = [];\n    let array_to_bytes;\n    let bytes_to_bytes = [];\n    for await (let { Codec, meta } of promises) {\n        let codec = Codec.fromConfig(meta.configuration, chunk_meta);\n        switch (codec.kind) {\n            case \"array_to_array\":\n                array_to_array.push(codec);\n                break;\n            case \"array_to_bytes\":\n                array_to_bytes = codec;\n                break;\n            default:\n                bytes_to_bytes.push(codec);\n        }\n    }\n    if (!array_to_bytes) {\n        assert(is_typed_array_like_meta(chunk_meta), `Cannot encode ${chunk_meta.data_type} to bytes without a codec`);\n        array_to_bytes = BytesCodec.fromConfig({ endian: \"little\" }, chunk_meta);\n    }\n    return { array_to_array, array_to_bytes, bytes_to_bytes };\n}\nfunction is_typed_array_like_meta(meta) {\n    return meta.data_type !== \"v2:object\";\n}\n","import { assert } from \"../util.js\";\nimport { create_codec_pipeline } from \"../codecs.js\";\nconst MAX_BIG_UINT = 18446744073709551615n;\nexport function create_sharded_chunk_getter(location, shard_shape, encode_shard_key, sharding_config) {\n    assert(location.store.getRange, \"Store does not support range requests\");\n    let get_range = location.store.getRange.bind(location.store);\n    let index_shape = shard_shape.map((d, i) => d / sharding_config.chunk_shape[i]);\n    let index_codec = create_codec_pipeline({\n        data_type: \"uint64\",\n        shape: [...index_shape, 2],\n        codecs: sharding_config.index_codecs,\n    });\n    let cache = {};\n    return async (chunk_coord) => {\n        let shard_coord = chunk_coord.map((d, i) => Math.floor(d / index_shape[i]));\n        let shard_path = location.resolve(encode_shard_key(shard_coord)).path;\n        let index;\n        if (shard_path in cache) {\n            index = cache[shard_path];\n        }\n        else {\n            let checksum_size = 4;\n            let index_size = 16 * index_shape.reduce((a, b) => a * b, 1);\n            let bytes = await get_range(shard_path, {\n                suffixLength: index_size + checksum_size,\n            });\n            index = cache[shard_path] = bytes\n                ? await index_codec.decode(bytes)\n                : null;\n        }\n        if (index === null) {\n            return undefined;\n        }\n        let { data, shape, stride } = index;\n        let linear_offset = chunk_coord\n            .map((d, i) => d % shape[i])\n            .reduce((acc, sel, idx) => acc + sel * stride[idx], 0);\n        let offset = data[linear_offset];\n        let length = data[linear_offset + 1];\n        // write null chunk when 2^64-1 indicates fill value\n        if (offset === MAX_BIG_UINT && length === MAX_BIG_UINT) {\n            return undefined;\n        }\n        return get_range(shard_path, {\n            offset: Number(offset),\n            length: Number(length),\n        });\n    };\n}\n","import { create_codec_pipeline } from \"./codecs.js\";\nimport { create_sharded_chunk_getter } from \"./codecs/sharding.js\";\nimport { is_dtype, is_sharding_codec, } from \"./util.js\";\nimport { create_chunk_key_encoder, ensure_correct_scalar, get_ctr, get_strides, } from \"./util.js\";\nexport class Location {\n    store;\n    path;\n    constructor(store, path = \"/\") {\n        this.store = store;\n        this.path = path;\n    }\n    resolve(path) {\n        // reuse URL resolution logic built into the browser\n        // handles relative paths, absolute paths, etc.\n        let root = new URL(`file://${this.path.endsWith(\"/\") ? this.path : `${this.path}/`}`);\n        return new Location(this.store, new URL(path, root).pathname);\n    }\n}\nexport function root(store) {\n    return new Location(store ?? new Map());\n}\nexport class Group extends Location {\n    kind = \"group\";\n    #metadata;\n    constructor(store, path, metadata) {\n        super(store, path);\n        this.#metadata = metadata;\n    }\n    get attrs() {\n        return this.#metadata.attributes;\n    }\n}\nfunction get_array_order(codecs) {\n    const maybe_transpose_codec = codecs.find((c) => c.name === \"transpose\");\n    // @ts-expect-error - TODO: Should validate?\n    return maybe_transpose_codec?.configuration?.order ?? \"C\";\n}\nconst CONTEXT_MARKER = Symbol(\"zarrita.context\");\nexport function get_context(obj) {\n    return obj[CONTEXT_MARKER];\n}\nfunction create_context(location, metadata) {\n    let { configuration } = metadata.codecs.find(is_sharding_codec) ?? {};\n    let shared_context = {\n        encode_chunk_key: create_chunk_key_encoder(metadata.chunk_key_encoding),\n        TypedArray: get_ctr(metadata.data_type),\n        fill_value: metadata.fill_value,\n    };\n    if (configuration) {\n        let native_order = get_array_order(configuration.codecs);\n        return {\n            ...shared_context,\n            kind: \"sharded\",\n            chunk_shape: configuration.chunk_shape,\n            codec: create_codec_pipeline({\n                data_type: metadata.data_type,\n                shape: configuration.chunk_shape,\n                codecs: configuration.codecs,\n            }),\n            get_strides(shape) {\n                return get_strides(shape, native_order);\n            },\n            get_chunk_bytes: create_sharded_chunk_getter(location, metadata.chunk_grid.configuration.chunk_shape, shared_context.encode_chunk_key, configuration),\n        };\n    }\n    let native_order = get_array_order(metadata.codecs);\n    return {\n        ...shared_context,\n        kind: \"regular\",\n        chunk_shape: metadata.chunk_grid.configuration.chunk_shape,\n        codec: create_codec_pipeline({\n            data_type: metadata.data_type,\n            shape: metadata.chunk_grid.configuration.chunk_shape,\n            codecs: metadata.codecs,\n        }),\n        get_strides(shape) {\n            return get_strides(shape, native_order);\n        },\n        async get_chunk_bytes(chunk_coords, options) {\n            let chunk_key = shared_context.encode_chunk_key(chunk_coords);\n            let chunk_path = location.resolve(chunk_key).path;\n            return location.store.get(chunk_path, options);\n        },\n    };\n}\nexport class Array extends Location {\n    kind = \"array\";\n    #metadata;\n    [CONTEXT_MARKER];\n    constructor(store, path, metadata) {\n        super(store, path);\n        this.#metadata = {\n            ...metadata,\n            fill_value: ensure_correct_scalar(metadata),\n        };\n        this[CONTEXT_MARKER] = create_context(this, metadata);\n    }\n    get attrs() {\n        return this.#metadata.attributes;\n    }\n    get shape() {\n        return this.#metadata.shape;\n    }\n    get chunks() {\n        return this[CONTEXT_MARKER].chunk_shape;\n    }\n    get dtype() {\n        return this.#metadata.data_type;\n    }\n    async getChunk(chunk_coords, options) {\n        let context = this[CONTEXT_MARKER];\n        let maybe_bytes = await context.get_chunk_bytes(chunk_coords, options);\n        if (!maybe_bytes) {\n            let size = context.chunk_shape.reduce((a, b) => a * b, 1);\n            let data = new context.TypedArray(size);\n            // @ts-expect-error: TS can't infer that `fill_value` is union (assumes never) but this is ok\n            data.fill(context.fill_value);\n            return {\n                data,\n                shape: context.chunk_shape,\n                stride: context.get_strides(context.chunk_shape),\n            };\n        }\n        return context.codec.decode(maybe_bytes);\n    }\n    /**\n     * A helper method to narrow `zarr.Array` Dtype.\n     *\n     * ```typescript\n     * let arr: zarr.Array<DataType, FetchStore> = zarr.open(store, { kind: \"array\" });\n     *\n     * // Option 1: narrow by scalar type (e.g. \"bool\", \"raw\", \"bigint\", \"number\")\n     * if (arr.is(\"bigint\")) {\n     *   // zarr.Array<\"int64\" | \"uint64\", FetchStore>\n     * }\n     *\n     * // Option 3: exact match\n     * if (arr.is(\"float32\")) {\n     *   // zarr.Array<\"float32\", FetchStore, \"/\">\n     * }\n     * ```\n     */\n    is(query) {\n        return is_dtype(this.dtype, query);\n    }\n}\n","import { product, range, slice, slice_indices } from \"./util.js\";\nexport class IndexError extends Error {\n    constructor(msg) {\n        super(msg);\n        this.name = \"IndexError\";\n    }\n}\nfunction err_too_many_indices(selection, shape) {\n    throw new IndexError(`too many indicies for array; expected ${shape.length}, got ${selection.length}`);\n}\nfunction err_boundscheck(dim_len) {\n    throw new IndexError(`index out of bounds for dimension with length ${dim_len}`);\n}\nfunction err_negative_step() {\n    throw new IndexError(\"only slices with step >= 1 are supported\");\n}\nfunction check_selection_length(selection, shape) {\n    if (selection.length > shape.length) {\n        err_too_many_indices(selection, shape);\n    }\n}\nexport function normalize_integer_selection(dim_sel, dim_len) {\n    // normalize type to int\n    dim_sel = Math.trunc(dim_sel);\n    // handle wraparound\n    if (dim_sel < 0) {\n        dim_sel = dim_len + dim_sel;\n    }\n    // handle out of bounds\n    if (dim_sel >= dim_len || dim_sel < 0) {\n        err_boundscheck(dim_len);\n    }\n    return dim_sel;\n}\nclass IntDimIndexer {\n    dim_sel;\n    dim_len;\n    dim_chunk_len;\n    nitems;\n    constructor({ dim_sel, dim_len, dim_chunk_len }) {\n        // normalize\n        dim_sel = normalize_integer_selection(dim_sel, dim_len);\n        // store properties\n        this.dim_sel = dim_sel;\n        this.dim_len = dim_len;\n        this.dim_chunk_len = dim_chunk_len;\n        this.nitems = 1;\n    }\n    *[Symbol.iterator]() {\n        const dim_chunk_ix = Math.floor(this.dim_sel / this.dim_chunk_len);\n        const dim_offset = dim_chunk_ix * this.dim_chunk_len;\n        const dim_chunk_sel = this.dim_sel - dim_offset;\n        yield { dim_chunk_ix, dim_chunk_sel };\n    }\n}\nclass SliceDimIndexer {\n    start;\n    stop;\n    step;\n    dim_len;\n    dim_chunk_len;\n    nitems;\n    nchunks;\n    constructor({ dim_sel, dim_len, dim_chunk_len }) {\n        // normalize\n        const [start, stop, step] = slice_indices(dim_sel, dim_len);\n        this.start = start;\n        this.stop = stop;\n        this.step = step;\n        if (this.step < 1)\n            err_negative_step();\n        // store properties\n        this.dim_len = dim_len;\n        this.dim_chunk_len = dim_chunk_len;\n        this.nitems = Math.max(0, Math.ceil((this.stop - this.start) / this.step));\n        this.nchunks = Math.ceil(this.dim_len / this.dim_chunk_len);\n    }\n    *[Symbol.iterator]() {\n        // figure out the range of chunks we need to visit\n        const dim_chunk_ix_from = Math.floor(this.start / this.dim_chunk_len);\n        const dim_chunk_ix_to = Math.ceil(this.stop / this.dim_chunk_len);\n        for (const dim_chunk_ix of range(dim_chunk_ix_from, dim_chunk_ix_to)) {\n            // compute offsets for chunk within overall array\n            const dim_offset = dim_chunk_ix * this.dim_chunk_len;\n            const dim_limit = Math.min(this.dim_len, (dim_chunk_ix + 1) * this.dim_chunk_len);\n            // determine chunk length, accounting for trailing chunk\n            const dim_chunk_len = dim_limit - dim_offset;\n            let dim_out_offset = 0;\n            let dim_chunk_sel_start = 0;\n            if (this.start < dim_offset) {\n                // selection start before current chunk\n                const remainder = (dim_offset - this.start) % this.step;\n                if (remainder)\n                    dim_chunk_sel_start += this.step - remainder;\n                // compute number of previous items, provides offset into output array\n                dim_out_offset = Math.ceil((dim_offset - this.start) / this.step);\n            }\n            else {\n                // selection starts within current chunk\n                dim_chunk_sel_start = this.start - dim_offset;\n            }\n            // selection starts within current chunk if true,\n            // otherwise selection ends after current chunk.\n            const dim_chunk_sel_stop = this.stop > dim_limit ? dim_chunk_len : this.stop - dim_offset;\n            const dim_chunk_sel = [\n                dim_chunk_sel_start,\n                dim_chunk_sel_stop,\n                this.step,\n            ];\n            const dim_chunk_nitems = Math.ceil((dim_chunk_sel_stop - dim_chunk_sel_start) / this.step);\n            const dim_out_sel = [\n                dim_out_offset,\n                dim_out_offset + dim_chunk_nitems,\n                1,\n            ];\n            yield { dim_chunk_ix, dim_chunk_sel, dim_out_sel };\n        }\n    }\n}\nexport function normalize_selection(selection, shape) {\n    let normalized = [];\n    if (selection === null) {\n        normalized = shape.map((_) => slice(null));\n    }\n    else if (Array.isArray(selection)) {\n        normalized = selection.map((s) => s ?? slice(null));\n    }\n    check_selection_length(normalized, shape);\n    return normalized;\n}\nexport class BasicIndexer {\n    dim_indexers;\n    shape;\n    constructor({ selection, shape, chunk_shape }) {\n        // setup per-dimension indexers\n        this.dim_indexers = normalize_selection(selection, shape).map((dim_sel, i) => {\n            return new (typeof dim_sel === \"number\" ? IntDimIndexer : SliceDimIndexer)({\n                // @ts-expect-error ts inference not strong enough to know correct chunk\n                dim_sel: dim_sel,\n                dim_len: shape[i],\n                dim_chunk_len: chunk_shape[i],\n            });\n        });\n        this.shape = this.dim_indexers\n            .filter((ixr) => ixr instanceof SliceDimIndexer)\n            .map((sixr) => sixr.nitems);\n    }\n    *[Symbol.iterator]() {\n        for (const dim_projections of product(...this.dim_indexers)) {\n            const chunk_coords = dim_projections.map((p) => p.dim_chunk_ix);\n            const mapping = dim_projections.map((p) => {\n                if (\"dim_out_sel\" in p) {\n                    return { from: p.dim_chunk_sel, to: p.dim_out_sel };\n                }\n                return { from: p.dim_chunk_sel, to: null };\n            });\n            yield { chunk_coords, mapping };\n        }\n    }\n}\n","import { get as get_with_setter } from \"./get.js\";\nimport { set as set_with_setter } from \"./set.js\";\n/** A 1D \"view\" of an array that can be used to set values in the array. */\nfunction object_array_view(arr, offset = 0, size) {\n    let length = size ?? arr.length - offset;\n    return {\n        length,\n        subarray(from, to = length) {\n            return object_array_view(arr, offset + from, to - from);\n        },\n        set(data, start = 0) {\n            for (let i = 0; i < data.length; i++) {\n                arr[offset + start + i] = data.get(i);\n            }\n        },\n        get(index) {\n            return arr[offset + index];\n        },\n    };\n}\n/**\n * Convert a chunk to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more than\n * just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the underlying, which is supported by our binary set functions.\n */\nfunction compat_chunk(arr) {\n    if (globalThis.Array.isArray(arr.data)) {\n        return {\n            // @ts-expect-error\n            data: object_array_view(arr.data),\n            stride: arr.stride,\n            bytes_per_element: 1,\n        };\n    }\n    return {\n        data: new Uint8Array(arr.data.buffer, arr.data.byteOffset, arr.data.byteLength),\n        stride: arr.stride,\n        bytes_per_element: arr.data.BYTES_PER_ELEMENT,\n    };\n}\n/** Hack to get the constructor of a typed array constructor from an existing TypedArray. */\nfunction get_typed_array_constructor(arr) {\n    if (\"chars\" in arr) {\n        // our custom TypedArray needs to bind the number of characters per\n        // element to the constructor.\n        return arr.constructor.bind(null, arr.chars);\n    }\n    return arr.constructor;\n}\n/**\n * Convert a scalar to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more\n * than just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the scalar, which is supported by our binary set functions.\n */\nfunction compat_scalar(arr, value) {\n    if (globalThis.Array.isArray(arr.data)) {\n        // @ts-expect-error\n        return object_array_view([value]);\n    }\n    let TypedArray = get_typed_array_constructor(arr.data);\n    // @ts-expect-error - value is a scalar and matches\n    let data = new TypedArray([value]);\n    return new Uint8Array(data.buffer, data.byteOffset, data.byteLength);\n}\nexport const setter = {\n    prepare(data, shape, stride) {\n        return { data, shape, stride };\n    },\n    set_scalar(dest, sel, value) {\n        let view = compat_chunk(dest);\n        set_scalar_binary(view, sel, compat_scalar(dest, value), view.bytes_per_element);\n    },\n    set_from_chunk(dest, src, projections) {\n        let view = compat_chunk(dest);\n        set_from_chunk_binary(view, compat_chunk(src), view.bytes_per_element, projections);\n    },\n};\n/** @category Utility */\nexport async function get(arr, selection = null, opts = {}) {\n    return get_with_setter(arr, selection, opts, setter);\n}\n/** @category Utility */\nexport async function set(arr, selection, value, opts = {}) {\n    return set_with_setter(arr, selection, value, opts, setter);\n}\nfunction indices_len(start, stop, step) {\n    if (step < 0 && stop < start) {\n        return Math.floor((start - stop - 1) / -step) + 1;\n    }\n    if (start < stop)\n        return Math.floor((stop - start - 1) / step) + 1;\n    return 0;\n}\nfunction set_scalar_binary(out, out_selection, value, bytes_per_element) {\n    if (out_selection.length === 0) {\n        out.data.set(value, 0);\n        return;\n    }\n    const [slice, ...slices] = out_selection;\n    const [curr_stride, ...stride] = out.stride;\n    if (typeof slice === \"number\") {\n        const data = out.data.subarray(curr_stride * slice * bytes_per_element);\n        set_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n        return;\n    }\n    const [from, to, step] = slice;\n    const len = indices_len(from, to, step);\n    if (slices.length === 0) {\n        for (let i = 0; i < len; i++) {\n            out.data.set(value, curr_stride * (from + step * i) * bytes_per_element);\n        }\n        return;\n    }\n    for (let i = 0; i < len; i++) {\n        const data = out.data.subarray(curr_stride * (from + step * i) * bytes_per_element);\n        set_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n    }\n}\nfunction set_from_chunk_binary(dest, src, bytes_per_element, projections) {\n    const [proj, ...projs] = projections;\n    const [dstride, ...dstrides] = dest.stride;\n    const [sstride, ...sstrides] = src.stride;\n    if (proj.from === null) {\n        if (projs.length === 0) {\n            dest.data.set(src.data.subarray(0, bytes_per_element), proj.to * bytes_per_element);\n            return;\n        }\n        set_from_chunk_binary({\n            data: dest.data.subarray(dstride * proj.to * bytes_per_element),\n            stride: dstrides,\n        }, src, bytes_per_element, projs);\n        return;\n    }\n    if (proj.to === null) {\n        if (projs.length === 0) {\n            let offset = proj.from * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + bytes_per_element), 0);\n            return;\n        }\n        set_from_chunk_binary(dest, {\n            data: src.data.subarray(sstride * proj.from * bytes_per_element),\n            stride: sstrides,\n        }, bytes_per_element, projs);\n        return;\n    }\n    const [from, to, step] = proj.to;\n    const [sfrom, _, sstep] = proj.from;\n    const len = indices_len(from, to, step);\n    if (projs.length === 0) {\n        // NB: we have a contiguous block of memory\n        // so we can just copy over all the data at once.\n        if (step === 1 && sstep === 1 && dstride === 1 && sstride === 1) {\n            let offset = sfrom * bytes_per_element;\n            let size = len * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + size), from * bytes_per_element);\n            return;\n        }\n        // Otherwise, we have to copy over each element individually.\n        for (let i = 0; i < len; i++) {\n            let offset = sstride * (sfrom + sstep * i) * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + bytes_per_element), dstride * (from + step * i) * bytes_per_element);\n        }\n        return;\n    }\n    for (let i = 0; i < len; i++) {\n        set_from_chunk_binary({\n            data: dest.data.subarray(dstride * (from + i * step) * bytes_per_element),\n            stride: dstrides,\n        }, {\n            data: src.data.subarray(sstride * (sfrom + i * sstep) * bytes_per_element),\n            stride: sstrides,\n        }, bytes_per_element, projs);\n    }\n}\n","import { get_context } from \"../hierarchy.js\";\nimport { BasicIndexer } from \"./indexer.js\";\nimport { create_queue } from \"./util.js\";\nfunction unwrap(arr, idx) {\n    return (\"get\" in arr ? arr.get(idx) : arr[idx]);\n}\nexport async function get(arr, selection, opts, setter) {\n    let context = get_context(arr);\n    let indexer = new BasicIndexer({\n        selection,\n        shape: arr.shape,\n        chunk_shape: arr.chunks,\n    });\n    let out = setter.prepare(new context.TypedArray(indexer.shape.reduce((a, b) => a * b, 1)), indexer.shape, context.get_strides(indexer.shape));\n    let queue = opts.create_queue?.() ?? create_queue();\n    for (const { chunk_coords, mapping } of indexer) {\n        queue.add(async () => {\n            let { data, shape, stride } = await arr.getChunk(chunk_coords, opts.opts);\n            let chunk = setter.prepare(data, shape, stride);\n            setter.set_from_chunk(out, chunk, mapping);\n        });\n    }\n    await queue.onIdle();\n    // If the final out shape is empty, we just return a scalar.\n    // @ts-expect-error - TS can't narrow this conditional type\n    return indexer.shape.length === 0 ? unwrap(out.data, 0) : out;\n}\n","/** Similar to python's `range` function. Supports positive ranges only. */\nexport function* range(start, stop, step = 1) {\n    if (stop === undefined) {\n        stop = start;\n        start = 0;\n    }\n    for (let i = start; i < stop; i += step) {\n        yield i;\n    }\n}\n/**\n * python-like itertools.product generator\n * https://gist.github.com/cybercase/db7dde901d7070c98c48\n */\nexport function* product(...iterables) {\n    if (iterables.length === 0) {\n        return;\n    }\n    // make a list of iterators from the iterables\n    const iterators = iterables.map((it) => it[Symbol.iterator]());\n    const results = iterators.map((it) => it.next());\n    if (results.some((r) => r.done)) {\n        throw new Error(\"Input contains an empty iterator.\");\n    }\n    for (let i = 0;;) {\n        if (results[i].done) {\n            // reset the current iterator\n            iterators[i] = iterables[i][Symbol.iterator]();\n            results[i] = iterators[i].next();\n            // advance, and exit if we've reached the end\n            if (++i >= iterators.length) {\n                return;\n            }\n        }\n        else {\n            // @ts-expect-error - TS can't infer this\n            yield results.map(({ value }) => value);\n            i = 0;\n        }\n        results[i] = iterators[i].next();\n    }\n}\n// https://github.com/python/cpython/blob/263c0dd16017613c5ea2fbfc270be4de2b41b5ad/Objects/sliceobject.c#L376-L519\nexport function slice_indices({ start, stop, step }, length) {\n    if (step === 0) {\n        throw new Error(\"slice step cannot be zero\");\n    }\n    step = step ?? 1;\n    const step_is_negative = step < 0;\n    /* Find lower and upper bounds for start and stop. */\n    const [lower, upper] = step_is_negative ? [-1, length - 1] : [0, length];\n    /* Compute start. */\n    if (start === null) {\n        start = step_is_negative ? upper : lower;\n    }\n    else {\n        if (start < 0) {\n            start += length;\n            if (start < lower) {\n                start = lower;\n            }\n        }\n        else if (start > upper) {\n            start = upper;\n        }\n    }\n    /* Compute stop. */\n    if (stop === null) {\n        stop = step_is_negative ? lower : upper;\n    }\n    else {\n        if (stop < 0) {\n            stop += length;\n            if (stop < lower) {\n                stop = lower;\n            }\n        }\n        else if (stop > upper) {\n            stop = upper;\n        }\n    }\n    return [start, stop, step];\n}\nexport function slice(start, stop, step = null) {\n    if (stop === undefined) {\n        stop = start;\n        start = null;\n    }\n    return {\n        start,\n        stop,\n        step,\n    };\n}\n/** Built-in \"queue\" for awaiting promises. */\nexport function create_queue() {\n    const promises = [];\n    return {\n        add: (fn) => promises.push(fn()),\n        onIdle: () => Promise.all(promises),\n    };\n}\n","import { KeyError, NodeNotFoundError } from \"./errors.js\";\nimport { Array, Group, Location } from \"./hierarchy.js\";\nimport { ensure_correct_scalar, json_decode_object, rethrow_unless, v2_to_v3_array_metadata, v2_to_v3_group_metadata, } from \"./util.js\";\nlet VERSION_COUNTER = create_version_counter();\nfunction create_version_counter() {\n    let version_counts = new WeakMap();\n    function get_counts(store) {\n        let counts = version_counts.get(store) ?? { v2: 0, v3: 0 };\n        version_counts.set(store, counts);\n        return counts;\n    }\n    return {\n        increment(store, version) {\n            get_counts(store)[version] += 1;\n        },\n        version_max(store) {\n            let counts = get_counts(store);\n            return counts.v3 > counts.v2 ? \"v3\" : \"v2\";\n        },\n    };\n}\nasync function load_attrs(location) {\n    let meta_bytes = await location.store.get(location.resolve(\".zattrs\").path);\n    if (!meta_bytes)\n        return {};\n    return json_decode_object(meta_bytes);\n}\nasync function open_v2(location, options = {}) {\n    let loc = \"store\" in location ? location : new Location(location);\n    let attrs = {};\n    if (options.attrs ?? true)\n        attrs = await load_attrs(loc);\n    if (options.kind === \"array\")\n        return open_array_v2(loc, attrs);\n    if (options.kind === \"group\")\n        return open_group_v2(loc, attrs);\n    return open_array_v2(loc, attrs).catch((err) => {\n        rethrow_unless(err, NodeNotFoundError);\n        return open_group_v2(loc, attrs);\n    });\n}\nasync function open_array_v2(location, attrs) {\n    let { path } = location.resolve(\".zarray\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v2 array\", {\n            cause: new KeyError(path),\n        });\n    }\n    VERSION_COUNTER.increment(location.store, \"v2\");\n    return new Array(location.store, location.path, v2_to_v3_array_metadata(json_decode_object(meta), attrs));\n}\nasync function open_group_v2(location, attrs) {\n    let { path } = location.resolve(\".zgroup\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v2 group\", {\n            cause: new KeyError(path),\n        });\n    }\n    VERSION_COUNTER.increment(location.store, \"v2\");\n    return new Group(location.store, location.path, v2_to_v3_group_metadata(json_decode_object(meta), attrs));\n}\nasync function _open_v3(location) {\n    let { store, path } = location.resolve(\"zarr.json\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v3 array or group\", {\n            cause: new KeyError(path),\n        });\n    }\n    let meta_doc = json_decode_object(meta);\n    if (meta_doc.node_type === \"array\") {\n        meta_doc.fill_value = ensure_correct_scalar(meta_doc);\n    }\n    return meta_doc.node_type === \"array\"\n        ? new Array(store, location.path, meta_doc)\n        : new Group(store, location.path, meta_doc);\n}\nasync function open_v3(location, options = {}) {\n    let loc = \"store\" in location ? location : new Location(location);\n    let node = await _open_v3(loc);\n    VERSION_COUNTER.increment(loc.store, \"v3\");\n    if (options.kind === undefined)\n        return node;\n    if (options.kind === \"array\" && node instanceof Array)\n        return node;\n    if (options.kind === \"group\" && node instanceof Group)\n        return node;\n    let kind = node instanceof Array ? \"array\" : \"group\";\n    throw new Error(`Expected node of kind ${options.kind}, found ${kind}.`);\n}\nexport async function open(location, options = {}) {\n    let store = \"store\" in location ? location.store : location;\n    let version_max = VERSION_COUNTER.version_max(store);\n    // Use the open function for the version with the most successful opens.\n    // Note that here we use the dot syntax to access the open functions\n    // because this enables us to use vi.spyOn during testing.\n    let open_primary = version_max === \"v2\" ? open.v2 : open.v3;\n    let open_secondary = version_max === \"v2\" ? open.v3 : open.v2;\n    return open_primary(location, options).catch((err) => {\n        rethrow_unless(err, NodeNotFoundError);\n        return open_secondary(location, options);\n    });\n}\nopen.v2 = open_v2;\nopen.v3 = open_v3;\n","/**\n * Custom array-like views (i.e., TypedArrays) for Zarr binary data buffers.\n *\n * @module\n */\n/**\n * An array-like view of a fixed-length boolean buffer.\n *\n * Encoded as 1 byte per value.\n */\nexport class BoolArray {\n    #bytes;\n    constructor(x, byteOffset, length) {\n        if (typeof x === \"number\") {\n            this.#bytes = new Uint8Array(x);\n        }\n        else if (x instanceof ArrayBuffer) {\n            this.#bytes = new Uint8Array(x, byteOffset, length);\n        }\n        else {\n            this.#bytes = new Uint8Array(Array.from(x, (v) => (v ? 1 : 0)));\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return 1;\n    }\n    get byteOffset() {\n        return this.#bytes.byteOffset;\n    }\n    get byteLength() {\n        return this.#bytes.byteLength;\n    }\n    get buffer() {\n        return this.#bytes.buffer;\n    }\n    get length() {\n        return this.#bytes.length;\n    }\n    get(idx) {\n        let value = this.#bytes[idx];\n        return typeof value === \"number\" ? value !== 0 : value;\n    }\n    set(idx, value) {\n        this.#bytes[idx] = value ? 1 : 0;\n    }\n    fill(value) {\n        this.#bytes.fill(value ? 1 : 0);\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n/**\n * An array-like view of a fixed-length byte buffer.\n *\n * Encodes a raw byte sequences without enforced encoding.\n */\nexport class ByteStringArray {\n    _data;\n    chars;\n    #encoder;\n    constructor(chars, x, byteOffset, length) {\n        this.chars = chars;\n        this.#encoder = new TextEncoder();\n        if (typeof x === \"number\") {\n            this._data = new Uint8Array(x * chars);\n        }\n        else if (x instanceof ArrayBuffer) {\n            if (length)\n                length = length * chars;\n            this._data = new Uint8Array(x, byteOffset, length);\n        }\n        else {\n            let values = Array.from(x);\n            this._data = new Uint8Array(values.length * chars);\n            for (let i = 0; i < values.length; i++) {\n                this.set(i, values[i]);\n            }\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return this.chars;\n    }\n    get byteOffset() {\n        return this._data.byteOffset;\n    }\n    get byteLength() {\n        return this._data.byteLength;\n    }\n    get buffer() {\n        return this._data.buffer;\n    }\n    get length() {\n        return this.byteLength / this.BYTES_PER_ELEMENT;\n    }\n    get(idx) {\n        const view = new Uint8Array(this.buffer, this.byteOffset + this.chars * idx, this.chars);\n        // biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n        return new TextDecoder().decode(view).replace(/\\x00/g, \"\");\n    }\n    set(idx, value) {\n        const view = new Uint8Array(this.buffer, this.byteOffset + this.chars * idx, this.chars);\n        view.fill(0); // clear current\n        view.set(this.#encoder.encode(value));\n    }\n    fill(value) {\n        const encoded = this.#encoder.encode(value);\n        for (let i = 0; i < this.length; i++) {\n            this._data.set(encoded, i * this.chars);\n        }\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n/**\n * An array-like view of a fixed-length Unicode string buffer.\n *\n * Encoded as UTF-32 code points.\n */\nexport class UnicodeStringArray {\n    #data;\n    chars;\n    constructor(chars, x, byteOffset, length) {\n        this.chars = chars;\n        if (typeof x === \"number\") {\n            this.#data = new Int32Array(x * chars);\n        }\n        else if (x instanceof ArrayBuffer) {\n            if (length)\n                length *= chars;\n            this.#data = new Int32Array(x, byteOffset, length);\n        }\n        else {\n            const values = x;\n            const d = new UnicodeStringArray(chars, 1);\n            this.#data = new Int32Array((function* () {\n                for (let str of values) {\n                    d.set(0, str);\n                    yield* d.#data;\n                }\n            })());\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return this.#data.BYTES_PER_ELEMENT * this.chars;\n    }\n    get byteLength() {\n        return this.#data.byteLength;\n    }\n    get byteOffset() {\n        return this.#data.byteOffset;\n    }\n    get buffer() {\n        return this.#data.buffer;\n    }\n    get length() {\n        return this.#data.length / this.chars;\n    }\n    get(idx) {\n        const offset = this.chars * idx;\n        let result = \"\";\n        for (let i = 0; i < this.chars; i++) {\n            result += String.fromCodePoint(this.#data[offset + i]);\n        }\n        // biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n        return result.replace(/\\u0000/g, \"\");\n    }\n    set(idx, value) {\n        const offset = this.chars * idx;\n        const view = this.#data.subarray(offset, offset + this.chars);\n        view.fill(0); // clear current\n        for (let i = 0; i < this.chars; i++) {\n            view[i] = value.codePointAt(i) ?? 0;\n        }\n    }\n    fill(value) {\n        // encode once\n        this.set(0, value);\n        // copy the encoded values to all other elements\n        let encoded = this.#data.subarray(0, this.chars);\n        for (let i = 1; i < this.length; i++) {\n            this.#data.set(encoded, i * this.chars);\n        }\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n","import { BoolArray, ByteStringArray, UnicodeStringArray, } from \"./typedarray.js\";\nexport function json_encode_object(o) {\n    const str = JSON.stringify(o, null, 2);\n    return new TextEncoder().encode(str);\n}\nexport function json_decode_object(bytes) {\n    const str = new TextDecoder().decode(bytes);\n    return JSON.parse(str);\n}\nexport function byteswap_inplace(view, bytes_per_element) {\n    const numFlips = bytes_per_element / 2;\n    const endByteIndex = bytes_per_element - 1;\n    let t = 0;\n    for (let i = 0; i < view.length; i += bytes_per_element) {\n        for (let j = 0; j < numFlips; j += 1) {\n            t = view[i + j];\n            view[i + j] = view[i + endByteIndex - j];\n            view[i + endByteIndex - j] = t;\n        }\n    }\n}\nexport function get_ctr(data_type) {\n    if (data_type === \"v2:object\") {\n        return globalThis.Array;\n    }\n    let match = data_type.match(/v2:([US])(\\d+)/);\n    if (match) {\n        let [, kind, chars] = match;\n        // @ts-expect-error\n        return (kind === \"U\" ? UnicodeStringArray : ByteStringArray).bind(null, Number(chars));\n    }\n    // @ts-expect-error - We've checked that the key exists\n    let ctr = {\n        int8: Int8Array,\n        int16: Int16Array,\n        int32: Int32Array,\n        int64: globalThis.BigInt64Array,\n        uint8: Uint8Array,\n        uint16: Uint16Array,\n        uint32: Uint32Array,\n        uint64: globalThis.BigUint64Array,\n        float16: globalThis.Float16Array,\n        float32: Float32Array,\n        float64: Float64Array,\n        bool: BoolArray,\n    }[data_type];\n    assert(ctr, `Unknown or unsupported data_type: ${data_type}`);\n    return ctr;\n}\n/** Compute strides for 'C' or 'F' ordered array from shape */\nexport function get_strides(shape, order) {\n    const rank = shape.length;\n    if (typeof order === \"string\") {\n        order =\n            order === \"C\"\n                ? Array.from({ length: rank }, (_, i) => i) // Row-major (identity order)\n                : Array.from({ length: rank }, (_, i) => rank - 1 - i); // Column-major (reverse order)\n    }\n    assert(rank === order.length, \"Order length must match the number of dimensions.\");\n    let step = 1;\n    let stride = new Array(rank);\n    for (let i = order.length - 1; i >= 0; i--) {\n        stride[order[i]] = step;\n        step *= shape[order[i]];\n    }\n    return stride;\n}\n// https://zarr-specs.readthedocs.io/en/latest/v3/core/v3.0.html#chunk-key-encoding\nexport function create_chunk_key_encoder({ name, configuration, }) {\n    if (name === \"default\") {\n        const separator = configuration?.separator ?? \"/\";\n        return (chunk_coords) => [\"c\", ...chunk_coords].join(separator);\n    }\n    if (name === \"v2\") {\n        const separator = configuration?.separator ?? \".\";\n        return (chunk_coords) => chunk_coords.join(separator) || \"0\";\n    }\n    throw new Error(`Unknown chunk key encoding: ${name}`);\n}\nfunction coerce_dtype(dtype) {\n    if (dtype === \"|O\") {\n        return { data_type: \"v2:object\" };\n    }\n    let match = dtype.match(/^([<|>])(.*)$/);\n    assert(match, `Invalid dtype: ${dtype}`);\n    let [, endian, rest] = match;\n    let data_type = {\n        b1: \"bool\",\n        i1: \"int8\",\n        u1: \"uint8\",\n        i2: \"int16\",\n        u2: \"uint16\",\n        i4: \"int32\",\n        u4: \"uint32\",\n        i8: \"int64\",\n        u8: \"uint64\",\n        f2: \"float16\",\n        f4: \"float32\",\n        f8: \"float64\",\n    }[rest] ??\n        (rest.startsWith(\"S\") || rest.startsWith(\"U\") ? `v2:${rest}` : undefined);\n    assert(data_type, `Unsupported or unknown dtype: ${dtype}`);\n    if (endian === \"|\") {\n        return { data_type };\n    }\n    return { data_type, endian: endian === \"<\" ? \"little\" : \"big\" };\n}\nexport function v2_to_v3_array_metadata(meta, attributes = {}) {\n    let codecs = [];\n    let dtype = coerce_dtype(meta.dtype);\n    if (meta.order === \"F\") {\n        codecs.push({ name: \"transpose\", configuration: { order: \"F\" } });\n    }\n    if (\"endian\" in dtype && dtype.endian === \"big\") {\n        codecs.push({ name: \"bytes\", configuration: { endian: \"big\" } });\n    }\n    for (let { id, ...configuration } of meta.filters ?? []) {\n        codecs.push({ name: id, configuration });\n    }\n    if (meta.compressor) {\n        let { id, ...configuration } = meta.compressor;\n        codecs.push({ name: id, configuration });\n    }\n    return {\n        zarr_format: 3,\n        node_type: \"array\",\n        shape: meta.shape,\n        data_type: dtype.data_type,\n        chunk_grid: {\n            name: \"regular\",\n            configuration: {\n                chunk_shape: meta.chunks,\n            },\n        },\n        chunk_key_encoding: {\n            name: \"v2\",\n            configuration: {\n                separator: meta.dimension_separator ?? \".\",\n            },\n        },\n        codecs,\n        fill_value: meta.fill_value,\n        attributes,\n    };\n}\nexport function v2_to_v3_group_metadata(_meta, attributes = {}) {\n    return {\n        zarr_format: 3,\n        node_type: \"group\",\n        attributes,\n    };\n}\nexport function is_dtype(dtype, query) {\n    if (query !== \"number\" &&\n        query !== \"bigint\" &&\n        query !== \"boolean\" &&\n        query !== \"object\" &&\n        query !== \"string\") {\n        return dtype === query;\n    }\n    let is_boolean = dtype === \"bool\";\n    if (query === \"boolean\")\n        return is_boolean;\n    let is_string = dtype.startsWith(\"v2:U\") || dtype.startsWith(\"v2:S\");\n    if (query === \"string\")\n        return is_string;\n    let is_bigint = dtype === \"int64\" || dtype === \"uint64\";\n    if (query === \"bigint\")\n        return is_bigint;\n    let is_object = dtype === \"v2:object\";\n    if (query === \"object\")\n        return is_object;\n    return !is_string && !is_bigint && !is_boolean && !is_object;\n}\nexport function is_sharding_codec(codec) {\n    return codec?.name === \"sharding_indexed\";\n}\nexport function ensure_correct_scalar(metadata) {\n    if ((metadata.data_type === \"uint64\" || metadata.data_type === \"int64\") &&\n        metadata.fill_value != null) {\n        // @ts-expect-error - We've narrowed the type of fill_value correctly\n        return BigInt(metadata.fill_value);\n    }\n    return metadata.fill_value;\n}\n/**\n * Ensures an error matches expected type(s), otherwise rethrows.\n *\n * Unmatched errors bubble up, like Python's `except`. Narrows error types for\n * type-safe property access.\n *\n * @see {@link https://gist.github.com/manzt/3702f19abb714e21c22ce48851c75abf}\n *\n * @example\n * ```ts\n * class DatabaseError extends Error { }\n * class NetworkError extends Error { }\n *\n * try {\n *   await db.query();\n * } catch (err) {\n *   rethrow_unless(err, DatabaseError, NetworkError);\n *   err // DatabaseError | NetworkError\n * }\n * ```\n *\n * @param error - The error to check\n * @param errors - Expected error type(s)\n * @throws The original error if it doesn't match expected type(s)\n */\nexport function rethrow_unless(error, ...errors) {\n    if (!errors.some((ErrorClass) => error instanceof ErrorClass)) {\n        throw error;\n    }\n}\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(expression, msg = \"\") {\n    if (!expression) {\n        throw new Error(msg);\n    }\n}\n"],"names":["Histogram","constructor","data","this","dataMinBin","dataMaxBin","maxBin","bins","Uint32Array","min","max","binSize","hinfo","calculateHistogram","i","length","pixelCount","findBin","dataValue","dataMin","numBins","binIndex","Math","floor","findBinOfValue","value","getDataMin","getDataMax","getMin","getMax","getNumBins","getBin","getBinRange","findBinOfPercentile","pct","limit","count","findBestFitBins","hmin","findAutoIJBins","pixcount","threshold","hmax","findAutoMinMax","th","b","e","x","arr","fill","item","volumeSize","volumeDims","shape","defaultImageInfo","name","atlasTileDims","subregionSize","subregionOffset","combinedNumChannels","channelNames","channelColors","multiscaleLevel","multiscaleLevelDims","spacing","spaceUnit","timeUnit","dataType","transform","translation","rotation","scale","CImageInfo","imageInfo","currentLevelDims","numChannels","originalSize","physicalPixelSize","spatialUnit","times","timeScale","numMultiscaleLevels","computeAtlasSize","volDims","allEqual","every","v","pushN","val","n","push","directionToIndex","dir","absDir","Number","updateMinMax","minmax","ChunkPrefetchIterator","chunks","tzyxMaxPrefetchOffset","tczyxChunksPerSource","priorityDirections","onlyPriorityDirections","extrema","Infinity","chunk","flat","some","isFinite","directionStates","priorityDirectionStates","direction","start","entries","dimension","tczyxIndex","end","endsPerSource","map","chunkDims","sourceEnd","directionState","includes","iterateDirections","directions","offset","filter","Array","isArray","offsetDir","newChunk","slice","Symbol","iterator","getSourceChannelNames","src","omeroMetadata","channels","label","idx","channelOffset","cIdx","axesTCZYX","scaleLevels","from","_","getDimensionCount","t","c","z","remapAxesToTCZYX","axes","axisNames","forEach","axis","axisIdx","indexOf","type","INVALID_METADATA","noXAxis","orderByDimension","valsTCZYX","orderTCZYX","specLen","result","orderByTCZYX","valsDimension","defaultValue","getScale","dataset","transforms","coordinateTransformations","undefined","console","warn","scaleTransform","find","compareZarrArraySize","aArr","aTCZYX","bArr","bTCZYX","diffZ","diffY","diffX","aboutEquals","a","abs","scaleTransformsAreEqual","aSrc","aLevel","bSrc","bLevel","aScale","multiscaleMetadata","datasets","bScale","matchSourceScaleLevels","sources","matchedLevels","matchedMetas","scaleIndexes","smallestIdx","smallestSrc","smallestArr","currentIdx","currentSrc","currentArr","ordering","INVALID_MULTI_SOURCE_ZARR","largestT","currentT","matchedScaleLevel","srcIdx","toOMEZarrMetaV4","meta","ome","isObjectWithProp","obj","prop","assertMetadataHasProp","assertPropIsArray","assertMetadataHasMultiscales","validateOMEZarrMetadata","multiscaleIdx","multiscaleMeta","multiscales","multiscaleName","wrapArray","array","basePath","cache","queue","keyBase","endsWith","path","getChunk","async","coords","opts","subscriber","reportChunk","fullKey","join","cacheResult","get","addRequest","isPrefetch","insert","Proxy","target","Function","args","apply","DEFAULT_REQUEST_CANCEL_REASON","RequestQueue","maxActiveRequests","maxLowPriorityRequests","allRequests","Map","activeRequests","Set","queueLowPriority","registerRequest","key","requestAction","promiseResolve","promiseReject","promise","Promise","resolve","reject","requestItem","action","set","addRequestToQueue","lowPriority","has","timeoutId","clearTimeout","dequeue","delayMs","lowPriorityIndex","splice","setTimeout","Error","addRequests","requests","promises","numRequests","size","requestKey","shift","add","then","delete","cancelRequest","cancelReason","queueIndex","cancelAllRequests","keys","hasRequest","requestRunning","SubscribableRequestQueue","nextSubscriberId","subscribers","resolveAll","subscriberId","rejectAll","reason","addSubscriber","catch","existingRequest","rejectSubscription","subscriptions","findIndex","sub","rejecters","removeSubscriber","hasSubscriber","isSubscribed","WorkerMsgType","WorkerResponseResult","WorkerEventType","rebuildLoadSpec","spec","subregion","copy","fetch_range","url","headers","Range","fetch","root","base","URL","pathname","resolved","search","handle_response","response","status","Uint8Array","arrayBuffer","statusText","options","overrides","useSuffixRequest","storeOverrides","requestOverrides","href","getRange","range","init","suffix_length","use_suffix_request","method","ok","content_length","fetch_suffix","suffixLength","BitroundCodec","kind","configuration","_meta","keepbits","fromConfig","encode","_arr","decode","LITTLE_ENDIAN_OS","buffer","byteOffset","byteLength","system_is_little_endian","bytes_per_element","TypedArray","BYTES_PER_ELEMENT","BytesCodec","endian","data_type","sample","bytes","stride","Crc32cCodec","throw_on_nan_replacer","_key","isNaN","POSITIVE_INFINITY","NEGATIVE_INFINITY","sort_keys_replacer","Object","sort","reduce","sorted","JsonCodec","encoding","skipkeys","ensure_ascii","check_circular","allow_nan","sort_keys","indent","strict","separators","buf","replacer_functions","items","replacer","new_value","sub_replacer","json_str","JSON","stringify","replace","chr","full_str","charCodeAt","toString","substring","TextEncoder","pop","proxy","TransposeCodec","order","rank","inverseOrder","source","s","index","entry","get_order","dim","matches_order","out","chars","empty_like","n_dims","src_data","out_data","src_idx","out_idx","convert_array_order","VLenUTF8","_chunk","decoder","TextDecoder","view","DataView","getUint32","pos","item_length","registry","m","default","create_codec_pipeline","chunk_metadata","codecs","load_codecs","codec","array_to_array","array_to_bytes","bytes_to_bytes","chunk_meta","Codec","MAX_BIG_UINT","create_sharded_chunk_getter","location","shard_shape","encode_shard_key","sharding_config","store","get_range","bind","index_shape","d","chunk_shape","index_codec","index_codecs","chunk_coord","shard_coord","shard_path","checksum_size","index_size","linear_offset","acc","sel","Location","Group","metadata","super","attrs","attributes","get_array_order","maybe_transpose_codec","CONTEXT_MARKER","get_context","fill_value","shared_context","encode_chunk_key","chunk_key_encoding","native_order","get_strides","get_chunk_bytes","chunk_grid","chunk_coords","chunk_key","chunk_path","create_context","dtype","context","maybe_bytes","is","query","IndexError","msg","IntDimIndexer","dim_sel","dim_len","dim_chunk_len","nitems","trunc","err_boundscheck","normalize_integer_selection","dim_chunk_ix","dim_offset","dim_chunk_sel","SliceDimIndexer","stop","step","nchunks","err_negative_step","ceil","dim_chunk_ix_from","dim_chunk_ix_to","dim_limit","dim_out_offset","dim_chunk_sel_start","remainder","dim_chunk_sel_stop","dim_out_sel","BasicIndexer","dim_indexers","selection","normalized","err_too_many_indices","check_selection_length","normalize_selection","ixr","sixr","dim_projections","p","mapping","to","object_array_view","subarray","compat_chunk","globalThis","setter","prepare","set_scalar","dest","set_scalar_binary","get_typed_array_constructor","compat_scalar","set_from_chunk","projections","set_from_chunk_binary","indexer","create_queue","onIdle","unwrap","indices_len","out_selection","slices","curr_stride","len","proj","projs","dstride","dstrides","sstride","sstrides","sfrom","sstep","product","iterables","iterators","it","results","next","r","done","slice_indices","step_is_negative","lower","upper","fn","all","VERSION_COUNTER","version_counts","WeakMap","get_counts","counts","v2","v3","increment","version","version_max","create_version_counter","open_array_v2","cause","open_group_v2","open","open_primary","open_secondary","err","loc","meta_bytes","load_attrs","node","meta_doc","node_type","_open_v3","BoolArray","ArrayBuffer","ByteStringArray","_data","values","encoded","UnicodeStringArray","Int32Array","str","String","fromCodePoint","codePointAt","json_decode_object","parse","byteswap_inplace","numFlips","endByteIndex","j","get_ctr","match","ctr","int8","Int8Array","int16","Int16Array","int32","int64","BigInt64Array","uint8","uint16","Uint16Array","uint32","uint64","BigUint64Array","float16","Float16Array","float32","Float32Array","float64","Float64Array","bool","assert","create_chunk_key_encoder","separator","v2_to_v3_array_metadata","rest","b1","i1","u1","i2","u2","i4","u4","i8","u8","f2","f4","f8","startsWith","coerce_dtype","id","filters","compressor","zarr_format","dimension_separator","v2_to_v3_group_metadata","is_dtype","is_boolean","is_string","is_bigint","is_object","is_sharding_codec","ensure_correct_scalar","BigInt","rethrow_unless","error","errors","ErrorClass","expression"],"sourceRoot":""}