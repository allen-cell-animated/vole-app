{"version":3,"file":"214.bundle.js","mappings":"iKAUO,SAASA,EAAWC,GACzB,OAAO,IAAI,MAAQA,EAAWC,MAAM,GAAID,EAAWC,MAAM,GAAID,EAAWC,MAAM,GAChF,CCVO,SAASC,IACd,MAAO,CACLC,KAAM,GACNC,cAAe,CAAC,EAAG,GACnBC,cAAe,CAAC,EAAG,EAAG,GACtBC,gBAAiB,CAAC,EAAG,EAAG,GACxBC,qBAAsB,CAAC,GACvBC,aAAc,CAAC,KACfC,cAAe,CAAC,CAAC,IAAK,IAAK,MAC3BC,gBAAiB,EACjBC,oBAAqB,CAAC,CACpBV,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBW,QAAS,CAAC,EAAG,EAAG,EAAG,EAAG,GACtBC,UAAW,GACXC,SAAU,GACVC,SAAU,UAEZC,UAAW,CACTC,YAAa,CAAC,EAAG,EAAG,GACpBC,SAAU,CAAC,EAAG,EAAG,GACjBC,MAAO,CAAC,EAAG,EAAG,IAGpB,CACO,MAAMC,EACX,WAAAC,CAAYC,GACVC,KAAKD,UAAYA,GAzBZ,CACLnB,KAAM,GACNC,cAAe,CAAC,EAAG,GACnBC,cAAe,CAAC,EAAG,EAAG,GACtBC,gBAAiB,CAAC,EAAG,EAAG,GACxBC,qBAAsB,CAAC,GACvBC,aAAc,CAAC,KACfC,cAAe,CAAC,CAAC,IAAK,IAAK,MAC3BC,gBAAiB,EACjBC,oBAAqB,CAAC,CACpBV,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBW,QAAS,CAAC,EAAG,EAAG,EAAG,EAAG,GACtBC,UAAW,GACXC,SAAU,GACVC,SAAU,UAEZC,UAAW,CACTC,YAAa,CAAC,EAAG,EAAG,GACpBC,SAAU,CAAC,EAAG,EAAG,GACjBC,MAAO,CAAC,EAAG,EAAG,IAOlB,CACA,oBAAIK,GACF,OAAOD,KAAKD,UAAUX,oBAAoBY,KAAKD,UAAUZ,gBAC3D,CAGA,eAAIe,GACF,OAAOF,KAAKD,UAAUf,qBAAqBmB,QAAO,CAACC,EAAGC,IAAMD,EAAIC,GAAG,EACrE,CAGA,wBAAIrB,GACF,OAAOgB,KAAKD,UAAUf,oBACxB,CAGA,gBAAIsB,GACF,OAAO9B,EAAWwB,KAAKD,UAAUX,oBAAoB,GACvD,CAGA,cAAIZ,GACF,OAAOA,EAAWwB,KAAKC,iBACzB,CAGA,qBAAIM,GACF,OD3C8B9B,EC2CLuB,KAAKD,UAAUX,oBAAoB,GD1CvD,IAAI,MAAQX,EAAWY,QAAQ,GAAIZ,EAAWY,QAAQ,GAAIZ,EAAWY,QAAQ,IAD/E,IAA2BZ,CC4ChC,CAGA,eAAI+B,GACF,OAAOR,KAAKD,UAAUX,oBAAoB,GAAGE,SAC/C,CAGA,SAAImB,GAEF,OAAOT,KAAKC,iBAAiBvB,MAAM,EACrC,CAGA,aAAIgC,GAEF,OAAOV,KAAKC,iBAAiBZ,QAAQ,EACvC,CAGA,YAAIE,GACF,OAAOS,KAAKC,iBAAiBV,QAC/B,CAGA,uBAAIoB,GACF,OAAOX,KAAKD,UAAUX,oBAAoBwB,MAC5C,CAGA,gBAAI3B,GACF,OAAOe,KAAKD,UAAUd,YACxB,CAGA,iBAAIC,GACF,OAAOc,KAAKD,UAAUb,aACxB,CAGA,iBAAIJ,GACF,OAAO,IAAI,SAAWkB,KAAKD,UAAUjB,cACvC,CAGA,mBAAIC,GACF,OAAO,IAAI,SAAWiB,KAAKD,UAAUhB,gBACvC,CACA,mBAAII,GACF,OAAOa,KAAKD,UAAUZ,eACxB,CAMA,iBAAIN,GACF,OAAO,IAAI,SAAWmB,KAAKD,UAAUlB,cACvC,CACA,aAAIY,GACF,MAAO,CACLC,YAAa,IAAI,SAAWM,KAAKD,UAAUN,UAAUC,aACrDC,SAAU,IAAI,SAAWK,KAAKD,UAAUN,UAAUE,UAClDC,MAAO,IAAI,SAAWI,KAAKD,UAAUN,UAAUG,OAEnD,EAEK,SAASiB,EAAiBd,GAC/B,MAAM,cACJlB,GACEkB,EACEe,EAAUf,EAAUX,oBAAoBW,EAAUZ,iBAExD,MAAO,CAACN,EAAc,GAAKiC,EAAQpC,MAAM,GAAIG,EAAc,GAAKiC,EAAQpC,MAAM,GAChF,C,2EC9HO,IAAIqC,EAAmC,SAAUA,GAOtD,OANAA,EAA6B,QAAI,UACjCA,EAA+B,UAAI,YACnCA,EAA+B,UAAI,YACnCA,EAAsC,iBAAI,mBAC1CA,EAAsC,iBAAI,mBAC1CA,EAA+C,0BAAI,4BAC5CA,CACT,CAR8C,CAQ5C,CAAC,GACI,MAAMC,UAAwBC,MACnC,WAAAnB,CAAYoB,EAASC,GACnBC,MAAMF,EAASC,GACfnB,KAAKpB,KAAO,kBACZoB,KAAKqB,KAAOF,GAASE,MAAQN,EAAoBO,OACnD,EAUK,SAASC,EAAoBL,EAAU,mDAAoDG,EAAON,EAAoBO,QAASE,GACpI,OAAOC,IACL,QAAeC,IAAXF,GAAwBC,IAAMD,EAChC,OAAOC,EAET,GAAIA,aAAaT,EACf,MAAMS,EAGR,MADAE,QAAQC,IAAI,8BAA8BH,KACpC,IAAIT,EAAgBE,EAAS,CACjCG,OACAQ,MAAOJ,GACP,CAEN,CAnBA,IAAkBK,IAAI,oBAAqB,KAC3C,IAAkBA,IAAI,WAAY,KAClC,IAAkBA,IAAI,kBAAmBd,E,kCC1BzC,MAAMe,EAAWC,GAAOA,EAAIC,OAAMC,GAAKA,IAAMF,EAAI,KAC3CG,EAAQ,CAACH,EAAKI,EAAKC,KACvB,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAGC,IACrBN,EAAIO,KAAKH,EACX,EAEII,EAAmBC,IACvB,MAAMC,EAASD,GAAO,EACtB,OAAOC,EAASC,OAAkB,IAAXD,EAAa,EAEtC,SAASE,EAAaR,EAAKS,GACrBT,EAAMS,EAAO,KACfA,EAAO,GAAKT,GAEVA,EAAMS,EAAO,KACfA,EAAO,GAAKT,EAEhB,CAQe,MAAMU,EACnB,WAAAhD,CAAYiD,EAAQC,EAAuBC,EAAsBC,EAAoBC,GAAyB,GAE5G,MAAMC,EAAU,CAAC,CAACC,KAAU,KAAY,CAACA,KAAU,KAAY,CAACA,KAAU,KAAY,CAACA,KAAU,MACjG,IAAK,MAAMC,KAASP,EAClBH,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAIjC,GAAIA,EAAQG,OAAOC,MAAKpB,IAAQO,OAAOc,SAASrB,KAG9C,OAFApC,KAAK0D,gBAAkB,QACvB1D,KAAK2D,wBAA0B,IAKjC3D,KAAK0D,gBAAkB,GACvB1D,KAAK2D,wBAA0B,GAK/B,IAAK,MAAOC,EAAWC,KAAUT,EAAQG,OAAOO,UAAW,CACzD,MAAMC,EAAYH,GAAa,EACzBI,EAAaD,EAAYpB,OAAqB,IAAdoB,GACtC,IAAIE,EACJ,GAAgB,EAAZL,EAAe,CAGjB,MAAMM,EAAgBjB,EAAqBkB,KAAIC,GACtCC,KAAKC,IAAIT,EAAQb,EAAsBe,GAAYK,EAAUJ,GAAc,KAIpF,GAAIjC,EAASmC,GACXD,EAAMC,EAAc,OACf,CAELD,EAAM,GACN,IAAK,MAAO3B,EAAGiC,KAAcL,EAAcJ,UACzC3B,EAAM8B,EAAKM,EAAWtB,EAAqBX,GAAG,GAElD,CAEF,MAGE2B,EAAMI,KAAKG,IAAIX,EAAQb,EAAsBe,GAAY,GAE3D,MAAMU,EAAiB,CACrBb,YACAC,QACAI,MACAlB,OAAQ,IAENG,GAAsBA,EAAmBwB,SAASd,GACpD5D,KAAK2D,wBAAwBpB,KAAKkC,GAG7BtB,GACHnD,KAAK0D,gBAAgBnB,KAAKkC,EAGhC,CAGA,IAAK,MAAMnB,KAASP,EAAQ,CAC1B,IAAK,MAAMN,KAAOzC,KAAK0D,gBACjBJ,EAAMd,EAAiBC,EAAImB,cAAgBnB,EAAIoB,OACjDpB,EAAIM,OAAOR,KAAKe,GAGpB,IAAK,MAAMb,KAAOzC,KAAK2D,wBACjBL,EAAMd,EAAiBC,EAAImB,cAAgBnB,EAAIoB,OACjDpB,EAAIM,OAAOR,KAAKe,EAGtB,CACF,CACA,wBAAQqB,CAAkBC,GACxB,IAAIC,EAAS,EACb,KAAOD,EAAWhE,OAAS,GAAG,CAE5BgE,EAAaA,EAAWE,QAAOrC,IAC7B,MAAMwB,EAAMc,MAAMC,QAAQvC,EAAIwB,KAAOI,KAAKG,OAAO/B,EAAIwB,KAAOxB,EAAIwB,IAChE,OAAoB,EAAhBxB,EAAImB,UACCnB,EAAIoB,MAAQgB,GAAUZ,EAEtBxB,EAAIoB,MAAQgB,GAAUZ,CAC/B,IAIF,IAAK,MAAMxB,KAAOmC,EAAY,CAC5B,MAAMK,EAAYJ,GAA0B,EAAhBpC,EAAImB,UAAgB,GAAK,GACrD,IAAK,MAAMN,KAASb,EAAIM,OAAQ,CAE9B,GAAIgC,MAAMC,QAAQvC,EAAIwB,MAAQX,EAAMd,EAAiBC,EAAImB,YAAcqB,EAAYxC,EAAIwB,IAAIX,EAAM,IAC/F,SAEF,MAAM4B,EAAW5B,EAAM6B,QACvBD,EAAS1C,EAAiBC,EAAImB,aAAeqB,QACvCC,CACR,CACF,CACAL,GAAU,CACZ,CACF,CACA,EAAEO,OAAOC,YAEP,GAAIrF,KAAK2D,wBAAwB/C,OAAS,EACxC,IAAK,MAAM0C,KAASR,EAAsB6B,kBAAkB3E,KAAK2D,+BACzDL,EAKV,IAAK,MAAMA,KAASR,EAAsB6B,kBAAkB3E,KAAK0D,uBACzDJ,CAEV,E,6FC9IK,SAASgC,EAAcC,GAC5B,QAAc7D,IAAV6D,EACF,OAEF,MAAMC,EAAS,qDAAqDC,KAAKF,GACzE,OAAIC,EACK,CAACE,SAASF,EAAO,GAAI,IAAKE,SAASF,EAAO,GAAI,IAAKE,SAASF,EAAO,GAAI,UAE9E,CAEJ,CAGO,SAASG,EAAqBC,GACnC,GAAIA,EAAIC,eAAeC,SAAU,CAC/B,MAAM,SACJA,GACEF,EAAIC,cACFE,EAAQ,GACRC,EAAS,GACf,IAAK,IAAI1D,EAAI,EAAGA,EAAIwD,EAASlF,OAAQ0B,IAAK,CACxC,MAAM2D,EAAUH,EAASxD,GACzByD,EAAMxD,KAAK0D,EAAQC,OAAS,WAAW5D,EAAIsD,EAAIO,iBAC/CH,EAAOzD,KAAK+C,EAAcW,EAAQV,OACpC,CACA,MAAO,CACLQ,QACAC,SAEJ,CACA,MAAMI,EAAOR,EAAIS,UAAU,GACrBzF,EAASwF,EAAO,EAAI,EAAIR,EAAIU,YAAY,GAAG5H,MAAM0H,GAOvD,MAAO,CACLL,MAPYhB,MAAMwB,KAAK,CACvB3F,WACC,CAAC4F,EAAGC,IAAQ,WAAWA,EAAMb,EAAIO,kBAMlCH,OALajB,MAAMwB,KAAK,CACxB3F,WACC,KAAe,IAKpB,CAGO,MAAM8F,EAAoB,EAAEC,EAAGC,EAAGC,KAAO,EAAIlE,OAAOgE,GAAK,GAAKhE,OAAOiE,GAAK,GAAKjE,OAAOkE,GAAK,GAC3F,SAASC,EAAiBC,GAC/B,MAAMV,EAAY,EAAE,GAAI,GAAI,GAAI,GAAI,GAC9BW,EAAY,CAAC,IAAK,IAAK,IAAK,IAAK,KACvCD,EAAKE,SAAQ,CAACC,EAAMT,KAClB,MAAMU,EAAUH,EAAUI,QAAQF,EAAKtI,MACvC,KAAIuI,GAAW,GAGb,MAAM,IAAI,KAAgB,8BAA8BD,EAAKtI,OAAQ,CACnEyC,KAAM,KAAoBgG,mBAH5BhB,EAAUc,GAAWV,CAKvB,IAIF,MAAMa,GAA4B,IAAlBjB,EAAU,GAC1B,GAAIiB,IAA6B,IAAlBjB,EAAU,GACvB,MAAM,IAAI,KAAgB,gBAAgBiB,EAAU,OAAS,qBAAsB,CACjFjG,KAAM,KAAoBgG,mBAG9B,OAAOhB,CACT,CAGO,SAASkB,EAAiBC,EAAWC,GAC1C,MAAMC,EAAUhB,EAAkBe,GAC5BjC,EAAST,MAAM2C,GAWrB,OAVAD,EAAWR,SAAQ,CAAC7E,EAAKqE,KACvB,GAAIrE,GAAO,EAAG,CACZ,GAAIA,GAAOsF,EACT,MAAM,IAAI,KAAgB,kCAAkCtF,IAAO,CACjEf,KAAM,KAAoBgG,mBAG9B7B,EAAOpD,GAAOoF,EAAUf,EAC1B,KAEKjB,CACT,CAGO,SAASmC,EAAaC,EAAeH,EAAYI,GACtD,MAAMrC,EAAS,CAACqC,EAAcA,EAAcA,EAAcA,EAAcA,GAWxE,OAVAJ,EAAWR,SAAQ,CAAC7E,EAAKqE,KACvB,GAAIrE,GAAO,EAAG,CACZ,GAAIA,GAAOwF,EAAchH,OACvB,MAAM,IAAI,KAAgB,kCAAkCwB,IAAO,CACjEf,KAAM,KAAoBgG,mBAG9B7B,EAAOiB,GAAOmB,EAAcxF,EAC9B,KAEKoD,CACT,CAGO,SAASsC,EAASC,EAASN,GAChC,MAAMO,EAAaD,EAAQE,0BAC3B,QAAmBvG,IAAfsG,EAEF,OADArG,QAAQuG,KAAK,0EACN,CAAC,EAAG,EAAG,EAAG,EAAG,GAItB,MAIMC,EAAiBH,EAAWI,MAJTzB,GAAgB,UAAXA,EAAEtF,OAKhC,OAAK8G,EAKER,EADOQ,EAAevI,MAAMuF,QACRsC,EAAY,IAJrC9F,QAAQuG,KAAK,yFACN,CAAC,EAAG,EAAG,EAAG,EAAG,GAIxB,CAQA,SAASG,EAAqBC,EAAMC,EAAQC,EAAMC,GAChD,MAEMC,GAFKH,EAAO,IAAM,EAAID,EAAK5J,MAAM6J,EAAO,IAAM,IACzCE,EAAO,IAAM,EAAID,EAAK9J,MAAM+J,EAAO,IAAM,GAE9CE,EAAQL,EAAK5J,MAAM6J,EAAO,IAAMC,EAAK9J,MAAM+J,EAAO,IAClDG,EAAQN,EAAK5J,MAAM6J,EAAO,IAAMC,EAAK9J,MAAM+J,EAAO,IACxD,OAAc,IAAVC,GAAyB,IAAVC,GAAyB,IAAVC,EACzB,EACEF,GAAS,GAAKC,GAAS,GAAKC,GAAS,GACtC,EACCF,GAAS,GAAKC,GAAS,GAAKC,GAAS,EACvC,OAEP,CAEJ,CACA,MACMC,EAAc,CAACzI,EAAGC,IAAMgE,KAAKyE,IAAI1I,EAAIC,GAD3B,KAEhB,SAAS0I,EAAwBC,EAAMC,EAAQC,EAAMC,GACnD,MAAMC,EAAStB,EAASkB,EAAKK,mBAAmBC,SAASL,GAASD,EAAK3C,WACjEkD,EAASzB,EAASoB,EAAKG,mBAAmBC,SAASH,GAASD,EAAK7C,WACvE,OAAOwC,EAAYO,EAAO,GAAIG,EAAO,KAAOV,EAAYO,EAAO,GAAIG,EAAO,KAAOV,EAAYO,EAAO,GAAIG,EAAO,GACjH,CAYO,SAASC,EAAuBC,GACrC,GAAIA,EAAQ7I,OAAS,EACnB,OAIF,MAAM8I,EAAgB3E,MAAMwB,KAAK,CAC/B3F,OAAQ6I,EAAQ7I,SACf,IAAM,KACH+I,EAAe5E,MAAMwB,KAAK,CAC9B3F,OAAQ6I,EAAQ7I,SACf,IAAM,KAGHgJ,EAAe,IAAI7E,MAAM0E,EAAQ7I,QAAQiJ,KAAK,GACpD,KAAOD,EAAa3H,OAAM,CAACG,EAAKqE,IAAQrE,EAAMqH,EAAQhD,GAAKH,YAAY1F,UAAS,CAE9E,IAAImB,GAAW,EACX+H,EAAc,EACdC,EAAcN,EAAQ,GACtBO,EAAcD,EAAYzD,YAAYsD,EAAa,IACvD,IAAK,IAAIK,EAAa,EAAGA,EAAaR,EAAQ7I,OAAQqJ,IAAc,CAClE,MAAMC,EAAaT,EAAQQ,GACrBE,EAAaD,EAAW5D,YAAYsD,EAAaK,IACjDG,EAAW/B,EAAqB2B,EAAaD,EAAY1D,UAAW8D,EAAYD,EAAW7D,WACjG,GAAK+D,EA0BHrI,GAAW,EACPqI,EAAW,IACbN,EAAcG,EACdF,EAAcG,EACdF,EAAcG,OA9BH,CAEb,QAAiBzI,IAAb0I,EACF,MAAM,IAAI,KAAgB,4DAA6D,CACrF/I,KAAM,KAAoBgJ,4BAMzBtB,EAAwBgB,EAAaH,EAAaE,GAAcI,EAAYN,EAAaK,KAI5FtI,QAAQuG,KAAK,6FAIf,MAAMoC,EAAWP,EAAY1D,UAAU,IAAM,EAAI2D,EAAYtL,MAAMqL,EAAY1D,UAAU,IAAM,EACzFkE,EAAWL,EAAW7D,UAAU,IAAM,EAAI8D,EAAWzL,MAAMwL,EAAW7D,UAAU,IAAM,EACxFiE,IAAaC,GAGf5I,QAAQuG,KAAK,6DAA6DoC,QAAeC,IAE7F,CAQF,CACA,GAAIxI,EAEF,IAAK,IAAIO,EAAI,EAAGA,EAAIsH,EAAahJ,OAAQ0B,IAAK,CAC5C,MAAM4H,EAAaT,EAAQnH,GACrBkI,EAAoBZ,EAAatH,GACvCoH,EAAcpH,GAAGC,KAAK2H,EAAW5D,YAAYkE,IAC7Cb,EAAarH,GAAGC,KAAK2H,EAAWb,mBAAmBC,SAASkB,IAC5DZ,EAAatH,IAAM,CACrB,MAGA,IAAK,MAAOmE,EAAKgE,KAAWb,EAAa9F,UAAW,CAClD,MAAMoG,EAAaT,EAAQhD,GACrB0D,EAAaD,EAAW5D,YAAYmE,GAEzB,IADApC,EAAqB2B,EAAaD,EAAY1D,UAAW8D,EAAYD,EAAW7D,aAE/FuD,EAAanD,IAAQ,EAEzB,CAEJ,CACA,GAAsC,IAAlCgD,EAAQ,GAAGnD,YAAY1F,OACzB,MAAM,IAAI,KAAgB,sFAAuF,CAC/GS,KAAM,KAAoBgJ,4BAG9B,IAAK,IAAI/H,EAAI,EAAGA,EAAImH,EAAQ7I,OAAQ0B,IAClCmH,EAAQnH,GAAGgE,YAAcoD,EAAcpH,GACvCmH,EAAQnH,GAAG+G,mBAAmBC,SAAWK,EAAarH,EAE1D,C,kEC7PO,MAAMoI,EAAkBC,GAAQA,EAAKC,KAAOD,EACnD,SAASE,EAAiBC,EAAKC,GAC7B,MAAsB,iBAARD,GAA4B,OAARA,GAAgBC,KAAQD,CAC5D,CACA,SAASE,EAAsBF,EAAKC,EAAMnM,EAAO,QAC/C,IAAKiM,EAAiBC,EAAKC,GACzB,MAAM,IAAI,KAAgB,GAAGnM,yCAA4CmM,KAAS,CAChF1J,KAAM,KAAoBgG,kBAGhC,CACA,SAAS4D,EAAkBH,EAAKC,EAAMnM,EAAO,QAC3C,IAAKmG,MAAMC,QAAQ8F,EAAIC,IACrB,MAAM,IAAI,KAAgB,GAAGnM,qBAAwBmM,qBAAyB,CAC5E1J,KAAM,KAAoBgG,kBAGhC,CAIO,SAAS6D,EAA6BP,EAAM/L,EAAO,QAExDoM,EAAsBL,EAAM,cAAe/L,GAC3CqM,EAAkBN,EAAM,cAAe/L,EACzC,CAOO,SAASuM,EAAwBR,EAAMS,EAAgB,EAAGxM,EAAO,QAEtE,MAAMyM,EAAiBV,EAAKW,YAAYF,GACxC,IAAKC,EACH,MAAM,IAAI,KAAgB,GAAGzM,uDAA0DwM,IAAiB,CACtG/J,KAAM,KAAoBgG,mBAG9B,MACMkE,EAAiB,GAAG3M,gBAAmBwM,IADlBP,EAAiBQ,EAAgB,QAAU,MAAMA,EAAezM,QAAU,KAIrGoM,EAAsBK,EAAgB,OAAQE,GAC9CN,EAAkBI,EAAgB,OAAQE,GAC1CF,EAAetE,KAAKE,SAAQ,CAACC,EAAM5E,IAAM0I,EAAsB9D,EAAM,OAAQ,GAAGqE,UAAuBjJ,OAGvG0I,EAAsBK,EAAgB,WAAYzM,GAClDqM,EAAkBI,EAAgB,WAAYzM,GAC9CyM,EAAe/B,SAASrC,SAAQ,CAACuE,EAAMlJ,IAAM0I,EAAsBQ,EAAM,OAAQ,GAAGD,aAA0BjJ,MAChH,C,iBC1CO,SAASmJ,EAAYC,EAAK7G,EAAQjE,EAAQ+K,EAAO,CAAC,GAWrD,YAVejK,IAAXmD,QAAmCnD,IAAXd,IAExB+K,EAAO,IACAA,EACHC,QAAS,IACFD,EAAKC,QACRC,MAAO,SAAShH,KAAUA,EAASjE,EAAS,OAIjDkL,MAAMJ,EAAKC,EACtB,CC5BA,SAASI,EAAQC,EAAMC,GACnB,MAAMC,EAAuB,iBAATF,EAAoB,IAAIG,IAAIH,GAAQA,EACnDE,EAAKE,SAASC,SAAS,OAExBH,EAAKE,UAAY,KAErB,MAAME,EAAW,IAAIH,IAAIF,EAAK9G,MAAM,GAAI+G,GAGxC,OADAI,EAASC,OAASL,EAAKK,OAChBD,CACX,CACAE,eAAeC,EAAgBC,GAC3B,GAAwB,MAApBA,EAASC,OAAb,CAGA,GAAwB,MAApBD,EAASC,QAAsC,MAApBD,EAASC,OACpC,OAAO,IAAIC,iBAAiBF,EAASG,eAEzC,MAAM,IAAI5L,MAAM,8BAA8ByL,EAASC,UAAUD,EAASI,aAJ1E,CAKJ,C,yBAyDA,QA9BA,MACIpB,IACA,GACA,GACA,WAAA5L,CAAY4L,EAAKvK,EAAU,CAAC,GACxBnB,KAAK0L,IAAMA,EACX1L,MAAK,EAAamB,EAAQ4L,WAAa,CAAC,EACxC/M,MAAK,EAAsBmB,EAAQ6L,mBAAoB,CAC3D,CACA,GAAYD,GACR,OD3BmBE,EC2BDjN,MAAK,ED3BYkN,EC2BAH,EDzBhC,IACAE,KACAC,EACHtB,QAAS,IACFqB,EAAerB,WACfsB,EAAiBtB,UAPzB,IAAoBqB,EAAgBC,CC4BvC,CACA,SAAMC,CAAIC,EAAKjM,EAAU,CAAC,GACtB,IAAIkM,EAAOtB,EAAQ/L,KAAK0L,IAAK0B,GAAKC,KAElC,OAAOZ,QADcX,MAAMuB,EAAMrN,MAAK,EAAYmB,IAEtD,CACA,cAAMmM,CAASF,EAAKG,EAAOpM,EAAU,CAAC,GAClC,IAEIuL,EAFAhB,EAAMK,EAAQ/L,KAAK0L,IAAK0B,GACxBI,EAAOxN,MAAK,EAAYmB,GAQ5B,OALIuL,EADA,iBAAkBa,QA/C9Bf,eAA4Bd,EAAK+B,EAAeD,EAAME,GAClD,GAAIA,EACA,OAAO5B,MAAMJ,EAAK,IACX8B,EACH5B,QAAS,IAAK4B,EAAK5B,QAASC,MAAO,UAAU4B,OAGrD,IAAIf,QAAiBZ,MAAMJ,EAAK,IAAK8B,EAAMG,OAAQ,SACnD,IAAKjB,EAASkB,GAEV,OAAOlB,EAEX,IAAImB,EAAiBnB,EAASd,QAAQuB,IAAI,kBACtCvM,EAAS+B,OAAOkL,GACpB,OAAOpC,EAAYC,EAAK9K,EAAS6M,EAAe7M,EAAQ4M,EAC5D,CAiC6BM,CAAapC,EAAK6B,EAAMQ,aAAcP,EAAMxN,MAAK,SAGjDyL,EAAYC,EAAK6B,EAAM1I,OAAQ0I,EAAM3M,OAAQ4M,GAE3Df,EAAgBC,EAC3B,G,aCzEW,SAASsB,EAAUC,EAAOC,EAAUC,EAAOC,GACxD,MACMC,GADOH,EAAS7B,SAAS,KAAO6B,EAAS/I,MAAM,GAAI,GAAK+I,GACvCD,EAAMhC,MAAQgC,EAAMhC,KAAKI,SAAS,KAAO,GAAK,KAC/DiC,EAAW9B,MAAO+B,EAAQ5C,KAC1BA,GAAM6C,YAAc7C,EAAK8C,aAC3B9C,EAAK8C,YAAYF,EAAQ5C,EAAK6C,YAEhC,MAAME,EAAUL,EAAUE,EAAOI,KAAK,KAChCC,EAAcT,GAAOhB,IAAIuB,GAC/B,GAAIE,IAAe,OAAQA,GACzB,OAAOA,EAET,IAAIpJ,EAOJ,OALEA,EADE4I,GAASzC,GAAM6C,iBACFJ,EAAMS,WAAWH,EAAS/C,GAAM6C,YAAY,IAAMP,EAAMK,SAASC,EAAQ5C,IAAOA,EAAKmD,kBAErFb,EAAMK,SAASC,EAAQ5C,GAExCwC,GAAOY,OAAOL,EAASlJ,GAChBA,CAAM,EAEf,OAAO,IAAIwJ,MAAMf,EAAO,CACtBd,IAAK,CAAC8B,EAAQlE,KACZ,GAAa,aAATA,EACF,OAAOuD,EAIT,MAAMY,EAAQD,EAAOlE,GACrB,OAAImE,aAAiBC,SACZ,YAAaC,GAClB,OAAOF,EAAMG,MAAMJ,EAAQG,EAC7B,EAEKF,CAAK,GAGlB,CACO,MAAMI,UAA0B,EACrC,WAAAxP,CAAYyP,EAASpO,GACnBC,MAAMmO,EAASpO,EACjB,CAIA,SAAMgM,CAAIC,EAAKjM,EAAU,CAAC,GACxB,IACE,aAAaC,MAAM+L,IAAIC,EAAKjM,EAE9B,CAAE,MAAOM,GACP,GAAIA,GAAGP,SAASsO,WAAW,kCACzB,OAEF,MAAM/N,CACR,CACF,E,kCCvDK,MAAMgO,EAAgC,oBAW9B,MAAMC,EA0BnB,WAAA5P,CAAY6P,EAAoB,GAAIC,EAAyB,GAC3D5P,KAAK6P,YAAc,IAAIC,IACvB9P,KAAK+P,eAAiB,IAAIC,IAC1BhQ,KAAKoO,MAAQ,GACbpO,KAAKiQ,iBAAmB,GACxBjQ,KAAK2P,kBAAoBA,EACzB3P,KAAK4P,uBAAyBvL,KAAKC,IAAIqL,EAAmBC,EAC5D,CAQA,eAAAM,CAAgB9C,EAAK+C,GAInB,IAAIC,EAAgBC,EACpB,MAAMC,EAAU,IAAIC,SAAQ,CAACxE,EAASyE,KACpCJ,EAAiBrE,EACjBsE,EAAgBG,CAAM,IAGlBC,EAAc,CAClBrD,IAAKA,EACLsD,OAAQP,EACRpE,QAASqE,EACTI,OAAQH,EACRC,WAGF,OADAtQ,KAAK6P,YAAY/N,IAAIsL,EAAKqD,GACnBA,CACT,CAOA,iBAAAE,CAAkBvD,EAAKwD,GAErB,GAAI5Q,KAAK6P,YAAYgB,IAAIzD,GAAM,CAE7B,MAAMqD,EAAczQ,KAAK6P,YAAY1C,IAAIC,GACrCqD,GAAeA,EAAYK,YAC7BC,aAAaN,EAAYK,WACzBL,EAAYK,eAAYpP,GAErB1B,KAAKoO,MAAM1J,SAAS0I,IAASpN,KAAKiQ,iBAAiBvL,SAAS0I,KAE3DwD,EACF5Q,KAAKiQ,iBAAiB1N,KAAK6K,GAE3BpN,KAAKoO,MAAM7L,KAAK6K,GAElBpN,KAAKgR,UAET,CACF,CAoBA,UAAAnC,CAAWzB,EAAK+C,EAAeS,GAAc,EAAOK,EAAU,GAC5D,GAAKjR,KAAK6P,YAAYgB,IAAIzD,GAYnB,CACL,MAAM8D,EAAmBlR,KAAKiQ,iBAAiB7I,QAAQgG,GACnD8D,GAAoB,IAAMN,GAG5B5Q,KAAKiQ,iBAAiBkB,OAAOD,EAAkB,GAC/ClR,KAAK2Q,kBAAkBvD,IACd6D,GAAW,GAGpBjR,KAAK2Q,kBAAkBvD,EAAKwD,EAEhC,KAxBgC,CAE9B,MAAMH,EAAczQ,KAAKkQ,gBAAgB9C,EAAK+C,GAE9C,GAAIc,EAAU,EAAG,CACf,MAAMH,EAAYM,YAAW,IAAMpR,KAAK2Q,kBAAkBvD,EAAKwD,IAAcK,GAE7ER,EAAYK,UAAYA,CAC1B,MAEE9Q,KAAK2Q,kBAAkBvD,EAAKwD,EAEhC,CAaA,MAAMN,EAAUtQ,KAAK6P,YAAY1C,IAAIC,IAAMkD,QAC3C,IAAKA,EACH,MAAM,IAAIrP,MAAM,gEAElB,OAAOqP,CACT,CAaA,WAAAe,CAAYC,EAAUV,GAAc,EAAOK,EAAU,IACnD,MAAMM,EAAW,GACjB,IAAK,IAAIjP,EAAI,EAAGA,EAAIgP,EAAS1Q,OAAQ0B,IAAK,CACxC,MAAMkP,EAAOF,EAAShP,GAChBgO,EAAUtQ,KAAK6O,WAAW2C,EAAKpE,IAAKoE,EAAKrB,cAAeS,EAAaK,EAAU3O,GACrFiP,EAAShP,KAAK+N,EAChB,CACA,OAAOiB,CACT,CAOA,aAAMP,GACJ,MAAMS,EAAczR,KAAK+P,eAAe2B,KACxC,GAAID,GAAezR,KAAK2P,mBAA2C,IAAtB3P,KAAKoO,MAAMxN,SAAiB6Q,GAAezR,KAAK4P,wBAA2D,IAAjC5P,KAAKiQ,iBAAiBrP,QAC3I,OAEF,MAAM+Q,EAAa3R,KAAKoO,MAAMwD,SAAW5R,KAAKiQ,iBAAiB2B,QAC/D,IAAKD,EACH,OAEF,GAAI3R,KAAK+P,eAAec,IAAIc,GAG1B,YADA3R,KAAKgR,UAGP,MAAMP,EAAczQ,KAAK6P,YAAY1C,IAAIwE,GACzC,IAAKlB,EACH,OAEF,MAAMrD,EAAMqD,EAAYrD,IAExBpN,KAAK+P,eAAe8B,IAAIzE,SAClBqD,EAAYC,SAASoB,KAAKrB,EAAY1E,QAAS0E,EAAYD,QACjExQ,KAAK+P,eAAegC,OAAO3E,GAC3BpN,KAAK6P,YAAYkC,OAAO3E,GACxBpN,KAAKgR,SACP,CAOA,aAAAgB,CAAc5E,EAAK6E,EAAexC,GAChC,IAAKzP,KAAK6P,YAAYgB,IAAIzD,GACxB,OAEF,MAAMqD,EAAczQ,KAAK6P,YAAY1C,IAAIC,GACrCqD,IACEA,EAAYK,WAEdC,aAAaN,EAAYK,WAG3BL,EAAYD,OAAOyB,IAErB,MAAMC,EAAalS,KAAKoO,MAAMhH,QAAQgG,GACtC,GAAI8E,GAAc,EAChBlS,KAAKoO,MAAM+C,OAAOe,EAAY,OACzB,CACL,MAAMhB,EAAmBlR,KAAKiQ,iBAAiB7I,QAAQgG,GACnD8D,GAAoB,GACtBlR,KAAKiQ,iBAAiBkB,OAAOD,EAAkB,EAEnD,CACAlR,KAAK6P,YAAYkC,OAAO3E,GACxBpN,KAAK+P,eAAegC,OAAO3E,EAC7B,CAMA,iBAAA+E,CAAkBF,EAAexC,GAE/BzP,KAAKoO,MAAQ,GACbpO,KAAKiQ,iBAAmB,GACxB,IAAK,MAAM7C,KAAOpN,KAAK6P,YAAYuC,OACjCpS,KAAKgS,cAAc5E,EAAK6E,EAE5B,CAOA,UAAAI,CAAWjF,GACT,OAAOpN,KAAK6P,YAAYgB,IAAIzD,EAC9B,CAOA,cAAAkF,CAAelF,GACb,OAAOpN,KAAK+P,eAAec,IAAIzD,EACjC,E,gDCjQa,MAAMmF,EAenB,WAAAzS,CAAY6P,EAAmBC,GAE3B5P,KAAKoO,MAD0B,iBAAtBuB,QAAwDjO,IAAtBiO,EAC9B,IAAI,IAAaA,EAAmBC,GAEpCD,EAEf3P,KAAKwS,iBAAmB,EACxBxS,KAAKyS,YAAc,IAAI3C,IACvB9P,KAAKsR,SAAW,IAAIxB,GACtB,CAGA,UAAA4C,CAAWtF,EAAK8B,GACd,MAAMoC,EAAWtR,KAAKsR,SAASnE,IAAIC,GACnC,GAAIkE,EAAU,CACZ,IAAK,MAAM,QACTvF,EAAO,aACP4G,KACGrB,EACHvF,EAAQmD,GACRlP,KAAKyS,YAAYtF,IAAIwF,IAAeZ,OAAO3E,GAE7CpN,KAAKsR,SAASS,OAAO3E,EACvB,CACF,CAGA,SAAAwF,CAAUxF,EAAKyF,GACb,MAAMvB,EAAWtR,KAAKsR,SAASnE,IAAIC,GACnC,GAAIkE,EAAU,CACZ,IAAK,MAAM,OACTd,EAAM,aACNmC,KACGrB,EACHd,EAAOqC,GACP7S,KAAKyS,YAAYtF,IAAIwF,IAAeZ,OAAO3E,GAE7CpN,KAAKsR,SAASS,OAAO3E,EACvB,CACF,CAGA,aAAA0F,GACE,MAAMH,EAAe3S,KAAKwS,iBAG1B,OAFAxS,KAAKwS,mBACLxS,KAAKyS,YAAY3Q,IAAI6Q,EAAc,IAAI7C,KAChC6C,CACT,CAOA,UAAA9D,CAAWzB,EAAKuF,EAAcxC,EAAeS,EAAaK,GAQxD,GANAjR,KAAKoO,MAAMS,WAAWzB,EAAK+C,EAAeS,EAAaK,GAASa,MAAK5C,GAASlP,KAAK0S,WAAWtF,EAAK8B,KAAQ6D,OAAMF,GAAU7S,KAAK4S,UAAUxF,EAAKyF,KAC1I7S,KAAKsR,SAAST,IAAIzD,IACrBpN,KAAKsR,SAASxP,IAAIsL,EAAK,IAIrBuF,GAAgB3S,KAAKwS,kBAAoBG,EAAe,EAC1D,MAAM,IAAI1R,MAAM,2CAA2C0R,6BAG7D,IADmB3S,KAAKyS,YAAYtF,IAAIwF,GAEtC,MAAM,IAAI1R,MAAM,2CAA2C0R,sBAI7D,OAAO,IAAIpC,SAAQ,CAACxE,EAASyE,KAC3BxQ,KAAKsR,SAASnE,IAAIC,IAAM7K,KAAK,CAC3BwJ,UACAyE,SACAmC,iBAEF,MAAMnE,EAAaxO,KAAKyS,YAAYtF,IAAIwF,GAClCK,EAAkBxE,GAAYrB,IAAIC,GACpC4F,EACFA,EAAgBzQ,KAAKiO,GAErBhC,GAAY1M,IAAIsL,EAAK,CAACoD,GACxB,GAEJ,CAMA,kBAAAyC,CAAmB7F,EAAKoD,EAAQyB,GAE9BzB,EAAOyB,GAGP,MAAMiB,EAAgBlT,KAAKsR,SAASnE,IAAIC,GACxC,IAAK8F,EAEH,OAGF,MAAMzM,EAAMyM,EAAcC,WAAUC,GAAOA,EAAI5C,SAAWA,IACtD/J,GAAO,GACTyM,EAAc/B,OAAO1K,EAAK,GAIxByM,EAActS,OAAS,IAAMZ,KAAKoO,MAAMkE,eAAelF,KACzDpN,KAAKoO,MAAM4D,cAAc5E,EAAK6E,GAC9BjS,KAAKsR,SAASS,OAAO3E,GAEzB,CAGA,aAAA4E,CAAc5E,EAAKuF,EAAcV,GAC/B,MAAMzD,EAAaxO,KAAKyS,YAAYtF,IAAIwF,GACxC,IAAKnE,EACH,OAAO,EAET,MAAM6E,EAAY7E,EAAWrB,IAAIC,GACjC,IAAKiG,IAAcA,EAAUzS,OAC3B,OAAO,EAET,IAAK,MAAM4P,KAAU6C,EACnBrT,KAAKiT,mBAAmB7F,EAAKoD,EAAQyB,GAGvC,OADAzD,EAAWuD,OAAO3E,IACX,CACT,CAGA,gBAAAkG,CAAiBX,EAAcV,GAC7B,MAAMiB,EAAgBlT,KAAKyS,YAAYtF,IAAIwF,GAC3C,GAAIO,EAAe,CACjB,IAAK,MAAO9F,EAAKiG,KAAcH,EAAcpP,UAC3C,IAAK,MAAM0M,KAAU6C,EACnBrT,KAAKiT,mBAAmB7F,EAAKoD,EAAQyB,GAGzCjS,KAAKyS,YAAYV,OAAOY,EAC1B,CACF,CAGA,UAAAN,CAAWjF,GACT,OAAOpN,KAAKoO,MAAMiE,WAAWjF,EAC/B,CAGA,cAAAkF,CAAelF,GACb,OAAOpN,KAAKoO,MAAMkE,eAAelF,EACnC,CAGA,aAAAmG,CAAcZ,GACZ,OAAO3S,KAAKyS,YAAY5B,IAAI8B,EAC9B,CAGA,YAAAa,CAAab,EAAcvF,GACzB,OAAOpN,KAAKyS,YAAYtF,IAAIwF,IAAe9B,IAAIzD,KAAQ,CACzD,E,qDCxLK,IAAIqG,EAA6B,SAAUA,GAUhD,OATAA,EAAcA,EAAoB,KAAI,GAAK,OAC3CA,EAAcA,EAA6B,cAAI,GAAK,gBACpDA,EAAcA,EAA4B,aAAI,GAAK,eACnDA,EAAcA,EAA6B,cAAI,GAAK,gBACpDA,EAAcA,EAAyB,UAAI,GAAK,YAChDA,EAAcA,EAAgC,iBAAI,GAAK,mBACvDA,EAAcA,EAAgD,iCAAI,GAAK,mCACvEA,EAAcA,EAAgD,iCAAI,GAAK,mCACvEA,EAAcA,EAAoC,qBAAI,GAAK,uBACpDA,CACT,CAXwC,CAWtC,CAAC,GAOQC,EAAoC,SAAUA,GAIvD,OAHAA,EAAqBA,EAA8B,QAAI,GAAK,UAC5DA,EAAqBA,EAA4B,MAAI,GAAK,QAC1DA,EAAqBA,EAA4B,MAAI,GAAK,QACnDA,CACT,CAL+C,CAK7C,CAAC,GAGQC,EAA+B,SAAUA,GAKlD,OAHAA,EAAgBA,EAAiC,gBAAI,GAAK,kBAE1DA,EAAgBA,EAA8B,aAAI,GAAK,eAChDA,CACT,CAN0C,CAMxC,CAAC,E,gDC/BI,SAASC,EAAgBC,GAC9B,MAAO,IACFA,EACHC,UAAW,IAAI,OAAK,IAAI,OAAUC,KAAKF,EAAKC,UAAUxP,MAAM,IAAI,OAAUyP,KAAKF,EAAKC,UAAUtP,MAElG,C,qFCUO,MAAMwP,EACTC,KAAO,iBACP,WAAAnU,CAAYoU,EAAeC,IACvB,QAAOD,EAAcE,UAAY,EAAG,oCACxC,CACA,iBAAOC,CAAWH,EAAevJ,GAC7B,OAAO,IAAIqJ,EAAcE,EAAevJ,EAC5C,CAKA,MAAA2J,CAAOC,GACH,MAAM,IAAItT,MAAM,iHACpB,CAMA,MAAAuT,CAAOxS,GACH,OAAOA,CACX,ECtCJ,MAAMyS,EACN,WACI,MAAMrU,EAAI,IAAIsU,YAAY,CAAC,YAE3B,QAAkB,KADR,IAAI9H,WAAWxM,EAAEuU,OAAQvU,EAAEwU,WAAYxU,EAAEyU,YACxC,GACf,CALyBC,GAMzB,SAASC,EAAkBC,GACvB,MAAI,sBAAuBA,EAChBA,EAAWC,kBAGf,CACX,CACO,MAAMC,EACTjB,KAAO,iBACP,GACA,GACA,GACA,GACA,GACA,WAAAnU,CAAYoU,EAAevJ,GACvB3K,MAAK,EAAUkU,GAAeiB,OAC9BnV,MAAK,GAAc,QAAQ2K,EAAKyK,WAChCpV,MAAK,EAAS2K,EAAKjM,MACnBsB,MAAK,GAAU,QAAY2K,EAAKjM,MAAO,KAGvC,MAAM2W,EAAS,IAAIrV,MAAK,EAAY,GACpCA,MAAK,EAAqBqV,EAAOJ,iBACrC,CACA,iBAAOZ,CAAWH,EAAevJ,GAC7B,OAAO,IAAIuK,EAAWhB,EAAevJ,EACzC,CACA,MAAA2J,CAAOtS,GACH,IAAIsT,EAAQ,IAAI1I,WAAW5K,EAAIwJ,KAAKmJ,QAIpC,OAHIF,GAAqC,QAAjBzU,MAAK,IACzB,QAAiBsV,EAAOP,EAAkB/U,MAAK,IAE5CsV,CACX,CACA,MAAAd,CAAOc,GAIH,OAHIb,GAAqC,QAAjBzU,MAAK,IACzB,QAAiBsV,EAAOP,EAAkB/U,MAAK,IAE5C,CACHwL,KAAM,IAAIxL,MAAK,EAAYsV,EAAMX,OAAQW,EAAMV,WAAYU,EAAMT,WAAa7U,MAAK,GACnFtB,MAAOsB,MAAK,EACZuV,OAAQvV,MAAK,EAErB,EClDG,MAAMwV,EACTvB,KAAO,iBACP,iBAAOI,GACH,OAAO,IAAImB,CACf,CACA,MAAAlB,CAAO9N,GACH,MAAM,IAAIvF,MAAM,kBACpB,CACA,MAAAuT,CAAOxS,GACH,OAAO,IAAI4K,WAAW5K,EAAI2S,OAAQ3S,EAAI4S,WAAY5S,EAAI6S,WAAa,EACvE,ECTG,MAAMY,EACTxB,KAAO,iBACP,iBAAOI,CAAW7N,GACd,OAAO,IAAIiP,CACf,CACA,MAAAnB,CAAOoB,GACH,MAAM,IAAIzU,MAAM,iGACpB,CACA,YAAMuT,CAAOc,GACT,MAAMX,QAAe,QAAWW,EAAO,CAAEK,OAAQ,SACjD,OAAO,IAAI/I,WAAW+H,EAC1B,ECVJ,SAASiB,EAAsBC,EAAM3G,GAIjC,OAHA,SAAQvM,OAAOmT,MAAM5G,GAAQ,0EAC7B,QAAOA,IAAUvM,OAAOoT,kBAAmB,+EAC3C,QAAO7G,IAAUvM,OAAOqT,kBAAmB,+EACpC9G,CACX,CAEA,SAAS+G,EAAmBJ,EAAM3G,GAC9B,OAAOA,aAAiBgH,SAAWnR,MAAMC,QAAQkK,GAC3CgH,OAAO9D,KAAKlD,GACTiH,OACAhW,QAAO,CAACiW,EAAQhJ,KACjBgJ,EAAOhJ,GAAO8B,EAAM9B,GACbgJ,IACR,CAAC,GACFlH,CACV,CACO,MAAMmH,EACTnC,cACAD,KAAO,iBACP,GACA,GACA,WAAAnU,CAAYoU,EAAgB,CAAC,GACzBlU,KAAKkU,cAAgBA,EAErB,MAAM,SAAEoC,EAAW,QAAO,SAAEC,GAAW,EAAK,aAAEC,GAAe,EAAI,eAAEC,GAAiB,EAAI,UAAEC,GAAY,EAAI,UAAEC,GAAY,EAAI,OAAEC,EAAM,OAAEC,GAAS,GAAU3C,EACzJ,IAAI4C,EAAa5C,EAAc4C,WAC1BA,IAOGA,EAJCF,EAIY,CAAC,KAAM,MAHP,CAAC,IAAK,MAM3B5W,MAAK,EAAkB,CACnBsW,WACAC,WACAC,eACAC,iBACAC,YACAE,SACAE,aACAH,aAEJ3W,MAAK,EAAkB,CAAE6W,SAC7B,CACA,iBAAOxC,CAAWH,GACd,OAAO,IAAImC,EAAUnC,EACzB,CACA,MAAAI,CAAOyC,GACH,MAAM,OAAEH,EAAM,SAAEN,EAAQ,aAAEE,EAAY,eAAEC,EAAc,UAAEC,EAAS,UAAEC,GAAe3W,MAAK,GACvF,QAAoB,UAAbsW,EAAsB,sDAC7B,MAAMU,EAAqB,IAG3B,QAAOP,EAAgB,8FAClBC,GAEDM,EAAmBzU,KAAKqT,GAExBe,GAGAK,EAAmBzU,KAAK0T,GAE5B,MAAMgB,EAAQlS,MAAMwB,KAAKwQ,EAAIvL,MAG7B,IAAI0L,EAFJD,EAAM1U,KAAK,MACX0U,EAAM1U,KAAKwU,EAAIrY,OAEXsY,EAAmBpW,SACnBsW,EAAW,CAAC9J,EAAK8B,KACb,IAAIiI,EAAYjI,EAChB,IAAK,IAAIkI,KAAgBJ,EACrBG,EAAYC,EAAahK,EAAK+J,GAElC,OAAOA,CAAS,GAGxB,IAAIE,EAAWC,KAAKC,UAAUN,EAAOC,EAAUN,GAY/C,OAXIJ,IAKAa,EAAWA,EAASG,QAAQ,oBAAqBC,IAC7C,MAAMC,EAAW,OAAOD,EAAIE,WAAW,GAAGC,SAAS,MAEnD,MAAO,MADSF,EAASG,UAAUH,EAAS9W,OAAS,IAC/B,MAGvB,IAAIkX,aAAcxD,OAAO+C,EACpC,CACA,MAAA7C,CAAOc,GACH,MAAM,OAAEuB,GAAW7W,MAAK,GAExB,QAAO6W,EAAQ,uDACf,MAAMI,GAAQ,QAAmB3B,GAC3B5W,EAAQuY,EAAMc,MAMpB,OALAd,EAAMc,OAEN,QAAOrZ,EAAO,qCAGP,CAAE8M,KADIyL,EACEvY,QAAO6W,QAFP,QAAY7W,EAAO,KAGtC,E,cC3GJ,SAASsZ,EAAMhW,GACX,OAAIA,aAAe,MACfA,aAAe,MACfA,aAAe,KAEF,IAAIgN,MAAMhN,EAAK,CACxBmL,IAAG,CAAC8B,EAAQlE,IACDkE,EAAO9B,IAAIxK,OAAOoI,IAE7BjJ,IAAG,CAACmN,EAAQlE,EAAMmE,KAEdD,EAAOnN,IAAIa,OAAOoI,GAAOmE,IAClB,KAMZlN,CACX,CA0DO,MAAMiW,EACThE,KAAO,iBACP,GACA,GACA,WAAAnU,CAAYoU,EAAevJ,GACvB,IAAIuE,EAAQgF,EAAcgE,OAAS,IAC/BC,EAAOxN,EAAKjM,MAAMkC,OAClBsX,EAAQ,IAAInT,MAAMoT,GAClBC,EAAe,IAAIrT,MAAMoT,GAC7B,GAAc,MAAVjJ,EACA,IAAK,IAAI5M,EAAI,EAAGA,EAAI6V,IAAQ7V,EACxB4V,EAAM5V,GAAKA,EACX8V,EAAa9V,GAAKA,OAGrB,GAAc,MAAV4M,EACL,IAAK,IAAI5M,EAAI,EAAGA,EAAI6V,IAAQ7V,EACxB4V,EAAM5V,GAAK6V,EAAO7V,EAAI,EACtB8V,EAAa9V,GAAK6V,EAAO7V,EAAI,OAIjC4V,EAAQhJ,EACRgJ,EAAMjR,SAAQ,CAACoR,EAAG/V,MACd,aAA2BZ,IAApB0W,EAAaC,GAAkB,wBAAwBf,KAAKC,UAAUrI,MAC7EkJ,EAAaC,GAAK/V,CAAC,IAG3BtC,MAAK,EAASkY,EACdlY,MAAK,EAAgBoY,CACzB,CACA,iBAAO/D,CAAWH,EAAevJ,GAC7B,OAAO,IAAIsN,EAAe/D,EAAevJ,EAC7C,CACA,MAAA2J,CAAOtS,GACH,OAxCR,SAAuBsB,EAAO2L,GAC1B,IAAIqJ,EATR,SAAmBhV,GACf,IAAI6U,EAAO7U,EAAM5E,MAAMkC,OAEvB,OADA,QAAOuX,IAAS7U,EAAMiS,OAAO3U,OAAQ,+CAC9B0C,EAAMiS,OACRpR,KAAI,CAACoU,EAAGjW,KAAM,CAAGiT,OAAQgD,EAAGC,MAAOlW,MACnC6T,MAAK,CAAC/V,EAAGC,IAAMA,EAAEkV,OAASnV,EAAEmV,SAC5BpR,KAAKsU,GAAUA,EAAMD,OAC9B,CAEiBE,CAAUpV,GAEvB,OADA,QAAOgV,EAAO1X,SAAWqO,EAAOrO,OAAQ,qBACjC0X,EAAOrW,OAAM,CAAC0W,EAAKrW,IAAMqW,IAAQ1J,EAAO3M,IACnD,CAoCYsW,CAAc5W,EAAKhC,MAAK,GAEjBgC,EA7EnB,SAA6B4D,EAAKqJ,GAC9B,IAAI4J,EAlBR,SAAoBvV,EAAO4U,GACvB,IAAI1M,EAUJ,OAPIA,EAFAlI,EAAMkI,gBAAgB,MACtBlI,EAAMkI,gBAAgB,KACf,IAAIlI,EAAMxD,YAEjBwD,EAAMkI,KAAK5K,OAAQ0C,EAAMkI,KAAKsN,OAGvB,IAAIxV,EAAMxD,YAAYwD,EAAMkI,KAAK5K,QAErC,CACH4K,OACA9M,MAAO4E,EAAM5E,MACb6W,QAAQ,QAAYjS,EAAM5E,MAAOwZ,GAEzC,CAEca,CAAWnT,EAAKqJ,GACtB+J,EAASpT,EAAIlH,MAAMkC,OACnB8Q,EAAO9L,EAAI4F,KAAK5K,OAChB4X,EAAQzT,MAAMiU,GAAQnP,KAAK,GAC3BoP,EAAWjB,EAAMpS,EAAI4F,MACrB0N,EAAWlB,EAAMa,EAAIrN,MACzB,IAAK,IAAI2N,EAAU,EAAGA,EAAUzH,EAAMyH,IAAW,CAC7C,IAAIC,EAAU,EACd,IAAK,IAAIT,EAAM,EAAGA,EAAMK,EAAQL,IAC5BS,GAAWZ,EAAMG,GAAOE,EAAItD,OAAOoD,GAEvCO,EAASE,GAAWH,EAASE,GAC7BX,EAAM,IAAM,EACZ,IAAK,IAAIG,EAAM,EAAGA,EAAMK,EAAQL,IAC5B,GAAIH,EAAMG,KAAS/S,EAAIlH,MAAMia,GAAM,CAC/B,GAAIA,EAAM,IAAMK,EACZ,MAEJR,EAAMG,GAAO,EACbH,EAAMG,EAAM,IAAM,CACtB,CAER,CACA,OAAOE,CACX,CAsDeQ,CAAoBrX,EAAKhC,MAAK,EACzC,CACA,MAAAwU,CAAOxS,GACH,MAAO,CACHwJ,KAAMxJ,EAAIwJ,KACV9M,MAAOsD,EAAItD,MACX6W,QAAQ,QAAYvT,EAAItD,MAAOsB,MAAK,GAE5C,EC7HG,MAAMsZ,EACTrF,KAAO,iBACP,GACA,GACA,WAAAnU,CAAYpB,GACRsB,MAAK,EAAStB,EACdsB,MAAK,GAAW,QAAYtB,EAAO,IACvC,CACA,iBAAO2V,CAAW7N,EAAGmE,GACjB,OAAO,IAAI2O,EAAS3O,EAAKjM,MAC7B,CACA,MAAA4V,CAAOiF,GACH,MAAM,IAAItY,MAAM,0BACpB,CACA,MAAAuT,CAAOc,GACH,IAAIkE,EAAU,IAAIC,YACdC,EAAO,IAAIC,SAASrE,EAAMX,QAC1BnJ,EAAOzG,MAAM2U,EAAKE,UAAU,GAAG,IAC/BC,EAAM,EACV,IAAK,IAAIvX,EAAI,EAAGA,EAAIkJ,EAAK5K,OAAQ0B,IAAK,CAClC,IAAIwX,EAAcJ,EAAKE,UAAUC,GAAK,GACtCA,GAAO,EACPrO,EAAKlJ,GAAKkX,EAAQhF,OAAOc,EAAMX,OAAOxP,MAAM0U,EAAKA,EAAMC,IACvDD,GAAOC,CACX,CACA,MAAO,CAAEtO,OAAM9M,MAAOsB,MAAK,EAAQuV,OAAQvV,MAAK,EACpD,EC1BG,MAAM+Z,EACT9F,KAAO,iBACP,iBAAOI,CAAW7N,GACd,OAAO,IAAIuT,CACf,CACA,MAAAzF,CAAOoB,GACH,MAAM,IAAIzU,MAAM,0FACpB,CACA,YAAMuT,CAAOc,GACT,MAAMX,QAAe,QAAWW,EAAO,CAAEK,OAAQ,YACjD,OAAO,IAAI/I,WAAW+H,EAC1B,ECWG,MAAMqF,GAbF,IAAIlK,KACNhO,IAAI,SAAS,IAAM,8BAA0BgQ,MAAMmI,GAAMA,EAAEC,YAC3DpY,IAAI,OAAO,IAAM,8BAAwBgQ,MAAMmI,GAAMA,EAAEC,YACvDpY,IAAI,QAAQ,IAAM,8BAAyBgQ,MAAMmI,GAAMA,EAAEC,YACzDpY,IAAI,QAAQ,IAAM2T,IAClB3T,IAAI,QAAQ,IAAMiY,IAClBjY,IAAI,aAAa,IAAMmW,IACvBnW,IAAI,SAAS,IAAMoT,IACnBpT,IAAI,UAAU,IAAM0T,IACpB1T,IAAI,aAAa,IAAMwX,IACvBxX,IAAI,SAAS,IAAMuU,IACnBvU,IAAI,YAAY,IAAMkS,IAGxB,SAASmG,EAAsBC,GAClC,IAAIC,EACJ,MAAO,CACH,YAAM/F,CAAOhR,GACJ+W,IACDA,QAAeC,EAAYF,IAC/B,IAAK,MAAMG,KAASF,EAAOG,eACvBlX,QAAciX,EAAMjG,OAAOhR,GAE/B,IAAIgS,QAAc+E,EAAOI,eAAenG,OAAOhR,GAC/C,IAAK,MAAMiX,KAASF,EAAOK,eACvBpF,QAAciF,EAAMjG,OAAOgB,GAE/B,OAAOA,CACX,EACA,YAAMd,CAAOc,GACJ+E,IACDA,QAAeC,EAAYF,IAC/B,IAAK,IAAI9X,EAAI+X,EAAOK,eAAe9Z,OAAS,EAAG0B,GAAK,EAAGA,IACnDgT,QAAc+E,EAAOK,eAAepY,GAAGkS,OAAOc,GAElD,IAAIhS,QAAc+W,EAAOI,eAAejG,OAAOc,GAC/C,IAAK,IAAIhT,EAAI+X,EAAOG,eAAe5Z,OAAS,EAAG0B,GAAK,EAAGA,IACnDgB,QAAc+W,EAAOG,eAAelY,GAAGkS,OAAOlR,GAElD,OAAOA,CACX,EAER,CACAkJ,eAAe8N,EAAYK,GACvB,IAMIF,EANAlJ,EAAWoJ,EAAWN,OAAOlW,KAAIqI,MAAO7B,IACxC,IAAIiQ,QAAcZ,EAAS7M,IAAIxC,EAAK/L,KAAlBob,MAElB,OADA,QAAOY,EAAO,kBAAkBjQ,EAAK/L,QAC9B,CAAEgc,QAAOjQ,OAAM,IAEtB6P,EAAiB,GAEjBE,EAAiB,GACrB,UAAW,IAAI,MAAEE,EAAK,KAAEjQ,KAAU4G,EAAU,CACxC,IAAIgJ,EAAQK,EAAMvG,WAAW1J,EAAKuJ,cAAeyG,GACjD,OAAQJ,EAAMtG,MACV,IAAK,iBACDuG,EAAejY,KAAKgY,GACpB,MACJ,IAAK,iBACDE,EAAiBF,EACjB,MACJ,QACIG,EAAenY,KAAKgY,GAEhC,CAKA,OAJKE,KACD,QAMsB,cANUE,EAMxBvF,UANqC,iBAAiBuF,EAAWvF,sCACzEqF,EAAiBvF,EAAWb,WAAW,CAAEc,OAAQ,UAAYwF,IAE1D,CAAEH,iBAAgBC,iBAAgBC,iBAC7C,CC9EA,MAAMG,EAAe,sBACd,SAASC,EAA4BC,EAAUC,EAAaC,EAAkBC,IACjF,QAAOH,EAASI,MAAM7N,SAAU,yCAChC,IAAI8N,EAAYL,EAASI,MAAM7N,SAAS+N,KAAKN,EAASI,OAClDG,EAAcN,EAAY7W,KAAI,CAACoX,EAAGjZ,IAAMiZ,EAAIL,EAAgBM,YAAYlZ,KACxEmZ,EAActB,EAAsB,CACpC/E,UAAW,SACX1W,MAAO,IAAI4c,EAAa,GACxBjB,OAAQa,EAAgBQ,eAExBvN,EAAQ,CAAC,EACb,OAAO3B,MAAOmP,IACV,IAEInD,EAFAoD,EAAcD,EAAYxX,KAAI,CAACoX,EAAGjZ,IAAM+B,KAAKwX,MAAMN,EAAID,EAAYhZ,MACnEwZ,EAAaf,EAAShP,QAAQkP,EAAiBW,IAAc3P,KAEjE,GAAI6P,KAAc3N,EACdqK,EAAQrK,EAAM2N,OAEb,CACD,IAAIC,EAAgB,EAChBC,EAAa,GAAKV,EAAYnb,QAAO,CAACC,EAAGC,IAAMD,EAAIC,GAAG,GACtDiV,QAAc8F,EAAUU,EAAY,CACpC/N,aAAciO,EAAaD,IAE/BvD,EAAQrK,EAAM2N,GAAcxG,QAChBmG,EAAYjH,OAAOc,GACzB,IACV,CACA,GAAc,OAAVkD,EACA,OAEJ,IAAI,KAAEhN,EAAI,MAAE9M,EAAK,OAAE6W,GAAWiD,EAC1ByD,EAAgBN,EACfxX,KAAI,CAACoX,EAAGjZ,IAAMiZ,EAAI7c,EAAM4D,KACxBnC,QAAO,CAAC+b,EAAKC,EAAK1V,IAAQyV,EAAMC,EAAM5G,EAAO9O,IAAM,GACpD5B,EAAS2G,EAAKyQ,GACdrb,EAAS4K,EAAKyQ,EAAgB,GAElC,OAAIpX,IAAWgW,GAAgBja,IAAWia,EAGnCO,EAAUU,EAAY,CACzBjX,OAAQlC,OAAOkC,GACfjE,OAAQ+B,OAAO/B,UALnB,CAME,CAEV,CC7CO,MAAMwb,EACTjB,MACAlP,KACA,WAAAnM,CAAYqb,EAAOlP,EAAO,KACtBjM,KAAKmb,MAAQA,EACbnb,KAAKiM,KAAOA,CAChB,CACA,OAAAF,CAAQE,GAGJ,IAAID,EAAO,IAAIG,IAAI,UAAUnM,KAAKiM,KAAKI,SAAS,KAAOrM,KAAKiM,KAAO,GAAGjM,KAAKiM,WAC3E,OAAO,IAAImQ,EAASpc,KAAKmb,MAAO,IAAIhP,IAAIF,EAAMD,GAAMI,SACxD,EAEG,SAASJ,EAAKmP,GACjB,OAAO,IAAIiB,EAASjB,GAAS,IAAIrL,IACrC,CACO,MAAMuM,UAAcD,EACvBnI,KAAO,QACP,GACA,WAAAnU,CAAYqb,EAAOlP,EAAMqQ,GACrBlb,MAAM+Z,EAAOlP,GACbjM,MAAK,EAAYsc,CACrB,CACA,SAAIC,GACA,OAAOvc,MAAK,EAAUwc,UAC1B,EAEJ,SAASC,EAAgBpC,GACrB,MAAMqC,EAAwBrC,EAAOjS,MAAMxB,GAAiB,cAAXA,EAAEhI,OAEnD,OAAO8d,GAAuBxI,eAAegE,OAAS,GAC1D,CACA,MAAMyE,EAAiBvX,OAAO,mBACvB,SAASwX,EAAY9R,GACxB,OAAOA,EAAI6R,EACf,CA6CO,MAAM,UAAcP,EACvBnI,KAAO,QACP,GACA,CAAC0I,GACD,WAAA7c,CAAYqb,EAAOlP,EAAMqQ,GACrBlb,MAAM+Z,EAAOlP,GACbjM,MAAK,EAAY,IACVsc,EACHO,YAAY,QAAsBP,IAEtCtc,KAAK2c,GAtDb,SAAwB5B,EAAUuB,GAC9B,IAAI,cAAEpI,GAAkBoI,EAASjC,OAAOjS,KAAK,MAAsB,CAAC,EAChE0U,EAAiB,CACjBC,kBAAkB,QAAyBT,EAASU,oBACpDhI,YAAY,QAAQsH,EAASlH,WAC7ByH,WAAYP,EAASO,YAEzB,GAAI3I,EAAe,CACf,IAAI+I,EAAeR,EAAgBvI,EAAcmG,QACjD,MAAO,IACAyC,EACH7I,KAAM,UACNuH,YAAatH,EAAcsH,YAC3BjB,MAAOJ,EAAsB,CACzB/E,UAAWkH,EAASlH,UACpB1W,MAAOwV,EAAcsH,YACrBnB,OAAQnG,EAAcmG,SAE1B6C,YAAYxe,IACD,QAAYA,EAAOue,GAE9BE,gBAAiBrC,EAA4BC,EAAUuB,EAASc,WAAWlJ,cAAcsH,YAAasB,EAAeC,iBAAkB7I,GAE/I,CACA,IAAI+I,EAAeR,EAAgBH,EAASjC,QAC5C,MAAO,IACAyC,EACH7I,KAAM,UACNuH,YAAac,EAASc,WAAWlJ,cAAcsH,YAC/CjB,MAAOJ,EAAsB,CACzB/E,UAAWkH,EAASlH,UACpB1W,MAAO4d,EAASc,WAAWlJ,cAAcsH,YACzCnB,OAAQiC,EAASjC,SAErB6C,YAAYxe,IACD,QAAYA,EAAOue,GAE9B,qBAAME,CAAgBE,EAAclc,GAChC,IAAImc,EAAYR,EAAeC,iBAAiBM,GAC5CE,EAAaxC,EAAShP,QAAQuR,GAAWrR,KAC7C,OAAO8O,EAASI,MAAMhO,IAAIoQ,EAAYpc,EAC1C,EAER,CAW+Bqc,CAAexd,KAAMsc,EAChD,CACA,SAAIC,GACA,OAAOvc,MAAK,EAAUwc,UAC1B,CACA,SAAI9d,GACA,OAAOsB,MAAK,EAAUtB,KAC1B,CACA,UAAIqE,GACA,OAAO/C,KAAK2c,GAAgBnB,WAChC,CACA,SAAIiC,GACA,OAAOzd,MAAK,EAAUoV,SAC1B,CACA,cAAM9G,CAAS+O,EAAclc,GACzB,IAAIuc,EAAU1d,KAAK2c,GACfgB,QAAoBD,EAAQP,gBAAgBE,EAAclc,GAC9D,IAAKwc,EAAa,CACd,IAAIjM,EAAOgM,EAAQlC,YAAYrb,QAAO,CAACC,EAAGC,IAAMD,EAAIC,GAAG,GACnDmL,EAAO,IAAIkS,EAAQ1I,WAAWtD,GAGlC,OADAlG,EAAK3B,KAAK6T,EAAQb,YACX,CACHrR,OACA9M,MAAOgf,EAAQlC,YACfjG,OAAQmI,EAAQR,YAAYQ,EAAQlC,aAE5C,CACA,OAAOkC,EAAQnD,MAAM/F,OAAOmJ,EAChC,CAkBA,EAAAC,CAAGC,GACC,OAAO,QAAS7d,KAAKyd,MAAOI,EAChC,E,8GC9IG,MAAMC,UAAmB7c,MAC5B,WAAAnB,CAAYie,GACR3c,MAAM2c,GACN/d,KAAKpB,KAAO,YAChB,EA6BJ,MAAMof,EACFC,QACAC,QACAC,cACAC,OACA,WAAAte,EAAY,QAAEme,EAAO,QAAEC,EAAO,cAAEC,IAE5BF,EApBD,SAAqCA,EAASC,GAWjD,OATAD,EAAU5Z,KAAKga,MAAMJ,IAEP,IACVA,EAAUC,EAAUD,IAGpBA,GAAWC,GAAWD,EAAU,IAnBxC,SAAyBC,GACrB,MAAM,IAAIJ,EAAW,iDAAiDI,IAC1E,CAkBQI,CAAgBJ,GAEbD,CACX,CAQkBM,CAA4BN,EAASC,GAE/Cle,KAAKie,QAAUA,EACfje,KAAKke,QAAUA,EACfle,KAAKme,cAAgBA,EACrBne,KAAKoe,OAAS,CAClB,CACA,EAAEhZ,OAAOC,YACL,MAAMmZ,EAAena,KAAKwX,MAAM7b,KAAKie,QAAUje,KAAKme,eAC9CM,EAAaD,EAAexe,KAAKme,cACjCO,EAAgB1e,KAAKie,QAAUQ,OAC/B,CAAED,eAAcE,gBAC1B,EAEJ,MAAMC,EACF9a,MACA+a,KACAC,KACAX,QACAC,cACAC,OACAU,QACA,WAAAhf,EAAY,QAAEme,EAAO,QAAEC,EAAO,cAAEC,IAE5B,MAAOta,EAAO+a,EAAMC,IAAQ,QAAcZ,EAASC,GACnDle,KAAK6D,MAAQA,EACb7D,KAAK4e,KAAOA,EACZ5e,KAAK6e,KAAOA,EACR7e,KAAK6e,KAAO,GAxDxB,WACI,MAAM,IAAIf,EAAW,2CACzB,CAuDYiB,GAEJ/e,KAAKke,QAAUA,EACfle,KAAKme,cAAgBA,EACrBne,KAAKoe,OAAS/Z,KAAKG,IAAI,EAAGH,KAAK2a,MAAMhf,KAAK4e,KAAO5e,KAAK6D,OAAS7D,KAAK6e,OACpE7e,KAAK8e,QAAUza,KAAK2a,KAAKhf,KAAKke,QAAUle,KAAKme,cACjD,CACA,EAAE/Y,OAAOC,YAEL,MAAM4Z,EAAoB5a,KAAKwX,MAAM7b,KAAK6D,MAAQ7D,KAAKme,eACjDe,EAAkB7a,KAAK2a,KAAKhf,KAAK4e,KAAO5e,KAAKme,eACnD,IAAK,MAAMK,KAAgB,QAAMS,EAAmBC,GAAkB,CAElE,MAAMT,EAAaD,EAAexe,KAAKme,cACjCgB,EAAY9a,KAAKC,IAAItE,KAAKke,SAAUM,EAAe,GAAKxe,KAAKme,eAE7DA,EAAgBgB,EAAYV,EAClC,IAAIW,EAAiB,EACjBC,EAAsB,EAC1B,GAAIrf,KAAK6D,MAAQ4a,EAAY,CAEzB,MAAMa,GAAab,EAAaze,KAAK6D,OAAS7D,KAAK6e,KAC/CS,IACAD,GAAuBrf,KAAK6e,KAAOS,GAEvCF,EAAiB/a,KAAK2a,MAAMP,EAAaze,KAAK6D,OAAS7D,KAAK6e,KAChE,MAGIQ,EAAsBrf,KAAK6D,MAAQ4a,EAIvC,MAAMc,EAAqBvf,KAAK4e,KAAOO,EAAYhB,EAAgBne,KAAK4e,KAAOH,EACzEC,EAAgB,CAClBW,EACAE,EACAvf,KAAK6e,MAGHW,EAAc,CAChBJ,EACAA,EAHqB/a,KAAK2a,MAAMO,EAAqBF,GAAuBrf,KAAK6e,MAIjF,QAEE,CAAEL,eAAcE,gBAAec,cACzC,CACJ,EAaG,MAAMC,EACTC,aACAhhB,MACA,WAAAoB,EAAY,UAAE6f,EAAS,MAAEjhB,EAAK,YAAE8c,IAE5Bxb,KAAK0f,aAhBN,SAA6BC,EAAWjhB,GAC3C,IAAIkhB,EAAa,GAQjB,OAPkB,OAAdD,EACAC,EAAalhB,EAAMyF,KAAKqC,IAAM,QAAM,QAE/BzB,MAAMC,QAAQ2a,KACnBC,EAAaD,EAAUxb,KAAKoU,GAAMA,IAAK,QAAM,SA7GrD,SAAgCoH,EAAWjhB,GACnCihB,EAAU/e,OAASlC,EAAMkC,QAVjC,SAA8B+e,EAAWjhB,GACrC,MAAM,IAAIof,EAAW,yCAAyCpf,EAAMkC,eAAe+e,EAAU/e,SACjG,CASQif,CAAqBF,EAAWjhB,EAExC,CA2GIohB,CAAuBF,EAAYlhB,GAC5BkhB,CACX,CAM4BG,CAAoBJ,EAAWjhB,GAAOyF,KAAI,CAAC8Z,EAAS3b,IAC7D,IAAwB,iBAAZ2b,EAAuBD,EAAgBW,GAAiB,CAEvEV,QAASA,EACTC,QAASxf,EAAM4D,GACf6b,cAAe3C,EAAYlZ,OAGnCtC,KAAKtB,MAAQsB,KAAK0f,aACb5a,QAAQkb,GAAQA,aAAerB,IAC/Bxa,KAAK8b,GAASA,EAAK7B,QAC5B,CACA,EAAEhZ,OAAOC,YACL,IAAK,MAAM6a,KAAmB,WAAWlgB,KAAK0f,cAAe,CACzD,MAAMrC,EAAe6C,EAAgB/b,KAAKgc,GAAMA,EAAE3B,eAC5C4B,EAAUF,EAAgB/b,KAAKgc,GAC7B,gBAAiBA,EACV,CAAE5Z,KAAM4Z,EAAEzB,cAAe2B,GAAIF,EAAEX,aAEnC,CAAEjZ,KAAM4Z,EAAEzB,cAAe2B,GAAI,aAElC,CAAEhD,eAAc+C,UAC1B,CACJ,EC3JJ,SAASE,EAAkBte,EAAK6C,EAAS,EAAG6M,GACxC,IAAI9Q,EAAS8Q,GAAQ1P,EAAIpB,OAASiE,EAClC,MAAO,CACHjE,SACA2f,SAAQ,CAACha,EAAM8Z,EAAKzf,IACT0f,EAAkBte,EAAK6C,EAAS0B,EAAM8Z,EAAK9Z,GAEtD,GAAAzE,CAAI0J,EAAM3H,EAAQ,GACd,IAAK,IAAIvB,EAAI,EAAGA,EAAIkJ,EAAK5K,OAAQ0B,IAC7BN,EAAI6C,EAAShB,EAAQvB,GAAKkJ,EAAK2B,IAAI7K,EAE3C,EACA6K,IAAIqL,GACOxW,EAAI6C,EAAS2T,GAGhC,CAWA,SAASgI,EAAaxe,GAClB,OAAIye,WAAW1b,MAAMC,QAAQhD,EAAIwJ,MACtB,CAEHA,KAAM8U,EAAkBte,EAAIwJ,MAC5B+J,OAAQvT,EAAIuT,OACZR,kBAAmB,GAGpB,CACHvJ,KAAM,IAAIoB,WAAW5K,EAAIwJ,KAAKmJ,OAAQ3S,EAAIwJ,KAAKoJ,WAAY5S,EAAIwJ,KAAKqJ,YACpEU,OAAQvT,EAAIuT,OACZR,kBAAmB/S,EAAIwJ,KAAKyJ,kBAEpC,CA8BO,MAAMyL,EAAS,CAClBC,QAAO,CAACnV,EAAM9M,EAAO6W,KACV,CAAE/J,OAAM9M,QAAO6W,WAE1B,UAAAqL,CAAWC,EAAM1E,EAAKjN,GAClB,IAAIwK,EAAO8G,EAAaK,GACxBC,EAAkBpH,EAAMyC,EAhBhC,SAAuBna,EAAKkN,GACxB,GAAIuR,WAAW1b,MAAMC,QAAQhD,EAAIwJ,MAE7B,OAAO8U,EAAkB,CAACpR,IAE9B,IAEI1D,EAAO,IAzBf,SAAqCxJ,GACjC,MAAI,UAAWA,EAGJA,EAAIlC,YAAYub,KAAK,KAAMrZ,EAAI8W,OAEnC9W,EAAIlC,WACf,CAgBqBihB,CAA4B/e,EAAIwJ,MAEtC,CAAe,CAAC0D,IAC3B,OAAO,IAAItC,WAAWpB,EAAKmJ,OAAQnJ,EAAKoJ,WAAYpJ,EAAKqJ,WAC7D,CAOqCmM,CAAcH,EAAM3R,GAAQwK,EAAK3E,kBAClE,EACA,cAAAkM,CAAeJ,EAAMjb,EAAKsb,GACtB,IAAIxH,EAAO8G,EAAaK,GACxBM,EAAsBzH,EAAM8G,EAAa5a,GAAM8T,EAAK3E,kBAAmBmM,EAC3E,GAGG1U,eAAe,EAAIxK,EAAK2d,EAAY,KAAMhU,EAAO,CAAC,GACrD,OCnFGa,eAAmBxK,EAAK2d,EAAWhU,EAAM+U,GAC5C,IAAIhD,GAAU,QAAY1b,GACtBof,EAAU,IAAI3B,EAAa,CAC3BE,YACAjhB,MAAOsD,EAAItD,MACX8c,YAAaxZ,EAAIe,SAEjB8V,EAAM6H,EAAOC,QAAQ,IAAIjD,EAAQ1I,WAAWoM,EAAQ1iB,MAAMyB,QAAO,CAACC,EAAGC,IAAMD,EAAIC,GAAG,IAAK+gB,EAAQ1iB,MAAOgf,EAAQR,YAAYkE,EAAQ1iB,QAClI0P,EAAQzC,EAAK0V,mBAAoB,UACrC,IAAK,MAAM,aAAEhE,EAAY,QAAE+C,KAAagB,EACpChT,EAAMyD,KAAIrF,UACN,IAAI,KAAEhB,EAAI,MAAE9M,EAAK,OAAE6W,SAAiBvT,EAAIsM,SAAS+O,EAAc1R,EAAKA,MAChErI,EAAQod,EAAOC,QAAQnV,EAAM9M,EAAO6W,GACxCmL,EAAOO,eAAepI,EAAKvV,EAAO8c,EAAQ,IAMlD,aAHMhS,EAAMkT,SAGoB,IAAzBF,EAAQ1iB,MAAMkC,OAtBzB,SAAgBoB,GACZ,MAAQ,QAASA,EAAMA,EAAImL,IAqB0B,GArBfnL,EAqBe,EApBzD,CAoBwCuf,CAAO1I,EAAIrN,MAAWqN,CAC9D,CD+DW1L,CAAgBnL,EAAK2d,EAAWhU,EAAM+U,EACjD,CAKA,SAASc,EAAY3d,EAAO+a,EAAMC,GAC9B,OAAIA,EAAO,GAAKD,EAAO/a,EACZQ,KAAKwX,OAAOhY,EAAQ+a,EAAO,IAAMC,GAAQ,EAEhDhb,EAAQ+a,EACDva,KAAKwX,OAAO+C,EAAO/a,EAAQ,GAAKgb,GAAQ,EAC5C,CACX,CACA,SAASiC,EAAkBjI,EAAK4I,EAAevS,EAAO6F,GAClD,GAA6B,IAAzB0M,EAAc7gB,OAEd,YADAiY,EAAIrN,KAAK1J,IAAIoN,EAAO,GAGxB,MAAO/J,KAAUuc,GAAUD,GACpBE,KAAgBpM,GAAUsD,EAAItD,OACrC,GAAqB,iBAAVpQ,EAGP,YADA2b,EAAkB,CAAEtV,KADPqN,EAAIrN,KAAK+U,SAASoB,EAAcxc,EAAQ4P,GAC3BQ,UAAUmM,EAAQxS,EAAO6F,GAGvD,MAAOxO,EAAM8Z,EAAIxB,GAAQ1Z,EACnByc,EAAMJ,EAAYjb,EAAM8Z,EAAIxB,GAClC,GAAsB,IAAlB6C,EAAO9gB,OAMX,IAAK,IAAI0B,EAAI,EAAGA,EAAIsf,EAAKtf,IAErBwe,EAAkB,CAAEtV,KADPqN,EAAIrN,KAAK+U,SAASoB,GAAepb,EAAOsY,EAAOvc,GAAKyS,GACvCQ,UAAUmM,EAAQxS,EAAO6F,QAPnD,IAAK,IAAIzS,EAAI,EAAGA,EAAIsf,EAAKtf,IACrBuW,EAAIrN,KAAK1J,IAAIoN,EAAOyS,GAAepb,EAAOsY,EAAOvc,GAAKyS,EAQlE,CACA,SAASoM,EAAsBN,EAAMjb,EAAKmP,EAAmBmM,GACzD,MAAOW,KAASC,GAASZ,GAClBa,KAAYC,GAAYnB,EAAKtL,QAC7B0M,KAAYC,GAAYtc,EAAI2P,OACnC,GAAkB,OAAdsM,EAAKtb,KACL,OAAqB,IAAjBub,EAAMlhB,YACNigB,EAAKrV,KAAK1J,IAAI8D,EAAI4F,KAAK+U,SAAS,EAAGxL,GAAoB8M,EAAKxB,GAAKtL,QAGrEoM,EAAsB,CAClB3V,KAAMqV,EAAKrV,KAAK+U,SAASwB,EAAUF,EAAKxB,GAAKtL,GAC7CQ,OAAQyM,GACTpc,EAAKmP,EAAmB+M,GAG/B,GAAgB,OAAZD,EAAKxB,GAAa,CAClB,GAAqB,IAAjByB,EAAMlhB,OAAc,CACpB,IAAIiE,EAASgd,EAAKtb,KAAOwO,EAEzB,YADA8L,EAAKrV,KAAK1J,IAAI8D,EAAI4F,KAAK+U,SAAS1b,EAAQA,EAASkQ,GAAoB,EAEzE,CAKA,YAJAoM,EAAsBN,EAAM,CACxBrV,KAAM5F,EAAI4F,KAAK+U,SAAS0B,EAAUJ,EAAKtb,KAAOwO,GAC9CQ,OAAQ2M,GACTnN,EAAmB+M,EAE1B,CACA,MAAOvb,EAAM8Z,EAAIxB,GAAQgD,EAAKxB,IACvB8B,EAAO3b,EAAG4b,GAASP,EAAKtb,KACzBqb,EAAMJ,EAAYjb,EAAM8Z,EAAIxB,GAClC,GAAqB,IAAjBiD,EAAMlhB,OAgBV,IAAK,IAAI0B,EAAI,EAAGA,EAAIsf,EAAKtf,IACrB6e,EAAsB,CAClB3V,KAAMqV,EAAKrV,KAAK+U,SAASwB,GAAWxb,EAAOjE,EAAIuc,GAAQ9J,GACvDQ,OAAQyM,GACT,CACCxW,KAAM5F,EAAI4F,KAAK+U,SAAS0B,GAAWE,EAAQ7f,EAAI8f,GAASrN,GACxDQ,OAAQ2M,GACTnN,EAAmB+M,OAvB1B,CAGI,GAAa,IAATjD,GAAwB,IAAVuD,GAA2B,IAAZL,GAA6B,IAAZE,EAAe,CAC7D,IAAIpd,EAASsd,EAAQpN,EACjBrD,EAAOkQ,EAAM7M,EAEjB,YADA8L,EAAKrV,KAAK1J,IAAI8D,EAAI4F,KAAK+U,SAAS1b,EAAQA,EAAS6M,GAAOnL,EAAOwO,EAEnE,CAEA,IAAK,IAAIzS,EAAI,EAAGA,EAAIsf,EAAKtf,IAAK,CAC1B,IAAIuC,EAASod,GAAWE,EAAQC,EAAQ9f,GAAKyS,EAC7C8L,EAAKrV,KAAK1J,IAAI8D,EAAI4F,KAAK+U,SAAS1b,EAAQA,EAASkQ,GAAoBgN,GAAWxb,EAAOsY,EAAOvc,GAAKyS,EACvG,CAEJ,CAUJ,C,iBEtLO,SAAUxH,EAAM1J,EAAO+a,EAAMC,EAAO,QAC1Bnd,IAATkd,IACAA,EAAO/a,EACPA,EAAQ,GAEZ,IAAK,IAAIvB,EAAIuB,EAAOvB,EAAIsc,EAAMtc,GAAKuc,QACzBvc,CAEd,CAKO,SAAU+f,KAAWC,GACxB,GAAyB,IAArBA,EAAU1hB,OACV,OAGJ,MAAM2hB,EAAYD,EAAUne,KAAKqe,GAAOA,EAAGpd,OAAOC,cAC5Cod,EAAUF,EAAUpe,KAAKqe,GAAOA,EAAGE,SACzC,GAAID,EAAQjf,MAAMmf,GAAMA,EAAEC,OACtB,MAAM,IAAI3hB,MAAM,qCAEpB,IAAK,IAAIqB,EAAI,IAAK,CACd,GAAImgB,EAAQngB,GAAGsgB,MAKX,GAHAL,EAAUjgB,GAAKggB,EAAUhgB,GAAG8C,OAAOC,YACnCod,EAAQngB,GAAKigB,EAAUjgB,GAAGogB,SAEpBpgB,GAAKigB,EAAU3hB,OACjB,kBAKE6hB,EAAQte,KAAI,EAAG+K,WAAYA,IACjC5M,EAAI,EAERmgB,EAAQngB,GAAKigB,EAAUjgB,GAAGogB,MAC9B,CACJ,CAEO,SAASG,GAAc,MAAEhf,EAAK,KAAE+a,EAAI,KAAEC,GAAQje,GACjD,GAAa,IAATie,EACA,MAAM,IAAI5d,MAAM,6BAGpB,MAAM6hB,GADNjE,EAAOA,GAAQ,GACiB,GAEzBkE,EAAOC,GAASF,EAAmB,EAAE,EAAGliB,EAAS,GAAK,CAAC,EAAGA,GA+BjE,OA7Bc,OAAViD,EACAA,EAAQif,EAAmBE,EAAQD,EAG/Blf,EAAQ,GACRA,GAASjD,GACGmiB,IACRlf,EAAQkf,GAGPlf,EAAQmf,IACbnf,EAAQmf,GAIH,OAATpE,EACAA,EAAOkE,EAAmBC,EAAQC,EAG9BpE,EAAO,GACPA,GAAQhe,GACGmiB,IACPnE,EAAOmE,GAGNnE,EAAOoE,IACZpE,EAAOoE,GAGR,CAACnf,EAAO+a,EAAMC,EACzB,CACO,SAAS1Z,EAAMtB,EAAO+a,EAAMC,EAAO,MAKtC,YAJand,IAATkd,IACAA,EAAO/a,EACPA,EAAQ,MAEL,CACHA,QACA+a,OACAC,OAER,CAEO,SAASwC,IACZ,MAAM9P,EAAW,GACjB,MAAO,CACHM,IAAMoR,GAAO1R,EAAShP,KAAK0gB,KAC3B3B,OAAQ,IAAM/Q,QAAQ2S,IAAI3R,GAElC,C,yHClGA,IAAI4R,EACJ,WACI,IAAIC,EAAiB,IAAIC,QACzB,SAASC,EAAWnI,GAChB,IAAIoI,EAASH,EAAejW,IAAIgO,IAAU,CAAEqI,GAAI,EAAGC,GAAI,GAEvD,OADAL,EAAethB,IAAIqZ,EAAOoI,GACnBA,CACX,CACA,MAAO,CACH,SAAAG,CAAUvI,EAAOwI,GACbL,EAAWnI,GAAOwI,IAAY,CAClC,EACA,WAAAC,CAAYzI,GACR,IAAIoI,EAASD,EAAWnI,GACxB,OAAOoI,EAAOE,GAAKF,EAAOC,GAAK,KAAO,IAC1C,EAER,CAjBsBK,GAsCtBrX,eAAesX,EAAc/I,EAAUwB,GACnC,IAAI,KAAEtQ,GAAS8O,EAAShP,QAAQ,WAC5BpB,QAAaoQ,EAASI,MAAMhO,IAAIlB,GACpC,IAAKtB,EACD,MAAM,IAAI,IAAkB,WAAY,CACpC9I,MAAO,IAAI,IAASoK,KAI5B,OADAkX,EAAgBO,UAAU3I,EAASI,MAAO,MACnC,IAAI,KAAMJ,EAASI,MAAOJ,EAAS9O,MAAM,SAAwB,QAAmBtB,GAAO4R,GACtG,CACA/P,eAAeuX,EAAchJ,EAAUwB,GACnC,IAAI,KAAEtQ,GAAS8O,EAAShP,QAAQ,WAC5BpB,QAAaoQ,EAASI,MAAMhO,IAAIlB,GACpC,IAAKtB,EACD,MAAM,IAAI,IAAkB,WAAY,CACpC9I,MAAO,IAAI,IAASoK,KAI5B,OADAkX,EAAgBO,UAAU3I,EAASI,MAAO,MACnC,IAAI,KAAMJ,EAASI,MAAOJ,EAAS9O,MAAM,SAAwB,QAAmBtB,GAAO4R,GACtG,CA8BO/P,eAAewX,EAAKjJ,EAAU5Z,EAAU,CAAC,GAC5C,IAAIga,EAAQ,UAAWJ,EAAWA,EAASI,MAAQJ,EAC/C6I,EAAcT,EAAgBS,YAAYzI,GAI1C8I,EAA+B,OAAhBL,EAAuBI,EAAKR,GAAKQ,EAAKP,GACrDS,EAAiC,OAAhBN,EAAuBI,EAAKP,GAAKO,EAAKR,GAC3D,OAAOS,EAAalJ,EAAU5Z,GAAS4R,OAAOoR,KAC1C,QAAeA,EAAK,KACbD,EAAenJ,EAAU5Z,KAExC,CACA6iB,EAAKR,GA9ELhX,eAAuBuO,EAAU5Z,EAAU,CAAC,GACxC,IAAIijB,EAAM,UAAWrJ,EAAWA,EAAW,IAAI,KAASA,GACpDwB,EAAQ,CAAC,EAGb,OAFIpb,EAAQob,OAAS,KACjBA,QAVR/P,eAA0BuO,GACtB,IAAIsJ,QAAmBtJ,EAASI,MAAMhO,IAAI4N,EAAShP,QAAQ,WAAWE,MACtE,OAAKoY,GAEE,QAAmBA,GADf,CAAC,CAEhB,CAKsBC,CAAWF,IACR,UAAjBjjB,EAAQ8S,KACD6P,EAAcM,EAAK7H,GACT,UAAjBpb,EAAQ8S,KACD8P,EAAcK,EAAK7H,GACvBuH,EAAcM,EAAK7H,GAAOxJ,OAAOoR,KACpC,QAAeA,EAAK,KACbJ,EAAcK,EAAK7H,KAElC,EAkEAyH,EAAKP,GA3BLjX,eAAuBuO,EAAU5Z,EAAU,CAAC,GACxC,IAAIijB,EAAM,UAAWrJ,EAAWA,EAAW,IAAI,KAASA,GACpDwJ,QAlBR/X,eAAwBuO,GACpB,IAAI,MAAEI,EAAK,KAAElP,GAAS8O,EAAShP,QAAQ,aACnCpB,QAAaoQ,EAASI,MAAMhO,IAAIlB,GACpC,IAAKtB,EACD,MAAM,IAAI,IAAkB,oBAAqB,CAC7C9I,MAAO,IAAI,IAASoK,KAG5B,IAAIuY,GAAW,QAAmB7Z,GAIlC,MAH2B,UAAvB6Z,EAASC,YACTD,EAAS3H,YAAa,QAAsB2H,IAElB,UAAvBA,EAASC,UACV,IAAI,KAAMtJ,EAAOJ,EAAS9O,KAAMuY,GAChC,IAAI,KAAMrJ,EAAOJ,EAAS9O,KAAMuY,EAC1C,CAGqBE,CAASN,GAE1B,GADAjB,EAAgBO,UAAUU,EAAIjJ,MAAO,WAChBzZ,IAAjBP,EAAQ8S,KACR,OAAOsQ,EACX,GAAqB,UAAjBpjB,EAAQ8S,MAAoBsQ,aAAgB,KAC5C,OAAOA,EACX,GAAqB,UAAjBpjB,EAAQ8S,MAAoBsQ,aAAgB,KAC5C,OAAOA,EACX,IAAItQ,EAAOsQ,aAAgB,KAAQ,QAAU,QAC7C,MAAM,IAAItjB,MAAM,yBAAyBE,EAAQ8S,eAAeA,KACpE,C,qDCjFO,MAAM0Q,EACT,GACA,WAAA7kB,CAAYuY,EAAGzD,EAAYhU,GACN,iBAANyX,EACPrY,MAAK,EAAS,IAAI4M,WAAWyL,GAExBA,aAAauM,YAClB5kB,MAAK,EAAS,IAAI4M,WAAWyL,EAAGzD,EAAYhU,GAG5CZ,MAAK,EAAS,IAAI4M,WAAW7H,MAAMwB,KAAK8R,GAAInW,GAAOA,EAAI,EAAI,IAEnE,CACA,qBAAI+S,GACA,OAAO,CACX,CACA,cAAIL,GACA,OAAO5U,MAAK,EAAO4U,UACvB,CACA,cAAIC,GACA,OAAO7U,MAAK,EAAO6U,UACvB,CACA,UAAIF,GACA,OAAO3U,MAAK,EAAO2U,MACvB,CACA,UAAI/T,GACA,OAAOZ,MAAK,EAAOY,MACvB,CACA,GAAAuM,CAAI1G,GACA,IAAIyI,EAAQlP,MAAK,EAAOyG,GACxB,MAAwB,iBAAVyI,EAA+B,IAAVA,EAAcA,CACrD,CACA,GAAApN,CAAI2E,EAAKyI,GACLlP,MAAK,EAAOyG,GAAOyI,EAAQ,EAAI,CACnC,CACA,IAAArF,CAAKqF,GACDlP,MAAK,EAAO6J,KAAKqF,EAAQ,EAAI,EACjC,CACA,EAAE9J,OAAOC,YACL,IAAK,IAAI/C,EAAI,EAAGA,EAAItC,KAAKY,OAAQ0B,UACvBtC,KAAKmN,IAAI7K,EAEvB,EAOG,MAAMuiB,EACTC,MACAhM,MACA,GACA,WAAAhZ,CAAYgZ,EAAOT,EAAGzD,EAAYhU,GAG9B,GAFAZ,KAAK8Y,MAAQA,EACb9Y,MAAK,EAAW,IAAI8X,YACH,iBAANO,EACPrY,KAAK8kB,MAAQ,IAAIlY,WAAWyL,EAAIS,QAE/B,GAAIT,aAAauM,YACdhkB,IACAA,GAAkBkY,GACtB9Y,KAAK8kB,MAAQ,IAAIlY,WAAWyL,EAAGzD,EAAYhU,OAE1C,CACD,IAAImkB,EAAShgB,MAAMwB,KAAK8R,GACxBrY,KAAK8kB,MAAQ,IAAIlY,WAAWmY,EAAOnkB,OAASkY,GAC5C,IAAK,IAAIxW,EAAI,EAAGA,EAAIyiB,EAAOnkB,OAAQ0B,IAC/BtC,KAAK8B,IAAIQ,EAAGyiB,EAAOziB,GAE3B,CACJ,CACA,qBAAI2S,GACA,OAAOjV,KAAK8Y,KAChB,CACA,cAAIlE,GACA,OAAO5U,KAAK8kB,MAAMlQ,UACtB,CACA,cAAIC,GACA,OAAO7U,KAAK8kB,MAAMjQ,UACtB,CACA,UAAIF,GACA,OAAO3U,KAAK8kB,MAAMnQ,MACtB,CACA,UAAI/T,GACA,OAAOZ,KAAK6U,WAAa7U,KAAKiV,iBAClC,CACA,GAAA9H,CAAI1G,GACA,MAAMiT,EAAO,IAAI9M,WAAW5M,KAAK2U,OAAQ3U,KAAK4U,WAAa5U,KAAK8Y,MAAQrS,EAAKzG,KAAK8Y,OAElF,OAAO,IAAIW,aAAcjF,OAAOkF,GAAMlC,QAAQ,QAAS,GAC3D,CACA,GAAA1V,CAAI2E,EAAKyI,GACL,MAAMwK,EAAO,IAAI9M,WAAW5M,KAAK2U,OAAQ3U,KAAK4U,WAAa5U,KAAK8Y,MAAQrS,EAAKzG,KAAK8Y,OAClFY,EAAK7P,KAAK,GACV6P,EAAK5X,IAAI9B,MAAK,EAASsU,OAAOpF,GAClC,CACA,IAAArF,CAAKqF,GACD,MAAM8V,EAAUhlB,MAAK,EAASsU,OAAOpF,GACrC,IAAK,IAAI5M,EAAI,EAAGA,EAAItC,KAAKY,OAAQ0B,IAC7BtC,KAAK8kB,MAAMhjB,IAAIkjB,EAAS1iB,EAAItC,KAAK8Y,MAEzC,CACA,EAAE1T,OAAOC,YACL,IAAK,IAAI/C,EAAI,EAAGA,EAAItC,KAAKY,OAAQ0B,UACvBtC,KAAKmN,IAAI7K,EAEvB,EAOG,MAAM2iB,EACT,GACAnM,MACA,WAAAhZ,CAAYgZ,EAAOT,EAAGzD,EAAYhU,GAE9B,GADAZ,KAAK8Y,MAAQA,EACI,iBAANT,EACPrY,MAAK,EAAQ,IAAIklB,WAAW7M,EAAIS,QAE/B,GAAIT,aAAauM,YACdhkB,IACAA,GAAUkY,GACd9Y,MAAK,EAAQ,IAAIklB,WAAW7M,EAAGzD,EAAYhU,OAE1C,CACD,MAAMmkB,EAAS1M,EACTkD,EAAI,IAAI0J,EAAmBnM,EAAO,GACxC9Y,MAAK,EAAQ,IAAIklB,WAAW,YACxB,IAAK,IAAIC,KAAOJ,EACZxJ,EAAEzZ,IAAI,EAAGqjB,SACF5J,GAAE,CAEhB,CAL2B,GAMhC,CACJ,CACA,qBAAItG,GACA,OAAOjV,MAAK,EAAMiV,kBAAoBjV,KAAK8Y,KAC/C,CACA,cAAIjE,GACA,OAAO7U,MAAK,EAAM6U,UACtB,CACA,cAAID,GACA,OAAO5U,MAAK,EAAM4U,UACtB,CACA,UAAID,GACA,OAAO3U,MAAK,EAAM2U,MACtB,CACA,UAAI/T,GACA,OAAOZ,MAAK,EAAMY,OAASZ,KAAK8Y,KACpC,CACA,GAAA3L,CAAI1G,GACA,MAAM5B,EAAS7E,KAAK8Y,MAAQrS,EAC5B,IAAIjB,EAAS,GACb,IAAK,IAAIlD,EAAI,EAAGA,EAAItC,KAAK8Y,MAAOxW,IAC5BkD,GAAU4f,OAAOC,cAAcrlB,MAAK,EAAM6E,EAASvC,IAGvD,OAAOkD,EAAOgS,QAAQ,UAAW,GACrC,CACA,GAAA1V,CAAI2E,EAAKyI,GACL,MAAMrK,EAAS7E,KAAK8Y,MAAQrS,EACtBiT,EAAO1Z,MAAK,EAAMugB,SAAS1b,EAAQA,EAAS7E,KAAK8Y,OACvDY,EAAK7P,KAAK,GACV,IAAK,IAAIvH,EAAI,EAAGA,EAAItC,KAAK8Y,MAAOxW,IAC5BoX,EAAKpX,GAAK4M,EAAMoW,YAAYhjB,IAAM,CAE1C,CACA,IAAAuH,CAAKqF,GAEDlP,KAAK8B,IAAI,EAAGoN,GAEZ,IAAI8V,EAAUhlB,MAAK,EAAMugB,SAAS,EAAGvgB,KAAK8Y,OAC1C,IAAK,IAAIxW,EAAI,EAAGA,EAAItC,KAAKY,OAAQ0B,IAC7BtC,MAAK,EAAM8B,IAAIkjB,EAAS1iB,EAAItC,KAAK8Y,MAEzC,CACA,EAAE1T,OAAOC,YACL,IAAK,IAAI/C,EAAI,EAAGA,EAAItC,KAAKY,OAAQ0B,UACvBtC,KAAKmN,IAAI7K,EAEvB,E,4JC5LG,SAASijB,EAAmBjQ,GAC/B,MAAM6P,GAAM,IAAI1L,aAAcjF,OAAOc,GACrC,OAAOgC,KAAKkO,MAAML,EACtB,CACO,SAASM,EAAiB/L,EAAM3E,GACnC,MAAM2Q,EAAW3Q,EAAoB,EAC/B4Q,EAAe5Q,EAAoB,EACzC,IAAIpO,EAAI,EACR,IAAK,IAAIrE,EAAI,EAAGA,EAAIoX,EAAK9Y,OAAQ0B,GAAKyS,EAClC,IAAK,IAAI6Q,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAC/Bjf,EAAI+S,EAAKpX,EAAIsjB,GACblM,EAAKpX,EAAIsjB,GAAKlM,EAAKpX,EAAIqjB,EAAeC,GACtClM,EAAKpX,EAAIqjB,EAAeC,GAAKjf,CAGzC,CACO,SAASkf,EAAQzQ,GACpB,GAAkB,cAAdA,EACA,OAAOqL,WAAW1b,MAEtB,IAAI+gB,EAAQ1Q,EAAU0Q,MAAM,kBAC5B,GAAIA,EAAO,CACP,IAAK,CAAE7R,EAAM6E,GAASgN,EAEtB,OAAiB,MAAT7R,EAAe,KAAqB,MAAiBoH,KAAK,KAAM1Y,OAAOmW,GACnF,CAEA,IAAIiN,EAAM,CACNC,KAAMC,UACNC,MAAOC,WACPC,MAAOlB,WACPmB,MAAO5F,WAAW6F,cAClBC,MAAO3Z,WACP4Z,OAAQC,YACRC,OAAQhS,YACRiS,OAAQlG,WAAWmG,eACnBC,QAASpG,WAAWqG,aACpBC,QAASC,aACTC,QAASC,aACTC,KAAM,MACR/R,GAEF,OADAgS,EAAOrB,EAAK,qCAAqC3Q,KAC1C2Q,CACX,CAEO,SAAS7I,EAAYxe,EAAOwZ,GAC/B,MAAMC,EAAOzZ,EAAMkC,OACE,iBAAVsX,IACPA,EACc,MAAVA,EACMnT,MAAMwB,KAAK,CAAE3F,OAAQuX,IAAQ,CAAC3R,EAAGlE,IAAMA,IACvCyC,MAAMwB,KAAK,CAAE3F,OAAQuX,IAAQ,CAAC3R,EAAGlE,IAAM6V,EAAO,EAAI7V,KAEhE8kB,EAAOjP,IAASD,EAAMtX,OAAQ,qDAC9B,IAAIie,EAAO,EACPtJ,EAAS,IAAIxQ,MAAMoT,GACvB,IAAK,IAAI7V,EAAI4V,EAAMtX,OAAS,EAAG0B,GAAK,EAAGA,IACnCiT,EAAO2C,EAAM5V,IAAMuc,EACnBA,GAAQngB,EAAMwZ,EAAM5V,IAExB,OAAOiT,CACX,CAEO,SAAS8R,GAAyB,KAAEzoB,EAAI,cAAEsV,IAC7C,GAAa,YAATtV,EAAoB,CACpB,MAAM0oB,EAAYpT,GAAeoT,WAAa,IAC9C,OAAQjK,GAAiB,CAAC,OAAQA,GAAc1O,KAAK2Y,EACzD,CACA,GAAa,OAAT1oB,EAAe,CACf,MAAM0oB,EAAYpT,GAAeoT,WAAa,IAC9C,OAAQjK,GAAiBA,EAAa1O,KAAK2Y,IAAc,GAC7D,CACA,MAAM,IAAIrmB,MAAM,+BAA+BrC,IACnD,CA6BO,SAAS2oB,EAAwB5c,EAAM6R,EAAa,CAAC,GACxD,IAAInC,EAAS,GACToD,EA9BR,SAAsBA,GAClB,GAAc,OAAVA,EACA,MAAO,CAAErI,UAAW,aAExB,IAAI0Q,EAAQrI,EAAMqI,MAAM,iBACxBsB,EAAOtB,EAAO,kBAAkBrI,KAChC,IAAK,CAAEtI,EAAQqS,GAAQ1B,EACnB1Q,EAAY,CACZqS,GAAI,OACJC,GAAI,OACJC,GAAI,QACJC,GAAI,QACJC,GAAI,SACJC,GAAI,QACJC,GAAI,SACJC,GAAI,QACJC,GAAI,SACJC,GAAI,UACJC,GAAI,UACJC,GAAI,WACNZ,KACGA,EAAKhY,WAAW,MAAQgY,EAAKhY,WAAW,KAAO,MAAMgY,SAAS9lB,GAEnE,OADA0lB,EAAOhS,EAAW,iCAAiCqI,KACpC,MAAXtI,EACO,CAAEC,aAEN,CAAEA,YAAWD,OAAmB,MAAXA,EAAiB,SAAW,MAC5D,CAGgBkT,CAAa1d,EAAK8S,OACX,MAAf9S,EAAKuN,OACLmC,EAAO9X,KAAK,CAAE3D,KAAM,YAAasV,cAAe,CAAEgE,MAAO,OAEzD,WAAYuF,GAA0B,QAAjBA,EAAMtI,QAC3BkF,EAAO9X,KAAK,CAAE3D,KAAM,QAASsV,cAAe,CAAEiB,OAAQ,SAE1D,IAAK,IAAI,GAAEmT,KAAOpU,KAAmBvJ,EAAK4d,SAAW,GACjDlO,EAAO9X,KAAK,CAAE3D,KAAM0pB,EAAIpU,kBAE5B,GAAIvJ,EAAK6d,WAAY,CACjB,IAAI,GAAEF,KAAOpU,GAAkBvJ,EAAK6d,WACpCnO,EAAO9X,KAAK,CAAE3D,KAAM0pB,EAAIpU,iBAC5B,CACA,MAAO,CACHuU,YAAa,EACbhE,UAAW,QACX/lB,MAAOiM,EAAKjM,MACZ0W,UAAWqI,EAAMrI,UACjBgI,WAAY,CACRxe,KAAM,UACNsV,cAAe,CACXsH,YAAa7Q,EAAK5H,SAG1Bia,mBAAoB,CAChBpe,KAAM,KACNsV,cAAe,CACXoT,UAAW3c,EAAK+d,qBAAuB,MAG/CrO,SACAwC,WAAYlS,EAAKkS,WACjBL,aAER,CACO,SAASmM,EAAwBxU,EAAOqI,EAAa,CAAC,GACzD,MAAO,CACHiM,YAAa,EACbhE,UAAW,QACXjI,aAER,CACO,SAASoM,EAASnL,EAAOI,GAC5B,GAAc,WAAVA,GACU,WAAVA,GACU,YAAVA,GACU,WAAVA,GACU,WAAVA,EACA,OAAOJ,IAAUI,EAErB,IAAIgL,EAAuB,SAAVpL,EACjB,GAAc,YAAVI,EACA,OAAOgL,EACX,IAAIC,EAAYrL,EAAMjO,WAAW,SAAWiO,EAAMjO,WAAW,QAC7D,GAAc,WAAVqO,EACA,OAAOiL,EACX,IAAIC,EAAsB,UAAVtL,GAA+B,WAAVA,EACrC,GAAc,WAAVI,EACA,OAAOkL,EACX,IAAIC,EAAsB,cAAVvL,EAChB,MAAc,WAAVI,EACOmL,IACHF,GAAcC,GAAcF,GAAeG,EACvD,CACO,SAASC,EAAkB1O,GAC9B,MAAuB,qBAAhBA,GAAO3b,IAClB,CACO,SAASsqB,EAAsB5M,GAClC,MAA4B,WAAvBA,EAASlH,WAAiD,UAAvBkH,EAASlH,WACtB,MAAvBkH,EAASO,WAINP,EAASO,WAFLsM,OAAO7M,EAASO,WAG/B,CA0BO,SAASuM,EAAeC,KAAUC,GACrC,IAAKA,EAAO9lB,MAAM+lB,GAAeF,aAAiBE,IAC9C,MAAMF,CAEd,CAgBO,SAASjC,EAAOoC,EAAYzL,EAAM,IACrC,IAAKyL,EACD,MAAM,IAAIvoB,MAAM8c,EAExB,CASOvR,eAAeid,EAAWje,GAAM,OAAEmK,EAAM,OAAE+T,IAC7C,MAAMhd,EAAWlB,aAAgBme,SAAWne,EAAO,IAAIme,SAASne,GAChE4b,EAAO1a,EAASkd,KAAM,mCACtB,IACI,MAAMC,EAAuB,IAAIF,SAASjd,EAASkd,KAAKE,YAAY,IAAIC,oBAAoBpU,GAAS,CAAE+T,YAEvG,aADqBG,EAAqBhd,aAE9C,CACA,MAEI,MADA6c,GAAQM,iBACF,IAAI/oB,MAAM,oBAAoB0U,IACxC,CACJ,C","sources":["webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/VolumeDims.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/ImageInfo.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/VolumeLoadError.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/ChunkPrefetchIterator.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/utils.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/validation.js","webpack://@aics/vole-app/./node_modules/@zarrita/storage/dist/src/util.js","webpack://@aics/vole-app/./node_modules/@zarrita/storage/dist/src/fetch.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/wrappers.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/RequestQueue.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/SubscribableRequestQueue.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/workers/types.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/workers/util.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/bitround.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/bytes.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/crc32c.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/gzip.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/json2.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/transpose.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/vlen-utf8.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/zlib.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/sharding.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/hierarchy.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/indexer.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/ops.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/get.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/util.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/open.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/typedarray.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/util.js"],"sourcesContent":["import { Vector3 } from \"three\";\nexport function defaultVolumeDims() {\n  return {\n    shape: [0, 0, 0, 0, 0],\n    spacing: [1, 1, 1, 1, 1],\n    spaceUnit: \"μm\",\n    timeUnit: \"s\",\n    dataType: \"uint8\"\n  };\n}\nexport function volumeSize(volumeDims) {\n  return new Vector3(volumeDims.shape[4], volumeDims.shape[3], volumeDims.shape[2]);\n}\nexport function physicalPixelSize(volumeDims) {\n  return new Vector3(volumeDims.spacing[4], volumeDims.spacing[3], volumeDims.spacing[2]);\n}","import { volumeSize, physicalPixelSize } from \"./VolumeDims.js\";\nimport { Vector3, Vector2 } from \"three\";\nexport function defaultImageInfo() {\n  return {\n    name: \"\",\n    atlasTileDims: [1, 1],\n    subregionSize: [1, 1, 1],\n    subregionOffset: [0, 0, 0],\n    numChannelsPerSource: [1],\n    channelNames: [\"0\"],\n    channelColors: [[255, 255, 255]],\n    multiscaleLevel: 0,\n    multiscaleLevelDims: [{\n      shape: [1, 1, 1, 1, 1],\n      spacing: [1, 1, 1, 1, 1],\n      spaceUnit: \"\",\n      timeUnit: \"\",\n      dataType: \"uint8\"\n    }],\n    transform: {\n      translation: [0, 0, 0],\n      rotation: [0, 0, 0],\n      scale: [1, 1, 1]\n    }\n  };\n}\nexport class CImageInfo {\n  constructor(imageInfo) {\n    this.imageInfo = imageInfo || defaultImageInfo();\n  }\n  get currentLevelDims() {\n    return this.imageInfo.multiscaleLevelDims[this.imageInfo.multiscaleLevel];\n  }\n\n  /** Number of channels in the image */\n  get numChannels() {\n    return this.imageInfo.numChannelsPerSource.reduce((a, b) => a + b, 0);\n  }\n\n  /** Number of channels per source, ordered by source index */\n  get numChannelsPerSource() {\n    return this.imageInfo.numChannelsPerSource;\n  }\n\n  /** XYZ size of the *original* (not downsampled) volume, in pixels */\n  get originalSize() {\n    return volumeSize(this.imageInfo.multiscaleLevelDims[0]);\n  }\n\n  /** Size of the volume, in pixels */\n  get volumeSize() {\n    return volumeSize(this.currentLevelDims);\n  }\n\n  /** Size of a single *original* (not downsampled) pixel, in spatial units */\n  get physicalPixelSize() {\n    return physicalPixelSize(this.imageInfo.multiscaleLevelDims[0]);\n  }\n\n  /** Symbol of physical spatial unit used by `physicalPixelSize` */\n  get spatialUnit() {\n    return this.imageInfo.multiscaleLevelDims[0].spaceUnit;\n  }\n\n  /** Number of timesteps in the time series, or 1 if the image is not a time series */\n  get times() {\n    // 0 is T\n    return this.currentLevelDims.shape[0];\n  }\n\n  /** Size of each timestep in temporal units */\n  get timeScale() {\n    // 0 is T\n    return this.currentLevelDims.spacing[0];\n  }\n\n  /** Symbol of physical time unit used by `timeScale` */\n  get timeUnit() {\n    return this.currentLevelDims.timeUnit;\n  }\n\n  /** Number of scale levels available for this volume */\n  get numMultiscaleLevels() {\n    return this.imageInfo.multiscaleLevelDims.length;\n  }\n\n  /** The names of each channel */\n  get channelNames() {\n    return this.imageInfo.channelNames;\n  }\n\n  /** Optional overrides to default channel colors, in 0-255 range */\n  get channelColors() {\n    return this.imageInfo.channelColors;\n  }\n\n  /** Size of the currently loaded subregion, in pixels */\n  get subregionSize() {\n    return new Vector3(...this.imageInfo.subregionSize);\n  }\n\n  /** Offset of the loaded subregion into the total volume, in pixels */\n  get subregionOffset() {\n    return new Vector3(...this.imageInfo.subregionOffset);\n  }\n  get multiscaleLevel() {\n    return this.imageInfo.multiscaleLevel;\n  }\n\n  /**\n   * XY dimensions of the texture atlas used by `RayMarchedAtlasVolume` and `Atlas2DSlice`, in number of z-slice\n   * tiles (not pixels). Chosen by the loader to lay out the 3D volume in the squarest possible 2D texture atlas.\n   */\n  get atlasTileDims() {\n    return new Vector2(...this.imageInfo.atlasTileDims);\n  }\n  get transform() {\n    return {\n      translation: new Vector3(...this.imageInfo.transform.translation),\n      rotation: new Vector3(...this.imageInfo.transform.rotation),\n      scale: new Vector3(...this.imageInfo.transform.scale)\n    };\n  }\n}\nexport function computeAtlasSize(imageInfo) {\n  const {\n    atlasTileDims\n  } = imageInfo;\n  const volDims = imageInfo.multiscaleLevelDims[imageInfo.multiscaleLevel];\n  // TCZYX: 4 = x, 3 = y\n  return [atlasTileDims[0] * volDims.shape[4], atlasTileDims[1] * volDims.shape[3]];\n}","import { errorConstructors } from \"serialize-error\";\nimport { NodeNotFoundError, KeyError } from \"zarrita\";\n// geotiff doesn't export its error types...\n\n/** Groups possible load errors into a few broad categories which we can give similar guidance to the user about. */\nexport let VolumeLoadErrorType = /*#__PURE__*/function (VolumeLoadErrorType) {\n  VolumeLoadErrorType[\"UNKNOWN\"] = \"unknown\";\n  VolumeLoadErrorType[\"NOT_FOUND\"] = \"not_found\";\n  VolumeLoadErrorType[\"TOO_LARGE\"] = \"too_large\";\n  VolumeLoadErrorType[\"LOAD_DATA_FAILED\"] = \"load_data_failed\";\n  VolumeLoadErrorType[\"INVALID_METADATA\"] = \"invalid_metadata\";\n  VolumeLoadErrorType[\"INVALID_MULTI_SOURCE_ZARR\"] = \"invalid_multi_source_zarr\";\n  return VolumeLoadErrorType;\n}({});\nexport class VolumeLoadError extends Error {\n  constructor(message, options) {\n    super(message, options);\n    this.name = \"VolumeLoadError\";\n    this.type = options?.type ?? VolumeLoadErrorType.UNKNOWN;\n  }\n}\n\n// serialize-error only ever calls an error constructor with zero arguments. The required `ErrorConstructor`\n// type is a bit too restrictive - as long as the constructor can be called with no arguments it's fine.\nerrorConstructors.set(\"NodeNotFoundError\", NodeNotFoundError);\nerrorConstructors.set(\"KeyError\", KeyError);\nerrorConstructors.set(\"VolumeLoadError\", VolumeLoadError);\n\n/** Curried function to re-throw an error wrapped in a `VolumeLoadError` with the given `message` and `type`. */\nexport function wrapVolumeLoadError(message = \"Unknown error occurred while loading volume data\", type = VolumeLoadErrorType.UNKNOWN, ignore) {\n  return e => {\n    if (ignore !== undefined && e === ignore) {\n      return e;\n    }\n    if (e instanceof VolumeLoadError) {\n      throw e;\n    }\n    console.log(`Error loading volume data: ${e}`);\n    throw new VolumeLoadError(message, {\n      type,\n      cause: e\n    });\n  };\n}","const allEqual = arr => arr.every(v => v === arr[0]);\nconst pushN = (arr, val, n) => {\n  for (let i = 0; i < n; i++) {\n    arr.push(val);\n  }\n};\nconst directionToIndex = dir => {\n  const absDir = dir >> 1; // shave off sign bit to get index in TZYX\n  return absDir + Number(absDir !== 0); // convert TZYX -> TCZYX by skipping c (index 1)\n};\nfunction updateMinMax(val, minmax) {\n  if (val < minmax[0]) {\n    minmax[0] = val;\n  }\n  if (val > minmax[1]) {\n    minmax[1] = val;\n  }\n}\n\n/**\n * Since the user is most likely to want nearby data (in space or time) first, we should prefetch those chunks first.\n *\n * Given a list of just-loaded chunks and some bounds, `ChunkPrefetchIterator` iterates evenly outwards in T/Z/Y/X.\n */\n// NOTE: Assumes `chunks` form a rectangular prism! Will create gaps otherwise! (in practice they always should)\nexport default class ChunkPrefetchIterator {\n  constructor(chunks, tzyxMaxPrefetchOffset, tczyxChunksPerSource, priorityDirections, onlyPriorityDirections = false) {\n    // Get min and max chunk coordinates for T/Z/Y/X\n    const extrema = [[Infinity, -Infinity], [Infinity, -Infinity], [Infinity, -Infinity], [Infinity, -Infinity]];\n    for (const chunk of chunks) {\n      updateMinMax(chunk[0], extrema[0]);\n      updateMinMax(chunk[2], extrema[1]);\n      updateMinMax(chunk[3], extrema[2]);\n      updateMinMax(chunk[4], extrema[3]);\n    }\n\n    // Bail out if we have any non-finite values in the extrema (the iterator will be empty)\n    if (extrema.flat().some(val => !Number.isFinite(val))) {\n      this.directionStates = [];\n      this.priorityDirectionStates = [];\n      return;\n    }\n\n    // Create `PrefetchDirectionState`s for each direction\n    this.directionStates = [];\n    this.priorityDirectionStates = [];\n\n    // iterating like this: direction is the index in the flattened entries\n    // and corresponds to our +T, -T, +Z, -Z, +Y, -Y, +X, -X directions in order\n    // because extrema is in TZYX order.\n    for (const [direction, start] of extrema.flat().entries()) {\n      const dimension = direction >> 1; // shave off sign bit to get index in TZYX\n      const tczyxIndex = dimension + Number(dimension !== 0); // convert TZYX -> TCZYX by skipping c (index 1)\n      let end;\n      if (direction & 1) {\n        // Positive direction - end is either the max coordinate in the fetched set plus the max offset in this\n        // dimension, or the max chunk coordinate in this dimension, whichever comes first\n        const endsPerSource = tczyxChunksPerSource.map(chunkDims => {\n          return Math.min(start + tzyxMaxPrefetchOffset[dimension], chunkDims[tczyxIndex] - 1);\n        });\n\n        // Save some time: if all sources have the same end, we can just store that\n        if (allEqual(endsPerSource)) {\n          end = endsPerSource[0];\n        } else {\n          // Otherwise, expand our ends per source array to ends per channel\n          end = [];\n          for (const [i, sourceEnd] of endsPerSource.entries()) {\n            pushN(end, sourceEnd, tczyxChunksPerSource[i][1]);\n          }\n        }\n        // end = Math.min(start + tzyxMaxPrefetchOffset[dimension], tczyxChunksPerDimension[dimension] - 1);\n      } else {\n        // Negative direction - end is either the min coordinate in the fetched set minus the max offset in this\n        // dimension, or 0, whichever comes first\n        end = Math.max(start - tzyxMaxPrefetchOffset[dimension], 0);\n      }\n      const directionState = {\n        direction,\n        start,\n        end,\n        chunks: []\n      };\n      if (priorityDirections && priorityDirections.includes(direction)) {\n        this.priorityDirectionStates.push(directionState);\n      } else {\n        // we have an option setting that can let us ignore non-priority directions\n        if (!onlyPriorityDirections) {\n          this.directionStates.push(directionState);\n        }\n      }\n    }\n\n    // Fill each `PrefetchDirectionState` with chunks at the border of the fetched set\n    for (const chunk of chunks) {\n      for (const dir of this.directionStates) {\n        if (chunk[directionToIndex(dir.direction)] === dir.start) {\n          dir.chunks.push(chunk);\n        }\n      }\n      for (const dir of this.priorityDirectionStates) {\n        if (chunk[directionToIndex(dir.direction)] === dir.start) {\n          dir.chunks.push(chunk);\n        }\n      }\n    }\n  }\n  static *iterateDirections(directions) {\n    let offset = 1;\n    while (directions.length > 0) {\n      // Remove directions in which we have reached the end (or, if per-channel ends, the end for all channels)\n      directions = directions.filter(dir => {\n        const end = Array.isArray(dir.end) ? Math.max(...dir.end) : dir.end;\n        if (dir.direction & 1) {\n          return dir.start + offset <= end;\n        } else {\n          return dir.start - offset >= end;\n        }\n      });\n\n      // Yield chunks one chunk farther out in every remaining direction\n      for (const dir of directions) {\n        const offsetDir = offset * (dir.direction & 1 ? 1 : -1);\n        for (const chunk of dir.chunks) {\n          // Skip this chunk if this channel has a specific per-channel end and we've reached it\n          if (Array.isArray(dir.end) && chunk[directionToIndex(dir.direction)] + offsetDir > dir.end[chunk[1]]) {\n            continue;\n          }\n          const newChunk = chunk.slice();\n          newChunk[directionToIndex(dir.direction)] += offsetDir;\n          yield newChunk;\n        }\n      }\n      offset += 1;\n    }\n  }\n  *[Symbol.iterator]() {\n    // Yield all chunks in priority direction(s) first, if any\n    if (this.priorityDirectionStates.length > 0) {\n      for (const chunk of ChunkPrefetchIterator.iterateDirections(this.priorityDirectionStates)) {\n        yield chunk;\n      }\n    }\n\n    // Then yield all chunks in other directions\n    for (const chunk of ChunkPrefetchIterator.iterateDirections(this.directionStates)) {\n      yield chunk;\n    }\n  }\n}","import { VolumeLoadErrorType, VolumeLoadError } from \"../VolumeLoadError.js\";\n/**\n * Attempts to parse `color` as a 24-bit (6-digit) hexadecimal color with a possible leading `#`.\n *\n * Six-digit hex is the only allowable color representation in the OMERO metadata spec.\n */\nexport function parseHexColor(color) {\n  if (color === undefined) {\n    return undefined;\n  }\n  const result = /^#?([a-fA-F\\d]{2})([a-fA-F\\d]{2})([a-fA-F\\d]{2})$/i.exec(color);\n  if (result) {\n    return [parseInt(result[1], 16), parseInt(result[2], 16), parseInt(result[3], 16)];\n  } else {\n    return undefined;\n  }\n}\n\n/** Extracts channel names from a `ZarrSource`. Handles missing `omeroMetadata`. Does *not* resolve name collisions. */\nexport function getSourceChannelMeta(src) {\n  if (src.omeroMetadata?.channels) {\n    const {\n      channels\n    } = src.omeroMetadata;\n    const names = [];\n    const colors = [];\n    for (let i = 0; i < channels.length; i++) {\n      const channel = channels[i];\n      names.push(channel.label ?? `Channel ${i + src.channelOffset}`);\n      colors.push(parseHexColor(channel.color));\n    }\n    return {\n      names,\n      colors\n    };\n  }\n  const cIdx = src.axesTCZYX[1];\n  const length = cIdx < 0 ? 1 : src.scaleLevels[0].shape[cIdx];\n  const names = Array.from({\n    length\n  }, (_, idx) => `Channel ${idx + src.channelOffset}`);\n  const colors = Array.from({\n    length\n  }, () => undefined);\n  return {\n    names,\n    colors\n  };\n}\n\n/** Turns `axesTCZYX` into the number of dimensions in the array */\nexport const getDimensionCount = ([t, c, z]) => 2 + Number(t > -1) + Number(c > -1) + Number(z > -1);\nexport function remapAxesToTCZYX(axes) {\n  const axesTCZYX = [-1, -1, -1, -1, -1];\n  const axisNames = [\"t\", \"c\", \"z\", \"y\", \"x\"];\n  axes.forEach((axis, idx) => {\n    const axisIdx = axisNames.indexOf(axis.name);\n    if (axisIdx > -1) {\n      axesTCZYX[axisIdx] = idx;\n    } else {\n      throw new VolumeLoadError(`Unrecognized axis in zarr: ${axis.name}`, {\n        type: VolumeLoadErrorType.INVALID_METADATA\n      });\n    }\n  });\n\n  // it is possible that Z might not exist but we require X and Y at least.\n  const noXAxis = axesTCZYX[4] === -1;\n  if (noXAxis || axesTCZYX[3] === -1) {\n    throw new VolumeLoadError(`Did not find ${noXAxis ? \"an X\" : \"a Y\"} axis in zarr`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n  return axesTCZYX;\n}\n\n/** Reorder an array of values [T, C, Z, Y, X] to the given dimension order */\nexport function orderByDimension(valsTCZYX, orderTCZYX) {\n  const specLen = getDimensionCount(orderTCZYX);\n  const result = Array(specLen);\n  orderTCZYX.forEach((val, idx) => {\n    if (val >= 0) {\n      if (val >= specLen) {\n        throw new VolumeLoadError(`Unexpected axis index in zarr: ${val}`, {\n          type: VolumeLoadErrorType.INVALID_METADATA\n        });\n      }\n      result[val] = valsTCZYX[idx];\n    }\n  });\n  return result;\n}\n\n/** Reorder an array of values in the given dimension order to [T, C, Z, Y, X] */\nexport function orderByTCZYX(valsDimension, orderTCZYX, defaultValue) {\n  const result = [defaultValue, defaultValue, defaultValue, defaultValue, defaultValue];\n  orderTCZYX.forEach((val, idx) => {\n    if (val >= 0) {\n      if (val >= valsDimension.length) {\n        throw new VolumeLoadError(`Unexpected axis index in zarr: ${val}`, {\n          type: VolumeLoadErrorType.INVALID_METADATA\n        });\n      }\n      result[idx] = valsDimension[val];\n    }\n  });\n  return result;\n}\n\n/** Select the scale transform from an OME metadata object with coordinate transforms, and return it in TCZYX order */\nexport function getScale(dataset, orderTCZYX) {\n  const transforms = dataset.coordinateTransformations;\n  if (transforms === undefined) {\n    console.warn(\"WARNING: OMEZarrLoader: no coordinate transformations for scale level.\");\n    return [1, 1, 1, 1, 1];\n  }\n\n  // this assumes we'll never encounter the \"path\" variant\n  const isScaleTransform = t => t.type === \"scale\";\n\n  // there can be any number of coordinateTransformations\n  // but there must be only one of type \"scale\".\n  const scaleTransform = transforms.find(isScaleTransform);\n  if (!scaleTransform) {\n    console.warn(`WARNING: OMEZarrLoader: no coordinate transformation of type \"scale\" for scale level.`);\n    return [1, 1, 1, 1, 1];\n  }\n  const scale = scaleTransform.scale.slice();\n  return orderByTCZYX(scale, orderTCZYX, 1);\n}\n\n/**\n * Defines a partial order of zarr arrays based on their size. Specifically:\n * - If array size x, y, z are all equal, the arrays are equal\n * - otherwise, if all xyz of `a` are less than or equal to those of `b`, `a` is less than `b` (and vice versa)\n * - if some xyz is less and some is greater, the arrays are uncomparable\n */\nfunction compareZarrArraySize(aArr, aTCZYX, bArr, bTCZYX) {\n  const aZ = aTCZYX[2] > -1 ? aArr.shape[aTCZYX[2]] : 1;\n  const bZ = bTCZYX[2] > -1 ? bArr.shape[bTCZYX[2]] : 1;\n  const diffZ = aZ - bZ;\n  const diffY = aArr.shape[aTCZYX[3]] - bArr.shape[bTCZYX[3]];\n  const diffX = aArr.shape[aTCZYX[4]] - bArr.shape[bTCZYX[4]];\n  if (diffZ === 0 && diffY === 0 && diffX === 0) {\n    return 0;\n  } else if (diffZ <= 0 && diffY <= 0 && diffX <= 0) {\n    return -1;\n  } else if (diffZ >= 0 && diffY >= 0 && diffX >= 0) {\n    return 1;\n  } else {\n    return undefined;\n  }\n}\nconst EPSILON = 0.00001;\nconst aboutEquals = (a, b) => Math.abs(a - b) < EPSILON;\nfunction scaleTransformsAreEqual(aSrc, aLevel, bSrc, bLevel) {\n  const aScale = getScale(aSrc.multiscaleMetadata.datasets[aLevel], aSrc.axesTCZYX);\n  const bScale = getScale(bSrc.multiscaleMetadata.datasets[bLevel], bSrc.axesTCZYX);\n  return aboutEquals(aScale[2], bScale[2]) && aboutEquals(aScale[3], bScale[3]) && aboutEquals(aScale[4], bScale[4]);\n}\n\n/**\n * Ensures that all scale levels in `sources` are matched up by size. More precisely: enforces that, for any scale\n * level `i`, the size of zarr array `s[i]` is equal for every source `s`. We accomplish this by removing any arrays\n * (and their associated OME dataset metadata) which don't match up in all sources.\n *\n * Note that this function modifies the input `sources` array rather than returning a new value.\n *\n * Assumes all sources have scale levels ordered by size from largest to smallest. (This should always be true for\n * compliant OME-Zarr data.)\n */\nexport function matchSourceScaleLevels(sources) {\n  if (sources.length < 2) {\n    return;\n  }\n\n  // Save matching scale levels and metadata here\n  const matchedLevels = Array.from({\n    length: sources.length\n  }, () => []);\n  const matchedMetas = Array.from({\n    length: sources.length\n  }, () => []);\n\n  // Start as many index counters as we have sources\n  const scaleIndexes = new Array(sources.length).fill(0);\n  while (scaleIndexes.every((val, idx) => val < sources[idx].scaleLevels.length)) {\n    // First pass: find the smallest source / determine if all sources are equal\n    let allEqual = true;\n    let smallestIdx = 0;\n    let smallestSrc = sources[0];\n    let smallestArr = smallestSrc.scaleLevels[scaleIndexes[0]];\n    for (let currentIdx = 1; currentIdx < sources.length; currentIdx++) {\n      const currentSrc = sources[currentIdx];\n      const currentArr = currentSrc.scaleLevels[scaleIndexes[currentIdx]];\n      const ordering = compareZarrArraySize(smallestArr, smallestSrc.axesTCZYX, currentArr, currentSrc.axesTCZYX);\n      if (!ordering) {\n        // Arrays are equal, or they are uncomparable\n        if (ordering === undefined) {\n          throw new VolumeLoadError(\"Incompatible zarr arrays: pixel dimensions are mismatched\", {\n            type: VolumeLoadErrorType.INVALID_MULTI_SOURCE_ZARR\n          });\n        }\n\n        // Now we know the arrays are equal, but they may still be invalid to match up because...\n        // ...they have different scale transformations\n        if (!scaleTransformsAreEqual(smallestSrc, scaleIndexes[smallestIdx], currentSrc, scaleIndexes[currentIdx])) {\n          // today we are going to treat this as a warning.\n          // For our implementation it is enough that the xyz pixel ranges are the same.\n          // Ideally scale*arraysize=physical size is really the quantity that should be equal, for combining two volume data sets as channels.\n          console.warn(\"Incompatible zarr arrays: scale levels of equal size have different scale transformations\");\n        }\n\n        // ...they have different numbers of timesteps\n        const largestT = smallestSrc.axesTCZYX[0] > -1 ? smallestArr.shape[smallestSrc.axesTCZYX[0]] : 1;\n        const currentT = currentSrc.axesTCZYX[0] > -1 ? currentArr.shape[currentSrc.axesTCZYX[0]] : 1;\n        if (largestT !== currentT) {\n          // we also treat this as a warning.\n          // In OmeZarrLoader we will take the minimum T size of all sources\n          console.warn(`Incompatible zarr arrays: different numbers of timesteps: ${largestT} vs ${currentT}`);\n        }\n      } else {\n        allEqual = false;\n        if (ordering > 0) {\n          smallestIdx = currentIdx;\n          smallestSrc = currentSrc;\n          smallestArr = currentArr;\n        }\n      }\n    }\n    if (allEqual) {\n      // We've found a matching set of scale levels! Save it and increment all indexes\n      for (let i = 0; i < scaleIndexes.length; i++) {\n        const currentSrc = sources[i];\n        const matchedScaleLevel = scaleIndexes[i];\n        matchedLevels[i].push(currentSrc.scaleLevels[matchedScaleLevel]);\n        matchedMetas[i].push(currentSrc.multiscaleMetadata.datasets[matchedScaleLevel]);\n        scaleIndexes[i] += 1;\n      }\n    } else {\n      // Increment the indexes of the sources which are larger than the smallest\n      for (const [idx, srcIdx] of scaleIndexes.entries()) {\n        const currentSrc = sources[idx];\n        const currentArr = currentSrc.scaleLevels[srcIdx];\n        const ordering = compareZarrArraySize(smallestArr, smallestSrc.axesTCZYX, currentArr, currentSrc.axesTCZYX);\n        if (ordering !== 0) {\n          scaleIndexes[idx] += 1;\n        }\n      }\n    }\n  }\n  if (sources[0].scaleLevels.length === 0) {\n    throw new VolumeLoadError(\"Incompatible zarr arrays: no sets of scale levels found that matched in all sources\", {\n      type: VolumeLoadErrorType.INVALID_MULTI_SOURCE_ZARR\n    });\n  }\n  for (let i = 0; i < sources.length; i++) {\n    sources[i].scaleLevels = matchedLevels[i];\n    sources[i].multiscaleMetadata.datasets = matchedMetas[i];\n  }\n}","import { VolumeLoadError, VolumeLoadErrorType } from \"../VolumeLoadError.js\";\n/**\n * If `meta` is the top-level metadata of a zarr node formatted according to the OME-Zarr spec version 0.5, returns\n * the object formatted according to v0.4 of the spec. For our purposes this just means flattening out the `ome` key.\n *\n * Return type is `unknown` because this does no actual validation; use `validateOMEZarrMetadata` for that.\n */\nexport const toOMEZarrMetaV4 = meta => meta.ome ?? meta;\nfunction isObjectWithProp(obj, prop) {\n  return typeof obj === \"object\" && obj !== null && prop in obj;\n}\nfunction assertMetadataHasProp(obj, prop, name = \"zarr\") {\n  if (!isObjectWithProp(obj, prop)) {\n    throw new VolumeLoadError(`${name} metadata is missing required entry \"${prop}\"`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n}\nfunction assertPropIsArray(obj, prop, name = \"zarr\") {\n  if (!Array.isArray(obj[prop])) {\n    throw new VolumeLoadError(`${name} metadata entry \"${prop}\" is not an array`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n}\n\n/** Intermediate stage of validation, before we've picked a single multiscale to validate */\n\nexport function assertMetadataHasMultiscales(meta, name = \"zarr\") {\n  // data is an object with a key \"multiscales\", which is a non-empty array\n  assertMetadataHasProp(meta, \"multiscales\", name);\n  assertPropIsArray(meta, \"multiscales\", name);\n}\n\n/**\n * Validates that the `OMEZarrMetadata` record `meta` has the minimal amount of data required to open a volume. Since\n * we only ever open one multiscale, we only validate the multiscale metadata record at index `multiscaleIdx` here.\n * `name` is used in error messages to identify the source of the metadata.\n */\nexport function validateOMEZarrMetadata(meta, multiscaleIdx = 0, name = \"zarr\") {\n  // check that a multiscale metadata entry exists at `multiscaleIdx`\n  const multiscaleMeta = meta.multiscales[multiscaleIdx];\n  if (!multiscaleMeta) {\n    throw new VolumeLoadError(`${name} metadata does not have requested multiscale level ${multiscaleIdx}`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n  const multiscaleMetaName = isObjectWithProp(multiscaleMeta, \"name\") ? ` (\"${multiscaleMeta.name})` : \"\";\n  const multiscaleName = `${name} multiscale ${multiscaleIdx}${multiscaleMetaName}`;\n\n  // multiscale has a key \"axes\", which is an array. Each axis has a \"name\".\n  assertMetadataHasProp(multiscaleMeta, \"axes\", multiscaleName);\n  assertPropIsArray(multiscaleMeta, \"axes\", multiscaleName);\n  multiscaleMeta.axes.forEach((axis, i) => assertMetadataHasProp(axis, \"name\", `${multiscaleName} axis ${i}`));\n\n  // multiscale has a key \"datasets\", which is an array. Each dataset has a \"path\".\n  assertMetadataHasProp(multiscaleMeta, \"datasets\", name);\n  assertPropIsArray(multiscaleMeta, \"datasets\", name);\n  multiscaleMeta.datasets.forEach((data, i) => assertMetadataHasProp(data, \"path\", `${multiscaleName} dataset ${i}`));\n}","export function strip_prefix(path) {\n    // @ts-expect-error - TS can't infer this type correctly\n    return path.slice(1);\n}\nexport function uri2href(url) {\n    let [protocol, rest] = (typeof url === \"string\" ? url : url.href).split(\"://\");\n    if (protocol === \"https\" || protocol === \"http\") {\n        return url;\n    }\n    if (protocol === \"gc\") {\n        return `https://storage.googleapis.com/${rest}`;\n    }\n    if (protocol === \"s3\") {\n        return `https://s3.amazonaws.com/${rest}`;\n    }\n    throw Error(`Protocol not supported, got: ${JSON.stringify(protocol)}`);\n}\nexport function fetch_range(url, offset, length, opts = {}) {\n    if (offset !== undefined && length !== undefined) {\n        // merge request opts\n        opts = {\n            ...opts,\n            headers: {\n                ...opts.headers,\n                Range: `bytes=${offset}-${offset + length - 1}`,\n            },\n        };\n    }\n    return fetch(url, opts);\n}\nexport function merge_init(storeOverrides, requestOverrides) {\n    // Request overrides take precedence over storeOverrides.\n    return {\n        ...storeOverrides,\n        ...requestOverrides,\n        headers: {\n            ...storeOverrides.headers,\n            ...requestOverrides.headers,\n        },\n    };\n}\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(expression, msg = \"\") {\n    if (!expression)\n        throw new Error(msg);\n}\n//# sourceMappingURL=util.js.map","import { fetch_range, merge_init } from \"./util.js\";\nfunction resolve(root, path) {\n    const base = typeof root === \"string\" ? new URL(root) : root;\n    if (!base.pathname.endsWith(\"/\")) {\n        // ensure trailing slash so that base is resolved as _directory_\n        base.pathname += \"/\";\n    }\n    const resolved = new URL(path.slice(1), base);\n    // copy search params to new URL\n    resolved.search = base.search;\n    return resolved;\n}\nasync function handle_response(response) {\n    if (response.status === 404) {\n        return undefined;\n    }\n    if (response.status === 200 || response.status === 206) {\n        return new Uint8Array(await response.arrayBuffer());\n    }\n    throw new Error(`Unexpected response status ${response.status} ${response.statusText}`);\n}\nasync function fetch_suffix(url, suffix_length, init, use_suffix_request) {\n    if (use_suffix_request) {\n        return fetch(url, {\n            ...init,\n            headers: { ...init.headers, Range: `bytes=-${suffix_length}` },\n        });\n    }\n    let response = await fetch(url, { ...init, method: \"HEAD\" });\n    if (!response.ok) {\n        // will be picked up by handle_response\n        return response;\n    }\n    let content_length = response.headers.get(\"Content-Length\");\n    let length = Number(content_length);\n    return fetch_range(url, length - suffix_length, length, init);\n}\n/**\n * Readonly store based in the [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n * Must polyfill `fetch` for use in Node.js.\n *\n * ```typescript\n * import * as zarr from \"zarrita\";\n * const store = new FetchStore(\"http://localhost:8080/data.zarr\");\n * const arr = await zarr.get(store, { kind: \"array\" });\n * ```\n */\nclass FetchStore {\n    url;\n    #overrides;\n    #use_suffix_request;\n    constructor(url, options = {}) {\n        this.url = url;\n        this.#overrides = options.overrides ?? {};\n        this.#use_suffix_request = options.useSuffixRequest ?? false;\n    }\n    #merge_init(overrides) {\n        return merge_init(this.#overrides, overrides);\n    }\n    async get(key, options = {}) {\n        let href = resolve(this.url, key).href;\n        let response = await fetch(href, this.#merge_init(options));\n        return handle_response(response);\n    }\n    async getRange(key, range, options = {}) {\n        let url = resolve(this.url, key);\n        let init = this.#merge_init(options);\n        let response;\n        if (\"suffixLength\" in range) {\n            response = await fetch_suffix(url, range.suffixLength, init, this.#use_suffix_request);\n        }\n        else {\n            response = await fetch_range(url, range.offset, range.length, init);\n        }\n        return handle_response(response);\n    }\n}\nexport default FetchStore;\n//# sourceMappingURL=fetch.js.map","import { FetchStore } from \"zarrita\";\nimport { isChunk } from \"../../VolumeCache.js\";\nexport default function wrapArray(array, basePath, cache, queue) {\n  const path = basePath.endsWith(\"/\") ? basePath.slice(0, -1) : basePath;\n  const keyBase = path + array.path + (array.path.endsWith(\"/\") ? \"\" : \"/\");\n  const getChunk = async (coords, opts) => {\n    if (opts?.subscriber && opts.reportChunk) {\n      opts.reportChunk(coords, opts.subscriber);\n    }\n    const fullKey = keyBase + coords.join(\",\");\n    const cacheResult = cache?.get(fullKey);\n    if (cacheResult && isChunk(cacheResult)) {\n      return cacheResult;\n    }\n    let result;\n    if (queue && opts?.subscriber) {\n      result = await queue.addRequest(fullKey, opts?.subscriber, () => array.getChunk(coords, opts), opts.isPrefetch);\n    } else {\n      result = await array.getChunk(coords, opts);\n    }\n    cache?.insert(fullKey, result);\n    return result;\n  };\n  return new Proxy(array, {\n    get: (target, prop) => {\n      if (prop === \"getChunk\") {\n        return getChunk;\n      }\n\n      // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy#no_private_property_forwarding\n      const value = target[prop];\n      if (value instanceof Function) {\n        return function (...args) {\n          return value.apply(target, args);\n        };\n      }\n      return value;\n    }\n  });\n}\nexport class RelaxedFetchStore extends FetchStore {\n  constructor(baseUrl, options) {\n    super(baseUrl, options);\n  }\n\n  // Solution for https://github.com/manzt/zarrita.js/pull/212\n  // taken from https://github.com/vitessce/vitessce/pull/2069\n  async get(key, options = {}) {\n    try {\n      return await super.get(key, options);\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    } catch (e) {\n      if (e?.message?.startsWith(\"Unexpected response status 403\")) {\n        return undefined;\n      }\n      throw e;\n    }\n  }\n}","/** Object format used when passing multiple requests to RequestQueue at once. */\n\nexport const DEFAULT_REQUEST_CANCEL_REASON = \"request cancelled\";\n\n/**\n * Internal object interface used by RequestQueue to store request metadata and callbacks.\n */\n\n/**\n * Manages a queue of asynchronous requests with unique string keys, which can be added to or cancelled.\n * If redundant requests with the same key are issued, the request action will only be run once per key\n * while the original request is still in the queue.\n */\nexport default class RequestQueue {\n  /**\n   * The maximum number of requests that can be handled concurrently.\n   * Once reached, additional requests will be queued up to run once a running request completes.\n   */\n\n  /**\n   * The maximum number of requests that can be handled concurrently if only low-priority requests are waiting. Set\n   * lower than `concurrencyLimit` to always leave space for high-priority requests. Cannot be set higher than\n   * `concurrencyLimit`.\n   */\n\n  /** A queue of requests that are ready to be executed, in order of request time. */\n\n  /** A queue of low-priority tasks that are ready to be executed. `queue` must be empty before any of these tasks run. */\n\n  /** Stores all requests, even those that are currently active. */\n\n  /** Stores requests whose actions are currently being run. */\n\n  /**\n   * Creates a new RequestQueue.\n   * @param maxActiveRequests The maximum number of requests that will be handled concurrently. This is 10 by default.\n   * @param maxLowPriorityRequests The maximum number of low-priority requests that will be handled concurrently. Equal\n   *    to `maxActiveRequests` by default, but may be set lower to always leave space for new high-priority requests.\n   */\n  constructor(maxActiveRequests = 10, maxLowPriorityRequests = 5) {\n    this.allRequests = new Map();\n    this.activeRequests = new Set();\n    this.queue = [];\n    this.queueLowPriority = [];\n    this.maxActiveRequests = maxActiveRequests;\n    this.maxLowPriorityRequests = Math.min(maxActiveRequests, maxLowPriorityRequests);\n  }\n\n  /**\n   * Stores request metadata to the internal map of all pending requests.\n   * @param key string identifier of the request.\n   * @param requestAction callable function action of the request.\n   * @returns a reference to the new, registered RequestItem.\n   */\n  registerRequest(key, requestAction) {\n    // Create a new promise and store the resolve and reject callbacks for later.\n    // This lets us perform the actual action at a later point, when the request is at the\n    // front of the processing queue.\n    let promiseResolve, promiseReject;\n    const promise = new Promise((resolve, reject) => {\n      promiseResolve = resolve;\n      promiseReject = reject;\n    });\n    // Store the request data.\n    const requestItem = {\n      key: key,\n      action: requestAction,\n      resolve: promiseResolve,\n      reject: promiseReject,\n      promise\n    };\n    this.allRequests.set(key, requestItem);\n    return requestItem;\n  }\n\n  /**\n   * Moves a registered request into the processing queue, clearing any timeouts on the request.\n   * @param key string identifier of the request.\n   * @param lowPriority Whether this request should be added with low priority. False by default.\n   */\n  addRequestToQueue(key, lowPriority) {\n    // Check that this request is not cancelled.\n    if (this.allRequests.has(key)) {\n      // Clear the request timeout, if it has one, since it is being added to the queue.\n      const requestItem = this.allRequests.get(key);\n      if (requestItem && requestItem.timeoutId) {\n        clearTimeout(requestItem.timeoutId);\n        requestItem.timeoutId = undefined;\n      }\n      if (!this.queue.includes(key) && !this.queueLowPriority.includes(key)) {\n        // Add to queue and check if the request can be processed right away.\n        if (lowPriority) {\n          this.queueLowPriority.push(key);\n        } else {\n          this.queue.push(key);\n        }\n        this.dequeue();\n      }\n    }\n  }\n\n  /**\n   * Adds a request with a unique key to the queue, if it doesn't already exist.\n   * @param key The key used to track the request.\n   * @param requestAction Function that will be called to complete the request. The function\n   *  will be run only once per unique key while the request exists, and may be deferred by the\n   *  queue at any time.\n   * @param lowPriority Whether this request should be added with low priority. False by default.\n   * @param delayMs Minimum delay, in milliseconds, before this request should be executed.\n   *\n   * NOTE: Cancelling a request while the action is running WILL NOT stop the action. If this behavior is desired,\n   * actions must be responsible for checking the RequestQueue, determining if the request is still valid (e.g.\n   * using `.hasRequest()`), and stopping or returning early.\n   *\n   * @returns A promise that will resolve on completion of the request, or reject if the request is cancelled.\n   *  If multiple requests are issued with the same key, a promise for the first request will be returned\n   *  until the request is resolved or cancelled.\n   *  Note that the return type of the promise will match that of the first request's instance.\n   */\n  addRequest(key, requestAction, lowPriority = false, delayMs = 0) {\n    if (!this.allRequests.has(key)) {\n      // New request!\n      const requestItem = this.registerRequest(key, requestAction);\n      // If a delay is set, wait to add this to the queue.\n      if (delayMs > 0) {\n        const timeoutId = setTimeout(() => this.addRequestToQueue(key, lowPriority), delayMs);\n        // Save timeout information to request metadata\n        requestItem.timeoutId = timeoutId;\n      } else {\n        // No delay, add immediately\n        this.addRequestToQueue(key, lowPriority);\n      }\n    } else {\n      const lowPriorityIndex = this.queueLowPriority.indexOf(key);\n      if (lowPriorityIndex > -1 && !lowPriority) {\n        // This request is registered and queued, but is now being requested with high priority.\n        // Promote it to high priority.\n        this.queueLowPriority.splice(lowPriorityIndex, 1);\n        this.addRequestToQueue(key);\n      } else if (delayMs <= 0) {\n        // This request is registered, but is now being requested without a delay.\n        // Move into queue immediately if it's not already added, and clear any timeouts it may have.\n        this.addRequestToQueue(key, lowPriority);\n      }\n    }\n    const promise = this.allRequests.get(key)?.promise;\n    if (!promise) {\n      throw new Error(\"Found no promise to return when getting stored request data.\");\n    }\n    return promise;\n  }\n\n  /**\n   * Adds multiple requests to the queue, with an optional delay between each.\n   * @param requests An array of RequestItems, which include a key and a request action.\n   * @param lowPriority Whether these requests should be added with low priority. False by default.\n   * @param delayMs An optional minimum delay in milliseconds to be added between each request.\n   *  For example, a delay of 10 ms will cause the second request to be added to the processing queue\n   *  after 10 ms, the third to added after 20 ms, and so on. Set to 10 ms by default.\n   * @returns An array of promises corresponding to the provided requests. (i.e., the `i`th value\n   * of the returned array will be a Promise for the resolution of `requests[i]`). If a request\n   *  with a matching key is already pending, returns the promise for the initial request.\n   */\n  addRequests(requests, lowPriority = false, delayMs = 10) {\n    const promises = [];\n    for (let i = 0; i < requests.length; i++) {\n      const item = requests[i];\n      const promise = this.addRequest(item.key, item.requestAction, lowPriority, delayMs * i);\n      promises.push(promise);\n    }\n    return promises;\n  }\n\n  /**\n   * Attempts to remove and run the next queued request item, if resources are available.\n   * @returns true if a request was started, or false if there are too many\n   * requests already active.\n   */\n  async dequeue() {\n    const numRequests = this.activeRequests.size;\n    if (numRequests >= this.maxActiveRequests || this.queue.length === 0 && (numRequests >= this.maxLowPriorityRequests || this.queueLowPriority.length === 0)) {\n      return;\n    }\n    const requestKey = this.queue.shift() ?? this.queueLowPriority.shift();\n    if (!requestKey) {\n      return;\n    }\n    if (this.activeRequests.has(requestKey)) {\n      // This request is already active, try the next one instead. (this shouldn't happen)\n      this.dequeue();\n      return;\n    }\n    const requestItem = this.allRequests.get(requestKey);\n    if (!requestItem) {\n      return;\n    }\n    const key = requestItem.key;\n    // Mark that this request is active\n    this.activeRequests.add(key);\n    await requestItem.action().then(requestItem.resolve, requestItem.reject);\n    this.activeRequests.delete(key);\n    this.allRequests.delete(key);\n    this.dequeue();\n  }\n\n  /**\n   * Removes any request matching the provided key from the queue and rejects its promise.\n   * @param key The key that should be matched against.\n   * @param cancelReason A message or object that will be used as the promise rejection.\n   */\n  cancelRequest(key, cancelReason = DEFAULT_REQUEST_CANCEL_REASON) {\n    if (!this.allRequests.has(key)) {\n      return;\n    }\n    const requestItem = this.allRequests.get(key);\n    if (requestItem) {\n      if (requestItem.timeoutId) {\n        // Cancel requests that have not been queued yet.\n        clearTimeout(requestItem.timeoutId);\n      }\n      // Reject the request, then clear from the queue and known requests.\n      requestItem.reject(cancelReason);\n    }\n    const queueIndex = this.queue.indexOf(key);\n    if (queueIndex > -1) {\n      this.queue.splice(queueIndex, 1);\n    } else {\n      const lowPriorityIndex = this.queueLowPriority.indexOf(key);\n      if (lowPriorityIndex > -1) {\n        this.queueLowPriority.splice(lowPriorityIndex, 1);\n      }\n    }\n    this.allRequests.delete(key);\n    this.activeRequests.delete(key);\n  }\n\n  /**\n   * Rejects all request promises and clears the queue.\n   * @param cancelReason A message or object that will be used as the promise rejection.\n   */\n  cancelAllRequests(cancelReason = DEFAULT_REQUEST_CANCEL_REASON) {\n    // Clear the queue so we don't do extra work while filtering it\n    this.queue = [];\n    this.queueLowPriority = [];\n    for (const key of this.allRequests.keys()) {\n      this.cancelRequest(key, cancelReason);\n    }\n  }\n\n  /**\n   * Returns whether a request with the given key exists in the RequestQueue and is not cancelled.\n   * @param key the key to search for.\n   * @returns true if the request is in the RequestQueue.\n   */\n  hasRequest(key) {\n    return this.allRequests.has(key);\n  }\n\n  /**\n   * Returns whether the request with the given key is currently running (not waiting in the queue).\n   * @param key the key to search for.\n   * @returns true if the request is actively running.\n   */\n  requestRunning(key) {\n    return this.activeRequests.has(key);\n  }\n}","import RequestQueue from \"./RequestQueue.js\";\n\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n/**\n * An extension of `RequestQueue` that adds a concept of \"subscribers,\" which may share references to a single request\n * or cancel their subscription without disrupting the request for other subscribers.\n */\nexport default class SubscribableRequestQueue {\n  /** The next unused subscriber ID. Increments whenever a subscriber is added. */\n\n  /**\n   * Map of subscribers keyed by ID. Subscribers store a map to all their subscriptions by request key.\n   * Subscribers are only useful as handles to cancel subscriptions early, so we only need to store rejecters here.\n   */\n\n  /** Map from \"inner\" request (managed by `queue`) to \"outer\" promises generated per-subscriber. */\n\n  /**\n   * Since `SubscribableRequestQueue` wraps `RequestQueue`, its constructor may either take the same arguments as the\n   * `RequestQueue` constructor and create a new `RequestQueue`, or it may take an existing `RequestQueue` to wrap.\n   */\n\n  constructor(maxActiveRequests, maxLowPriorityRequests) {\n    if (typeof maxActiveRequests === \"number\" || maxActiveRequests === undefined) {\n      this.queue = new RequestQueue(maxActiveRequests, maxLowPriorityRequests);\n    } else {\n      this.queue = maxActiveRequests;\n    }\n    this.nextSubscriberId = 0;\n    this.subscribers = new Map();\n    this.requests = new Map();\n  }\n\n  /** Resolves all subscriptions to request `key` with `value` */\n  resolveAll(key, value) {\n    const requests = this.requests.get(key);\n    if (requests) {\n      for (const {\n        resolve,\n        subscriberId\n      } of requests) {\n        resolve(value);\n        this.subscribers.get(subscriberId)?.delete(key);\n      }\n      this.requests.delete(key);\n    }\n  }\n\n  /** Rejects all subscriptions to request `key` with `reason` */\n  rejectAll(key, reason) {\n    const requests = this.requests.get(key);\n    if (requests) {\n      for (const {\n        reject,\n        subscriberId\n      } of requests) {\n        reject(reason);\n        this.subscribers.get(subscriberId)?.delete(key);\n      }\n      this.requests.delete(key);\n    }\n  }\n\n  /** Adds a new request subscriber. Returns a unique ID to identify this subscriber. */\n  addSubscriber() {\n    const subscriberId = this.nextSubscriberId;\n    this.nextSubscriberId++;\n    this.subscribers.set(subscriberId, new Map());\n    return subscriberId;\n  }\n\n  /**\n   * Queues a new request, or adds a subscription if the request is already queued/running.\n   *\n   * If `subscriberId` is already subscribed to the request, this rejects the existing promise and returns a new one.\n   */\n  addRequest(key, subscriberId, requestAction, lowPriority, delayMs) {\n    // Create single underlying request if it does not yet exist\n    this.queue.addRequest(key, requestAction, lowPriority, delayMs).then(value => this.resolveAll(key, value)).catch(reason => this.rejectAll(key, reason));\n    if (!this.requests.has(key)) {\n      this.requests.set(key, []);\n    }\n\n    // Validate subscriber\n    if (subscriberId >= this.nextSubscriberId || subscriberId < 0) {\n      throw new Error(`SubscribableRequestQueue: subscriber id ${subscriberId} has not been registered`);\n    }\n    const subscriber = this.subscribers.get(subscriberId);\n    if (!subscriber) {\n      throw new Error(`SubscribableRequestQueue: subscriber id ${subscriberId} has been removed`);\n    }\n\n    // Create promise and add to list of requests\n    return new Promise((resolve, reject) => {\n      this.requests.get(key)?.push({\n        resolve,\n        reject,\n        subscriberId\n      });\n      const subscriber = this.subscribers.get(subscriberId);\n      const existingRequest = subscriber?.get(key);\n      if (existingRequest) {\n        existingRequest.push(reject);\n      } else {\n        subscriber?.set(key, [reject]);\n      }\n    });\n  }\n\n  /**\n   * Rejects a subscription and removes it from the list of subscriptions for a request, then cancels the underlying\n   * request if it is no longer subscribed and is not running already.\n   */\n  rejectSubscription(key, reject, cancelReason) {\n    // Reject the outer \"subscription\" promise\n    reject(cancelReason);\n\n    // Get the list of subscriptions for this request\n    const subscriptions = this.requests.get(key);\n    if (!subscriptions) {\n      // This should never happen\n      return;\n    }\n    // Remove this request subscription by ref equality to `reject`\n    const idx = subscriptions.findIndex(sub => sub.reject === reject);\n    if (idx >= 0) {\n      subscriptions.splice(idx, 1);\n    }\n\n    // Remove the underlying request if there are no more subscribers and the request is not already running\n    if (subscriptions.length < 1 && !this.queue.requestRunning(key)) {\n      this.queue.cancelRequest(key, cancelReason);\n      this.requests.delete(key);\n    }\n  }\n\n  /** Cancels a request subscription, and cancels the underlying request if it is no longer subscribed or running. */\n  cancelRequest(key, subscriberId, cancelReason) {\n    const subscriber = this.subscribers.get(subscriberId);\n    if (!subscriber) {\n      return false;\n    }\n    const rejecters = subscriber.get(key);\n    if (!rejecters || !rejecters.length) {\n      return false;\n    }\n    for (const reject of rejecters) {\n      this.rejectSubscription(key, reject, cancelReason);\n    }\n    subscriber.delete(key);\n    return true;\n  }\n\n  /** Removes a subscriber and cancels its remaining subscriptions. */\n  removeSubscriber(subscriberId, cancelReason) {\n    const subscriptions = this.subscribers.get(subscriberId);\n    if (subscriptions) {\n      for (const [key, rejecters] of subscriptions.entries()) {\n        for (const reject of rejecters) {\n          this.rejectSubscription(key, reject, cancelReason);\n        }\n      }\n      this.subscribers.delete(subscriberId);\n    }\n  }\n\n  /** Returns whether a request with the given `key` is running or waiting in the queue */\n  hasRequest(key) {\n    return this.queue.hasRequest(key);\n  }\n\n  /** Returns whether a request with the given `key` is running */\n  requestRunning(key) {\n    return this.queue.requestRunning(key);\n  }\n\n  /** Returns whether a subscriber with the given `subscriberId` exists */\n  hasSubscriber(subscriberId) {\n    return this.subscribers.has(subscriberId);\n  }\n\n  /** Returns whether a subscriber with the given `subscriberId` is subscribed to the request with the given `key` */\n  isSubscribed(subscriberId, key) {\n    return this.subscribers.get(subscriberId)?.has(key) ?? false;\n  }\n}","/** The types of requests that can be made to the worker. Mostly corresponds to methods on `IVolumeLoader`. */\nexport let WorkerMsgType = /*#__PURE__*/function (WorkerMsgType) {\n  WorkerMsgType[WorkerMsgType[\"INIT\"] = 0] = \"INIT\";\n  WorkerMsgType[WorkerMsgType[\"CREATE_LOADER\"] = 1] = \"CREATE_LOADER\";\n  WorkerMsgType[WorkerMsgType[\"CLOSE_LOADER\"] = 2] = \"CLOSE_LOADER\";\n  WorkerMsgType[WorkerMsgType[\"CREATE_VOLUME\"] = 3] = \"CREATE_VOLUME\";\n  WorkerMsgType[WorkerMsgType[\"LOAD_DIMS\"] = 4] = \"LOAD_DIMS\";\n  WorkerMsgType[WorkerMsgType[\"LOAD_VOLUME_DATA\"] = 5] = \"LOAD_VOLUME_DATA\";\n  WorkerMsgType[WorkerMsgType[\"SET_PREFETCH_PRIORITY_DIRECTIONS\"] = 6] = \"SET_PREFETCH_PRIORITY_DIRECTIONS\";\n  WorkerMsgType[WorkerMsgType[\"SYNCHRONIZE_MULTICHANNEL_LOADING\"] = 7] = \"SYNCHRONIZE_MULTICHANNEL_LOADING\";\n  WorkerMsgType[WorkerMsgType[\"UPDATE_FETCH_OPTIONS\"] = 8] = \"UPDATE_FETCH_OPTIONS\";\n  return WorkerMsgType;\n}({});\n\n/** The variants of `WorkerMessageType` which represent \"global\" actions that don't require a specific loader */\n\n/** The variants of `WorkerMessageType` which represent actions on a specific loader */\n\n/** The kind of response a worker can return - `SUCCESS`, `ERROR`, or `EVENT`. */\nexport let WorkerResponseResult = /*#__PURE__*/function (WorkerResponseResult) {\n  WorkerResponseResult[WorkerResponseResult[\"SUCCESS\"] = 0] = \"SUCCESS\";\n  WorkerResponseResult[WorkerResponseResult[\"ERROR\"] = 1] = \"ERROR\";\n  WorkerResponseResult[WorkerResponseResult[\"EVENT\"] = 2] = \"EVENT\";\n  return WorkerResponseResult;\n}({});\n\n/** The kind of events that can occur when loading */\nexport let WorkerEventType = /*#__PURE__*/function (WorkerEventType) {\n  /** Fired to update a `Volume`'s `imageInfo` and/or `loadSpec` based on loaded data (time, channels, region, etc.) */\n  WorkerEventType[WorkerEventType[\"METADATA_UPDATE\"] = 0] = \"METADATA_UPDATE\";\n  /** Fired when data for a channel (or batch of channels) is loaded */\n  WorkerEventType[WorkerEventType[\"CHANNEL_LOAD\"] = 1] = \"CHANNEL_LOAD\";\n  return WorkerEventType;\n}({});\n\n/**\n * All messages to/from a worker carry a `msgId`, a `type`, and a `payload` (whose type is determined by `type`).\n * Messages which operate on a specific loader also require a `loaderId`.\n */\n\n/** Maps each `WorkerMsgType` to the type of the payload of requests of that type. */\n\n/** Maps each `WorkerMsgType` to the type of the payload of responses of that type. */\n\n/** Event for when a batch of channel data loads. */\n\n/** Event for when metadata updates. */\n\n/** All valid types of worker requests, with some `WorkerMsgType` and a matching payload type. */\n\n/** All valid types of worker responses: `SUCCESS` with a matching payload, `ERROR` with a message, or an `EVENT`. */","import { Box3, Vector3 } from \"three\";\n/** Recreates a `LoadSpec` that has just been sent to/from a worker to restore three.js object prototypes */\nexport function rebuildLoadSpec(spec) {\n  return {\n    ...spec,\n    subregion: new Box3(new Vector3().copy(spec.subregion.min), new Vector3().copy(spec.subregion.max))\n  };\n}","import { assert } from \"../util.js\";\n/**\n * A codec for bit-rounding.\n *\n * Reduces floating-point precision by truncating mantissa bits during encoding.\n * Decoding is a no-op as the process is lossy and precision cannot be restored.\n *\n * Note: {@link BitroundCodec.encode} is not yet implemented since Zarrita is\n * primarily used in read-only contexts (web browser). If you need encoding support,\n * please open an issue at {@link https://github.com/manzt/zarrita.js/issues}.\n *\n * @see {@link https://github.com/zarr-developers/numcodecs/blob/main/numcodecs/bitround.py}\n * for the original Python implementation.\n *\n * @remarks\n * Data types are not validated, and `float16` arrays are not supported (reflecting browser support).\n */\nexport class BitroundCodec {\n    kind = \"array_to_array\";\n    constructor(configuration, _meta) {\n        assert(configuration.keepbits >= 0, \"keepbits must be zero or positive\");\n    }\n    static fromConfig(configuration, meta) {\n        return new BitroundCodec(configuration, meta);\n    }\n    /**\n     * Encode a chunk of data with bit-rounding.\n     * @param _arr - The chunk to encode\n     */\n    encode(_arr) {\n        throw new Error(\"`BitroundCodec.encode` is not implemented. Please open an issue at https://github.com/manzt/zarrita.js/issues.\");\n    }\n    /**\n     * Decode a chunk of data (no-op).\n     * @param arr - The chunk to decode\n     * @returns The decoded chunk\n     */\n    decode(arr) {\n        return arr; // No-op as bit-rounding is lossy\n    }\n}\n//# sourceMappingURL=bitround.js.map","import { byteswap_inplace, get_ctr, get_strides } from \"../util.js\";\nconst LITTLE_ENDIAN_OS = system_is_little_endian();\nfunction system_is_little_endian() {\n    const a = new Uint32Array([0x12345678]);\n    const b = new Uint8Array(a.buffer, a.byteOffset, a.byteLength);\n    return !(b[0] === 0x12);\n}\nfunction bytes_per_element(TypedArray) {\n    if (\"BYTES_PER_ELEMENT\" in TypedArray) {\n        return TypedArray.BYTES_PER_ELEMENT;\n    }\n    // Unicode string array is backed by a Int32Array.\n    return 4;\n}\nexport class BytesCodec {\n    kind = \"array_to_bytes\";\n    #stride;\n    #TypedArray;\n    #BYTES_PER_ELEMENT;\n    #shape;\n    #endian;\n    constructor(configuration, meta) {\n        this.#endian = configuration?.endian;\n        this.#TypedArray = get_ctr(meta.data_type);\n        this.#shape = meta.shape;\n        this.#stride = get_strides(meta.shape, \"C\");\n        // TODO: fix me.\n        // hack to get bytes per element since it's dynamic for string types.\n        const sample = new this.#TypedArray(0);\n        this.#BYTES_PER_ELEMENT = sample.BYTES_PER_ELEMENT;\n    }\n    static fromConfig(configuration, meta) {\n        return new BytesCodec(configuration, meta);\n    }\n    encode(arr) {\n        let bytes = new Uint8Array(arr.data.buffer);\n        if (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n            byteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n        }\n        return bytes;\n    }\n    decode(bytes) {\n        if (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n            byteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n        }\n        return {\n            data: new this.#TypedArray(bytes.buffer, bytes.byteOffset, bytes.byteLength / this.#BYTES_PER_ELEMENT),\n            shape: this.#shape,\n            stride: this.#stride,\n        };\n    }\n}\n//# sourceMappingURL=bytes.js.map","export class Crc32cCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig() {\n        return new Crc32cCodec();\n    }\n    encode(_) {\n        throw new Error(\"Not implemented\");\n    }\n    decode(arr) {\n        return new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength - 4);\n    }\n}\n//# sourceMappingURL=crc32c.js.map","import { decompress } from \"../util.js\";\nexport class GzipCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig(_) {\n        return new GzipCodec();\n    }\n    encode(_bytes) {\n        throw new Error(\"Gzip encoding is not enabled by default. Please register a custom codec with `numcodecs/gzip`.\");\n    }\n    async decode(bytes) {\n        const buffer = await decompress(bytes, { format: \"gzip\" });\n        return new Uint8Array(buffer);\n    }\n}\n//# sourceMappingURL=gzip.js.map","import { assert, get_strides, json_decode_object } from \"../util.js\";\n// Reference: https://stackoverflow.com/a/21897413\nfunction throw_on_nan_replacer(_key, value) {\n    assert(!Number.isNaN(value), \"JsonCodec allow_nan is false but NaN was encountered during encoding.\");\n    assert(value !== Number.POSITIVE_INFINITY, \"JsonCodec allow_nan is false but Infinity was encountered during encoding.\");\n    assert(value !== Number.NEGATIVE_INFINITY, \"JsonCodec allow_nan is false but -Infinity was encountered during encoding.\");\n    return value;\n}\n// Reference: https://gist.github.com/davidfurlong/463a83a33b70a3b6618e97ec9679e490\nfunction sort_keys_replacer(_key, value) {\n    return value instanceof Object && !Array.isArray(value)\n        ? Object.keys(value)\n            .sort()\n            .reduce((sorted, key) => {\n            sorted[key] = value[key];\n            return sorted;\n        }, {})\n        : value;\n}\nexport class JsonCodec {\n    configuration;\n    kind = \"array_to_bytes\";\n    #encoder_config;\n    #decoder_config;\n    constructor(configuration = {}) {\n        this.configuration = configuration;\n        // Reference: https://github.com/zarr-developers/numcodecs/blob/0878717a3613d91a453fe3d3716aa9c67c023a8b/numcodecs/json.py#L36\n        const { encoding = \"utf-8\", skipkeys = false, ensure_ascii = true, check_circular = true, allow_nan = true, sort_keys = true, indent, strict = true, } = configuration;\n        let separators = configuration.separators;\n        if (!separators) {\n            // ensure separators are explicitly specified, and consistent behaviour across\n            // Python versions, and most compact representation if indent is None\n            if (!indent) {\n                separators = [\",\", \":\"];\n            }\n            else {\n                separators = [\", \", \": \"];\n            }\n        }\n        this.#encoder_config = {\n            encoding,\n            skipkeys,\n            ensure_ascii,\n            check_circular,\n            allow_nan,\n            indent,\n            separators,\n            sort_keys,\n        };\n        this.#decoder_config = { strict };\n    }\n    static fromConfig(configuration) {\n        return new JsonCodec(configuration);\n    }\n    encode(buf) {\n        const { indent, encoding, ensure_ascii, check_circular, allow_nan, sort_keys, } = this.#encoder_config;\n        assert(encoding === \"utf-8\", \"JsonCodec does not yet support non-utf-8 encoding.\");\n        const replacer_functions = [];\n        // By default, for JSON.stringify,\n        // a TypeError will be thrown if one attempts to encode an object with circular references\n        assert(check_circular, \"JsonCodec does not yet support skipping the check for circular references during encoding.\");\n        if (!allow_nan) {\n            // Throw if NaN/Infinity/-Infinity are encountered during encoding.\n            replacer_functions.push(throw_on_nan_replacer);\n        }\n        if (sort_keys) {\n            // We can ensure keys are sorted but not really the opposite since\n            // there is no guarantee of key ordering in JS.\n            replacer_functions.push(sort_keys_replacer);\n        }\n        const items = Array.from(buf.data);\n        items.push(\"|O\");\n        items.push(buf.shape);\n        let replacer;\n        if (replacer_functions.length) {\n            replacer = (key, value) => {\n                let new_value = value;\n                for (let sub_replacer of replacer_functions) {\n                    new_value = sub_replacer(key, new_value);\n                }\n                return new_value;\n            };\n        }\n        let json_str = JSON.stringify(items, replacer, indent);\n        if (ensure_ascii) {\n            // If ensure_ascii is true (the default), the output is guaranteed\n            // to have all incoming non-ASCII characters escaped.\n            // If ensure_ascii is false, these characters will be output as-is.\n            // Reference: https://stackoverflow.com/a/31652607\n            json_str = json_str.replace(/[\\u007F-\\uFFFF]/g, (chr) => {\n                const full_str = `0000${chr.charCodeAt(0).toString(16)}`;\n                const sub_str = full_str.substring(full_str.length - 4);\n                return `\\\\u${sub_str}`;\n            });\n        }\n        return new TextEncoder().encode(json_str);\n    }\n    decode(bytes) {\n        const { strict } = this.#decoder_config;\n        // (i.e., allowing control characters inside strings)\n        assert(strict, \"JsonCodec does not yet support non-strict decoding.\");\n        const items = json_decode_object(bytes);\n        const shape = items.pop();\n        items.pop(); // Pop off dtype (unused)\n        // O-d case\n        assert(shape, \"0D not implemented for JsonCodec.\");\n        const stride = get_strides(shape, \"C\");\n        const data = items;\n        return { data, shape, stride };\n    }\n}\n//# sourceMappingURL=json2.js.map","import { BoolArray, ByteStringArray, UnicodeStringArray, } from \"../typedarray.js\";\nimport { assert, get_strides } from \"../util.js\";\nfunction proxy(arr) {\n    if (arr instanceof BoolArray ||\n        arr instanceof ByteStringArray ||\n        arr instanceof UnicodeStringArray) {\n        // @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n        const arrp = new Proxy(arr, {\n            get(target, prop) {\n                return target.get(Number(prop));\n            },\n            set(target, prop, value) {\n                // @ts-expect-error - value is OK\n                target.set(Number(prop), value);\n                return true;\n            },\n        });\n        return arrp;\n    }\n    // @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n    return arr;\n}\nfunction empty_like(chunk, order) {\n    let data;\n    if (chunk.data instanceof ByteStringArray ||\n        chunk.data instanceof UnicodeStringArray) {\n        data = new chunk.constructor(\n        // @ts-expect-error\n        chunk.data.length, chunk.data.chars);\n    }\n    else {\n        data = new chunk.constructor(chunk.data.length);\n    }\n    return {\n        data,\n        shape: chunk.shape,\n        stride: get_strides(chunk.shape, order),\n    };\n}\nfunction convert_array_order(src, target) {\n    let out = empty_like(src, target);\n    let n_dims = src.shape.length;\n    let size = src.data.length;\n    let index = Array(n_dims).fill(0);\n    let src_data = proxy(src.data);\n    let out_data = proxy(out.data);\n    for (let src_idx = 0; src_idx < size; src_idx++) {\n        let out_idx = 0;\n        for (let dim = 0; dim < n_dims; dim++) {\n            out_idx += index[dim] * out.stride[dim];\n        }\n        out_data[out_idx] = src_data[src_idx];\n        index[0] += 1;\n        for (let dim = 0; dim < n_dims; dim++) {\n            if (index[dim] === src.shape[dim]) {\n                if (dim + 1 === n_dims) {\n                    break;\n                }\n                index[dim] = 0;\n                index[dim + 1] += 1;\n            }\n        }\n    }\n    return out;\n}\n/** Determine the memory order (axis permutation) for a chunk */\nfunction get_order(chunk) {\n    let rank = chunk.shape.length;\n    assert(rank === chunk.stride.length, \"Shape and stride must have the same length.\");\n    return chunk.stride\n        .map((s, i) => ({ stride: s, index: i }))\n        .sort((a, b) => b.stride - a.stride)\n        .map((entry) => entry.index);\n}\nfunction matches_order(chunk, target) {\n    let source = get_order(chunk);\n    assert(source.length === target.length, \"Orders must match\");\n    return source.every((dim, i) => dim === target[i]);\n}\nexport class TransposeCodec {\n    kind = \"array_to_array\";\n    #order;\n    #inverseOrder;\n    constructor(configuration, meta) {\n        let value = configuration.order ?? \"C\";\n        let rank = meta.shape.length;\n        let order = new Array(rank);\n        let inverseOrder = new Array(rank);\n        if (value === \"C\") {\n            for (let i = 0; i < rank; ++i) {\n                order[i] = i;\n                inverseOrder[i] = i;\n            }\n        }\n        else if (value === \"F\") {\n            for (let i = 0; i < rank; ++i) {\n                order[i] = rank - i - 1;\n                inverseOrder[i] = rank - i - 1;\n            }\n        }\n        else {\n            order = value;\n            order.forEach((x, i) => {\n                assert(inverseOrder[x] === undefined, `Invalid permutation: ${JSON.stringify(value)}`);\n                inverseOrder[x] = i;\n            });\n        }\n        this.#order = order;\n        this.#inverseOrder = inverseOrder;\n    }\n    static fromConfig(configuration, meta) {\n        return new TransposeCodec(configuration, meta);\n    }\n    encode(arr) {\n        if (matches_order(arr, this.#inverseOrder)) {\n            // can skip making a copy\n            return arr;\n        }\n        return convert_array_order(arr, this.#inverseOrder);\n    }\n    decode(arr) {\n        return {\n            data: arr.data,\n            shape: arr.shape,\n            stride: get_strides(arr.shape, this.#order),\n        };\n    }\n}\n//# sourceMappingURL=transpose.js.map","import { get_strides } from \"../util.js\";\nexport class VLenUTF8 {\n    kind = \"array_to_bytes\";\n    #shape;\n    #strides;\n    constructor(shape) {\n        this.#shape = shape;\n        this.#strides = get_strides(shape, \"C\");\n    }\n    static fromConfig(_, meta) {\n        return new VLenUTF8(meta.shape);\n    }\n    encode(_chunk) {\n        throw new Error(\"Method not implemented.\");\n    }\n    decode(bytes) {\n        let decoder = new TextDecoder();\n        let view = new DataView(bytes.buffer);\n        let data = Array(view.getUint32(0, true));\n        let pos = 4;\n        for (let i = 0; i < data.length; i++) {\n            let item_length = view.getUint32(pos, true);\n            pos += 4;\n            data[i] = decoder.decode(bytes.buffer.slice(pos, pos + item_length));\n            pos += item_length;\n        }\n        return { data, shape: this.#shape, stride: this.#strides };\n    }\n}\n//# sourceMappingURL=vlen-utf8.js.map","import { decompress } from \"../util.js\";\nexport class ZlibCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig(_) {\n        return new ZlibCodec();\n    }\n    encode(_bytes) {\n        throw new Error(\"Zlib encoding is not enabled by default. Please register a codec with `numcodecs/zlib`.\");\n    }\n    async decode(bytes) {\n        const buffer = await decompress(bytes, { format: \"deflate\" });\n        return new Uint8Array(buffer);\n    }\n}\n//# sourceMappingURL=zlib.js.map","import { BitroundCodec } from \"./codecs/bitround.js\";\nimport { BytesCodec } from \"./codecs/bytes.js\";\nimport { Crc32cCodec } from \"./codecs/crc32c.js\";\nimport { GzipCodec } from \"./codecs/gzip.js\";\nimport { JsonCodec } from \"./codecs/json2.js\";\nimport { TransposeCodec } from \"./codecs/transpose.js\";\nimport { VLenUTF8 } from \"./codecs/vlen-utf8.js\";\nimport { ZlibCodec } from \"./codecs/zlib.js\";\nimport { assert } from \"./util.js\";\nfunction create_default_registry() {\n    return new Map()\n        .set(\"blosc\", () => import(\"numcodecs/blosc\").then((m) => m.default))\n        .set(\"lz4\", () => import(\"numcodecs/lz4\").then((m) => m.default))\n        .set(\"zstd\", () => import(\"numcodecs/zstd\").then((m) => m.default))\n        .set(\"gzip\", () => GzipCodec)\n        .set(\"zlib\", () => ZlibCodec)\n        .set(\"transpose\", () => TransposeCodec)\n        .set(\"bytes\", () => BytesCodec)\n        .set(\"crc32c\", () => Crc32cCodec)\n        .set(\"vlen-utf8\", () => VLenUTF8)\n        .set(\"json2\", () => JsonCodec)\n        .set(\"bitround\", () => BitroundCodec);\n}\nexport const registry = create_default_registry();\nexport function create_codec_pipeline(chunk_metadata) {\n    let codecs;\n    return {\n        async encode(chunk) {\n            if (!codecs)\n                codecs = await load_codecs(chunk_metadata);\n            for (const codec of codecs.array_to_array) {\n                chunk = await codec.encode(chunk);\n            }\n            let bytes = await codecs.array_to_bytes.encode(chunk);\n            for (const codec of codecs.bytes_to_bytes) {\n                bytes = await codec.encode(bytes);\n            }\n            return bytes;\n        },\n        async decode(bytes) {\n            if (!codecs)\n                codecs = await load_codecs(chunk_metadata);\n            for (let i = codecs.bytes_to_bytes.length - 1; i >= 0; i--) {\n                bytes = await codecs.bytes_to_bytes[i].decode(bytes);\n            }\n            let chunk = await codecs.array_to_bytes.decode(bytes);\n            for (let i = codecs.array_to_array.length - 1; i >= 0; i--) {\n                chunk = await codecs.array_to_array[i].decode(chunk);\n            }\n            return chunk;\n        },\n    };\n}\nasync function load_codecs(chunk_meta) {\n    let promises = chunk_meta.codecs.map(async (meta) => {\n        let Codec = await registry.get(meta.name)?.();\n        assert(Codec, `Unknown codec: ${meta.name}`);\n        return { Codec, meta };\n    });\n    let array_to_array = [];\n    let array_to_bytes;\n    let bytes_to_bytes = [];\n    for await (let { Codec, meta } of promises) {\n        let codec = Codec.fromConfig(meta.configuration, chunk_meta);\n        switch (codec.kind) {\n            case \"array_to_array\":\n                array_to_array.push(codec);\n                break;\n            case \"array_to_bytes\":\n                array_to_bytes = codec;\n                break;\n            default:\n                bytes_to_bytes.push(codec);\n        }\n    }\n    if (!array_to_bytes) {\n        assert(is_typed_array_like_meta(chunk_meta), `Cannot encode ${chunk_meta.data_type} to bytes without a codec`);\n        array_to_bytes = BytesCodec.fromConfig({ endian: \"little\" }, chunk_meta);\n    }\n    return { array_to_array, array_to_bytes, bytes_to_bytes };\n}\nfunction is_typed_array_like_meta(meta) {\n    return meta.data_type !== \"v2:object\";\n}\n//# sourceMappingURL=codecs.js.map","import { create_codec_pipeline } from \"../codecs.js\";\nimport { assert } from \"../util.js\";\nconst MAX_BIG_UINT = 18446744073709551615n;\nexport function create_sharded_chunk_getter(location, shard_shape, encode_shard_key, sharding_config) {\n    assert(location.store.getRange, \"Store does not support range requests\");\n    let get_range = location.store.getRange.bind(location.store);\n    let index_shape = shard_shape.map((d, i) => d / sharding_config.chunk_shape[i]);\n    let index_codec = create_codec_pipeline({\n        data_type: \"uint64\",\n        shape: [...index_shape, 2],\n        codecs: sharding_config.index_codecs,\n    });\n    let cache = {};\n    return async (chunk_coord) => {\n        let shard_coord = chunk_coord.map((d, i) => Math.floor(d / index_shape[i]));\n        let shard_path = location.resolve(encode_shard_key(shard_coord)).path;\n        let index;\n        if (shard_path in cache) {\n            index = cache[shard_path];\n        }\n        else {\n            let checksum_size = 4;\n            let index_size = 16 * index_shape.reduce((a, b) => a * b, 1);\n            let bytes = await get_range(shard_path, {\n                suffixLength: index_size + checksum_size,\n            });\n            index = cache[shard_path] = bytes\n                ? await index_codec.decode(bytes)\n                : null;\n        }\n        if (index === null) {\n            return undefined;\n        }\n        let { data, shape, stride } = index;\n        let linear_offset = chunk_coord\n            .map((d, i) => d % shape[i])\n            .reduce((acc, sel, idx) => acc + sel * stride[idx], 0);\n        let offset = data[linear_offset];\n        let length = data[linear_offset + 1];\n        // write null chunk when 2^64-1 indicates fill value\n        if (offset === MAX_BIG_UINT && length === MAX_BIG_UINT) {\n            return undefined;\n        }\n        return get_range(shard_path, {\n            offset: Number(offset),\n            length: Number(length),\n        });\n    };\n}\n//# sourceMappingURL=sharding.js.map","import { create_sharded_chunk_getter } from \"./codecs/sharding.js\";\nimport { create_codec_pipeline } from \"./codecs.js\";\nimport { create_chunk_key_encoder, ensure_correct_scalar, get_ctr, get_strides, is_dtype, is_sharding_codec, } from \"./util.js\";\nexport class Location {\n    store;\n    path;\n    constructor(store, path = \"/\") {\n        this.store = store;\n        this.path = path;\n    }\n    resolve(path) {\n        // reuse URL resolution logic built into the browser\n        // handles relative paths, absolute paths, etc.\n        let root = new URL(`file://${this.path.endsWith(\"/\") ? this.path : `${this.path}/`}`);\n        return new Location(this.store, new URL(path, root).pathname);\n    }\n}\nexport function root(store) {\n    return new Location(store ?? new Map());\n}\nexport class Group extends Location {\n    kind = \"group\";\n    #metadata;\n    constructor(store, path, metadata) {\n        super(store, path);\n        this.#metadata = metadata;\n    }\n    get attrs() {\n        return this.#metadata.attributes;\n    }\n}\nfunction get_array_order(codecs) {\n    const maybe_transpose_codec = codecs.find((c) => c.name === \"transpose\");\n    // @ts-expect-error - TODO: Should validate?\n    return maybe_transpose_codec?.configuration?.order ?? \"C\";\n}\nconst CONTEXT_MARKER = Symbol(\"zarrita.context\");\nexport function get_context(obj) {\n    return obj[CONTEXT_MARKER];\n}\nfunction create_context(location, metadata) {\n    let { configuration } = metadata.codecs.find(is_sharding_codec) ?? {};\n    let shared_context = {\n        encode_chunk_key: create_chunk_key_encoder(metadata.chunk_key_encoding),\n        TypedArray: get_ctr(metadata.data_type),\n        fill_value: metadata.fill_value,\n    };\n    if (configuration) {\n        let native_order = get_array_order(configuration.codecs);\n        return {\n            ...shared_context,\n            kind: \"sharded\",\n            chunk_shape: configuration.chunk_shape,\n            codec: create_codec_pipeline({\n                data_type: metadata.data_type,\n                shape: configuration.chunk_shape,\n                codecs: configuration.codecs,\n            }),\n            get_strides(shape) {\n                return get_strides(shape, native_order);\n            },\n            get_chunk_bytes: create_sharded_chunk_getter(location, metadata.chunk_grid.configuration.chunk_shape, shared_context.encode_chunk_key, configuration),\n        };\n    }\n    let native_order = get_array_order(metadata.codecs);\n    return {\n        ...shared_context,\n        kind: \"regular\",\n        chunk_shape: metadata.chunk_grid.configuration.chunk_shape,\n        codec: create_codec_pipeline({\n            data_type: metadata.data_type,\n            shape: metadata.chunk_grid.configuration.chunk_shape,\n            codecs: metadata.codecs,\n        }),\n        get_strides(shape) {\n            return get_strides(shape, native_order);\n        },\n        async get_chunk_bytes(chunk_coords, options) {\n            let chunk_key = shared_context.encode_chunk_key(chunk_coords);\n            let chunk_path = location.resolve(chunk_key).path;\n            return location.store.get(chunk_path, options);\n        },\n    };\n}\nexport class Array extends Location {\n    kind = \"array\";\n    #metadata;\n    [CONTEXT_MARKER];\n    constructor(store, path, metadata) {\n        super(store, path);\n        this.#metadata = {\n            ...metadata,\n            fill_value: ensure_correct_scalar(metadata),\n        };\n        this[CONTEXT_MARKER] = create_context(this, metadata);\n    }\n    get attrs() {\n        return this.#metadata.attributes;\n    }\n    get shape() {\n        return this.#metadata.shape;\n    }\n    get chunks() {\n        return this[CONTEXT_MARKER].chunk_shape;\n    }\n    get dtype() {\n        return this.#metadata.data_type;\n    }\n    async getChunk(chunk_coords, options) {\n        let context = this[CONTEXT_MARKER];\n        let maybe_bytes = await context.get_chunk_bytes(chunk_coords, options);\n        if (!maybe_bytes) {\n            let size = context.chunk_shape.reduce((a, b) => a * b, 1);\n            let data = new context.TypedArray(size);\n            // @ts-expect-error: TS can't infer that `fill_value` is union (assumes never) but this is ok\n            data.fill(context.fill_value);\n            return {\n                data,\n                shape: context.chunk_shape,\n                stride: context.get_strides(context.chunk_shape),\n            };\n        }\n        return context.codec.decode(maybe_bytes);\n    }\n    /**\n     * A helper method to narrow `zarr.Array` Dtype.\n     *\n     * ```typescript\n     * let arr: zarr.Array<DataType, FetchStore> = zarr.open(store, { kind: \"array\" });\n     *\n     * // Option 1: narrow by scalar type (e.g. \"bool\", \"raw\", \"bigint\", \"number\")\n     * if (arr.is(\"bigint\")) {\n     *   // zarr.Array<\"int64\" | \"uint64\", FetchStore>\n     * }\n     *\n     * // Option 3: exact match\n     * if (arr.is(\"float32\")) {\n     *   // zarr.Array<\"float32\", FetchStore, \"/\">\n     * }\n     * ```\n     */\n    is(query) {\n        return is_dtype(this.dtype, query);\n    }\n}\n//# sourceMappingURL=hierarchy.js.map","import { product, range, slice, slice_indices } from \"./util.js\";\nexport class IndexError extends Error {\n    constructor(msg) {\n        super(msg);\n        this.name = \"IndexError\";\n    }\n}\nfunction err_too_many_indices(selection, shape) {\n    throw new IndexError(`too many indicies for array; expected ${shape.length}, got ${selection.length}`);\n}\nfunction err_boundscheck(dim_len) {\n    throw new IndexError(`index out of bounds for dimension with length ${dim_len}`);\n}\nfunction err_negative_step() {\n    throw new IndexError(\"only slices with step >= 1 are supported\");\n}\nfunction check_selection_length(selection, shape) {\n    if (selection.length > shape.length) {\n        err_too_many_indices(selection, shape);\n    }\n}\nexport function normalize_integer_selection(dim_sel, dim_len) {\n    // normalize type to int\n    dim_sel = Math.trunc(dim_sel);\n    // handle wraparound\n    if (dim_sel < 0) {\n        dim_sel = dim_len + dim_sel;\n    }\n    // handle out of bounds\n    if (dim_sel >= dim_len || dim_sel < 0) {\n        err_boundscheck(dim_len);\n    }\n    return dim_sel;\n}\nclass IntDimIndexer {\n    dim_sel;\n    dim_len;\n    dim_chunk_len;\n    nitems;\n    constructor({ dim_sel, dim_len, dim_chunk_len }) {\n        // normalize\n        dim_sel = normalize_integer_selection(dim_sel, dim_len);\n        // store properties\n        this.dim_sel = dim_sel;\n        this.dim_len = dim_len;\n        this.dim_chunk_len = dim_chunk_len;\n        this.nitems = 1;\n    }\n    *[Symbol.iterator]() {\n        const dim_chunk_ix = Math.floor(this.dim_sel / this.dim_chunk_len);\n        const dim_offset = dim_chunk_ix * this.dim_chunk_len;\n        const dim_chunk_sel = this.dim_sel - dim_offset;\n        yield { dim_chunk_ix, dim_chunk_sel };\n    }\n}\nclass SliceDimIndexer {\n    start;\n    stop;\n    step;\n    dim_len;\n    dim_chunk_len;\n    nitems;\n    nchunks;\n    constructor({ dim_sel, dim_len, dim_chunk_len }) {\n        // normalize\n        const [start, stop, step] = slice_indices(dim_sel, dim_len);\n        this.start = start;\n        this.stop = stop;\n        this.step = step;\n        if (this.step < 1)\n            err_negative_step();\n        // store properties\n        this.dim_len = dim_len;\n        this.dim_chunk_len = dim_chunk_len;\n        this.nitems = Math.max(0, Math.ceil((this.stop - this.start) / this.step));\n        this.nchunks = Math.ceil(this.dim_len / this.dim_chunk_len);\n    }\n    *[Symbol.iterator]() {\n        // figure out the range of chunks we need to visit\n        const dim_chunk_ix_from = Math.floor(this.start / this.dim_chunk_len);\n        const dim_chunk_ix_to = Math.ceil(this.stop / this.dim_chunk_len);\n        for (const dim_chunk_ix of range(dim_chunk_ix_from, dim_chunk_ix_to)) {\n            // compute offsets for chunk within overall array\n            const dim_offset = dim_chunk_ix * this.dim_chunk_len;\n            const dim_limit = Math.min(this.dim_len, (dim_chunk_ix + 1) * this.dim_chunk_len);\n            // determine chunk length, accounting for trailing chunk\n            const dim_chunk_len = dim_limit - dim_offset;\n            let dim_out_offset = 0;\n            let dim_chunk_sel_start = 0;\n            if (this.start < dim_offset) {\n                // selection start before current chunk\n                const remainder = (dim_offset - this.start) % this.step;\n                if (remainder)\n                    dim_chunk_sel_start += this.step - remainder;\n                // compute number of previous items, provides offset into output array\n                dim_out_offset = Math.ceil((dim_offset - this.start) / this.step);\n            }\n            else {\n                // selection starts within current chunk\n                dim_chunk_sel_start = this.start - dim_offset;\n            }\n            // selection starts within current chunk if true,\n            // otherwise selection ends after current chunk.\n            const dim_chunk_sel_stop = this.stop > dim_limit ? dim_chunk_len : this.stop - dim_offset;\n            const dim_chunk_sel = [\n                dim_chunk_sel_start,\n                dim_chunk_sel_stop,\n                this.step,\n            ];\n            const dim_chunk_nitems = Math.ceil((dim_chunk_sel_stop - dim_chunk_sel_start) / this.step);\n            const dim_out_sel = [\n                dim_out_offset,\n                dim_out_offset + dim_chunk_nitems,\n                1,\n            ];\n            yield { dim_chunk_ix, dim_chunk_sel, dim_out_sel };\n        }\n    }\n}\nexport function normalize_selection(selection, shape) {\n    let normalized = [];\n    if (selection === null) {\n        normalized = shape.map((_) => slice(null));\n    }\n    else if (Array.isArray(selection)) {\n        normalized = selection.map((s) => s ?? slice(null));\n    }\n    check_selection_length(normalized, shape);\n    return normalized;\n}\nexport class BasicIndexer {\n    dim_indexers;\n    shape;\n    constructor({ selection, shape, chunk_shape }) {\n        // setup per-dimension indexers\n        this.dim_indexers = normalize_selection(selection, shape).map((dim_sel, i) => {\n            return new (typeof dim_sel === \"number\" ? IntDimIndexer : SliceDimIndexer)({\n                // @ts-expect-error ts inference not strong enough to know correct chunk\n                dim_sel: dim_sel,\n                dim_len: shape[i],\n                dim_chunk_len: chunk_shape[i],\n            });\n        });\n        this.shape = this.dim_indexers\n            .filter((ixr) => ixr instanceof SliceDimIndexer)\n            .map((sixr) => sixr.nitems);\n    }\n    *[Symbol.iterator]() {\n        for (const dim_projections of product(...this.dim_indexers)) {\n            const chunk_coords = dim_projections.map((p) => p.dim_chunk_ix);\n            const mapping = dim_projections.map((p) => {\n                if (\"dim_out_sel\" in p) {\n                    return { from: p.dim_chunk_sel, to: p.dim_out_sel };\n                }\n                return { from: p.dim_chunk_sel, to: null };\n            });\n            yield { chunk_coords, mapping };\n        }\n    }\n}\n//# sourceMappingURL=indexer.js.map","import { get as get_with_setter } from \"./get.js\";\nimport { set as set_with_setter } from \"./set.js\";\n/** A 1D \"view\" of an array that can be used to set values in the array. */\nfunction object_array_view(arr, offset = 0, size) {\n    let length = size ?? arr.length - offset;\n    return {\n        length,\n        subarray(from, to = length) {\n            return object_array_view(arr, offset + from, to - from);\n        },\n        set(data, start = 0) {\n            for (let i = 0; i < data.length; i++) {\n                arr[offset + start + i] = data.get(i);\n            }\n        },\n        get(index) {\n            return arr[offset + index];\n        },\n    };\n}\n/**\n * Convert a chunk to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more than\n * just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the underlying, which is supported by our binary set functions.\n */\nfunction compat_chunk(arr) {\n    if (globalThis.Array.isArray(arr.data)) {\n        return {\n            // @ts-expect-error\n            data: object_array_view(arr.data),\n            stride: arr.stride,\n            bytes_per_element: 1,\n        };\n    }\n    return {\n        data: new Uint8Array(arr.data.buffer, arr.data.byteOffset, arr.data.byteLength),\n        stride: arr.stride,\n        bytes_per_element: arr.data.BYTES_PER_ELEMENT,\n    };\n}\n/** Hack to get the constructor of a typed array constructor from an existing TypedArray. */\nfunction get_typed_array_constructor(arr) {\n    if (\"chars\" in arr) {\n        // our custom TypedArray needs to bind the number of characters per\n        // element to the constructor.\n        return arr.constructor.bind(null, arr.chars);\n    }\n    return arr.constructor;\n}\n/**\n * Convert a scalar to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more\n * than just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the scalar, which is supported by our binary set functions.\n */\nfunction compat_scalar(arr, value) {\n    if (globalThis.Array.isArray(arr.data)) {\n        // @ts-expect-error\n        return object_array_view([value]);\n    }\n    let TypedArray = get_typed_array_constructor(arr.data);\n    // @ts-expect-error - value is a scalar and matches\n    let data = new TypedArray([value]);\n    return new Uint8Array(data.buffer, data.byteOffset, data.byteLength);\n}\nexport const setter = {\n    prepare(data, shape, stride) {\n        return { data, shape, stride };\n    },\n    set_scalar(dest, sel, value) {\n        let view = compat_chunk(dest);\n        set_scalar_binary(view, sel, compat_scalar(dest, value), view.bytes_per_element);\n    },\n    set_from_chunk(dest, src, projections) {\n        let view = compat_chunk(dest);\n        set_from_chunk_binary(view, compat_chunk(src), view.bytes_per_element, projections);\n    },\n};\n/** @category Utility */\nexport async function get(arr, selection = null, opts = {}) {\n    return get_with_setter(arr, selection, opts, setter);\n}\n/** @category Utility */\nexport async function set(arr, selection, value, opts = {}) {\n    return set_with_setter(arr, selection, value, opts, setter);\n}\nfunction indices_len(start, stop, step) {\n    if (step < 0 && stop < start) {\n        return Math.floor((start - stop - 1) / -step) + 1;\n    }\n    if (start < stop)\n        return Math.floor((stop - start - 1) / step) + 1;\n    return 0;\n}\nfunction set_scalar_binary(out, out_selection, value, bytes_per_element) {\n    if (out_selection.length === 0) {\n        out.data.set(value, 0);\n        return;\n    }\n    const [slice, ...slices] = out_selection;\n    const [curr_stride, ...stride] = out.stride;\n    if (typeof slice === \"number\") {\n        const data = out.data.subarray(curr_stride * slice * bytes_per_element);\n        set_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n        return;\n    }\n    const [from, to, step] = slice;\n    const len = indices_len(from, to, step);\n    if (slices.length === 0) {\n        for (let i = 0; i < len; i++) {\n            out.data.set(value, curr_stride * (from + step * i) * bytes_per_element);\n        }\n        return;\n    }\n    for (let i = 0; i < len; i++) {\n        const data = out.data.subarray(curr_stride * (from + step * i) * bytes_per_element);\n        set_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n    }\n}\nfunction set_from_chunk_binary(dest, src, bytes_per_element, projections) {\n    const [proj, ...projs] = projections;\n    const [dstride, ...dstrides] = dest.stride;\n    const [sstride, ...sstrides] = src.stride;\n    if (proj.from === null) {\n        if (projs.length === 0) {\n            dest.data.set(src.data.subarray(0, bytes_per_element), proj.to * bytes_per_element);\n            return;\n        }\n        set_from_chunk_binary({\n            data: dest.data.subarray(dstride * proj.to * bytes_per_element),\n            stride: dstrides,\n        }, src, bytes_per_element, projs);\n        return;\n    }\n    if (proj.to === null) {\n        if (projs.length === 0) {\n            let offset = proj.from * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + bytes_per_element), 0);\n            return;\n        }\n        set_from_chunk_binary(dest, {\n            data: src.data.subarray(sstride * proj.from * bytes_per_element),\n            stride: sstrides,\n        }, bytes_per_element, projs);\n        return;\n    }\n    const [from, to, step] = proj.to;\n    const [sfrom, _, sstep] = proj.from;\n    const len = indices_len(from, to, step);\n    if (projs.length === 0) {\n        // NB: we have a contiguous block of memory\n        // so we can just copy over all the data at once.\n        if (step === 1 && sstep === 1 && dstride === 1 && sstride === 1) {\n            let offset = sfrom * bytes_per_element;\n            let size = len * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + size), from * bytes_per_element);\n            return;\n        }\n        // Otherwise, we have to copy over each element individually.\n        for (let i = 0; i < len; i++) {\n            let offset = sstride * (sfrom + sstep * i) * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + bytes_per_element), dstride * (from + step * i) * bytes_per_element);\n        }\n        return;\n    }\n    for (let i = 0; i < len; i++) {\n        set_from_chunk_binary({\n            data: dest.data.subarray(dstride * (from + i * step) * bytes_per_element),\n            stride: dstrides,\n        }, {\n            data: src.data.subarray(sstride * (sfrom + i * sstep) * bytes_per_element),\n            stride: sstrides,\n        }, bytes_per_element, projs);\n    }\n}\n//# sourceMappingURL=ops.js.map","import { get_context } from \"../hierarchy.js\";\nimport { BasicIndexer } from \"./indexer.js\";\nimport { create_queue } from \"./util.js\";\nfunction unwrap(arr, idx) {\n    return (\"get\" in arr ? arr.get(idx) : arr[idx]);\n}\nexport async function get(arr, selection, opts, setter) {\n    let context = get_context(arr);\n    let indexer = new BasicIndexer({\n        selection,\n        shape: arr.shape,\n        chunk_shape: arr.chunks,\n    });\n    let out = setter.prepare(new context.TypedArray(indexer.shape.reduce((a, b) => a * b, 1)), indexer.shape, context.get_strides(indexer.shape));\n    let queue = opts.create_queue?.() ?? create_queue();\n    for (const { chunk_coords, mapping } of indexer) {\n        queue.add(async () => {\n            let { data, shape, stride } = await arr.getChunk(chunk_coords, opts.opts);\n            let chunk = setter.prepare(data, shape, stride);\n            setter.set_from_chunk(out, chunk, mapping);\n        });\n    }\n    await queue.onIdle();\n    // If the final out shape is empty, we just return a scalar.\n    // @ts-expect-error - TS can't narrow this conditional type\n    return indexer.shape.length === 0 ? unwrap(out.data, 0) : out;\n}\n//# sourceMappingURL=get.js.map","/** Similar to python's `range` function. Supports positive ranges only. */\nexport function* range(start, stop, step = 1) {\n    if (stop === undefined) {\n        stop = start;\n        start = 0;\n    }\n    for (let i = start; i < stop; i += step) {\n        yield i;\n    }\n}\n/**\n * python-like itertools.product generator\n * https://gist.github.com/cybercase/db7dde901d7070c98c48\n */\nexport function* product(...iterables) {\n    if (iterables.length === 0) {\n        return;\n    }\n    // make a list of iterators from the iterables\n    const iterators = iterables.map((it) => it[Symbol.iterator]());\n    const results = iterators.map((it) => it.next());\n    if (results.some((r) => r.done)) {\n        throw new Error(\"Input contains an empty iterator.\");\n    }\n    for (let i = 0;;) {\n        if (results[i].done) {\n            // reset the current iterator\n            iterators[i] = iterables[i][Symbol.iterator]();\n            results[i] = iterators[i].next();\n            // advance, and exit if we've reached the end\n            if (++i >= iterators.length) {\n                return;\n            }\n        }\n        else {\n            // @ts-expect-error - TS can't infer this\n            yield results.map(({ value }) => value);\n            i = 0;\n        }\n        results[i] = iterators[i].next();\n    }\n}\n// https://github.com/python/cpython/blob/263c0dd16017613c5ea2fbfc270be4de2b41b5ad/Objects/sliceobject.c#L376-L519\nexport function slice_indices({ start, stop, step }, length) {\n    if (step === 0) {\n        throw new Error(\"slice step cannot be zero\");\n    }\n    step = step ?? 1;\n    const step_is_negative = step < 0;\n    /* Find lower and upper bounds for start and stop. */\n    const [lower, upper] = step_is_negative ? [-1, length - 1] : [0, length];\n    /* Compute start. */\n    if (start === null) {\n        start = step_is_negative ? upper : lower;\n    }\n    else {\n        if (start < 0) {\n            start += length;\n            if (start < lower) {\n                start = lower;\n            }\n        }\n        else if (start > upper) {\n            start = upper;\n        }\n    }\n    /* Compute stop. */\n    if (stop === null) {\n        stop = step_is_negative ? lower : upper;\n    }\n    else {\n        if (stop < 0) {\n            stop += length;\n            if (stop < lower) {\n                stop = lower;\n            }\n        }\n        else if (stop > upper) {\n            stop = upper;\n        }\n    }\n    return [start, stop, step];\n}\nexport function slice(start, stop, step = null) {\n    if (stop === undefined) {\n        stop = start;\n        start = null;\n    }\n    return {\n        start,\n        stop,\n        step,\n    };\n}\n/** Built-in \"queue\" for awaiting promises. */\nexport function create_queue() {\n    const promises = [];\n    return {\n        add: (fn) => promises.push(fn()),\n        onIdle: () => Promise.all(promises),\n    };\n}\n//# sourceMappingURL=util.js.map","import { KeyError, NodeNotFoundError } from \"./errors.js\";\nimport { Array, Group, Location } from \"./hierarchy.js\";\nimport { ensure_correct_scalar, json_decode_object, rethrow_unless, v2_to_v3_array_metadata, v2_to_v3_group_metadata, } from \"./util.js\";\nlet VERSION_COUNTER = create_version_counter();\nfunction create_version_counter() {\n    let version_counts = new WeakMap();\n    function get_counts(store) {\n        let counts = version_counts.get(store) ?? { v2: 0, v3: 0 };\n        version_counts.set(store, counts);\n        return counts;\n    }\n    return {\n        increment(store, version) {\n            get_counts(store)[version] += 1;\n        },\n        version_max(store) {\n            let counts = get_counts(store);\n            return counts.v3 > counts.v2 ? \"v3\" : \"v2\";\n        },\n    };\n}\nasync function load_attrs(location) {\n    let meta_bytes = await location.store.get(location.resolve(\".zattrs\").path);\n    if (!meta_bytes)\n        return {};\n    return json_decode_object(meta_bytes);\n}\nasync function open_v2(location, options = {}) {\n    let loc = \"store\" in location ? location : new Location(location);\n    let attrs = {};\n    if (options.attrs ?? true)\n        attrs = await load_attrs(loc);\n    if (options.kind === \"array\")\n        return open_array_v2(loc, attrs);\n    if (options.kind === \"group\")\n        return open_group_v2(loc, attrs);\n    return open_array_v2(loc, attrs).catch((err) => {\n        rethrow_unless(err, NodeNotFoundError);\n        return open_group_v2(loc, attrs);\n    });\n}\nasync function open_array_v2(location, attrs) {\n    let { path } = location.resolve(\".zarray\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v2 array\", {\n            cause: new KeyError(path),\n        });\n    }\n    VERSION_COUNTER.increment(location.store, \"v2\");\n    return new Array(location.store, location.path, v2_to_v3_array_metadata(json_decode_object(meta), attrs));\n}\nasync function open_group_v2(location, attrs) {\n    let { path } = location.resolve(\".zgroup\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v2 group\", {\n            cause: new KeyError(path),\n        });\n    }\n    VERSION_COUNTER.increment(location.store, \"v2\");\n    return new Group(location.store, location.path, v2_to_v3_group_metadata(json_decode_object(meta), attrs));\n}\nasync function _open_v3(location) {\n    let { store, path } = location.resolve(\"zarr.json\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v3 array or group\", {\n            cause: new KeyError(path),\n        });\n    }\n    let meta_doc = json_decode_object(meta);\n    if (meta_doc.node_type === \"array\") {\n        meta_doc.fill_value = ensure_correct_scalar(meta_doc);\n    }\n    return meta_doc.node_type === \"array\"\n        ? new Array(store, location.path, meta_doc)\n        : new Group(store, location.path, meta_doc);\n}\nasync function open_v3(location, options = {}) {\n    let loc = \"store\" in location ? location : new Location(location);\n    let node = await _open_v3(loc);\n    VERSION_COUNTER.increment(loc.store, \"v3\");\n    if (options.kind === undefined)\n        return node;\n    if (options.kind === \"array\" && node instanceof Array)\n        return node;\n    if (options.kind === \"group\" && node instanceof Group)\n        return node;\n    let kind = node instanceof Array ? \"array\" : \"group\";\n    throw new Error(`Expected node of kind ${options.kind}, found ${kind}.`);\n}\nexport async function open(location, options = {}) {\n    let store = \"store\" in location ? location.store : location;\n    let version_max = VERSION_COUNTER.version_max(store);\n    // Use the open function for the version with the most successful opens.\n    // Note that here we use the dot syntax to access the open functions\n    // because this enables us to use vi.spyOn during testing.\n    let open_primary = version_max === \"v2\" ? open.v2 : open.v3;\n    let open_secondary = version_max === \"v2\" ? open.v3 : open.v2;\n    return open_primary(location, options).catch((err) => {\n        rethrow_unless(err, NodeNotFoundError);\n        return open_secondary(location, options);\n    });\n}\nopen.v2 = open_v2;\nopen.v3 = open_v3;\n//# sourceMappingURL=open.js.map","/**\n * Custom array-like views (i.e., TypedArrays) for Zarr binary data buffers.\n *\n * @module\n */\n/**\n * An array-like view of a fixed-length boolean buffer.\n *\n * Encoded as 1 byte per value.\n */\nexport class BoolArray {\n    #bytes;\n    constructor(x, byteOffset, length) {\n        if (typeof x === \"number\") {\n            this.#bytes = new Uint8Array(x);\n        }\n        else if (x instanceof ArrayBuffer) {\n            this.#bytes = new Uint8Array(x, byteOffset, length);\n        }\n        else {\n            this.#bytes = new Uint8Array(Array.from(x, (v) => (v ? 1 : 0)));\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return 1;\n    }\n    get byteOffset() {\n        return this.#bytes.byteOffset;\n    }\n    get byteLength() {\n        return this.#bytes.byteLength;\n    }\n    get buffer() {\n        return this.#bytes.buffer;\n    }\n    get length() {\n        return this.#bytes.length;\n    }\n    get(idx) {\n        let value = this.#bytes[idx];\n        return typeof value === \"number\" ? value !== 0 : value;\n    }\n    set(idx, value) {\n        this.#bytes[idx] = value ? 1 : 0;\n    }\n    fill(value) {\n        this.#bytes.fill(value ? 1 : 0);\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n/**\n * An array-like view of a fixed-length byte buffer.\n *\n * Encodes a raw byte sequences without enforced encoding.\n */\nexport class ByteStringArray {\n    _data;\n    chars;\n    #encoder;\n    constructor(chars, x, byteOffset, length) {\n        this.chars = chars;\n        this.#encoder = new TextEncoder();\n        if (typeof x === \"number\") {\n            this._data = new Uint8Array(x * chars);\n        }\n        else if (x instanceof ArrayBuffer) {\n            if (length)\n                length = length * chars;\n            this._data = new Uint8Array(x, byteOffset, length);\n        }\n        else {\n            let values = Array.from(x);\n            this._data = new Uint8Array(values.length * chars);\n            for (let i = 0; i < values.length; i++) {\n                this.set(i, values[i]);\n            }\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return this.chars;\n    }\n    get byteOffset() {\n        return this._data.byteOffset;\n    }\n    get byteLength() {\n        return this._data.byteLength;\n    }\n    get buffer() {\n        return this._data.buffer;\n    }\n    get length() {\n        return this.byteLength / this.BYTES_PER_ELEMENT;\n    }\n    get(idx) {\n        const view = new Uint8Array(this.buffer, this.byteOffset + this.chars * idx, this.chars);\n        // biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n        return new TextDecoder().decode(view).replace(/\\x00/g, \"\");\n    }\n    set(idx, value) {\n        const view = new Uint8Array(this.buffer, this.byteOffset + this.chars * idx, this.chars);\n        view.fill(0); // clear current\n        view.set(this.#encoder.encode(value));\n    }\n    fill(value) {\n        const encoded = this.#encoder.encode(value);\n        for (let i = 0; i < this.length; i++) {\n            this._data.set(encoded, i * this.chars);\n        }\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n/**\n * An array-like view of a fixed-length Unicode string buffer.\n *\n * Encoded as UTF-32 code points.\n */\nexport class UnicodeStringArray {\n    #data;\n    chars;\n    constructor(chars, x, byteOffset, length) {\n        this.chars = chars;\n        if (typeof x === \"number\") {\n            this.#data = new Int32Array(x * chars);\n        }\n        else if (x instanceof ArrayBuffer) {\n            if (length)\n                length *= chars;\n            this.#data = new Int32Array(x, byteOffset, length);\n        }\n        else {\n            const values = x;\n            const d = new UnicodeStringArray(chars, 1);\n            this.#data = new Int32Array((function* () {\n                for (let str of values) {\n                    d.set(0, str);\n                    yield* d.#data;\n                }\n            })());\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return this.#data.BYTES_PER_ELEMENT * this.chars;\n    }\n    get byteLength() {\n        return this.#data.byteLength;\n    }\n    get byteOffset() {\n        return this.#data.byteOffset;\n    }\n    get buffer() {\n        return this.#data.buffer;\n    }\n    get length() {\n        return this.#data.length / this.chars;\n    }\n    get(idx) {\n        const offset = this.chars * idx;\n        let result = \"\";\n        for (let i = 0; i < this.chars; i++) {\n            result += String.fromCodePoint(this.#data[offset + i]);\n        }\n        // biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n        return result.replace(/\\u0000/g, \"\");\n    }\n    set(idx, value) {\n        const offset = this.chars * idx;\n        const view = this.#data.subarray(offset, offset + this.chars);\n        view.fill(0); // clear current\n        for (let i = 0; i < this.chars; i++) {\n            view[i] = value.codePointAt(i) ?? 0;\n        }\n    }\n    fill(value) {\n        // encode once\n        this.set(0, value);\n        // copy the encoded values to all other elements\n        let encoded = this.#data.subarray(0, this.chars);\n        for (let i = 1; i < this.length; i++) {\n            this.#data.set(encoded, i * this.chars);\n        }\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n//# sourceMappingURL=typedarray.js.map","import { BoolArray, ByteStringArray, UnicodeStringArray, } from \"./typedarray.js\";\nexport function json_encode_object(o) {\n    const str = JSON.stringify(o, null, 2);\n    return new TextEncoder().encode(str);\n}\nexport function json_decode_object(bytes) {\n    const str = new TextDecoder().decode(bytes);\n    return JSON.parse(str);\n}\nexport function byteswap_inplace(view, bytes_per_element) {\n    const numFlips = bytes_per_element / 2;\n    const endByteIndex = bytes_per_element - 1;\n    let t = 0;\n    for (let i = 0; i < view.length; i += bytes_per_element) {\n        for (let j = 0; j < numFlips; j += 1) {\n            t = view[i + j];\n            view[i + j] = view[i + endByteIndex - j];\n            view[i + endByteIndex - j] = t;\n        }\n    }\n}\nexport function get_ctr(data_type) {\n    if (data_type === \"v2:object\") {\n        return globalThis.Array;\n    }\n    let match = data_type.match(/v2:([US])(\\d+)/);\n    if (match) {\n        let [, kind, chars] = match;\n        // @ts-expect-error\n        return (kind === \"U\" ? UnicodeStringArray : ByteStringArray).bind(null, Number(chars));\n    }\n    // @ts-expect-error - We've checked that the key exists\n    let ctr = {\n        int8: Int8Array,\n        int16: Int16Array,\n        int32: Int32Array,\n        int64: globalThis.BigInt64Array,\n        uint8: Uint8Array,\n        uint16: Uint16Array,\n        uint32: Uint32Array,\n        uint64: globalThis.BigUint64Array,\n        float16: globalThis.Float16Array,\n        float32: Float32Array,\n        float64: Float64Array,\n        bool: BoolArray,\n    }[data_type];\n    assert(ctr, `Unknown or unsupported data_type: ${data_type}`);\n    return ctr;\n}\n/** Compute strides for 'C' or 'F' ordered array from shape */\nexport function get_strides(shape, order) {\n    const rank = shape.length;\n    if (typeof order === \"string\") {\n        order =\n            order === \"C\"\n                ? Array.from({ length: rank }, (_, i) => i) // Row-major (identity order)\n                : Array.from({ length: rank }, (_, i) => rank - 1 - i); // Column-major (reverse order)\n    }\n    assert(rank === order.length, \"Order length must match the number of dimensions.\");\n    let step = 1;\n    let stride = new Array(rank);\n    for (let i = order.length - 1; i >= 0; i--) {\n        stride[order[i]] = step;\n        step *= shape[order[i]];\n    }\n    return stride;\n}\n// https://zarr-specs.readthedocs.io/en/latest/v3/core/v3.0.html#chunk-key-encoding\nexport function create_chunk_key_encoder({ name, configuration, }) {\n    if (name === \"default\") {\n        const separator = configuration?.separator ?? \"/\";\n        return (chunk_coords) => [\"c\", ...chunk_coords].join(separator);\n    }\n    if (name === \"v2\") {\n        const separator = configuration?.separator ?? \".\";\n        return (chunk_coords) => chunk_coords.join(separator) || \"0\";\n    }\n    throw new Error(`Unknown chunk key encoding: ${name}`);\n}\nfunction coerce_dtype(dtype) {\n    if (dtype === \"|O\") {\n        return { data_type: \"v2:object\" };\n    }\n    let match = dtype.match(/^([<|>])(.*)$/);\n    assert(match, `Invalid dtype: ${dtype}`);\n    let [, endian, rest] = match;\n    let data_type = {\n        b1: \"bool\",\n        i1: \"int8\",\n        u1: \"uint8\",\n        i2: \"int16\",\n        u2: \"uint16\",\n        i4: \"int32\",\n        u4: \"uint32\",\n        i8: \"int64\",\n        u8: \"uint64\",\n        f2: \"float16\",\n        f4: \"float32\",\n        f8: \"float64\",\n    }[rest] ??\n        (rest.startsWith(\"S\") || rest.startsWith(\"U\") ? `v2:${rest}` : undefined);\n    assert(data_type, `Unsupported or unknown dtype: ${dtype}`);\n    if (endian === \"|\") {\n        return { data_type };\n    }\n    return { data_type, endian: endian === \"<\" ? \"little\" : \"big\" };\n}\nexport function v2_to_v3_array_metadata(meta, attributes = {}) {\n    let codecs = [];\n    let dtype = coerce_dtype(meta.dtype);\n    if (meta.order === \"F\") {\n        codecs.push({ name: \"transpose\", configuration: { order: \"F\" } });\n    }\n    if (\"endian\" in dtype && dtype.endian === \"big\") {\n        codecs.push({ name: \"bytes\", configuration: { endian: \"big\" } });\n    }\n    for (let { id, ...configuration } of meta.filters ?? []) {\n        codecs.push({ name: id, configuration });\n    }\n    if (meta.compressor) {\n        let { id, ...configuration } = meta.compressor;\n        codecs.push({ name: id, configuration });\n    }\n    return {\n        zarr_format: 3,\n        node_type: \"array\",\n        shape: meta.shape,\n        data_type: dtype.data_type,\n        chunk_grid: {\n            name: \"regular\",\n            configuration: {\n                chunk_shape: meta.chunks,\n            },\n        },\n        chunk_key_encoding: {\n            name: \"v2\",\n            configuration: {\n                separator: meta.dimension_separator ?? \".\",\n            },\n        },\n        codecs,\n        fill_value: meta.fill_value,\n        attributes,\n    };\n}\nexport function v2_to_v3_group_metadata(_meta, attributes = {}) {\n    return {\n        zarr_format: 3,\n        node_type: \"group\",\n        attributes,\n    };\n}\nexport function is_dtype(dtype, query) {\n    if (query !== \"number\" &&\n        query !== \"bigint\" &&\n        query !== \"boolean\" &&\n        query !== \"object\" &&\n        query !== \"string\") {\n        return dtype === query;\n    }\n    let is_boolean = dtype === \"bool\";\n    if (query === \"boolean\")\n        return is_boolean;\n    let is_string = dtype.startsWith(\"v2:U\") || dtype.startsWith(\"v2:S\");\n    if (query === \"string\")\n        return is_string;\n    let is_bigint = dtype === \"int64\" || dtype === \"uint64\";\n    if (query === \"bigint\")\n        return is_bigint;\n    let is_object = dtype === \"v2:object\";\n    if (query === \"object\")\n        return is_object;\n    return !is_string && !is_bigint && !is_boolean && !is_object;\n}\nexport function is_sharding_codec(codec) {\n    return codec?.name === \"sharding_indexed\";\n}\nexport function ensure_correct_scalar(metadata) {\n    if ((metadata.data_type === \"uint64\" || metadata.data_type === \"int64\") &&\n        metadata.fill_value != null) {\n        // @ts-expect-error - We've narrowed the type of fill_value correctly\n        return BigInt(metadata.fill_value);\n    }\n    return metadata.fill_value;\n}\n/**\n * Ensures an error matches expected type(s), otherwise rethrows.\n *\n * Unmatched errors bubble up, like Python's `except`. Narrows error types for\n * type-safe property access.\n *\n * @see {@link https://gist.github.com/manzt/3702f19abb714e21c22ce48851c75abf}\n *\n * @example\n * ```ts\n * class DatabaseError extends Error { }\n * class NetworkError extends Error { }\n *\n * try {\n *   await db.query();\n * } catch (err) {\n *   rethrow_unless(err, DatabaseError, NetworkError);\n *   err // DatabaseError | NetworkError\n * }\n * ```\n *\n * @param error - The error to check\n * @param errors - Expected error type(s)\n * @throws The original error if it doesn't match expected type(s)\n */\nexport function rethrow_unless(error, ...errors) {\n    if (!errors.some((ErrorClass) => error instanceof ErrorClass)) {\n        throw error;\n    }\n}\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(expression, msg = \"\") {\n    if (!expression) {\n        throw new Error(msg);\n    }\n}\n/**\n * @param {ArrayBuffer |ArrayBufferView | Response} data\n * @param {Object} options\n * @param {CompressionFormat} options.format\n * @param {AbortSignal} [options.signal]\n *\n * @returns {Promise<ArrayBuffer>}\n */\nexport async function decompress(data, { format, signal }) {\n    const response = data instanceof Response ? data : new Response(data);\n    assert(response.body, \"Response does not contain body.\");\n    try {\n        const decompressedResponse = new Response(response.body.pipeThrough(new DecompressionStream(format), { signal }));\n        const buffer = await decompressedResponse.arrayBuffer();\n        return buffer;\n    }\n    catch {\n        signal?.throwIfAborted();\n        throw new Error(`Failed to decode ${format}`);\n    }\n}\n//# sourceMappingURL=util.js.map"],"names":["volumeSize","volumeDims","shape","defaultImageInfo","name","atlasTileDims","subregionSize","subregionOffset","numChannelsPerSource","channelNames","channelColors","multiscaleLevel","multiscaleLevelDims","spacing","spaceUnit","timeUnit","dataType","transform","translation","rotation","scale","CImageInfo","constructor","imageInfo","this","currentLevelDims","numChannels","reduce","a","b","originalSize","physicalPixelSize","spatialUnit","times","timeScale","numMultiscaleLevels","length","computeAtlasSize","volDims","VolumeLoadErrorType","VolumeLoadError","Error","message","options","super","type","UNKNOWN","wrapVolumeLoadError","ignore","e","undefined","console","log","cause","set","allEqual","arr","every","v","pushN","val","n","i","push","directionToIndex","dir","absDir","Number","updateMinMax","minmax","ChunkPrefetchIterator","chunks","tzyxMaxPrefetchOffset","tczyxChunksPerSource","priorityDirections","onlyPriorityDirections","extrema","Infinity","chunk","flat","some","isFinite","directionStates","priorityDirectionStates","direction","start","entries","dimension","tczyxIndex","end","endsPerSource","map","chunkDims","Math","min","sourceEnd","max","directionState","includes","iterateDirections","directions","offset","filter","Array","isArray","offsetDir","newChunk","slice","Symbol","iterator","parseHexColor","color","result","exec","parseInt","getSourceChannelMeta","src","omeroMetadata","channels","names","colors","channel","label","channelOffset","cIdx","axesTCZYX","scaleLevels","from","_","idx","getDimensionCount","t","c","z","remapAxesToTCZYX","axes","axisNames","forEach","axis","axisIdx","indexOf","INVALID_METADATA","noXAxis","orderByDimension","valsTCZYX","orderTCZYX","specLen","orderByTCZYX","valsDimension","defaultValue","getScale","dataset","transforms","coordinateTransformations","warn","scaleTransform","find","compareZarrArraySize","aArr","aTCZYX","bArr","bTCZYX","diffZ","diffY","diffX","aboutEquals","abs","scaleTransformsAreEqual","aSrc","aLevel","bSrc","bLevel","aScale","multiscaleMetadata","datasets","bScale","matchSourceScaleLevels","sources","matchedLevels","matchedMetas","scaleIndexes","fill","smallestIdx","smallestSrc","smallestArr","currentIdx","currentSrc","currentArr","ordering","INVALID_MULTI_SOURCE_ZARR","largestT","currentT","matchedScaleLevel","srcIdx","toOMEZarrMetaV4","meta","ome","isObjectWithProp","obj","prop","assertMetadataHasProp","assertPropIsArray","assertMetadataHasMultiscales","validateOMEZarrMetadata","multiscaleIdx","multiscaleMeta","multiscales","multiscaleName","data","fetch_range","url","opts","headers","Range","fetch","resolve","root","path","base","URL","pathname","endsWith","resolved","search","async","handle_response","response","status","Uint8Array","arrayBuffer","statusText","overrides","useSuffixRequest","storeOverrides","requestOverrides","get","key","href","getRange","range","init","suffix_length","use_suffix_request","method","ok","content_length","fetch_suffix","suffixLength","wrapArray","array","basePath","cache","queue","keyBase","getChunk","coords","subscriber","reportChunk","fullKey","join","cacheResult","addRequest","isPrefetch","insert","Proxy","target","value","Function","args","apply","RelaxedFetchStore","baseUrl","startsWith","DEFAULT_REQUEST_CANCEL_REASON","RequestQueue","maxActiveRequests","maxLowPriorityRequests","allRequests","Map","activeRequests","Set","queueLowPriority","registerRequest","requestAction","promiseResolve","promiseReject","promise","Promise","reject","requestItem","action","addRequestToQueue","lowPriority","has","timeoutId","clearTimeout","dequeue","delayMs","lowPriorityIndex","splice","setTimeout","addRequests","requests","promises","item","numRequests","size","requestKey","shift","add","then","delete","cancelRequest","cancelReason","queueIndex","cancelAllRequests","keys","hasRequest","requestRunning","SubscribableRequestQueue","nextSubscriberId","subscribers","resolveAll","subscriberId","rejectAll","reason","addSubscriber","catch","existingRequest","rejectSubscription","subscriptions","findIndex","sub","rejecters","removeSubscriber","hasSubscriber","isSubscribed","WorkerMsgType","WorkerResponseResult","WorkerEventType","rebuildLoadSpec","spec","subregion","copy","BitroundCodec","kind","configuration","_meta","keepbits","fromConfig","encode","_arr","decode","LITTLE_ENDIAN_OS","Uint32Array","buffer","byteOffset","byteLength","system_is_little_endian","bytes_per_element","TypedArray","BYTES_PER_ELEMENT","BytesCodec","endian","data_type","sample","bytes","stride","Crc32cCodec","GzipCodec","_bytes","format","throw_on_nan_replacer","_key","isNaN","POSITIVE_INFINITY","NEGATIVE_INFINITY","sort_keys_replacer","Object","sort","sorted","JsonCodec","encoding","skipkeys","ensure_ascii","check_circular","allow_nan","sort_keys","indent","strict","separators","buf","replacer_functions","items","replacer","new_value","sub_replacer","json_str","JSON","stringify","replace","chr","full_str","charCodeAt","toString","substring","TextEncoder","pop","proxy","TransposeCodec","order","rank","inverseOrder","x","source","s","index","entry","get_order","dim","matches_order","out","chars","empty_like","n_dims","src_data","out_data","src_idx","out_idx","convert_array_order","VLenUTF8","_chunk","decoder","TextDecoder","view","DataView","getUint32","pos","item_length","ZlibCodec","registry","m","default","create_codec_pipeline","chunk_metadata","codecs","load_codecs","codec","array_to_array","array_to_bytes","bytes_to_bytes","chunk_meta","Codec","MAX_BIG_UINT","create_sharded_chunk_getter","location","shard_shape","encode_shard_key","sharding_config","store","get_range","bind","index_shape","d","chunk_shape","index_codec","index_codecs","chunk_coord","shard_coord","floor","shard_path","checksum_size","index_size","linear_offset","acc","sel","Location","Group","metadata","attrs","attributes","get_array_order","maybe_transpose_codec","CONTEXT_MARKER","get_context","fill_value","shared_context","encode_chunk_key","chunk_key_encoding","native_order","get_strides","get_chunk_bytes","chunk_grid","chunk_coords","chunk_key","chunk_path","create_context","dtype","context","maybe_bytes","is","query","IndexError","msg","IntDimIndexer","dim_sel","dim_len","dim_chunk_len","nitems","trunc","err_boundscheck","normalize_integer_selection","dim_chunk_ix","dim_offset","dim_chunk_sel","SliceDimIndexer","stop","step","nchunks","err_negative_step","ceil","dim_chunk_ix_from","dim_chunk_ix_to","dim_limit","dim_out_offset","dim_chunk_sel_start","remainder","dim_chunk_sel_stop","dim_out_sel","BasicIndexer","dim_indexers","selection","normalized","err_too_many_indices","check_selection_length","normalize_selection","ixr","sixr","dim_projections","p","mapping","to","object_array_view","subarray","compat_chunk","globalThis","setter","prepare","set_scalar","dest","set_scalar_binary","get_typed_array_constructor","compat_scalar","set_from_chunk","projections","set_from_chunk_binary","indexer","create_queue","onIdle","unwrap","indices_len","out_selection","slices","curr_stride","len","proj","projs","dstride","dstrides","sstride","sstrides","sfrom","sstep","product","iterables","iterators","it","results","next","r","done","slice_indices","step_is_negative","lower","upper","fn","all","VERSION_COUNTER","version_counts","WeakMap","get_counts","counts","v2","v3","increment","version","version_max","create_version_counter","open_array_v2","open_group_v2","open","open_primary","open_secondary","err","loc","meta_bytes","load_attrs","node","meta_doc","node_type","_open_v3","BoolArray","ArrayBuffer","ByteStringArray","_data","values","encoded","UnicodeStringArray","Int32Array","str","String","fromCodePoint","codePointAt","json_decode_object","parse","byteswap_inplace","numFlips","endByteIndex","j","get_ctr","match","ctr","int8","Int8Array","int16","Int16Array","int32","int64","BigInt64Array","uint8","uint16","Uint16Array","uint32","uint64","BigUint64Array","float16","Float16Array","float32","Float32Array","float64","Float64Array","bool","assert","create_chunk_key_encoder","separator","v2_to_v3_array_metadata","rest","b1","i1","u1","i2","u2","i4","u4","i8","u8","f2","f4","f8","coerce_dtype","id","filters","compressor","zarr_format","dimension_separator","v2_to_v3_group_metadata","is_dtype","is_boolean","is_string","is_bigint","is_object","is_sharding_codec","ensure_correct_scalar","BigInt","rethrow_unless","error","errors","ErrorClass","expression","decompress","signal","Response","body","decompressedResponse","pipeThrough","DecompressionStream","throwIfAborted"],"sourceRoot":""}