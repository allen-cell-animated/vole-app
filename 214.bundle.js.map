{"version":3,"file":"214.bundle.js","mappings":"iKAUO,SAASA,EAAWC,GACzB,OAAO,IAAI,MAAQA,EAAWC,MAAM,GAAID,EAAWC,MAAM,GAAID,EAAWC,MAAM,GAChF,CCVO,SAASC,IACd,MAAO,CACLC,KAAM,GACNC,cAAe,CAAC,EAAG,GACnBC,cAAe,CAAC,EAAG,EAAG,GACtBC,gBAAiB,CAAC,EAAG,EAAG,GACxBC,oBAAqB,EACrBC,aAAc,CAAC,KACfC,cAAe,CAAC,CAAC,IAAK,IAAK,MAC3BC,gBAAiB,EACjBC,oBAAqB,CAAC,CACpBV,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBW,QAAS,CAAC,EAAG,EAAG,EAAG,EAAG,GACtBC,UAAW,GACXC,SAAU,GACVC,SAAU,UAEZC,UAAW,CACTC,YAAa,CAAC,EAAG,EAAG,GACpBC,SAAU,CAAC,EAAG,EAAG,GACjBC,MAAO,CAAC,EAAG,EAAG,IAGpB,CACO,MAAMC,EACX,WAAAC,CAAYC,GACVC,KAAKD,UAAYA,GAzBZ,CACLnB,KAAM,GACNC,cAAe,CAAC,EAAG,GACnBC,cAAe,CAAC,EAAG,EAAG,GACtBC,gBAAiB,CAAC,EAAG,EAAG,GACxBC,oBAAqB,EACrBC,aAAc,CAAC,KACfC,cAAe,CAAC,CAAC,IAAK,IAAK,MAC3BC,gBAAiB,EACjBC,oBAAqB,CAAC,CACpBV,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBW,QAAS,CAAC,EAAG,EAAG,EAAG,EAAG,GACtBC,UAAW,GACXC,SAAU,GACVC,SAAU,UAEZC,UAAW,CACTC,YAAa,CAAC,EAAG,EAAG,GACpBC,SAAU,CAAC,EAAG,EAAG,GACjBC,MAAO,CAAC,EAAG,EAAG,IAOlB,CACA,oBAAIK,GACF,OAAOD,KAAKD,UAAUX,oBAAoBY,KAAKD,UAAUZ,gBAC3D,CAGA,eAAIe,GACF,OAAOF,KAAKD,UAAUf,mBACxB,CAGA,gBAAImB,GACF,OAAO3B,EAAWwB,KAAKD,UAAUX,oBAAoB,GACvD,CAGA,cAAIZ,GACF,OAAOA,EAAWwB,KAAKC,iBACzB,CAGA,qBAAIG,GACF,ODtC8B3B,ECsCLuB,KAAKD,UAAUX,oBAAoB,GDrCvD,IAAI,MAAQX,EAAWY,QAAQ,GAAIZ,EAAWY,QAAQ,GAAIZ,EAAWY,QAAQ,IAD/E,IAA2BZ,CCuChC,CAGA,eAAI4B,GACF,OAAOL,KAAKD,UAAUX,oBAAoB,GAAGE,SAC/C,CAGA,SAAIgB,GAEF,OAAON,KAAKC,iBAAiBvB,MAAM,EACrC,CAGA,aAAI6B,GAEF,OAAOP,KAAKC,iBAAiBZ,QAAQ,EACvC,CAGA,YAAIE,GACF,OAAOS,KAAKC,iBAAiBV,QAC/B,CAGA,uBAAIiB,GACF,OAAOR,KAAKD,UAAUX,oBAAoBqB,MAC5C,CAGA,gBAAIxB,GACF,OAAOe,KAAKD,UAAUd,YACxB,CAGA,iBAAIC,GACF,OAAOc,KAAKD,UAAUb,aACxB,CAGA,iBAAIJ,GACF,OAAO,IAAI,SAAWkB,KAAKD,UAAUjB,cACvC,CAGA,mBAAIC,GACF,OAAO,IAAI,SAAWiB,KAAKD,UAAUhB,gBACvC,CACA,mBAAII,GACF,OAAOa,KAAKD,UAAUZ,eACxB,CAMA,iBAAIN,GACF,OAAO,IAAI,SAAWmB,KAAKD,UAAUlB,cACvC,CACA,aAAIY,GACF,MAAO,CACLC,YAAa,IAAI,SAAWM,KAAKD,UAAUN,UAAUC,aACrDC,SAAU,IAAI,SAAWK,KAAKD,UAAUN,UAAUE,UAClDC,MAAO,IAAI,SAAWI,KAAKD,UAAUN,UAAUG,OAEnD,EAEK,SAASc,EAAiBX,GAC/B,MAAM,cACJlB,GACEkB,EACEY,EAAUZ,EAAUX,oBAAoBW,EAAUZ,iBAExD,MAAO,CAACN,EAAc,GAAK8B,EAAQjC,MAAM,GAAIG,EAAc,GAAK8B,EAAQjC,MAAM,GAChF,C,2ECzHO,IAAIkC,EAAmC,SAAUA,GAOtD,OANAA,EAA6B,QAAI,UACjCA,EAA+B,UAAI,YACnCA,EAA+B,UAAI,YACnCA,EAAsC,iBAAI,mBAC1CA,EAAsC,iBAAI,mBAC1CA,EAA+C,0BAAI,4BAC5CA,CACT,CAR8C,CAQ5C,CAAC,GACI,MAAMC,UAAwBC,MACnC,WAAAhB,CAAYiB,EAASC,GACnBC,MAAMF,EAASC,GACfhB,KAAKpB,KAAO,kBACZoB,KAAKkB,KAAOF,GAASE,MAAQN,EAAoBO,OACnD,EAUK,SAASC,EAAoBL,EAAU,mDAAoDG,EAAON,EAAoBO,QAASE,GACpI,OAAOC,IACL,QAAeC,IAAXF,GAAwBC,IAAMD,EAChC,OAAOC,EAET,GAAIA,aAAaT,EACf,MAAMS,EAGR,MADAE,QAAQC,IAAI,8BAA8BH,KACpC,IAAIT,EAAgBE,EAAS,CACjCG,OACAQ,MAAOJ,GACP,CAEN,CAnBA,IAAkBK,IAAI,oBAAqB,KAC3C,IAAkBA,IAAI,WAAY,KAClC,IAAkBA,IAAI,kBAAmBd,E,kCC1BzC,MAAMe,EAAWC,GAAOA,EAAIC,OAAMC,GAAKA,IAAMF,EAAI,KAC3CG,EAAQ,CAACH,EAAKI,EAAKC,KACvB,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAGC,IACrBN,EAAIO,KAAKH,EACX,EAEII,EAAmBC,IACvB,MAAMC,EAASD,GAAO,EACtB,OAAOC,EAASC,OAAkB,IAAXD,EAAa,EAEtC,SAASE,EAAaR,EAAKS,GACrBT,EAAMS,EAAO,KACfA,EAAO,GAAKT,GAEVA,EAAMS,EAAO,KACfA,EAAO,GAAKT,EAEhB,CAQe,MAAMU,EACnB,WAAA7C,CAAY8C,EAAQC,EAAuBC,EAAsBC,EAAoBC,GAAyB,GAE5G,MAAMC,EAAU,CAAC,CAACC,KAAU,KAAY,CAACA,KAAU,KAAY,CAACA,KAAU,KAAY,CAACA,KAAU,MACjG,IAAK,MAAMC,KAASP,EAClBH,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAIjC,GAAIA,EAAQG,OAAOC,MAAKpB,IAAQO,OAAOc,SAASrB,KAG9C,OAFAjC,KAAKuD,gBAAkB,QACvBvD,KAAKwD,wBAA0B,IAKjCxD,KAAKuD,gBAAkB,GACvBvD,KAAKwD,wBAA0B,GAK/B,IAAK,MAAOC,EAAWC,KAAUT,EAAQG,OAAOO,UAAW,CACzD,MAAMC,EAAYH,GAAa,EACzBI,EAAaD,EAAYpB,OAAqB,IAAdoB,GACtC,IAAIE,EACJ,GAAgB,EAAZL,EAAe,CAGjB,MAAMM,EAAgBjB,EAAqBkB,KAAIC,GACtCC,KAAKC,IAAIT,EAAQb,EAAsBe,GAAYK,EAAUJ,GAAc,KAIpF,GAAIjC,EAASmC,GACXD,EAAMC,EAAc,OACf,CAELD,EAAM,GACN,IAAK,MAAO3B,EAAGiC,KAAcL,EAAcJ,UACzC3B,EAAM8B,EAAKM,EAAWtB,EAAqBX,GAAG,GAElD,CAEF,MAGE2B,EAAMI,KAAKG,IAAIX,EAAQb,EAAsBe,GAAY,GAE3D,MAAMU,EAAiB,CACrBb,YACAC,QACAI,MACAlB,OAAQ,IAENG,GAAsBA,EAAmBwB,SAASd,GACpDzD,KAAKwD,wBAAwBpB,KAAKkC,GAG7BtB,GACHhD,KAAKuD,gBAAgBnB,KAAKkC,EAGhC,CAGA,IAAK,MAAMnB,KAASP,EAAQ,CAC1B,IAAK,MAAMN,KAAOtC,KAAKuD,gBACjBJ,EAAMd,EAAiBC,EAAImB,cAAgBnB,EAAIoB,OACjDpB,EAAIM,OAAOR,KAAKe,GAGpB,IAAK,MAAMb,KAAOtC,KAAKwD,wBACjBL,EAAMd,EAAiBC,EAAImB,cAAgBnB,EAAIoB,OACjDpB,EAAIM,OAAOR,KAAKe,EAGtB,CACF,CACA,wBAAQqB,CAAkBC,GACxB,IAAIC,EAAS,EACb,KAAOD,EAAWhE,OAAS,GAAG,CAE5BgE,EAAaA,EAAWE,QAAOrC,IAC7B,MAAMwB,EAAMc,MAAMC,QAAQvC,EAAIwB,KAAOI,KAAKG,OAAO/B,EAAIwB,KAAOxB,EAAIwB,IAChE,OAAoB,EAAhBxB,EAAImB,UACCnB,EAAIoB,MAAQgB,GAAUZ,EAEtBxB,EAAIoB,MAAQgB,GAAUZ,CAC/B,IAIF,IAAK,MAAMxB,KAAOmC,EAAY,CAC5B,MAAMK,EAAYJ,GAA0B,EAAhBpC,EAAImB,UAAgB,GAAK,GACrD,IAAK,MAAMN,KAASb,EAAIM,OAAQ,CAE9B,GAAIgC,MAAMC,QAAQvC,EAAIwB,MAAQX,EAAMd,EAAiBC,EAAImB,YAAcqB,EAAYxC,EAAIwB,IAAIX,EAAM,IAC/F,SAEF,MAAM4B,EAAW5B,EAAM6B,QACvBD,EAAS1C,EAAiBC,EAAImB,aAAeqB,QACvCC,CACR,CACF,CACAL,GAAU,CACZ,CACF,CACA,EAAEO,OAAOC,YAEP,GAAIlF,KAAKwD,wBAAwB/C,OAAS,EACxC,IAAK,MAAM0C,KAASR,EAAsB6B,kBAAkBxE,KAAKwD,+BACzDL,EAKV,IAAK,MAAMA,KAASR,EAAsB6B,kBAAkBxE,KAAKuD,uBACzDJ,CAEV,E,6FClJK,SAASgC,EAAsBC,GACpC,GAAIA,EAAIC,eAAeC,SACrB,OAAOF,EAAIC,cAAcC,SAAStB,KAAI,EACpCuB,SACCC,IAAQD,GAAS,WAAWC,EAAMJ,EAAIK,kBAE3C,MAAMC,EAAON,EAAIO,UAAU,GACrBlF,EAASiF,EAAO,EAAI,EAAIN,EAAIQ,YAAY,GAAGlH,MAAMgH,GACvD,OAAOd,MAAMiB,KAAK,CAChBpF,WACC,CAACqF,EAAGN,IAAQ,WAAWA,EAAMJ,EAAIK,iBACtC,CAGO,MAAMM,EAAoB,EAAEC,EAAGC,EAAGC,KAAO,EAAI1D,OAAOwD,GAAK,GAAKxD,OAAOyD,GAAK,GAAKzD,OAAO0D,GAAK,GAC3F,SAASC,EAAiBC,GAC/B,MAAMT,EAAY,EAAE,GAAI,GAAI,GAAI,GAAI,GAC9BU,EAAY,CAAC,IAAK,IAAK,IAAK,IAAK,KACvCD,EAAKE,SAAQ,CAACC,EAAMf,KAClB,MAAMgB,EAAUH,EAAUI,QAAQF,EAAK3H,MACvC,KAAI4H,GAAW,GAGb,MAAM,IAAI,KAAgB,8BAA8BD,EAAK3H,OAAQ,CACnEsC,KAAM,KAAoBwF,mBAH5Bf,EAAUa,GAAWhB,CAKvB,IAIF,MAAMmB,GAA4B,IAAlBhB,EAAU,GAC1B,GAAIgB,IAA6B,IAAlBhB,EAAU,GACvB,MAAM,IAAI,KAAgB,gBAAgBgB,EAAU,OAAS,qBAAsB,CACjFzF,KAAM,KAAoBwF,mBAG9B,OAAOf,CACT,CAGO,SAASiB,EAAiBC,EAAWC,GAC1C,MAAMC,EAAUhB,EAAkBe,GAC5BE,EAASpC,MAAMmC,GAWrB,OAVAD,EAAWR,SAAQ,CAACrE,EAAKuD,KACvB,GAAIvD,GAAO,EAAG,CACZ,GAAIA,GAAO8E,EACT,MAAM,IAAI,KAAgB,kCAAkC9E,IAAO,CACjEf,KAAM,KAAoBwF,mBAG9BM,EAAO/E,GAAO4E,EAAUrB,EAC1B,KAEKwB,CACT,CAGO,SAASC,EAAaC,EAAeJ,EAAYK,GACtD,MAAMH,EAAS,CAACG,EAAcA,EAAcA,EAAcA,EAAcA,GAWxE,OAVAL,EAAWR,SAAQ,CAACrE,EAAKuD,KACvB,GAAIvD,GAAO,EAAG,CACZ,GAAIA,GAAOiF,EAAczG,OACvB,MAAM,IAAI,KAAgB,kCAAkCwB,IAAO,CACjEf,KAAM,KAAoBwF,mBAG9BM,EAAOxB,GAAO0B,EAAcjF,EAC9B,KAEK+E,CACT,CAGO,SAASI,EAASC,EAASP,GAChC,MAAMQ,EAAaD,EAAQE,0BAC3B,QAAmBhG,IAAf+F,EAEF,OADA9F,QAAQgG,KAAK,0EACN,CAAC,EAAG,EAAG,EAAG,EAAG,GAItB,MAIMC,EAAiBH,EAAWI,MAJT1B,GAAgB,UAAXA,EAAE9E,OAKhC,OAAKuG,EAKER,EADOQ,EAAe7H,MAAMoF,QACR8B,EAAY,IAJrCtF,QAAQgG,KAAK,yFACN,CAAC,EAAG,EAAG,EAAG,EAAG,GAIxB,CAQA,SAASG,EAAqBC,EAAMC,EAAQC,EAAMC,GAChD,MAEMC,GAFKH,EAAO,IAAM,EAAID,EAAKlJ,MAAMmJ,EAAO,IAAM,IACzCE,EAAO,IAAM,EAAID,EAAKpJ,MAAMqJ,EAAO,IAAM,GAE9CE,EAAQL,EAAKlJ,MAAMmJ,EAAO,IAAMC,EAAKpJ,MAAMqJ,EAAO,IAClDG,EAAQN,EAAKlJ,MAAMmJ,EAAO,IAAMC,EAAKpJ,MAAMqJ,EAAO,IACxD,OAAc,IAAVC,GAAyB,IAAVC,GAAyB,IAAVC,EACzB,EACEF,GAAS,GAAKC,GAAS,GAAKC,GAAS,GACtC,EACCF,GAAS,GAAKC,GAAS,GAAKC,GAAS,EACvC,OAEP,CAEJ,CACA,MACMC,EAAc,CAACC,EAAGC,IAAMnE,KAAKoE,IAAIF,EAAIC,GAD3B,KAEhB,SAASE,EAAwBC,EAAMC,EAAQC,EAAMC,GACnD,MAAMC,EAASxB,EAASoB,EAAKK,mBAAmBC,SAASL,GAASD,EAAK7C,WACjEoD,EAAS3B,EAASsB,EAAKG,mBAAmBC,SAASH,GAASD,EAAK/C,WACvE,OAAOwC,EAAYS,EAAO,GAAIG,EAAO,KAAOZ,EAAYS,EAAO,GAAIG,EAAO,KAAOZ,EAAYS,EAAO,GAAIG,EAAO,GACjH,CAYO,SAASC,EAAuBC,GACrC,GAAIA,EAAQxI,OAAS,EACnB,OAIF,MAAMyI,EAAgBtE,MAAMiB,KAAK,CAC/BpF,OAAQwI,EAAQxI,SACf,IAAM,KACH0I,EAAevE,MAAMiB,KAAK,CAC9BpF,OAAQwI,EAAQxI,SACf,IAAM,KAGH2I,EAAe,IAAIxE,MAAMqE,EAAQxI,QAAQ4I,KAAK,GACpD,KAAOD,EAAatH,OAAM,CAACG,EAAKuD,IAAQvD,EAAMgH,EAAQzD,GAAKI,YAAYnF,UAAS,CAE9E,IAAImB,GAAW,EACX0H,EAAc,EACdC,EAAcN,EAAQ,GACtBO,EAAcD,EAAY3D,YAAYwD,EAAa,IACvD,IAAK,IAAIK,EAAa,EAAGA,EAAaR,EAAQxI,OAAQgJ,IAAc,CAClE,MAAMC,EAAaT,EAAQQ,GACrBE,EAAaD,EAAW9D,YAAYwD,EAAaK,IACjDG,EAAWjC,EAAqB6B,EAAaD,EAAY5D,UAAWgE,EAAYD,EAAW/D,WACjG,GAAKiE,EA0BHhI,GAAW,EACPgI,EAAW,IACbN,EAAcG,EACdF,EAAcG,EACdF,EAAcG,OA9BH,CAEb,QAAiBpI,IAAbqI,EACF,MAAM,IAAI,KAAgB,4DAA6D,CACrF1I,KAAM,KAAoB2I,4BAMzBtB,EAAwBgB,EAAaH,EAAaE,GAAcI,EAAYN,EAAaK,KAI5FjI,QAAQgG,KAAK,6FAIf,MAAMsC,EAAWP,EAAY5D,UAAU,IAAM,EAAI6D,EAAY9K,MAAM6K,EAAY5D,UAAU,IAAM,EACzFoE,EAAWL,EAAW/D,UAAU,IAAM,EAAIgE,EAAWjL,MAAMgL,EAAW/D,UAAU,IAAM,EACxFmE,IAAaC,GAGfvI,QAAQgG,KAAK,6DAA6DsC,QAAeC,IAE7F,CAQF,CACA,GAAInI,EAEF,IAAK,IAAIO,EAAI,EAAGA,EAAIiH,EAAa3I,OAAQ0B,IAAK,CAC5C,MAAMuH,EAAaT,EAAQ9G,GACrB6H,EAAoBZ,EAAajH,GACvC+G,EAAc/G,GAAGC,KAAKsH,EAAW9D,YAAYoE,IAC7Cb,EAAahH,GAAGC,KAAKsH,EAAWb,mBAAmBC,SAASkB,IAC5DZ,EAAajH,IAAM,CACrB,MAGA,IAAK,MAAOqD,EAAKyE,KAAWb,EAAazF,UAAW,CAClD,MAAM+F,EAAaT,EAAQzD,GACrBmE,EAAaD,EAAW9D,YAAYqE,GAEzB,IADAtC,EAAqB6B,EAAaD,EAAY5D,UAAWgE,EAAYD,EAAW/D,aAE/FyD,EAAa5D,IAAQ,EAEzB,CAEJ,CACA,GAAsC,IAAlCyD,EAAQ,GAAGrD,YAAYnF,OACzB,MAAM,IAAI,KAAgB,sFAAuF,CAC/GS,KAAM,KAAoB2I,4BAG9B,IAAK,IAAI1H,EAAI,EAAGA,EAAI8G,EAAQxI,OAAQ0B,IAClC8G,EAAQ9G,GAAGyD,YAAcsD,EAAc/G,GACvC8G,EAAQ9G,GAAG0G,mBAAmBC,SAAWK,EAAahH,EAE1D,C,kEC1NO,MAAM+H,EAAkBC,GAAQA,EAAKC,KAAOD,EACnD,SAASE,EAAiBC,EAAKC,GAC7B,MAAsB,iBAARD,GAA4B,OAARA,GAAgBC,KAAQD,CAC5D,CACA,SAASE,EAAsBF,EAAKC,EAAM3L,EAAO,QAC/C,IAAKyL,EAAiBC,EAAKC,GACzB,MAAM,IAAI,KAAgB,GAAG3L,yCAA4C2L,KAAS,CAChFrJ,KAAM,KAAoBwF,kBAGhC,CACA,SAAS+D,EAAkBH,EAAKC,EAAM3L,EAAO,QAC3C,IAAKgG,MAAMC,QAAQyF,EAAIC,IACrB,MAAM,IAAI,KAAgB,GAAG3L,qBAAwB2L,qBAAyB,CAC5ErJ,KAAM,KAAoBwF,kBAGhC,CAIO,SAASgE,EAA6BP,EAAMvL,EAAO,QAExD4L,EAAsBL,EAAM,cAAevL,GAC3C6L,EAAkBN,EAAM,cAAevL,EACzC,CAOO,SAAS+L,EAAwBR,EAAMS,EAAgB,EAAGhM,EAAO,QAEtE,MAAMiM,EAAiBV,EAAKW,YAAYF,GACxC,IAAKC,EACH,MAAM,IAAI,KAAgB,GAAGjM,uDAA0DgM,IAAiB,CACtG1J,KAAM,KAAoBwF,mBAG9B,MACMqE,EAAiB,GAAGnM,gBAAmBgM,IADlBP,EAAiBQ,EAAgB,QAAU,MAAMA,EAAejM,QAAU,KAIrG4L,EAAsBK,EAAgB,OAAQE,GAC9CN,EAAkBI,EAAgB,OAAQE,GAC1CF,EAAezE,KAAKE,SAAQ,CAACC,EAAMpE,IAAMqI,EAAsBjE,EAAM,OAAQ,GAAGwE,UAAuB5I,OAGvGqI,EAAsBK,EAAgB,WAAYjM,GAClD6L,EAAkBI,EAAgB,WAAYjM,GAC9CiM,EAAe/B,SAASxC,SAAQ,CAAC0E,EAAM7I,IAAMqI,EAAsBQ,EAAM,OAAQ,GAAGD,aAA0B5I,MAChH,C,iBC1CO,SAAS8I,EAAYC,EAAKxG,EAAQjE,EAAQ0K,EAAO,CAAC,GAWrD,YAVe5J,IAAXmD,QAAmCnD,IAAXd,IAExB0K,EAAO,IACAA,EACHC,QAAS,IACFD,EAAKC,QACRC,MAAO,SAAS3G,KAAUA,EAASjE,EAAS,OAIjD6K,MAAMJ,EAAKC,EACtB,CC5BA,SAASI,EAAQC,EAAMC,GACnB,MAAMC,EAAuB,iBAATF,EAAoB,IAAIG,IAAIH,GAAQA,EACnDE,EAAKE,SAASC,SAAS,OAExBH,EAAKE,UAAY,KAErB,MAAME,EAAW,IAAIH,IAAIF,EAAKzG,MAAM,GAAI0G,GAGxC,OADAI,EAASC,OAASL,EAAKK,OAChBD,CACX,CACAE,eAAeC,EAAgBC,GAC3B,GAAwB,MAApBA,EAASC,OAAb,CAGA,GAAwB,MAApBD,EAASC,QAAsC,MAApBD,EAASC,OACpC,OAAO,IAAIC,iBAAiBF,EAASG,eAEzC,MAAM,IAAIvL,MAAM,8BAA8BoL,EAASC,UAAUD,EAASI,aAJ1E,CAKJ,C,yBAyDA,QA9BA,MACIpB,IACA,GACA,GACA,WAAApL,CAAYoL,EAAKlK,EAAU,CAAC,GACxBhB,KAAKkL,IAAMA,EACXlL,MAAK,EAAagB,EAAQuL,WAAa,CAAC,EACxCvM,MAAK,EAAsBgB,EAAQwL,mBAAoB,CAC3D,CACA,GAAYD,GACR,OD3BmBE,EC2BDzM,MAAK,ED3BY0M,EC2BAH,EDzBhC,IACAE,KACAC,EACHtB,QAAS,IACFqB,EAAerB,WACfsB,EAAiBtB,UAPzB,IAAoBqB,EAAgBC,CC4BvC,CACA,SAAMC,CAAIC,EAAK5L,EAAU,CAAC,GACtB,IAAI6L,EAAOtB,EAAQvL,KAAKkL,IAAK0B,GAAKC,KAElC,OAAOZ,QADcX,MAAMuB,EAAM7M,MAAK,EAAYgB,IAEtD,CACA,cAAM8L,CAASF,EAAKG,EAAO/L,EAAU,CAAC,GAClC,IAEIkL,EAFAhB,EAAMK,EAAQvL,KAAKkL,IAAK0B,GACxBI,EAAOhN,MAAK,EAAYgB,GAQ5B,OALIkL,EADA,iBAAkBa,QA/C9Bf,eAA4Bd,EAAK+B,EAAeD,EAAME,GAClD,GAAIA,EACA,OAAO5B,MAAMJ,EAAK,IACX8B,EACH5B,QAAS,IAAK4B,EAAK5B,QAASC,MAAO,UAAU4B,OAGrD,IAAIf,QAAiBZ,MAAMJ,EAAK,IAAK8B,EAAMG,OAAQ,SACnD,IAAKjB,EAASkB,GAEV,OAAOlB,EAEX,IAAImB,EAAiBnB,EAASd,QAAQuB,IAAI,kBACtClM,EAAS+B,OAAO6K,GACpB,OAAOpC,EAAYC,EAAKzK,EAASwM,EAAexM,EAAQuM,EAC5D,CAiC6BM,CAAapC,EAAK6B,EAAMQ,aAAcP,EAAMhN,MAAK,SAGjDiL,EAAYC,EAAK6B,EAAMrI,OAAQqI,EAAMtM,OAAQuM,GAE3Df,EAAgBC,EAC3B,G,aCzEW,SAASsB,EAAUC,EAAOC,EAAUC,EAAOC,GACxD,MACMC,GADOH,EAAS7B,SAAS,KAAO6B,EAAS1I,MAAM,GAAI,GAAK0I,GACvCD,EAAMhC,MAAQgC,EAAMhC,KAAKI,SAAS,KAAO,GAAK,KAC/DiC,EAAW9B,MAAO+B,EAAQ5C,KAC1BA,GAAM6C,YAAc7C,EAAK8C,aAC3B9C,EAAK8C,YAAYF,EAAQ5C,EAAK6C,YAEhC,MAAME,EAAUL,EAAUE,EAAOI,KAAK,KAChCC,EAAcT,GAAOhB,IAAIuB,GAC/B,GAAIE,IAAe,OAAQA,GACzB,OAAOA,EAET,IAAIpH,EAOJ,OALEA,EADE4G,GAASzC,GAAM6C,iBACFJ,EAAMS,WAAWH,EAAS/C,GAAM6C,YAAY,IAAMP,EAAMK,SAASC,EAAQ5C,IAAOA,EAAKmD,kBAErFb,EAAMK,SAASC,EAAQ5C,GAExCwC,GAAOY,OAAOL,EAASlH,GAChBA,CAAM,EAEf,OAAO,IAAIwH,MAAMf,EAAO,CACtBd,IAAK,CAAC8B,EAAQlE,KACZ,GAAa,aAATA,EACF,OAAOuD,EAIT,MAAMY,EAAQD,EAAOlE,GACrB,OAAImE,aAAiBC,SACZ,YAAaC,GAClB,OAAOF,EAAMG,MAAMJ,EAAQG,EAC7B,EAEKF,CAAK,GAGlB,CACO,MAAMI,UAA0B,EACrC,WAAAhP,CAAYiP,EAAS/N,GACnBC,MAAM8N,EAAS/N,EACjB,CAIA,SAAM2L,CAAIC,EAAK5L,EAAU,CAAC,GACxB,IACE,aAAaC,MAAM0L,IAAIC,EAAK5L,EAE9B,CAAE,MAAOM,GACP,GAAIA,GAAGP,SAASiO,WAAW,kCACzB,OAEF,MAAM1N,CACR,CACF,E,kCCvDK,MAAM2N,EAAgC,oBAW9B,MAAMC,EA0BnB,WAAApP,CAAYqP,EAAoB,GAAIC,EAAyB,GAC3DpP,KAAKqP,YAAc,IAAIC,IACvBtP,KAAKuP,eAAiB,IAAIC,IAC1BxP,KAAK4N,MAAQ,GACb5N,KAAKyP,iBAAmB,GACxBzP,KAAKmP,kBAAoBA,EACzBnP,KAAKoP,uBAAyBlL,KAAKC,IAAIgL,EAAmBC,EAC5D,CAQA,eAAAM,CAAgB9C,EAAK+C,GAInB,IAAIC,EAAgBC,EACpB,MAAMC,EAAU,IAAIC,SAAQ,CAACxE,EAASyE,KACpCJ,EAAiBrE,EACjBsE,EAAgBG,CAAM,IAGlBC,EAAc,CAClBrD,IAAKA,EACLsD,OAAQP,EACRpE,QAASqE,EACTI,OAAQH,EACRC,WAGF,OADA9P,KAAKqP,YAAY1N,IAAIiL,EAAKqD,GACnBA,CACT,CAOA,iBAAAE,CAAkBvD,EAAKwD,GAErB,GAAIpQ,KAAKqP,YAAYgB,IAAIzD,GAAM,CAE7B,MAAMqD,EAAcjQ,KAAKqP,YAAY1C,IAAIC,GACrCqD,GAAeA,EAAYK,YAC7BC,aAAaN,EAAYK,WACzBL,EAAYK,eAAY/O,GAErBvB,KAAK4N,MAAMrJ,SAASqI,IAAS5M,KAAKyP,iBAAiBlL,SAASqI,KAE3DwD,EACFpQ,KAAKyP,iBAAiBrN,KAAKwK,GAE3B5M,KAAK4N,MAAMxL,KAAKwK,GAElB5M,KAAKwQ,UAET,CACF,CAoBA,UAAAnC,CAAWzB,EAAK+C,EAAeS,GAAc,EAAOK,EAAU,GAC5D,GAAKzQ,KAAKqP,YAAYgB,IAAIzD,GAYnB,CACL,MAAM8D,EAAmB1Q,KAAKyP,iBAAiBhJ,QAAQmG,GACnD8D,GAAoB,IAAMN,GAG5BpQ,KAAKyP,iBAAiBkB,OAAOD,EAAkB,GAC/C1Q,KAAKmQ,kBAAkBvD,IACd6D,GAAW,GAGpBzQ,KAAKmQ,kBAAkBvD,EAAKwD,EAEhC,KAxBgC,CAE9B,MAAMH,EAAcjQ,KAAK0P,gBAAgB9C,EAAK+C,GAE9C,GAAIc,EAAU,EAAG,CACf,MAAMH,EAAYM,YAAW,IAAM5Q,KAAKmQ,kBAAkBvD,EAAKwD,IAAcK,GAE7ER,EAAYK,UAAYA,CAC1B,MAEEtQ,KAAKmQ,kBAAkBvD,EAAKwD,EAEhC,CAaA,MAAMN,EAAU9P,KAAKqP,YAAY1C,IAAIC,IAAMkD,QAC3C,IAAKA,EACH,MAAM,IAAIhP,MAAM,gEAElB,OAAOgP,CACT,CAaA,WAAAe,CAAYC,EAAUV,GAAc,EAAOK,EAAU,IACnD,MAAMM,EAAW,GACjB,IAAK,IAAI5O,EAAI,EAAGA,EAAI2O,EAASrQ,OAAQ0B,IAAK,CACxC,MAAM6O,EAAOF,EAAS3O,GAChB2N,EAAU9P,KAAKqO,WAAW2C,EAAKpE,IAAKoE,EAAKrB,cAAeS,EAAaK,EAAUtO,GACrF4O,EAAS3O,KAAK0N,EAChB,CACA,OAAOiB,CACT,CAOA,aAAMP,GACJ,MAAMS,EAAcjR,KAAKuP,eAAe2B,KACxC,GAAID,GAAejR,KAAKmP,mBAA2C,IAAtBnP,KAAK4N,MAAMnN,SAAiBwQ,GAAejR,KAAKoP,wBAA2D,IAAjCpP,KAAKyP,iBAAiBhP,QAC3I,OAEF,MAAM0Q,EAAanR,KAAK4N,MAAMwD,SAAWpR,KAAKyP,iBAAiB2B,QAC/D,IAAKD,EACH,OAEF,GAAInR,KAAKuP,eAAec,IAAIc,GAG1B,YADAnR,KAAKwQ,UAGP,MAAMP,EAAcjQ,KAAKqP,YAAY1C,IAAIwE,GACzC,IAAKlB,EACH,OAEF,MAAMrD,EAAMqD,EAAYrD,IAExB5M,KAAKuP,eAAe8B,IAAIzE,SAClBqD,EAAYC,SAASoB,KAAKrB,EAAY1E,QAAS0E,EAAYD,QACjEhQ,KAAKuP,eAAegC,OAAO3E,GAC3B5M,KAAKqP,YAAYkC,OAAO3E,GACxB5M,KAAKwQ,SACP,CAOA,aAAAgB,CAAc5E,EAAK6E,EAAexC,GAChC,IAAKjP,KAAKqP,YAAYgB,IAAIzD,GACxB,OAEF,MAAMqD,EAAcjQ,KAAKqP,YAAY1C,IAAIC,GACrCqD,IACEA,EAAYK,WAEdC,aAAaN,EAAYK,WAG3BL,EAAYD,OAAOyB,IAErB,MAAMC,EAAa1R,KAAK4N,MAAMnH,QAAQmG,GACtC,GAAI8E,GAAc,EAChB1R,KAAK4N,MAAM+C,OAAOe,EAAY,OACzB,CACL,MAAMhB,EAAmB1Q,KAAKyP,iBAAiBhJ,QAAQmG,GACnD8D,GAAoB,GACtB1Q,KAAKyP,iBAAiBkB,OAAOD,EAAkB,EAEnD,CACA1Q,KAAKqP,YAAYkC,OAAO3E,GACxB5M,KAAKuP,eAAegC,OAAO3E,EAC7B,CAMA,iBAAA+E,CAAkBF,EAAexC,GAE/BjP,KAAK4N,MAAQ,GACb5N,KAAKyP,iBAAmB,GACxB,IAAK,MAAM7C,KAAO5M,KAAKqP,YAAYuC,OACjC5R,KAAKwR,cAAc5E,EAAK6E,EAE5B,CAOA,UAAAI,CAAWjF,GACT,OAAO5M,KAAKqP,YAAYgB,IAAIzD,EAC9B,CAOA,cAAAkF,CAAelF,GACb,OAAO5M,KAAKuP,eAAec,IAAIzD,EACjC,E,gDCjQa,MAAMmF,EAenB,WAAAjS,CAAYqP,EAAmBC,GAE3BpP,KAAK4N,MAD0B,iBAAtBuB,QAAwD5N,IAAtB4N,EAC9B,IAAI,IAAaA,EAAmBC,GAEpCD,EAEfnP,KAAKgS,iBAAmB,EACxBhS,KAAKiS,YAAc,IAAI3C,IACvBtP,KAAK8Q,SAAW,IAAIxB,GACtB,CAGA,UAAA4C,CAAWtF,EAAK8B,GACd,MAAMoC,EAAW9Q,KAAK8Q,SAASnE,IAAIC,GACnC,GAAIkE,EAAU,CACZ,IAAK,MAAM,QACTvF,EAAO,aACP4G,KACGrB,EACHvF,EAAQmD,GACR1O,KAAKiS,YAAYtF,IAAIwF,IAAeZ,OAAO3E,GAE7C5M,KAAK8Q,SAASS,OAAO3E,EACvB,CACF,CAGA,SAAAwF,CAAUxF,EAAKyF,GACb,MAAMvB,EAAW9Q,KAAK8Q,SAASnE,IAAIC,GACnC,GAAIkE,EAAU,CACZ,IAAK,MAAM,OACTd,EAAM,aACNmC,KACGrB,EACHd,EAAOqC,GACPrS,KAAKiS,YAAYtF,IAAIwF,IAAeZ,OAAO3E,GAE7C5M,KAAK8Q,SAASS,OAAO3E,EACvB,CACF,CAGA,aAAA0F,GACE,MAAMH,EAAenS,KAAKgS,iBAG1B,OAFAhS,KAAKgS,mBACLhS,KAAKiS,YAAYtQ,IAAIwQ,EAAc,IAAI7C,KAChC6C,CACT,CAOA,UAAA9D,CAAWzB,EAAKuF,EAAcxC,EAAeS,EAAaK,GAQxD,GANAzQ,KAAK4N,MAAMS,WAAWzB,EAAK+C,EAAeS,EAAaK,GAASa,MAAK5C,GAAS1O,KAAKkS,WAAWtF,EAAK8B,KAAQ6D,OAAMF,GAAUrS,KAAKoS,UAAUxF,EAAKyF,KAC1IrS,KAAK8Q,SAAST,IAAIzD,IACrB5M,KAAK8Q,SAASnP,IAAIiL,EAAK,IAIrBuF,GAAgBnS,KAAKgS,kBAAoBG,EAAe,EAC1D,MAAM,IAAIrR,MAAM,2CAA2CqR,6BAG7D,IADmBnS,KAAKiS,YAAYtF,IAAIwF,GAEtC,MAAM,IAAIrR,MAAM,2CAA2CqR,sBAI7D,OAAO,IAAIpC,SAAQ,CAACxE,EAASyE,KAC3BhQ,KAAK8Q,SAASnE,IAAIC,IAAMxK,KAAK,CAC3BmJ,UACAyE,SACAmC,iBAEF,MAAMnE,EAAahO,KAAKiS,YAAYtF,IAAIwF,GAClCK,EAAkBxE,GAAYrB,IAAIC,GACpC4F,EACFA,EAAgBpQ,KAAK4N,GAErBhC,GAAYrM,IAAIiL,EAAK,CAACoD,GACxB,GAEJ,CAMA,kBAAAyC,CAAmB7F,EAAKoD,EAAQyB,GAE9BzB,EAAOyB,GAGP,MAAMiB,EAAgB1S,KAAK8Q,SAASnE,IAAIC,GACxC,IAAK8F,EAEH,OAGF,MAAMlN,EAAMkN,EAAcC,WAAUC,GAAOA,EAAI5C,SAAWA,IACtDxK,GAAO,GACTkN,EAAc/B,OAAOnL,EAAK,GAIxBkN,EAAcjS,OAAS,IAAMT,KAAK4N,MAAMkE,eAAelF,KACzD5M,KAAK4N,MAAM4D,cAAc5E,EAAK6E,GAC9BzR,KAAK8Q,SAASS,OAAO3E,GAEzB,CAGA,aAAA4E,CAAc5E,EAAKuF,EAAcV,GAC/B,MAAMzD,EAAahO,KAAKiS,YAAYtF,IAAIwF,GACxC,IAAKnE,EACH,OAAO,EAET,MAAM6E,EAAY7E,EAAWrB,IAAIC,GACjC,IAAKiG,IAAcA,EAAUpS,OAC3B,OAAO,EAET,IAAK,MAAMuP,KAAU6C,EACnB7S,KAAKyS,mBAAmB7F,EAAKoD,EAAQyB,GAGvC,OADAzD,EAAWuD,OAAO3E,IACX,CACT,CAGA,gBAAAkG,CAAiBX,EAAcV,GAC7B,MAAMiB,EAAgB1S,KAAKiS,YAAYtF,IAAIwF,GAC3C,GAAIO,EAAe,CACjB,IAAK,MAAO9F,EAAKiG,KAAcH,EAAc/O,UAC3C,IAAK,MAAMqM,KAAU6C,EACnB7S,KAAKyS,mBAAmB7F,EAAKoD,EAAQyB,GAGzCzR,KAAKiS,YAAYV,OAAOY,EAC1B,CACF,CAGA,UAAAN,CAAWjF,GACT,OAAO5M,KAAK4N,MAAMiE,WAAWjF,EAC/B,CAGA,cAAAkF,CAAelF,GACb,OAAO5M,KAAK4N,MAAMkE,eAAelF,EACnC,CAGA,aAAAmG,CAAcZ,GACZ,OAAOnS,KAAKiS,YAAY5B,IAAI8B,EAC9B,CAGA,YAAAa,CAAab,EAAcvF,GACzB,OAAO5M,KAAKiS,YAAYtF,IAAIwF,IAAe9B,IAAIzD,KAAQ,CACzD,E,qDCxLK,IAAIqG,EAA6B,SAAUA,GAUhD,OATAA,EAAcA,EAAoB,KAAI,GAAK,OAC3CA,EAAcA,EAA6B,cAAI,GAAK,gBACpDA,EAAcA,EAA4B,aAAI,GAAK,eACnDA,EAAcA,EAA6B,cAAI,GAAK,gBACpDA,EAAcA,EAAyB,UAAI,GAAK,YAChDA,EAAcA,EAAgC,iBAAI,GAAK,mBACvDA,EAAcA,EAAgD,iCAAI,GAAK,mCACvEA,EAAcA,EAAgD,iCAAI,GAAK,mCACvEA,EAAcA,EAAoC,qBAAI,GAAK,uBACpDA,CACT,CAXwC,CAWtC,CAAC,GAOQC,EAAoC,SAAUA,GAIvD,OAHAA,EAAqBA,EAA8B,QAAI,GAAK,UAC5DA,EAAqBA,EAA4B,MAAI,GAAK,QAC1DA,EAAqBA,EAA4B,MAAI,GAAK,QACnDA,CACT,CAL+C,CAK7C,CAAC,GAGQC,EAA+B,SAAUA,GAKlD,OAHAA,EAAgBA,EAAiC,gBAAI,GAAK,kBAE1DA,EAAgBA,EAA8B,aAAI,GAAK,eAChDA,CACT,CAN0C,CAMxC,CAAC,E,gDC/BI,SAASC,EAAgBC,GAC9B,MAAO,IACFA,EACHC,UAAW,IAAI,OAAK,IAAI,OAAUC,KAAKF,EAAKC,UAAUnP,MAAM,IAAI,OAAUoP,KAAKF,EAAKC,UAAUjP,MAElG,C,qFCUO,MAAMmP,EACTC,KAAO,iBACP,WAAA3T,CAAY4T,EAAeC,IACvB,QAAOD,EAAcE,UAAY,EAAG,oCACxC,CACA,iBAAOC,CAAWH,EAAevJ,GAC7B,OAAO,IAAIqJ,EAAcE,EAAevJ,EAC5C,CAKA,MAAA2J,CAAOC,GACH,MAAM,IAAIjT,MAAM,iHACpB,CAMA,MAAAkT,CAAOnS,GACH,OAAOA,CACX,ECtCJ,MAAMoS,EACN,WACI,MAAM7L,EAAI,IAAI8L,YAAY,CAAC,YAE3B,QAAkB,KADR,IAAI9H,WAAWhE,EAAE+L,OAAQ/L,EAAEgM,WAAYhM,EAAEiM,YACxC,GACf,CALyBC,GAMzB,SAASC,EAAkBC,GACvB,MAAI,sBAAuBA,EAChBA,EAAWC,kBAGf,CACX,CACO,MAAMC,EACTjB,KAAO,iBACP,GACA,GACA,GACA,GACA,GACA,WAAA3T,CAAY4T,EAAevJ,GACvBnK,MAAK,EAAU0T,GAAeiB,OAC9B3U,MAAK,GAAc,QAAQmK,EAAKyK,WAChC5U,MAAK,EAASmK,EAAKzL,MACnBsB,MAAK,GAAU,QAAYmK,EAAKzL,MAAO,KAGvC,MAAMmW,EAAS,IAAI7U,MAAK,EAAY,GACpCA,MAAK,EAAqB6U,EAAOJ,iBACrC,CACA,iBAAOZ,CAAWH,EAAevJ,GAC7B,OAAO,IAAIuK,EAAWhB,EAAevJ,EACzC,CACA,MAAA2J,CAAOjS,GACH,IAAIiT,EAAQ,IAAI1I,WAAWvK,EAAImJ,KAAKmJ,QAIpC,OAHIF,GAAqC,QAAjBjU,MAAK,IACzB,QAAiB8U,EAAOP,EAAkBvU,MAAK,IAE5C8U,CACX,CACA,MAAAd,CAAOc,GAIH,OAHIb,GAAqC,QAAjBjU,MAAK,IACzB,QAAiB8U,EAAOP,EAAkBvU,MAAK,IAE5C,CACHgL,KAAM,IAAIhL,MAAK,EAAY8U,EAAMX,OAAQW,EAAMV,WAAYU,EAAMT,WAAarU,MAAK,GACnFtB,MAAOsB,MAAK,EACZ+U,OAAQ/U,MAAK,EAErB,EClDG,MAAMgV,EACTvB,KAAO,iBACP,iBAAOI,GACH,OAAO,IAAImB,CACf,CACA,MAAAlB,CAAOhO,GACH,MAAM,IAAIhF,MAAM,kBACpB,CACA,MAAAkT,CAAOnS,GACH,OAAO,IAAIuK,WAAWvK,EAAIsS,OAAQtS,EAAIuS,WAAYvS,EAAIwS,WAAa,EACvE,ECTG,MAAMY,EACTxB,KAAO,iBACP,iBAAOI,CAAW/N,GACd,OAAO,IAAImP,CACf,CACA,MAAAnB,CAAOoB,GACH,MAAM,IAAIpU,MAAM,iGACpB,CACA,YAAMkT,CAAOc,GACT,MAAMX,QAAe,QAAWW,EAAO,CAAEK,OAAQ,SACjD,OAAO,IAAI/I,WAAW+H,EAC1B,ECVJ,SAASiB,EAAsBC,EAAM3G,GAIjC,OAHA,SAAQlM,OAAO8S,MAAM5G,GAAQ,0EAC7B,QAAOA,IAAUlM,OAAO+S,kBAAmB,+EAC3C,QAAO7G,IAAUlM,OAAOgT,kBAAmB,+EACpC9G,CACX,CAEA,SAAS+G,EAAmBJ,EAAM3G,GAC9B,OAAOA,aAAiBgH,SAAW9Q,MAAMC,QAAQ6J,GAC3CgH,OAAO9D,KAAKlD,GACTiH,OACAC,QAAO,CAACC,EAAQjJ,KACjBiJ,EAAOjJ,GAAO8B,EAAM9B,GACbiJ,IACR,CAAC,GACFnH,CACV,CACO,MAAMoH,EACTpC,cACAD,KAAO,iBACP,GACA,GACA,WAAA3T,CAAY4T,EAAgB,CAAC,GACzB1T,KAAK0T,cAAgBA,EAErB,MAAM,SAAEqC,EAAW,QAAO,SAAEC,GAAW,EAAK,aAAEC,GAAe,EAAI,eAAEC,GAAiB,EAAI,UAAEC,GAAY,EAAI,UAAEC,GAAY,EAAI,OAAEC,EAAM,OAAEC,GAAS,GAAU5C,EACzJ,IAAI6C,EAAa7C,EAAc6C,WAC1BA,IAOGA,EAJCF,EAIY,CAAC,KAAM,MAHP,CAAC,IAAK,MAM3BrW,MAAK,EAAkB,CACnB+V,WACAC,WACAC,eACAC,iBACAC,YACAE,SACAE,aACAH,aAEJpW,MAAK,EAAkB,CAAEsW,SAC7B,CACA,iBAAOzC,CAAWH,GACd,OAAO,IAAIoC,EAAUpC,EACzB,CACA,MAAAI,CAAO0C,GACH,MAAM,OAAEH,EAAM,SAAEN,EAAQ,aAAEE,EAAY,eAAEC,EAAc,UAAEC,EAAS,UAAEC,GAAepW,MAAK,GACvF,QAAoB,UAAb+V,EAAsB,sDAC7B,MAAMU,EAAqB,IAG3B,QAAOP,EAAgB,8FAClBC,GAEDM,EAAmBrU,KAAKgT,GAExBgB,GAGAK,EAAmBrU,KAAKqT,GAE5B,MAAMiB,EAAQ9R,MAAMiB,KAAK2Q,EAAIxL,MAG7B,IAAI2L,EAFJD,EAAMtU,KAAK,MACXsU,EAAMtU,KAAKoU,EAAI9X,OAEX+X,EAAmBhW,SACnBkW,EAAW,CAAC/J,EAAK8B,KACb,IAAIkI,EAAYlI,EAChB,IAAK,IAAImI,KAAgBJ,EACrBG,EAAYC,EAAajK,EAAKgK,GAElC,OAAOA,CAAS,GAGxB,IAAIE,EAAWC,KAAKC,UAAUN,EAAOC,EAAUN,GAY/C,OAXIJ,IAKAa,EAAWA,EAASG,QAAQ,oBAAqBC,IAC7C,MAAMC,EAAW,OAAOD,EAAIE,WAAW,GAAGC,SAAS,MAEnD,MAAO,MADSF,EAASG,UAAUH,EAAS1W,OAAS,IAC/B,MAGvB,IAAI8W,aAAczD,OAAOgD,EACpC,CACA,MAAA9C,CAAOc,GACH,MAAM,OAAEwB,GAAWtW,MAAK,GAExB,QAAOsW,EAAQ,uDACf,MAAMI,GAAQ,QAAmB5B,GAC3BpW,EAAQgY,EAAMc,MAMpB,OALAd,EAAMc,OAEN,QAAO9Y,EAAO,qCAGP,CAAEsM,KADI0L,EACEhY,QAAOqW,QAFP,QAAYrW,EAAO,KAGtC,E,cC3GJ,SAAS+Y,EAAM5V,GACX,OAAIA,aAAe,MACfA,aAAe,MACfA,aAAe,KAEF,IAAI2M,MAAM3M,EAAK,CACxB8K,IAAG,CAAC8B,EAAQlE,IACDkE,EAAO9B,IAAInK,OAAO+H,IAE7B5I,IAAG,CAAC8M,EAAQlE,EAAMmE,KAEdD,EAAO9M,IAAIa,OAAO+H,GAAOmE,IAClB,KAMZ7M,CACX,CA0DO,MAAM6V,EACTjE,KAAO,iBACP,GACA,GACA,WAAA3T,CAAY4T,EAAevJ,GACvB,IAAIuE,EAAQgF,EAAciE,OAAS,IAC/BC,EAAOzN,EAAKzL,MAAM+B,OAClBkX,EAAQ,IAAI/S,MAAMgT,GAClBC,EAAe,IAAIjT,MAAMgT,GAC7B,GAAc,MAAVlJ,EACA,IAAK,IAAIvM,EAAI,EAAGA,EAAIyV,IAAQzV,EACxBwV,EAAMxV,GAAKA,EACX0V,EAAa1V,GAAKA,OAGrB,GAAc,MAAVuM,EACL,IAAK,IAAIvM,EAAI,EAAGA,EAAIyV,IAAQzV,EACxBwV,EAAMxV,GAAKyV,EAAOzV,EAAI,EACtB0V,EAAa1V,GAAKyV,EAAOzV,EAAI,OAIjCwV,EAAQjJ,EACRiJ,EAAMrR,SAAQ,CAACwR,EAAG3V,MACd,aAA2BZ,IAApBsW,EAAaC,GAAkB,wBAAwBf,KAAKC,UAAUtI,MAC7EmJ,EAAaC,GAAK3V,CAAC,IAG3BnC,MAAK,EAAS2X,EACd3X,MAAK,EAAgB6X,CACzB,CACA,iBAAOhE,CAAWH,EAAevJ,GAC7B,OAAO,IAAIuN,EAAehE,EAAevJ,EAC7C,CACA,MAAA2J,CAAOjS,GACH,OAxCR,SAAuBsB,EAAOsL,GAC1B,IAAIsJ,EATR,SAAmB5U,GACf,IAAIyU,EAAOzU,EAAMzE,MAAM+B,OAEvB,OADA,QAAOmX,IAASzU,EAAM4R,OAAOtU,OAAQ,+CAC9B0C,EAAM4R,OACR/Q,KAAI,CAACgU,EAAG7V,KAAM,CAAG4S,OAAQiD,EAAGC,MAAO9V,MACnCwT,MAAK,CAACvN,EAAGC,IAAMA,EAAE0M,OAAS3M,EAAE2M,SAC5B/Q,KAAKkU,GAAUA,EAAMD,OAC9B,CAEiBE,CAAUhV,GAEvB,OADA,QAAO4U,EAAOtX,SAAWgO,EAAOhO,OAAQ,qBACjCsX,EAAOjW,OAAM,CAACsW,EAAKjW,IAAMiW,IAAQ3J,EAAOtM,IACnD,CAoCYkW,CAAcxW,EAAK7B,MAAK,GAEjB6B,EA7EnB,SAA6BuD,EAAKqJ,GAC9B,IAAI6J,EAlBR,SAAoBnV,EAAOwU,GACvB,IAAI3M,EAUJ,OAPIA,EAFA7H,EAAM6H,gBAAgB,MACtB7H,EAAM6H,gBAAgB,KACf,IAAI7H,EAAMrD,YAEjBqD,EAAM6H,KAAKvK,OAAQ0C,EAAM6H,KAAKuN,OAGvB,IAAIpV,EAAMrD,YAAYqD,EAAM6H,KAAKvK,QAErC,CACHuK,OACAtM,MAAOyE,EAAMzE,MACbqW,QAAQ,QAAY5R,EAAMzE,MAAOiZ,GAEzC,CAEca,CAAWpT,EAAKqJ,GACtBgK,EAASrT,EAAI1G,MAAM+B,OACnByQ,EAAO9L,EAAI4F,KAAKvK,OAChBwX,EAAQrT,MAAM6T,GAAQpP,KAAK,GAC3BqP,EAAWjB,EAAMrS,EAAI4F,MACrB2N,EAAWlB,EAAMa,EAAItN,MACzB,IAAK,IAAI4N,EAAU,EAAGA,EAAU1H,EAAM0H,IAAW,CAC7C,IAAIC,EAAU,EACd,IAAK,IAAIT,EAAM,EAAGA,EAAMK,EAAQL,IAC5BS,GAAWZ,EAAMG,GAAOE,EAAIvD,OAAOqD,GAEvCO,EAASE,GAAWH,EAASE,GAC7BX,EAAM,IAAM,EACZ,IAAK,IAAIG,EAAM,EAAGA,EAAMK,EAAQL,IAC5B,GAAIH,EAAMG,KAAShT,EAAI1G,MAAM0Z,GAAM,CAC/B,GAAIA,EAAM,IAAMK,EACZ,MAEJR,EAAMG,GAAO,EACbH,EAAMG,EAAM,IAAM,CACtB,CAER,CACA,OAAOE,CACX,CAsDeQ,CAAoBjX,EAAK7B,MAAK,EACzC,CACA,MAAAgU,CAAOnS,GACH,MAAO,CACHmJ,KAAMnJ,EAAImJ,KACVtM,MAAOmD,EAAInD,MACXqW,QAAQ,QAAYlT,EAAInD,MAAOsB,MAAK,GAE5C,EC7HG,MAAM+Y,EACTtF,KAAO,iBACP,GACA,GACA,WAAA3T,CAAYpB,GACRsB,MAAK,EAAStB,EACdsB,MAAK,GAAW,QAAYtB,EAAO,IACvC,CACA,iBAAOmV,CAAW/N,EAAGqE,GACjB,OAAO,IAAI4O,EAAS5O,EAAKzL,MAC7B,CACA,MAAAoV,CAAOkF,GACH,MAAM,IAAIlY,MAAM,0BACpB,CACA,MAAAkT,CAAOc,GACH,IAAImE,EAAU,IAAIC,YACdC,EAAO,IAAIC,SAAStE,EAAMX,QAC1BnJ,EAAOpG,MAAMuU,EAAKE,UAAU,GAAG,IAC/BC,EAAM,EACV,IAAK,IAAInX,EAAI,EAAGA,EAAI6I,EAAKvK,OAAQ0B,IAAK,CAClC,IAAIoX,EAAcJ,EAAKE,UAAUC,GAAK,GACtCA,GAAO,EACPtO,EAAK7I,GAAK8W,EAAQjF,OAAOc,EAAMX,OAAOnP,MAAMsU,EAAKA,EAAMC,IACvDD,GAAOC,CACX,CACA,MAAO,CAAEvO,OAAMtM,MAAOsB,MAAK,EAAQ+U,OAAQ/U,MAAK,EACpD,EC1BG,MAAMwZ,EACT/F,KAAO,iBACP,iBAAOI,CAAW/N,GACd,OAAO,IAAI0T,CACf,CACA,MAAA1F,CAAOoB,GACH,MAAM,IAAIpU,MAAM,0FACpB,CACA,YAAMkT,CAAOc,GACT,MAAMX,QAAe,QAAWW,EAAO,CAAEK,OAAQ,YACjD,OAAO,IAAI/I,WAAW+H,EAC1B,ECWG,MAAMsF,GAbF,IAAInK,KACN3N,IAAI,SAAS,IAAM,8BAA0B2P,MAAMoI,GAAMA,EAAEC,YAC3DhY,IAAI,OAAO,IAAM,8BAAwB2P,MAAMoI,GAAMA,EAAEC,YACvDhY,IAAI,QAAQ,IAAM,8BAAyB2P,MAAMoI,GAAMA,EAAEC,YACzDhY,IAAI,QAAQ,IAAMsT,IAClBtT,IAAI,QAAQ,IAAM6X,IAClB7X,IAAI,aAAa,IAAM+V,IACvB/V,IAAI,SAAS,IAAM+S,IACnB/S,IAAI,UAAU,IAAMqT,IACpBrT,IAAI,aAAa,IAAMoX,IACvBpX,IAAI,SAAS,IAAMmU,IACnBnU,IAAI,YAAY,IAAM6R,IAGxB,SAASoG,EAAsBC,GAClC,IAAIC,EACJ,MAAO,CACH,YAAMhG,CAAO3Q,GACJ2W,IACDA,QAAeC,EAAYF,IAC/B,IAAK,MAAMG,KAASF,EAAOG,eACvB9W,QAAc6W,EAAMlG,OAAO3Q,GAE/B,IAAI2R,QAAcgF,EAAOI,eAAepG,OAAO3Q,GAC/C,IAAK,MAAM6W,KAASF,EAAOK,eACvBrF,QAAckF,EAAMlG,OAAOgB,GAE/B,OAAOA,CACX,EACA,YAAMd,CAAOc,GACJgF,IACDA,QAAeC,EAAYF,IAC/B,IAAK,IAAI1X,EAAI2X,EAAOK,eAAe1Z,OAAS,EAAG0B,GAAK,EAAGA,IACnD2S,QAAcgF,EAAOK,eAAehY,GAAG6R,OAAOc,GAElD,IAAI3R,QAAc2W,EAAOI,eAAelG,OAAOc,GAC/C,IAAK,IAAI3S,EAAI2X,EAAOG,eAAexZ,OAAS,EAAG0B,GAAK,EAAGA,IACnDgB,QAAc2W,EAAOG,eAAe9X,GAAG6R,OAAO7Q,GAElD,OAAOA,CACX,EAER,CACA6I,eAAe+N,EAAYK,GACvB,IAMIF,EANAnJ,EAAWqJ,EAAWN,OAAO9V,KAAIgI,MAAO7B,IACxC,IAAIkQ,QAAcZ,EAAS9M,IAAIxC,EAAKvL,KAAlB6a,MAElB,OADA,QAAOY,EAAO,kBAAkBlQ,EAAKvL,QAC9B,CAAEyb,QAAOlQ,OAAM,IAEtB8P,EAAiB,GAEjBE,EAAiB,GACrB,UAAW,IAAI,MAAEE,EAAK,KAAElQ,KAAU4G,EAAU,CACxC,IAAIiJ,EAAQK,EAAMxG,WAAW1J,EAAKuJ,cAAe0G,GACjD,OAAQJ,EAAMvG,MACV,IAAK,iBACDwG,EAAe7X,KAAK4X,GACpB,MACJ,IAAK,iBACDE,EAAiBF,EACjB,MACJ,QACIG,EAAe/X,KAAK4X,GAEhC,CAKA,OAJKE,KACD,QAMsB,cANUE,EAMxBxF,UANqC,iBAAiBwF,EAAWxF,sCACzEsF,EAAiBxF,EAAWb,WAAW,CAAEc,OAAQ,UAAYyF,IAE1D,CAAEH,iBAAgBC,iBAAgBC,iBAC7C,CC9EA,MAAMG,EAAe,sBACd,SAASC,EAA4BC,EAAUC,EAAaC,EAAkBC,IACjF,QAAOH,EAASI,MAAM9N,SAAU,yCAChC,IAAI+N,EAAYL,EAASI,MAAM9N,SAASgO,KAAKN,EAASI,OAClDG,EAAcN,EAAYzW,KAAI,CAACgX,EAAG7Y,IAAM6Y,EAAIL,EAAgBM,YAAY9Y,KACxE+Y,EAActB,EAAsB,CACpChF,UAAW,SACXlW,MAAO,IAAIqc,EAAa,GACxBjB,OAAQa,EAAgBQ,eAExBxN,EAAQ,CAAC,EACb,OAAO3B,MAAOoP,IACV,IAEInD,EAFAoD,EAAcD,EAAYpX,KAAI,CAACgX,EAAG7Y,IAAM+B,KAAKoX,MAAMN,EAAID,EAAY5Y,MACnEoZ,EAAaf,EAASjP,QAAQmP,EAAiBW,IAAc5P,KAEjE,GAAI8P,KAAc5N,EACdsK,EAAQtK,EAAM4N,OAEb,CACD,IAAIC,EAAgB,EAChBC,EAAa,GAAKV,EAAYnF,QAAO,CAACxN,EAAGC,IAAMD,EAAIC,GAAG,GACtDyM,QAAc+F,EAAUU,EAAY,CACpChO,aAAckO,EAAaD,IAE/BvD,EAAQtK,EAAM4N,GAAczG,QAChBoG,EAAYlH,OAAOc,GACzB,IACV,CACA,GAAc,OAAVmD,EACA,OAEJ,IAAI,KAAEjN,EAAI,MAAEtM,EAAK,OAAEqW,GAAWkD,EAC1ByD,EAAgBN,EACfpX,KAAI,CAACgX,EAAG7Y,IAAM6Y,EAAItc,EAAMyD,KACxByT,QAAO,CAAC+F,EAAKC,EAAKpW,IAAQmW,EAAMC,EAAM7G,EAAOvP,IAAM,GACpDd,EAASsG,EAAK0Q,GACdjb,EAASuK,EAAK0Q,EAAgB,GAElC,OAAIhX,IAAW4V,GAAgB7Z,IAAW6Z,EAGnCO,EAAUU,EAAY,CACzB7W,OAAQlC,OAAOkC,GACfjE,OAAQ+B,OAAO/B,UALnB,CAME,CAEV,CC7CO,MAAMob,EACTjB,MACAnP,KACA,WAAA3L,CAAY8a,EAAOnP,EAAO,KACtBzL,KAAK4a,MAAQA,EACb5a,KAAKyL,KAAOA,CAChB,CACA,OAAAF,CAAQE,GAGJ,IAAID,EAAO,IAAIG,IAAI,UAAU3L,KAAKyL,KAAKI,SAAS,KAAO7L,KAAKyL,KAAO,GAAGzL,KAAKyL,WAC3E,OAAO,IAAIoQ,EAAS7b,KAAK4a,MAAO,IAAIjP,IAAIF,EAAMD,GAAMI,SACxD,EAEG,SAASJ,EAAKoP,GACjB,OAAO,IAAIiB,EAASjB,GAAS,IAAItL,IACrC,CACO,MAAMwM,UAAcD,EACvBpI,KAAO,QACP,GACA,WAAA3T,CAAY8a,EAAOnP,EAAMsQ,GACrB9a,MAAM2Z,EAAOnP,GACbzL,MAAK,EAAY+b,CACrB,CACA,SAAIC,GACA,OAAOhc,MAAK,EAAUic,UAC1B,EAEJ,SAASC,EAAgBpC,GACrB,MAAMqC,EAAwBrC,EAAOpS,MAAMzB,GAAiB,cAAXA,EAAErH,OAEnD,OAAOud,GAAuBzI,eAAeiE,OAAS,GAC1D,CACA,MAAMyE,EAAiBnX,OAAO,mBACvB,SAASoX,EAAY/R,GACxB,OAAOA,EAAI8R,EACf,CA6CO,MAAM,UAAcP,EACvBpI,KAAO,QACP,GACA,CAAC2I,GACD,WAAAtc,CAAY8a,EAAOnP,EAAMsQ,GACrB9a,MAAM2Z,EAAOnP,GACbzL,MAAK,EAAY,IACV+b,EACHO,YAAY,QAAsBP,IAEtC/b,KAAKoc,GAtDb,SAAwB5B,EAAUuB,GAC9B,IAAI,cAAErI,GAAkBqI,EAASjC,OAAOpS,KAAK,MAAsB,CAAC,EAChE6U,EAAiB,CACjBC,kBAAkB,QAAyBT,EAASU,oBACpDjI,YAAY,QAAQuH,EAASnH,WAC7B0H,WAAYP,EAASO,YAEzB,GAAI5I,EAAe,CACf,IAAIgJ,EAAeR,EAAgBxI,EAAcoG,QACjD,MAAO,IACAyC,EACH9I,KAAM,UACNwH,YAAavH,EAAcuH,YAC3BjB,MAAOJ,EAAsB,CACzBhF,UAAWmH,EAASnH,UACpBlW,MAAOgV,EAAcuH,YACrBnB,OAAQpG,EAAcoG,SAE1B6C,YAAYje,IACD,QAAYA,EAAOge,GAE9BE,gBAAiBrC,EAA4BC,EAAUuB,EAASc,WAAWnJ,cAAcuH,YAAasB,EAAeC,iBAAkB9I,GAE/I,CACA,IAAIgJ,EAAeR,EAAgBH,EAASjC,QAC5C,MAAO,IACAyC,EACH9I,KAAM,UACNwH,YAAac,EAASc,WAAWnJ,cAAcuH,YAC/CjB,MAAOJ,EAAsB,CACzBhF,UAAWmH,EAASnH,UACpBlW,MAAOqd,EAASc,WAAWnJ,cAAcuH,YACzCnB,OAAQiC,EAASjC,SAErB6C,YAAYje,IACD,QAAYA,EAAOge,GAE9B,qBAAME,CAAgBE,EAAc9b,GAChC,IAAI+b,EAAYR,EAAeC,iBAAiBM,GAC5CE,EAAaxC,EAASjP,QAAQwR,GAAWtR,KAC7C,OAAO+O,EAASI,MAAMjO,IAAIqQ,EAAYhc,EAC1C,EAER,CAW+Bic,CAAejd,KAAM+b,EAChD,CACA,SAAIC,GACA,OAAOhc,MAAK,EAAUic,UAC1B,CACA,SAAIvd,GACA,OAAOsB,MAAK,EAAUtB,KAC1B,CACA,UAAIkE,GACA,OAAO5C,KAAKoc,GAAgBnB,WAChC,CACA,SAAIiC,GACA,OAAOld,MAAK,EAAU4U,SAC1B,CACA,cAAM9G,CAASgP,EAAc9b,GACzB,IAAImc,EAAUnd,KAAKoc,GACfgB,QAAoBD,EAAQP,gBAAgBE,EAAc9b,GAC9D,IAAKoc,EAAa,CACd,IAAIlM,EAAOiM,EAAQlC,YAAYrF,QAAO,CAACxN,EAAGC,IAAMD,EAAIC,GAAG,GACnD2C,EAAO,IAAImS,EAAQ3I,WAAWtD,GAGlC,OADAlG,EAAK3B,KAAK8T,EAAQb,YACX,CACHtR,OACAtM,MAAOye,EAAQlC,YACflG,OAAQoI,EAAQR,YAAYQ,EAAQlC,aAE5C,CACA,OAAOkC,EAAQnD,MAAMhG,OAAOoJ,EAChC,CAkBA,EAAAC,CAAGC,GACC,OAAO,QAAStd,KAAKkd,MAAOI,EAChC,E,8GC9IG,MAAMC,UAAmBzc,MAC5B,WAAAhB,CAAY0d,GACRvc,MAAMuc,GACNxd,KAAKpB,KAAO,YAChB,EA6BJ,MAAM6e,EACFC,QACAC,QACAC,cACAC,OACA,WAAA/d,EAAY,QAAE4d,EAAO,QAAEC,EAAO,cAAEC,IAE5BF,EApBD,SAAqCA,EAASC,GAWjD,OATAD,EAAUxZ,KAAK4Z,MAAMJ,IAEP,IACVA,EAAUC,EAAUD,IAGpBA,GAAWC,GAAWD,EAAU,IAnBxC,SAAyBC,GACrB,MAAM,IAAIJ,EAAW,iDAAiDI,IAC1E,CAkBQI,CAAgBJ,GAEbD,CACX,CAQkBM,CAA4BN,EAASC,GAE/C3d,KAAK0d,QAAUA,EACf1d,KAAK2d,QAAUA,EACf3d,KAAK4d,cAAgBA,EACrB5d,KAAK6d,OAAS,CAClB,CACA,EAAE5Y,OAAOC,YACL,MAAM+Y,EAAe/Z,KAAKoX,MAAMtb,KAAK0d,QAAU1d,KAAK4d,eAC9CM,EAAaD,EAAeje,KAAK4d,cACjCO,EAAgBne,KAAK0d,QAAUQ,OAC/B,CAAED,eAAcE,gBAC1B,EAEJ,MAAMC,EACF1a,MACA2a,KACAC,KACAX,QACAC,cACAC,OACAU,QACA,WAAAze,EAAY,QAAE4d,EAAO,QAAEC,EAAO,cAAEC,IAE5B,MAAOla,EAAO2a,EAAMC,IAAQ,QAAcZ,EAASC,GACnD3d,KAAK0D,MAAQA,EACb1D,KAAKqe,KAAOA,EACZre,KAAKse,KAAOA,EACRte,KAAKse,KAAO,GAxDxB,WACI,MAAM,IAAIf,EAAW,2CACzB,CAuDYiB,GAEJxe,KAAK2d,QAAUA,EACf3d,KAAK4d,cAAgBA,EACrB5d,KAAK6d,OAAS3Z,KAAKG,IAAI,EAAGH,KAAKua,MAAMze,KAAKqe,KAAOre,KAAK0D,OAAS1D,KAAKse,OACpEte,KAAKue,QAAUra,KAAKua,KAAKze,KAAK2d,QAAU3d,KAAK4d,cACjD,CACA,EAAE3Y,OAAOC,YAEL,MAAMwZ,EAAoBxa,KAAKoX,MAAMtb,KAAK0D,MAAQ1D,KAAK4d,eACjDe,EAAkBza,KAAKua,KAAKze,KAAKqe,KAAOre,KAAK4d,eACnD,IAAK,MAAMK,KAAgB,QAAMS,EAAmBC,GAAkB,CAElE,MAAMT,EAAaD,EAAeje,KAAK4d,cACjCgB,EAAY1a,KAAKC,IAAInE,KAAK2d,SAAUM,EAAe,GAAKje,KAAK4d,eAE7DA,EAAgBgB,EAAYV,EAClC,IAAIW,EAAiB,EACjBC,EAAsB,EAC1B,GAAI9e,KAAK0D,MAAQwa,EAAY,CAEzB,MAAMa,GAAab,EAAale,KAAK0D,OAAS1D,KAAKse,KAC/CS,IACAD,GAAuB9e,KAAKse,KAAOS,GAEvCF,EAAiB3a,KAAKua,MAAMP,EAAale,KAAK0D,OAAS1D,KAAKse,KAChE,MAGIQ,EAAsB9e,KAAK0D,MAAQwa,EAIvC,MAAMc,EAAqBhf,KAAKqe,KAAOO,EAAYhB,EAAgB5d,KAAKqe,KAAOH,EACzEC,EAAgB,CAClBW,EACAE,EACAhf,KAAKse,MAGHW,EAAc,CAChBJ,EACAA,EAHqB3a,KAAKua,MAAMO,EAAqBF,GAAuB9e,KAAKse,MAIjF,QAEE,CAAEL,eAAcE,gBAAec,cACzC,CACJ,EAaG,MAAMC,EACTC,aACAzgB,MACA,WAAAoB,EAAY,UAAEsf,EAAS,MAAE1gB,EAAK,YAAEuc,IAE5Bjb,KAAKmf,aAhBN,SAA6BC,EAAW1gB,GAC3C,IAAI2gB,EAAa,GAQjB,OAPkB,OAAdD,EACAC,EAAa3gB,EAAMsF,KAAK8B,IAAM,QAAM,QAE/BlB,MAAMC,QAAQua,KACnBC,EAAaD,EAAUpb,KAAKgU,GAAMA,IAAK,QAAM,SA7GrD,SAAgCoH,EAAW1gB,GACnC0gB,EAAU3e,OAAS/B,EAAM+B,QAVjC,SAA8B2e,EAAW1gB,GACrC,MAAM,IAAI6e,EAAW,yCAAyC7e,EAAM+B,eAAe2e,EAAU3e,SACjG,CASQ6e,CAAqBF,EAAW1gB,EAExC,CA2GI6gB,CAAuBF,EAAY3gB,GAC5B2gB,CACX,CAM4BG,CAAoBJ,EAAW1gB,GAAOsF,KAAI,CAAC0Z,EAASvb,IAC7D,IAAwB,iBAAZub,EAAuBD,EAAgBW,GAAiB,CAEvEV,QAASA,EACTC,QAASjf,EAAMyD,GACfyb,cAAe3C,EAAY9Y,OAGnCnC,KAAKtB,MAAQsB,KAAKmf,aACbxa,QAAQ8a,GAAQA,aAAerB,IAC/Bpa,KAAK0b,GAASA,EAAK7B,QAC5B,CACA,EAAE5Y,OAAOC,YACL,IAAK,MAAMya,KAAmB,WAAW3f,KAAKmf,cAAe,CACzD,MAAMrC,EAAe6C,EAAgB3b,KAAK4b,GAAMA,EAAE3B,eAC5C4B,EAAUF,EAAgB3b,KAAK4b,GAC7B,gBAAiBA,EACV,CAAE/Z,KAAM+Z,EAAEzB,cAAe2B,GAAIF,EAAEX,aAEnC,CAAEpZ,KAAM+Z,EAAEzB,cAAe2B,GAAI,aAElC,CAAEhD,eAAc+C,UAC1B,CACJ,EC3JJ,SAASE,EAAkBle,EAAK6C,EAAS,EAAGwM,GACxC,IAAIzQ,EAASyQ,GAAQrP,EAAIpB,OAASiE,EAClC,MAAO,CACHjE,SACAuf,SAAQ,CAACna,EAAMia,EAAKrf,IACTsf,EAAkBle,EAAK6C,EAASmB,EAAMia,EAAKja,GAEtD,GAAAlE,CAAIqJ,EAAMtH,EAAQ,GACd,IAAK,IAAIvB,EAAI,EAAGA,EAAI6I,EAAKvK,OAAQ0B,IAC7BN,EAAI6C,EAAShB,EAAQvB,GAAK6I,EAAK2B,IAAIxK,EAE3C,EACAwK,IAAIsL,GACOpW,EAAI6C,EAASuT,GAGhC,CAWA,SAASgI,EAAape,GAClB,OAAIqe,WAAWtb,MAAMC,QAAQhD,EAAImJ,MACtB,CAEHA,KAAM+U,EAAkBle,EAAImJ,MAC5B+J,OAAQlT,EAAIkT,OACZR,kBAAmB,GAGpB,CACHvJ,KAAM,IAAIoB,WAAWvK,EAAImJ,KAAKmJ,OAAQtS,EAAImJ,KAAKoJ,WAAYvS,EAAImJ,KAAKqJ,YACpEU,OAAQlT,EAAIkT,OACZR,kBAAmB1S,EAAImJ,KAAKyJ,kBAEpC,CA8BO,MAAM0L,EAAS,CAClBC,QAAO,CAACpV,EAAMtM,EAAOqW,KACV,CAAE/J,OAAMtM,QAAOqW,WAE1B,UAAAsL,CAAWC,EAAM1E,EAAKlN,GAClB,IAAIyK,EAAO8G,EAAaK,GACxBC,EAAkBpH,EAAMyC,EAhBhC,SAAuB/Z,EAAK6M,GACxB,GAAIwR,WAAWtb,MAAMC,QAAQhD,EAAImJ,MAE7B,OAAO+U,EAAkB,CAACrR,IAE9B,IAEI1D,EAAO,IAzBf,SAAqCnJ,GACjC,MAAI,UAAWA,EAGJA,EAAI/B,YAAYgb,KAAK,KAAMjZ,EAAI0W,OAEnC1W,EAAI/B,WACf,CAgBqB0gB,CAA4B3e,EAAImJ,MAEtC,CAAe,CAAC0D,IAC3B,OAAO,IAAItC,WAAWpB,EAAKmJ,OAAQnJ,EAAKoJ,WAAYpJ,EAAKqJ,WAC7D,CAOqCoM,CAAcH,EAAM5R,GAAQyK,EAAK5E,kBAClE,EACA,cAAAmM,CAAeJ,EAAMlb,EAAKub,GACtB,IAAIxH,EAAO8G,EAAaK,GACxBM,EAAsBzH,EAAM8G,EAAa7a,GAAM+T,EAAK5E,kBAAmBoM,EAC3E,GAGG3U,eAAe,EAAInK,EAAKud,EAAY,KAAMjU,EAAO,CAAC,GACrD,OCnFGa,eAAmBnK,EAAKud,EAAWjU,EAAMgV,GAC5C,IAAIhD,GAAU,QAAYtb,GACtBgf,EAAU,IAAI3B,EAAa,CAC3BE,YACA1gB,MAAOmD,EAAInD,MACXuc,YAAapZ,EAAIe,SAEjB0V,EAAM6H,EAAOC,QAAQ,IAAIjD,EAAQ3I,WAAWqM,EAAQniB,MAAMkX,QAAO,CAACxN,EAAGC,IAAMD,EAAIC,GAAG,IAAKwY,EAAQniB,MAAOye,EAAQR,YAAYkE,EAAQniB,QAClIkP,EAAQzC,EAAK2V,mBAAoB,UACrC,IAAK,MAAM,aAAEhE,EAAY,QAAE+C,KAAagB,EACpCjT,EAAMyD,KAAIrF,UACN,IAAI,KAAEhB,EAAI,MAAEtM,EAAK,OAAEqW,SAAiBlT,EAAIiM,SAASgP,EAAc3R,EAAKA,MAChEhI,EAAQgd,EAAOC,QAAQpV,EAAMtM,EAAOqW,GACxCoL,EAAOO,eAAepI,EAAKnV,EAAO0c,EAAQ,IAMlD,aAHMjS,EAAMmT,SAGoB,IAAzBF,EAAQniB,MAAM+B,OAtBzB,SAAgBoB,GACZ,MAAQ,QAASA,EAAMA,EAAI8K,IAqB0B,GArBf9K,EAqBe,EApBzD,CAoBwCmf,CAAO1I,EAAItN,MAAWsN,CAC9D,CD+DW3L,CAAgB9K,EAAKud,EAAWjU,EAAMgV,EACjD,CAKA,SAASc,EAAYvd,EAAO2a,EAAMC,GAC9B,OAAIA,EAAO,GAAKD,EAAO3a,EACZQ,KAAKoX,OAAO5X,EAAQ2a,EAAO,IAAMC,GAAQ,EAEhD5a,EAAQ2a,EACDna,KAAKoX,OAAO+C,EAAO3a,EAAQ,GAAK4a,GAAQ,EAC5C,CACX,CACA,SAASiC,EAAkBjI,EAAK4I,EAAexS,EAAO6F,GAClD,GAA6B,IAAzB2M,EAAczgB,OAEd,YADA6X,EAAItN,KAAKrJ,IAAI+M,EAAO,GAGxB,MAAO1J,KAAUmc,GAAUD,GACpBE,KAAgBrM,GAAUuD,EAAIvD,OACrC,GAAqB,iBAAV/P,EAGP,YADAub,EAAkB,CAAEvV,KADPsN,EAAItN,KAAKgV,SAASoB,EAAcpc,EAAQuP,GAC3BQ,UAAUoM,EAAQzS,EAAO6F,GAGvD,MAAO1O,EAAMia,EAAIxB,GAAQtZ,EACnBqc,EAAMJ,EAAYpb,EAAMia,EAAIxB,GAClC,GAAsB,IAAlB6C,EAAO1gB,OAMX,IAAK,IAAI0B,EAAI,EAAGA,EAAIkf,EAAKlf,IAErBoe,EAAkB,CAAEvV,KADPsN,EAAItN,KAAKgV,SAASoB,GAAevb,EAAOyY,EAAOnc,GAAKoS,GACvCQ,UAAUoM,EAAQzS,EAAO6F,QAPnD,IAAK,IAAIpS,EAAI,EAAGA,EAAIkf,EAAKlf,IACrBmW,EAAItN,KAAKrJ,IAAI+M,EAAO0S,GAAevb,EAAOyY,EAAOnc,GAAKoS,EAQlE,CACA,SAASqM,EAAsBN,EAAMlb,EAAKmP,EAAmBoM,GACzD,MAAOW,KAASC,GAASZ,GAClBa,KAAYC,GAAYnB,EAAKvL,QAC7B2M,KAAYC,GAAYvc,EAAI2P,OACnC,GAAkB,OAAduM,EAAKzb,KACL,OAAqB,IAAjB0b,EAAM9gB,YACN6f,EAAKtV,KAAKrJ,IAAIyD,EAAI4F,KAAKgV,SAAS,EAAGzL,GAAoB+M,EAAKxB,GAAKvL,QAGrEqM,EAAsB,CAClB5V,KAAMsV,EAAKtV,KAAKgV,SAASwB,EAAUF,EAAKxB,GAAKvL,GAC7CQ,OAAQ0M,GACTrc,EAAKmP,EAAmBgN,GAG/B,GAAgB,OAAZD,EAAKxB,GAAa,CAClB,GAAqB,IAAjByB,EAAM9gB,OAAc,CACpB,IAAIiE,EAAS4c,EAAKzb,KAAO0O,EAEzB,YADA+L,EAAKtV,KAAKrJ,IAAIyD,EAAI4F,KAAKgV,SAAStb,EAAQA,EAAS6P,GAAoB,EAEzE,CAKA,YAJAqM,EAAsBN,EAAM,CACxBtV,KAAM5F,EAAI4F,KAAKgV,SAAS0B,EAAUJ,EAAKzb,KAAO0O,GAC9CQ,OAAQ4M,GACTpN,EAAmBgN,EAE1B,CACA,MAAO1b,EAAMia,EAAIxB,GAAQgD,EAAKxB,IACvB8B,EAAO9b,EAAG+b,GAASP,EAAKzb,KACzBwb,EAAMJ,EAAYpb,EAAMia,EAAIxB,GAClC,GAAqB,IAAjBiD,EAAM9gB,OAgBV,IAAK,IAAI0B,EAAI,EAAGA,EAAIkf,EAAKlf,IACrBye,EAAsB,CAClB5V,KAAMsV,EAAKtV,KAAKgV,SAASwB,GAAW3b,EAAO1D,EAAImc,GAAQ/J,GACvDQ,OAAQ0M,GACT,CACCzW,KAAM5F,EAAI4F,KAAKgV,SAAS0B,GAAWE,EAAQzf,EAAI0f,GAAStN,GACxDQ,OAAQ4M,GACTpN,EAAmBgN,OAvB1B,CAGI,GAAa,IAATjD,GAAwB,IAAVuD,GAA2B,IAAZL,GAA6B,IAAZE,EAAe,CAC7D,IAAIhd,EAASkd,EAAQrN,EACjBrD,EAAOmQ,EAAM9M,EAEjB,YADA+L,EAAKtV,KAAKrJ,IAAIyD,EAAI4F,KAAKgV,SAAStb,EAAQA,EAASwM,GAAOrL,EAAO0O,EAEnE,CAEA,IAAK,IAAIpS,EAAI,EAAGA,EAAIkf,EAAKlf,IAAK,CAC1B,IAAIuC,EAASgd,GAAWE,EAAQC,EAAQ1f,GAAKoS,EAC7C+L,EAAKtV,KAAKrJ,IAAIyD,EAAI4F,KAAKgV,SAAStb,EAAQA,EAAS6P,GAAoBiN,GAAW3b,EAAOyY,EAAOnc,GAAKoS,EACvG,CAEJ,CAUJ,C,iBEtLO,SAAUxH,EAAMrJ,EAAO2a,EAAMC,EAAO,QAC1B/c,IAAT8c,IACAA,EAAO3a,EACPA,EAAQ,GAEZ,IAAK,IAAIvB,EAAIuB,EAAOvB,EAAIkc,EAAMlc,GAAKmc,QACzBnc,CAEd,CAKO,SAAU2f,KAAWC,GACxB,GAAyB,IAArBA,EAAUthB,OACV,OAGJ,MAAMuhB,EAAYD,EAAU/d,KAAKie,GAAOA,EAAGhd,OAAOC,cAC5Cgd,EAAUF,EAAUhe,KAAKie,GAAOA,EAAGE,SACzC,GAAID,EAAQ7e,MAAM+e,GAAMA,EAAEC,OACtB,MAAM,IAAIvhB,MAAM,qCAEpB,IAAK,IAAIqB,EAAI,IAAK,CACd,GAAI+f,EAAQ/f,GAAGkgB,MAKX,GAHAL,EAAU7f,GAAK4f,EAAU5f,GAAG8C,OAAOC,YACnCgd,EAAQ/f,GAAK6f,EAAU7f,GAAGggB,SAEpBhgB,GAAK6f,EAAUvhB,OACjB,kBAKEyhB,EAAQle,KAAI,EAAG0K,WAAYA,IACjCvM,EAAI,EAER+f,EAAQ/f,GAAK6f,EAAU7f,GAAGggB,MAC9B,CACJ,CAEO,SAASG,GAAc,MAAE5e,EAAK,KAAE2a,EAAI,KAAEC,GAAQ7d,GACjD,GAAa,IAAT6d,EACA,MAAM,IAAIxd,MAAM,6BAGpB,MAAMyhB,GADNjE,EAAOA,GAAQ,GACiB,GAEzBkE,EAAOC,GAASF,EAAmB,EAAE,EAAG9hB,EAAS,GAAK,CAAC,EAAGA,GA+BjE,OA7Bc,OAAViD,EACAA,EAAQ6e,EAAmBE,EAAQD,EAG/B9e,EAAQ,GACRA,GAASjD,GACG+hB,IACR9e,EAAQ8e,GAGP9e,EAAQ+e,IACb/e,EAAQ+e,GAIH,OAATpE,EACAA,EAAOkE,EAAmBC,EAAQC,EAG9BpE,EAAO,GACPA,GAAQ5d,GACG+hB,IACPnE,EAAOmE,GAGNnE,EAAOoE,IACZpE,EAAOoE,GAGR,CAAC/e,EAAO2a,EAAMC,EACzB,CACO,SAAStZ,EAAMtB,EAAO2a,EAAMC,EAAO,MAKtC,YAJa/c,IAAT8c,IACAA,EAAO3a,EACPA,EAAQ,MAEL,CACHA,QACA2a,OACAC,OAER,CAEO,SAASwC,IACZ,MAAM/P,EAAW,GACjB,MAAO,CACHM,IAAMqR,GAAO3R,EAAS3O,KAAKsgB,KAC3B3B,OAAQ,IAAMhR,QAAQ4S,IAAI5R,GAElC,C,yHClGA,IAAI6R,EACJ,WACI,IAAIC,EAAiB,IAAIC,QACzB,SAASC,EAAWnI,GAChB,IAAIoI,EAASH,EAAelW,IAAIiO,IAAU,CAAEqI,GAAI,EAAGC,GAAI,GAEvD,OADAL,EAAelhB,IAAIiZ,EAAOoI,GACnBA,CACX,CACA,MAAO,CACH,SAAAG,CAAUvI,EAAOwI,GACbL,EAAWnI,GAAOwI,IAAY,CAClC,EACA,WAAAC,CAAYzI,GACR,IAAIoI,EAASD,EAAWnI,GACxB,OAAOoI,EAAOE,GAAKF,EAAOC,GAAK,KAAO,IAC1C,EAER,CAjBsBK,GAsCtBtX,eAAeuX,EAAc/I,EAAUwB,GACnC,IAAI,KAAEvQ,GAAS+O,EAASjP,QAAQ,WAC5BpB,QAAaqQ,EAASI,MAAMjO,IAAIlB,GACpC,IAAKtB,EACD,MAAM,IAAI,IAAkB,WAAY,CACpCzI,MAAO,IAAI,IAAS+J,KAI5B,OADAmX,EAAgBO,UAAU3I,EAASI,MAAO,MACnC,IAAI,KAAMJ,EAASI,MAAOJ,EAAS/O,MAAM,SAAwB,QAAmBtB,GAAO6R,GACtG,CACAhQ,eAAewX,EAAchJ,EAAUwB,GACnC,IAAI,KAAEvQ,GAAS+O,EAASjP,QAAQ,WAC5BpB,QAAaqQ,EAASI,MAAMjO,IAAIlB,GACpC,IAAKtB,EACD,MAAM,IAAI,IAAkB,WAAY,CACpCzI,MAAO,IAAI,IAAS+J,KAI5B,OADAmX,EAAgBO,UAAU3I,EAASI,MAAO,MACnC,IAAI,KAAMJ,EAASI,MAAOJ,EAAS/O,MAAM,SAAwB,QAAmBtB,GAAO6R,GACtG,CA8BOhQ,eAAeyX,EAAKjJ,EAAUxZ,EAAU,CAAC,GAC5C,IAAI4Z,EAAQ,UAAWJ,EAAWA,EAASI,MAAQJ,EAC/C6I,EAAcT,EAAgBS,YAAYzI,GAI1C8I,EAA+B,OAAhBL,EAAuBI,EAAKR,GAAKQ,EAAKP,GACrDS,EAAiC,OAAhBN,EAAuBI,EAAKP,GAAKO,EAAKR,GAC3D,OAAOS,EAAalJ,EAAUxZ,GAASuR,OAAOqR,KAC1C,QAAeA,EAAK,KACbD,EAAenJ,EAAUxZ,KAExC,CACAyiB,EAAKR,GA9ELjX,eAAuBwO,EAAUxZ,EAAU,CAAC,GACxC,IAAI6iB,EAAM,UAAWrJ,EAAWA,EAAW,IAAI,KAASA,GACpDwB,EAAQ,CAAC,EAGb,OAFIhb,EAAQgb,OAAS,KACjBA,QAVRhQ,eAA0BwO,GACtB,IAAIsJ,QAAmBtJ,EAASI,MAAMjO,IAAI6N,EAASjP,QAAQ,WAAWE,MACtE,OAAKqY,GAEE,QAAmBA,GADf,CAAC,CAEhB,CAKsBC,CAAWF,IACR,UAAjB7iB,EAAQyS,KACD8P,EAAcM,EAAK7H,GACT,UAAjBhb,EAAQyS,KACD+P,EAAcK,EAAK7H,GACvBuH,EAAcM,EAAK7H,GAAOzJ,OAAOqR,KACpC,QAAeA,EAAK,KACbJ,EAAcK,EAAK7H,KAElC,EAkEAyH,EAAKP,GA3BLlX,eAAuBwO,EAAUxZ,EAAU,CAAC,GACxC,IAAI6iB,EAAM,UAAWrJ,EAAWA,EAAW,IAAI,KAASA,GACpDwJ,QAlBRhY,eAAwBwO,GACpB,IAAI,MAAEI,EAAK,KAAEnP,GAAS+O,EAASjP,QAAQ,aACnCpB,QAAaqQ,EAASI,MAAMjO,IAAIlB,GACpC,IAAKtB,EACD,MAAM,IAAI,IAAkB,oBAAqB,CAC7CzI,MAAO,IAAI,IAAS+J,KAG5B,IAAIwY,GAAW,QAAmB9Z,GAIlC,MAH2B,UAAvB8Z,EAASC,YACTD,EAAS3H,YAAa,QAAsB2H,IAElB,UAAvBA,EAASC,UACV,IAAI,KAAMtJ,EAAOJ,EAAS/O,KAAMwY,GAChC,IAAI,KAAMrJ,EAAOJ,EAAS/O,KAAMwY,EAC1C,CAGqBE,CAASN,GAE1B,GADAjB,EAAgBO,UAAUU,EAAIjJ,MAAO,WAChBrZ,IAAjBP,EAAQyS,KACR,OAAOuQ,EACX,GAAqB,UAAjBhjB,EAAQyS,MAAoBuQ,aAAgB,KAC5C,OAAOA,EACX,GAAqB,UAAjBhjB,EAAQyS,MAAoBuQ,aAAgB,KAC5C,OAAOA,EACX,IAAIvQ,EAAOuQ,aAAgB,KAAQ,QAAU,QAC7C,MAAM,IAAIljB,MAAM,yBAAyBE,EAAQyS,eAAeA,KACpE,C,qDCjFO,MAAM2Q,EACT,GACA,WAAAtkB,CAAYgY,EAAG1D,EAAY3T,GACN,iBAANqX,EACP9X,MAAK,EAAS,IAAIoM,WAAW0L,GAExBA,aAAauM,YAClBrkB,MAAK,EAAS,IAAIoM,WAAW0L,EAAG1D,EAAY3T,GAG5CT,MAAK,EAAS,IAAIoM,WAAWxH,MAAMiB,KAAKiS,GAAI/V,GAAOA,EAAI,EAAI,IAEnE,CACA,qBAAI0S,GACA,OAAO,CACX,CACA,cAAIL,GACA,OAAOpU,MAAK,EAAOoU,UACvB,CACA,cAAIC,GACA,OAAOrU,MAAK,EAAOqU,UACvB,CACA,UAAIF,GACA,OAAOnU,MAAK,EAAOmU,MACvB,CACA,UAAI1T,GACA,OAAOT,MAAK,EAAOS,MACvB,CACA,GAAAkM,CAAInH,GACA,IAAIkJ,EAAQ1O,MAAK,EAAOwF,GACxB,MAAwB,iBAAVkJ,EAA+B,IAAVA,EAAcA,CACrD,CACA,GAAA/M,CAAI6D,EAAKkJ,GACL1O,MAAK,EAAOwF,GAAOkJ,EAAQ,EAAI,CACnC,CACA,IAAArF,CAAKqF,GACD1O,MAAK,EAAOqJ,KAAKqF,EAAQ,EAAI,EACjC,CACA,EAAEzJ,OAAOC,YACL,IAAK,IAAI/C,EAAI,EAAGA,EAAInC,KAAKS,OAAQ0B,UACvBnC,KAAK2M,IAAIxK,EAEvB,EAOG,MAAMmiB,EACTC,MACAhM,MACA,GACA,WAAAzY,CAAYyY,EAAOT,EAAG1D,EAAY3T,GAG9B,GAFAT,KAAKuY,MAAQA,EACbvY,MAAK,EAAW,IAAIuX,YACH,iBAANO,EACP9X,KAAKukB,MAAQ,IAAInY,WAAW0L,EAAIS,QAE/B,GAAIT,aAAauM,YACd5jB,IACAA,GAAkB8X,GACtBvY,KAAKukB,MAAQ,IAAInY,WAAW0L,EAAG1D,EAAY3T,OAE1C,CACD,IAAI+jB,EAAS5f,MAAMiB,KAAKiS,GACxB9X,KAAKukB,MAAQ,IAAInY,WAAWoY,EAAO/jB,OAAS8X,GAC5C,IAAK,IAAIpW,EAAI,EAAGA,EAAIqiB,EAAO/jB,OAAQ0B,IAC/BnC,KAAK2B,IAAIQ,EAAGqiB,EAAOriB,GAE3B,CACJ,CACA,qBAAIsS,GACA,OAAOzU,KAAKuY,KAChB,CACA,cAAInE,GACA,OAAOpU,KAAKukB,MAAMnQ,UACtB,CACA,cAAIC,GACA,OAAOrU,KAAKukB,MAAMlQ,UACtB,CACA,UAAIF,GACA,OAAOnU,KAAKukB,MAAMpQ,MACtB,CACA,UAAI1T,GACA,OAAOT,KAAKqU,WAAarU,KAAKyU,iBAClC,CACA,GAAA9H,CAAInH,GACA,MAAM2T,EAAO,IAAI/M,WAAWpM,KAAKmU,OAAQnU,KAAKoU,WAAapU,KAAKuY,MAAQ/S,EAAKxF,KAAKuY,OAElF,OAAO,IAAIW,aAAclF,OAAOmF,GAAMlC,QAAQ,QAAS,GAC3D,CACA,GAAAtV,CAAI6D,EAAKkJ,GACL,MAAMyK,EAAO,IAAI/M,WAAWpM,KAAKmU,OAAQnU,KAAKoU,WAAapU,KAAKuY,MAAQ/S,EAAKxF,KAAKuY,OAClFY,EAAK9P,KAAK,GACV8P,EAAKxX,IAAI3B,MAAK,EAAS8T,OAAOpF,GAClC,CACA,IAAArF,CAAKqF,GACD,MAAM+V,EAAUzkB,MAAK,EAAS8T,OAAOpF,GACrC,IAAK,IAAIvM,EAAI,EAAGA,EAAInC,KAAKS,OAAQ0B,IAC7BnC,KAAKukB,MAAM5iB,IAAI8iB,EAAStiB,EAAInC,KAAKuY,MAEzC,CACA,EAAEtT,OAAOC,YACL,IAAK,IAAI/C,EAAI,EAAGA,EAAInC,KAAKS,OAAQ0B,UACvBnC,KAAK2M,IAAIxK,EAEvB,EAOG,MAAMuiB,EACT,GACAnM,MACA,WAAAzY,CAAYyY,EAAOT,EAAG1D,EAAY3T,GAE9B,GADAT,KAAKuY,MAAQA,EACI,iBAANT,EACP9X,MAAK,EAAQ,IAAI2kB,WAAW7M,EAAIS,QAE/B,GAAIT,aAAauM,YACd5jB,IACAA,GAAU8X,GACdvY,MAAK,EAAQ,IAAI2kB,WAAW7M,EAAG1D,EAAY3T,OAE1C,CACD,MAAM+jB,EAAS1M,EACTkD,EAAI,IAAI0J,EAAmBnM,EAAO,GACxCvY,MAAK,EAAQ,IAAI2kB,WAAW,YACxB,IAAK,IAAIC,KAAOJ,EACZxJ,EAAErZ,IAAI,EAAGijB,SACF5J,GAAE,CAEhB,CAL2B,GAMhC,CACJ,CACA,qBAAIvG,GACA,OAAOzU,MAAK,EAAMyU,kBAAoBzU,KAAKuY,KAC/C,CACA,cAAIlE,GACA,OAAOrU,MAAK,EAAMqU,UACtB,CACA,cAAID,GACA,OAAOpU,MAAK,EAAMoU,UACtB,CACA,UAAID,GACA,OAAOnU,MAAK,EAAMmU,MACtB,CACA,UAAI1T,GACA,OAAOT,MAAK,EAAMS,OAAST,KAAKuY,KACpC,CACA,GAAA5L,CAAInH,GACA,MAAMd,EAAS1E,KAAKuY,MAAQ/S,EAC5B,IAAIwB,EAAS,GACb,IAAK,IAAI7E,EAAI,EAAGA,EAAInC,KAAKuY,MAAOpW,IAC5B6E,GAAU6d,OAAOC,cAAc9kB,MAAK,EAAM0E,EAASvC,IAGvD,OAAO6E,EAAOiQ,QAAQ,UAAW,GACrC,CACA,GAAAtV,CAAI6D,EAAKkJ,GACL,MAAMhK,EAAS1E,KAAKuY,MAAQ/S,EACtB2T,EAAOnZ,MAAK,EAAMggB,SAAStb,EAAQA,EAAS1E,KAAKuY,OACvDY,EAAK9P,KAAK,GACV,IAAK,IAAIlH,EAAI,EAAGA,EAAInC,KAAKuY,MAAOpW,IAC5BgX,EAAKhX,GAAKuM,EAAMqW,YAAY5iB,IAAM,CAE1C,CACA,IAAAkH,CAAKqF,GAED1O,KAAK2B,IAAI,EAAG+M,GAEZ,IAAI+V,EAAUzkB,MAAK,EAAMggB,SAAS,EAAGhgB,KAAKuY,OAC1C,IAAK,IAAIpW,EAAI,EAAGA,EAAInC,KAAKS,OAAQ0B,IAC7BnC,MAAK,EAAM2B,IAAI8iB,EAAStiB,EAAInC,KAAKuY,MAEzC,CACA,EAAEtT,OAAOC,YACL,IAAK,IAAI/C,EAAI,EAAGA,EAAInC,KAAKS,OAAQ0B,UACvBnC,KAAK2M,IAAIxK,EAEvB,E,4JC5LG,SAAS6iB,EAAmBlQ,GAC/B,MAAM8P,GAAM,IAAI1L,aAAclF,OAAOc,GACrC,OAAOiC,KAAKkO,MAAML,EACtB,CACO,SAASM,EAAiB/L,EAAM5E,GACnC,MAAM4Q,EAAW5Q,EAAoB,EAC/B6Q,EAAe7Q,EAAoB,EACzC,IAAIvO,EAAI,EACR,IAAK,IAAI7D,EAAI,EAAGA,EAAIgX,EAAK1Y,OAAQ0B,GAAKoS,EAClC,IAAK,IAAI8Q,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAC/Brf,EAAImT,EAAKhX,EAAIkjB,GACblM,EAAKhX,EAAIkjB,GAAKlM,EAAKhX,EAAIijB,EAAeC,GACtClM,EAAKhX,EAAIijB,EAAeC,GAAKrf,CAGzC,CACO,SAASsf,EAAQ1Q,GACpB,GAAkB,cAAdA,EACA,OAAOsL,WAAWtb,MAEtB,IAAI2gB,EAAQ3Q,EAAU2Q,MAAM,kBAC5B,GAAIA,EAAO,CACP,IAAK,CAAE9R,EAAM8E,GAASgN,EAEtB,OAAiB,MAAT9R,EAAe,KAAqB,MAAiBqH,KAAK,KAAMtY,OAAO+V,GACnF,CAEA,IAAIiN,EAAM,CACNC,KAAMC,UACNC,MAAOC,WACPC,MAAOlB,WACPmB,MAAO5F,WAAW6F,cAClBC,MAAO5Z,WACP6Z,OAAQC,YACRC,OAAQjS,YACRkS,OAAQlG,WAAWmG,eACnBC,QAASpG,WAAWqG,aACpBC,QAASC,aACTC,QAASC,aACTC,KAAM,MACRhS,GAEF,OADAiS,EAAOrB,EAAK,qCAAqC5Q,KAC1C4Q,CACX,CAEO,SAAS7I,EAAYje,EAAOiZ,GAC/B,MAAMC,EAAOlZ,EAAM+B,OACE,iBAAVkX,IACPA,EACc,MAAVA,EACM/S,MAAMiB,KAAK,CAAEpF,OAAQmX,IAAQ,CAAC9R,EAAG3D,IAAMA,IACvCyC,MAAMiB,KAAK,CAAEpF,OAAQmX,IAAQ,CAAC9R,EAAG3D,IAAMyV,EAAO,EAAIzV,KAEhE0kB,EAAOjP,IAASD,EAAMlX,OAAQ,qDAC9B,IAAI6d,EAAO,EACPvJ,EAAS,IAAInQ,MAAMgT,GACvB,IAAK,IAAIzV,EAAIwV,EAAMlX,OAAS,EAAG0B,GAAK,EAAGA,IACnC4S,EAAO4C,EAAMxV,IAAMmc,EACnBA,GAAQ5f,EAAMiZ,EAAMxV,IAExB,OAAO4S,CACX,CAEO,SAAS+R,GAAyB,KAAEloB,EAAI,cAAE8U,IAC7C,GAAa,YAAT9U,EAAoB,CACpB,MAAMmoB,EAAYrT,GAAeqT,WAAa,IAC9C,OAAQjK,GAAiB,CAAC,OAAQA,GAAc3O,KAAK4Y,EACzD,CACA,GAAa,OAATnoB,EAAe,CACf,MAAMmoB,EAAYrT,GAAeqT,WAAa,IAC9C,OAAQjK,GAAiBA,EAAa3O,KAAK4Y,IAAc,GAC7D,CACA,MAAM,IAAIjmB,MAAM,+BAA+BlC,IACnD,CA6BO,SAASooB,EAAwB7c,EAAM8R,EAAa,CAAC,GACxD,IAAInC,EAAS,GACToD,EA9BR,SAAsBA,GAClB,GAAc,OAAVA,EACA,MAAO,CAAEtI,UAAW,aAExB,IAAI2Q,EAAQrI,EAAMqI,MAAM,iBACxBsB,EAAOtB,EAAO,kBAAkBrI,KAChC,IAAK,CAAEvI,EAAQsS,GAAQ1B,EACnB3Q,EAAY,CACZsS,GAAI,OACJC,GAAI,OACJC,GAAI,QACJC,GAAI,QACJC,GAAI,SACJC,GAAI,QACJC,GAAI,SACJC,GAAI,QACJC,GAAI,SACJC,GAAI,UACJC,GAAI,UACJC,GAAI,WACNZ,KACGA,EAAKjY,WAAW,MAAQiY,EAAKjY,WAAW,KAAO,MAAMiY,SAAS1lB,GAEnE,OADAslB,EAAOjS,EAAW,iCAAiCsI,KACpC,MAAXvI,EACO,CAAEC,aAEN,CAAEA,YAAWD,OAAmB,MAAXA,EAAiB,SAAW,MAC5D,CAGgBmT,CAAa3d,EAAK+S,OACX,MAAf/S,EAAKwN,OACLmC,EAAO1X,KAAK,CAAExD,KAAM,YAAa8U,cAAe,CAAEiE,MAAO,OAEzD,WAAYuF,GAA0B,QAAjBA,EAAMvI,QAC3BmF,EAAO1X,KAAK,CAAExD,KAAM,QAAS8U,cAAe,CAAEiB,OAAQ,SAE1D,IAAK,IAAI,GAAEoT,KAAOrU,KAAmBvJ,EAAK6d,SAAW,GACjDlO,EAAO1X,KAAK,CAAExD,KAAMmpB,EAAIrU,kBAE5B,GAAIvJ,EAAK8d,WAAY,CACjB,IAAI,GAAEF,KAAOrU,GAAkBvJ,EAAK8d,WACpCnO,EAAO1X,KAAK,CAAExD,KAAMmpB,EAAIrU,iBAC5B,CACA,MAAO,CACHwU,YAAa,EACbhE,UAAW,QACXxlB,MAAOyL,EAAKzL,MACZkW,UAAWsI,EAAMtI,UACjBiI,WAAY,CACRje,KAAM,UACN8U,cAAe,CACXuH,YAAa9Q,EAAKvH,SAG1B6Z,mBAAoB,CAChB7d,KAAM,KACN8U,cAAe,CACXqT,UAAW5c,EAAKge,qBAAuB,MAG/CrO,SACAwC,WAAYnS,EAAKmS,WACjBL,aAER,CACO,SAASmM,EAAwBzU,EAAOsI,EAAa,CAAC,GACzD,MAAO,CACHiM,YAAa,EACbhE,UAAW,QACXjI,aAER,CACO,SAASoM,EAASnL,EAAOI,GAC5B,GAAc,WAAVA,GACU,WAAVA,GACU,YAAVA,GACU,WAAVA,GACU,WAAVA,EACA,OAAOJ,IAAUI,EAErB,IAAIgL,EAAuB,SAAVpL,EACjB,GAAc,YAAVI,EACA,OAAOgL,EACX,IAAIC,EAAYrL,EAAMlO,WAAW,SAAWkO,EAAMlO,WAAW,QAC7D,GAAc,WAAVsO,EACA,OAAOiL,EACX,IAAIC,EAAsB,UAAVtL,GAA+B,WAAVA,EACrC,GAAc,WAAVI,EACA,OAAOkL,EACX,IAAIC,EAAsB,cAAVvL,EAChB,MAAc,WAAVI,EACOmL,IACHF,GAAcC,GAAcF,GAAeG,EACvD,CACO,SAASC,EAAkB1O,GAC9B,MAAuB,qBAAhBA,GAAOpb,IAClB,CACO,SAAS+pB,EAAsB5M,GAClC,MAA4B,WAAvBA,EAASnH,WAAiD,UAAvBmH,EAASnH,WACtB,MAAvBmH,EAASO,WAINP,EAASO,WAFLsM,OAAO7M,EAASO,WAG/B,CA0BO,SAASuM,EAAeC,KAAUC,GACrC,IAAKA,EAAO1lB,MAAM2lB,GAAeF,aAAiBE,IAC9C,MAAMF,CAEd,CAgBO,SAASjC,EAAOoC,EAAYzL,EAAM,IACrC,IAAKyL,EACD,MAAM,IAAInoB,MAAM0c,EAExB,CASOxR,eAAekd,EAAWle,GAAM,OAAEmK,EAAM,OAAEgU,IAC7C,MAAMjd,EAAWlB,aAAgBoe,SAAWpe,EAAO,IAAIoe,SAASpe,GAChE6b,EAAO3a,EAASmd,KAAM,mCACtB,IACI,MAAMC,EAAuB,IAAIF,SAASld,EAASmd,KAAKE,YAAY,IAAIC,oBAAoBrU,GAAS,CAAEgU,YAEvG,aADqBG,EAAqBjd,aAE9C,CACA,MAEI,MADA8c,GAAQM,iBACF,IAAI3oB,MAAM,oBAAoBqU,IACxC,CACJ,C","sources":["webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/VolumeDims.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/ImageInfo.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/VolumeLoadError.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/ChunkPrefetchIterator.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/utils.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/validation.js","webpack://@aics/vole-app/./node_modules/@zarrita/storage/dist/src/util.js","webpack://@aics/vole-app/./node_modules/@zarrita/storage/dist/src/fetch.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/wrappers.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/RequestQueue.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/SubscribableRequestQueue.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/workers/types.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/workers/util.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/bitround.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/bytes.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/crc32c.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/gzip.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/json2.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/transpose.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/vlen-utf8.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/zlib.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/sharding.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/hierarchy.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/indexer.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/ops.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/get.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/util.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/open.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/typedarray.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/util.js"],"sourcesContent":["import { Vector3 } from \"three\";\nexport function defaultVolumeDims() {\n  return {\n    shape: [0, 0, 0, 0, 0],\n    spacing: [1, 1, 1, 1, 1],\n    spaceUnit: \"μm\",\n    timeUnit: \"s\",\n    dataType: \"uint8\"\n  };\n}\nexport function volumeSize(volumeDims) {\n  return new Vector3(volumeDims.shape[4], volumeDims.shape[3], volumeDims.shape[2]);\n}\nexport function physicalPixelSize(volumeDims) {\n  return new Vector3(volumeDims.spacing[4], volumeDims.spacing[3], volumeDims.spacing[2]);\n}","import { volumeSize, physicalPixelSize } from \"./VolumeDims.js\";\nimport { Vector3, Vector2 } from \"three\";\nexport function defaultImageInfo() {\n  return {\n    name: \"\",\n    atlasTileDims: [1, 1],\n    subregionSize: [1, 1, 1],\n    subregionOffset: [0, 0, 0],\n    combinedNumChannels: 1,\n    channelNames: [\"0\"],\n    channelColors: [[255, 255, 255]],\n    multiscaleLevel: 0,\n    multiscaleLevelDims: [{\n      shape: [1, 1, 1, 1, 1],\n      spacing: [1, 1, 1, 1, 1],\n      spaceUnit: \"\",\n      timeUnit: \"\",\n      dataType: \"uint8\"\n    }],\n    transform: {\n      translation: [0, 0, 0],\n      rotation: [0, 0, 0],\n      scale: [1, 1, 1]\n    }\n  };\n}\nexport class CImageInfo {\n  constructor(imageInfo) {\n    this.imageInfo = imageInfo || defaultImageInfo();\n  }\n  get currentLevelDims() {\n    return this.imageInfo.multiscaleLevelDims[this.imageInfo.multiscaleLevel];\n  }\n\n  /** Number of channels in the image */\n  get numChannels() {\n    return this.imageInfo.combinedNumChannels;\n  }\n\n  /** XYZ size of the *original* (not downsampled) volume, in pixels */\n  get originalSize() {\n    return volumeSize(this.imageInfo.multiscaleLevelDims[0]);\n  }\n\n  /** Size of the volume, in pixels */\n  get volumeSize() {\n    return volumeSize(this.currentLevelDims);\n  }\n\n  /** Size of a single *original* (not downsampled) pixel, in spatial units */\n  get physicalPixelSize() {\n    return physicalPixelSize(this.imageInfo.multiscaleLevelDims[0]);\n  }\n\n  /** Symbol of physical spatial unit used by `physicalPixelSize` */\n  get spatialUnit() {\n    return this.imageInfo.multiscaleLevelDims[0].spaceUnit;\n  }\n\n  /** Number of timesteps in the time series, or 1 if the image is not a time series */\n  get times() {\n    // 0 is T\n    return this.currentLevelDims.shape[0];\n  }\n\n  /** Size of each timestep in temporal units */\n  get timeScale() {\n    // 0 is T\n    return this.currentLevelDims.spacing[0];\n  }\n\n  /** Symbol of physical time unit used by `timeScale` */\n  get timeUnit() {\n    return this.currentLevelDims.timeUnit;\n  }\n\n  /** Number of scale levels available for this volume */\n  get numMultiscaleLevels() {\n    return this.imageInfo.multiscaleLevelDims.length;\n  }\n\n  /** The names of each channel */\n  get channelNames() {\n    return this.imageInfo.channelNames;\n  }\n\n  /** Optional overrides to default channel colors, in 0-255 range */\n  get channelColors() {\n    return this.imageInfo.channelColors;\n  }\n\n  /** Size of the currently loaded subregion, in pixels */\n  get subregionSize() {\n    return new Vector3(...this.imageInfo.subregionSize);\n  }\n\n  /** Offset of the loaded subregion into the total volume, in pixels */\n  get subregionOffset() {\n    return new Vector3(...this.imageInfo.subregionOffset);\n  }\n  get multiscaleLevel() {\n    return this.imageInfo.multiscaleLevel;\n  }\n\n  /**\n   * XY dimensions of the texture atlas used by `RayMarchedAtlasVolume` and `Atlas2DSlice`, in number of z-slice\n   * tiles (not pixels). Chosen by the loader to lay out the 3D volume in the squarest possible 2D texture atlas.\n   */\n  get atlasTileDims() {\n    return new Vector2(...this.imageInfo.atlasTileDims);\n  }\n  get transform() {\n    return {\n      translation: new Vector3(...this.imageInfo.transform.translation),\n      rotation: new Vector3(...this.imageInfo.transform.rotation),\n      scale: new Vector3(...this.imageInfo.transform.scale)\n    };\n  }\n}\nexport function computeAtlasSize(imageInfo) {\n  const {\n    atlasTileDims\n  } = imageInfo;\n  const volDims = imageInfo.multiscaleLevelDims[imageInfo.multiscaleLevel];\n  // TCZYX: 4 = x, 3 = y\n  return [atlasTileDims[0] * volDims.shape[4], atlasTileDims[1] * volDims.shape[3]];\n}","import { errorConstructors } from \"serialize-error\";\nimport { NodeNotFoundError, KeyError } from \"zarrita\";\n// geotiff doesn't export its error types...\n\n/** Groups possible load errors into a few broad categories which we can give similar guidance to the user about. */\nexport let VolumeLoadErrorType = /*#__PURE__*/function (VolumeLoadErrorType) {\n  VolumeLoadErrorType[\"UNKNOWN\"] = \"unknown\";\n  VolumeLoadErrorType[\"NOT_FOUND\"] = \"not_found\";\n  VolumeLoadErrorType[\"TOO_LARGE\"] = \"too_large\";\n  VolumeLoadErrorType[\"LOAD_DATA_FAILED\"] = \"load_data_failed\";\n  VolumeLoadErrorType[\"INVALID_METADATA\"] = \"invalid_metadata\";\n  VolumeLoadErrorType[\"INVALID_MULTI_SOURCE_ZARR\"] = \"invalid_multi_source_zarr\";\n  return VolumeLoadErrorType;\n}({});\nexport class VolumeLoadError extends Error {\n  constructor(message, options) {\n    super(message, options);\n    this.name = \"VolumeLoadError\";\n    this.type = options?.type ?? VolumeLoadErrorType.UNKNOWN;\n  }\n}\n\n// serialize-error only ever calls an error constructor with zero arguments. The required `ErrorConstructor`\n// type is a bit too restrictive - as long as the constructor can be called with no arguments it's fine.\nerrorConstructors.set(\"NodeNotFoundError\", NodeNotFoundError);\nerrorConstructors.set(\"KeyError\", KeyError);\nerrorConstructors.set(\"VolumeLoadError\", VolumeLoadError);\n\n/** Curried function to re-throw an error wrapped in a `VolumeLoadError` with the given `message` and `type`. */\nexport function wrapVolumeLoadError(message = \"Unknown error occurred while loading volume data\", type = VolumeLoadErrorType.UNKNOWN, ignore) {\n  return e => {\n    if (ignore !== undefined && e === ignore) {\n      return e;\n    }\n    if (e instanceof VolumeLoadError) {\n      throw e;\n    }\n    console.log(`Error loading volume data: ${e}`);\n    throw new VolumeLoadError(message, {\n      type,\n      cause: e\n    });\n  };\n}","const allEqual = arr => arr.every(v => v === arr[0]);\nconst pushN = (arr, val, n) => {\n  for (let i = 0; i < n; i++) {\n    arr.push(val);\n  }\n};\nconst directionToIndex = dir => {\n  const absDir = dir >> 1; // shave off sign bit to get index in TZYX\n  return absDir + Number(absDir !== 0); // convert TZYX -> TCZYX by skipping c (index 1)\n};\nfunction updateMinMax(val, minmax) {\n  if (val < minmax[0]) {\n    minmax[0] = val;\n  }\n  if (val > minmax[1]) {\n    minmax[1] = val;\n  }\n}\n\n/**\n * Since the user is most likely to want nearby data (in space or time) first, we should prefetch those chunks first.\n *\n * Given a list of just-loaded chunks and some bounds, `ChunkPrefetchIterator` iterates evenly outwards in T/Z/Y/X.\n */\n// NOTE: Assumes `chunks` form a rectangular prism! Will create gaps otherwise! (in practice they always should)\nexport default class ChunkPrefetchIterator {\n  constructor(chunks, tzyxMaxPrefetchOffset, tczyxChunksPerSource, priorityDirections, onlyPriorityDirections = false) {\n    // Get min and max chunk coordinates for T/Z/Y/X\n    const extrema = [[Infinity, -Infinity], [Infinity, -Infinity], [Infinity, -Infinity], [Infinity, -Infinity]];\n    for (const chunk of chunks) {\n      updateMinMax(chunk[0], extrema[0]);\n      updateMinMax(chunk[2], extrema[1]);\n      updateMinMax(chunk[3], extrema[2]);\n      updateMinMax(chunk[4], extrema[3]);\n    }\n\n    // Bail out if we have any non-finite values in the extrema (the iterator will be empty)\n    if (extrema.flat().some(val => !Number.isFinite(val))) {\n      this.directionStates = [];\n      this.priorityDirectionStates = [];\n      return;\n    }\n\n    // Create `PrefetchDirectionState`s for each direction\n    this.directionStates = [];\n    this.priorityDirectionStates = [];\n\n    // iterating like this: direction is the index in the flattened entries\n    // and corresponds to our +T, -T, +Z, -Z, +Y, -Y, +X, -X directions in order\n    // because extrema is in TZYX order.\n    for (const [direction, start] of extrema.flat().entries()) {\n      const dimension = direction >> 1; // shave off sign bit to get index in TZYX\n      const tczyxIndex = dimension + Number(dimension !== 0); // convert TZYX -> TCZYX by skipping c (index 1)\n      let end;\n      if (direction & 1) {\n        // Positive direction - end is either the max coordinate in the fetched set plus the max offset in this\n        // dimension, or the max chunk coordinate in this dimension, whichever comes first\n        const endsPerSource = tczyxChunksPerSource.map(chunkDims => {\n          return Math.min(start + tzyxMaxPrefetchOffset[dimension], chunkDims[tczyxIndex] - 1);\n        });\n\n        // Save some time: if all sources have the same end, we can just store that\n        if (allEqual(endsPerSource)) {\n          end = endsPerSource[0];\n        } else {\n          // Otherwise, expand our ends per source array to ends per channel\n          end = [];\n          for (const [i, sourceEnd] of endsPerSource.entries()) {\n            pushN(end, sourceEnd, tczyxChunksPerSource[i][1]);\n          }\n        }\n        // end = Math.min(start + tzyxMaxPrefetchOffset[dimension], tczyxChunksPerDimension[dimension] - 1);\n      } else {\n        // Negative direction - end is either the min coordinate in the fetched set minus the max offset in this\n        // dimension, or 0, whichever comes first\n        end = Math.max(start - tzyxMaxPrefetchOffset[dimension], 0);\n      }\n      const directionState = {\n        direction,\n        start,\n        end,\n        chunks: []\n      };\n      if (priorityDirections && priorityDirections.includes(direction)) {\n        this.priorityDirectionStates.push(directionState);\n      } else {\n        // we have an option setting that can let us ignore non-priority directions\n        if (!onlyPriorityDirections) {\n          this.directionStates.push(directionState);\n        }\n      }\n    }\n\n    // Fill each `PrefetchDirectionState` with chunks at the border of the fetched set\n    for (const chunk of chunks) {\n      for (const dir of this.directionStates) {\n        if (chunk[directionToIndex(dir.direction)] === dir.start) {\n          dir.chunks.push(chunk);\n        }\n      }\n      for (const dir of this.priorityDirectionStates) {\n        if (chunk[directionToIndex(dir.direction)] === dir.start) {\n          dir.chunks.push(chunk);\n        }\n      }\n    }\n  }\n  static *iterateDirections(directions) {\n    let offset = 1;\n    while (directions.length > 0) {\n      // Remove directions in which we have reached the end (or, if per-channel ends, the end for all channels)\n      directions = directions.filter(dir => {\n        const end = Array.isArray(dir.end) ? Math.max(...dir.end) : dir.end;\n        if (dir.direction & 1) {\n          return dir.start + offset <= end;\n        } else {\n          return dir.start - offset >= end;\n        }\n      });\n\n      // Yield chunks one chunk farther out in every remaining direction\n      for (const dir of directions) {\n        const offsetDir = offset * (dir.direction & 1 ? 1 : -1);\n        for (const chunk of dir.chunks) {\n          // Skip this chunk if this channel has a specific per-channel end and we've reached it\n          if (Array.isArray(dir.end) && chunk[directionToIndex(dir.direction)] + offsetDir > dir.end[chunk[1]]) {\n            continue;\n          }\n          const newChunk = chunk.slice();\n          newChunk[directionToIndex(dir.direction)] += offsetDir;\n          yield newChunk;\n        }\n      }\n      offset += 1;\n    }\n  }\n  *[Symbol.iterator]() {\n    // Yield all chunks in priority direction(s) first, if any\n    if (this.priorityDirectionStates.length > 0) {\n      for (const chunk of ChunkPrefetchIterator.iterateDirections(this.priorityDirectionStates)) {\n        yield chunk;\n      }\n    }\n\n    // Then yield all chunks in other directions\n    for (const chunk of ChunkPrefetchIterator.iterateDirections(this.directionStates)) {\n      yield chunk;\n    }\n  }\n}","import { VolumeLoadErrorType, VolumeLoadError } from \"../VolumeLoadError.js\";\n/** Extracts channel names from a `ZarrSource`. Handles missing `omeroMetadata`. Does *not* resolve name collisions. */\nexport function getSourceChannelNames(src) {\n  if (src.omeroMetadata?.channels) {\n    return src.omeroMetadata.channels.map(({\n      label\n    }, idx) => label ?? `Channel ${idx + src.channelOffset}`);\n  }\n  const cIdx = src.axesTCZYX[1];\n  const length = cIdx < 0 ? 1 : src.scaleLevels[0].shape[cIdx];\n  return Array.from({\n    length\n  }, (_, idx) => `Channel ${idx + src.channelOffset}`);\n}\n\n/** Turns `axesTCZYX` into the number of dimensions in the array */\nexport const getDimensionCount = ([t, c, z]) => 2 + Number(t > -1) + Number(c > -1) + Number(z > -1);\nexport function remapAxesToTCZYX(axes) {\n  const axesTCZYX = [-1, -1, -1, -1, -1];\n  const axisNames = [\"t\", \"c\", \"z\", \"y\", \"x\"];\n  axes.forEach((axis, idx) => {\n    const axisIdx = axisNames.indexOf(axis.name);\n    if (axisIdx > -1) {\n      axesTCZYX[axisIdx] = idx;\n    } else {\n      throw new VolumeLoadError(`Unrecognized axis in zarr: ${axis.name}`, {\n        type: VolumeLoadErrorType.INVALID_METADATA\n      });\n    }\n  });\n\n  // it is possible that Z might not exist but we require X and Y at least.\n  const noXAxis = axesTCZYX[4] === -1;\n  if (noXAxis || axesTCZYX[3] === -1) {\n    throw new VolumeLoadError(`Did not find ${noXAxis ? \"an X\" : \"a Y\"} axis in zarr`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n  return axesTCZYX;\n}\n\n/** Reorder an array of values [T, C, Z, Y, X] to the given dimension order */\nexport function orderByDimension(valsTCZYX, orderTCZYX) {\n  const specLen = getDimensionCount(orderTCZYX);\n  const result = Array(specLen);\n  orderTCZYX.forEach((val, idx) => {\n    if (val >= 0) {\n      if (val >= specLen) {\n        throw new VolumeLoadError(`Unexpected axis index in zarr: ${val}`, {\n          type: VolumeLoadErrorType.INVALID_METADATA\n        });\n      }\n      result[val] = valsTCZYX[idx];\n    }\n  });\n  return result;\n}\n\n/** Reorder an array of values in the given dimension order to [T, C, Z, Y, X] */\nexport function orderByTCZYX(valsDimension, orderTCZYX, defaultValue) {\n  const result = [defaultValue, defaultValue, defaultValue, defaultValue, defaultValue];\n  orderTCZYX.forEach((val, idx) => {\n    if (val >= 0) {\n      if (val >= valsDimension.length) {\n        throw new VolumeLoadError(`Unexpected axis index in zarr: ${val}`, {\n          type: VolumeLoadErrorType.INVALID_METADATA\n        });\n      }\n      result[idx] = valsDimension[val];\n    }\n  });\n  return result;\n}\n\n/** Select the scale transform from an OME metadata object with coordinate transforms, and return it in TCZYX order */\nexport function getScale(dataset, orderTCZYX) {\n  const transforms = dataset.coordinateTransformations;\n  if (transforms === undefined) {\n    console.warn(\"WARNING: OMEZarrLoader: no coordinate transformations for scale level.\");\n    return [1, 1, 1, 1, 1];\n  }\n\n  // this assumes we'll never encounter the \"path\" variant\n  const isScaleTransform = t => t.type === \"scale\";\n\n  // there can be any number of coordinateTransformations\n  // but there must be only one of type \"scale\".\n  const scaleTransform = transforms.find(isScaleTransform);\n  if (!scaleTransform) {\n    console.warn(`WARNING: OMEZarrLoader: no coordinate transformation of type \"scale\" for scale level.`);\n    return [1, 1, 1, 1, 1];\n  }\n  const scale = scaleTransform.scale.slice();\n  return orderByTCZYX(scale, orderTCZYX, 1);\n}\n\n/**\n * Defines a partial order of zarr arrays based on their size. Specifically:\n * - If array size x, y, z are all equal, the arrays are equal\n * - otherwise, if all xyz of `a` are less than or equal to those of `b`, `a` is less than `b` (and vice versa)\n * - if some xyz is less and some is greater, the arrays are uncomparable\n */\nfunction compareZarrArraySize(aArr, aTCZYX, bArr, bTCZYX) {\n  const aZ = aTCZYX[2] > -1 ? aArr.shape[aTCZYX[2]] : 1;\n  const bZ = bTCZYX[2] > -1 ? bArr.shape[bTCZYX[2]] : 1;\n  const diffZ = aZ - bZ;\n  const diffY = aArr.shape[aTCZYX[3]] - bArr.shape[bTCZYX[3]];\n  const diffX = aArr.shape[aTCZYX[4]] - bArr.shape[bTCZYX[4]];\n  if (diffZ === 0 && diffY === 0 && diffX === 0) {\n    return 0;\n  } else if (diffZ <= 0 && diffY <= 0 && diffX <= 0) {\n    return -1;\n  } else if (diffZ >= 0 && diffY >= 0 && diffX >= 0) {\n    return 1;\n  } else {\n    return undefined;\n  }\n}\nconst EPSILON = 0.00001;\nconst aboutEquals = (a, b) => Math.abs(a - b) < EPSILON;\nfunction scaleTransformsAreEqual(aSrc, aLevel, bSrc, bLevel) {\n  const aScale = getScale(aSrc.multiscaleMetadata.datasets[aLevel], aSrc.axesTCZYX);\n  const bScale = getScale(bSrc.multiscaleMetadata.datasets[bLevel], bSrc.axesTCZYX);\n  return aboutEquals(aScale[2], bScale[2]) && aboutEquals(aScale[3], bScale[3]) && aboutEquals(aScale[4], bScale[4]);\n}\n\n/**\n * Ensures that all scale levels in `sources` are matched up by size. More precisely: enforces that, for any scale\n * level `i`, the size of zarr array `s[i]` is equal for every source `s`. We accomplish this by removing any arrays\n * (and their associated OME dataset metadata) which don't match up in all sources.\n *\n * Note that this function modifies the input `sources` array rather than returning a new value.\n *\n * Assumes all sources have scale levels ordered by size from largest to smallest. (This should always be true for\n * compliant OME-Zarr data.)\n */\nexport function matchSourceScaleLevels(sources) {\n  if (sources.length < 2) {\n    return;\n  }\n\n  // Save matching scale levels and metadata here\n  const matchedLevels = Array.from({\n    length: sources.length\n  }, () => []);\n  const matchedMetas = Array.from({\n    length: sources.length\n  }, () => []);\n\n  // Start as many index counters as we have sources\n  const scaleIndexes = new Array(sources.length).fill(0);\n  while (scaleIndexes.every((val, idx) => val < sources[idx].scaleLevels.length)) {\n    // First pass: find the smallest source / determine if all sources are equal\n    let allEqual = true;\n    let smallestIdx = 0;\n    let smallestSrc = sources[0];\n    let smallestArr = smallestSrc.scaleLevels[scaleIndexes[0]];\n    for (let currentIdx = 1; currentIdx < sources.length; currentIdx++) {\n      const currentSrc = sources[currentIdx];\n      const currentArr = currentSrc.scaleLevels[scaleIndexes[currentIdx]];\n      const ordering = compareZarrArraySize(smallestArr, smallestSrc.axesTCZYX, currentArr, currentSrc.axesTCZYX);\n      if (!ordering) {\n        // Arrays are equal, or they are uncomparable\n        if (ordering === undefined) {\n          throw new VolumeLoadError(\"Incompatible zarr arrays: pixel dimensions are mismatched\", {\n            type: VolumeLoadErrorType.INVALID_MULTI_SOURCE_ZARR\n          });\n        }\n\n        // Now we know the arrays are equal, but they may still be invalid to match up because...\n        // ...they have different scale transformations\n        if (!scaleTransformsAreEqual(smallestSrc, scaleIndexes[smallestIdx], currentSrc, scaleIndexes[currentIdx])) {\n          // today we are going to treat this as a warning.\n          // For our implementation it is enough that the xyz pixel ranges are the same.\n          // Ideally scale*arraysize=physical size is really the quantity that should be equal, for combining two volume data sets as channels.\n          console.warn(\"Incompatible zarr arrays: scale levels of equal size have different scale transformations\");\n        }\n\n        // ...they have different numbers of timesteps\n        const largestT = smallestSrc.axesTCZYX[0] > -1 ? smallestArr.shape[smallestSrc.axesTCZYX[0]] : 1;\n        const currentT = currentSrc.axesTCZYX[0] > -1 ? currentArr.shape[currentSrc.axesTCZYX[0]] : 1;\n        if (largestT !== currentT) {\n          // we also treat this as a warning.\n          // In OmeZarrLoader we will take the minimum T size of all sources\n          console.warn(`Incompatible zarr arrays: different numbers of timesteps: ${largestT} vs ${currentT}`);\n        }\n      } else {\n        allEqual = false;\n        if (ordering > 0) {\n          smallestIdx = currentIdx;\n          smallestSrc = currentSrc;\n          smallestArr = currentArr;\n        }\n      }\n    }\n    if (allEqual) {\n      // We've found a matching set of scale levels! Save it and increment all indexes\n      for (let i = 0; i < scaleIndexes.length; i++) {\n        const currentSrc = sources[i];\n        const matchedScaleLevel = scaleIndexes[i];\n        matchedLevels[i].push(currentSrc.scaleLevels[matchedScaleLevel]);\n        matchedMetas[i].push(currentSrc.multiscaleMetadata.datasets[matchedScaleLevel]);\n        scaleIndexes[i] += 1;\n      }\n    } else {\n      // Increment the indexes of the sources which are larger than the smallest\n      for (const [idx, srcIdx] of scaleIndexes.entries()) {\n        const currentSrc = sources[idx];\n        const currentArr = currentSrc.scaleLevels[srcIdx];\n        const ordering = compareZarrArraySize(smallestArr, smallestSrc.axesTCZYX, currentArr, currentSrc.axesTCZYX);\n        if (ordering !== 0) {\n          scaleIndexes[idx] += 1;\n        }\n      }\n    }\n  }\n  if (sources[0].scaleLevels.length === 0) {\n    throw new VolumeLoadError(\"Incompatible zarr arrays: no sets of scale levels found that matched in all sources\", {\n      type: VolumeLoadErrorType.INVALID_MULTI_SOURCE_ZARR\n    });\n  }\n  for (let i = 0; i < sources.length; i++) {\n    sources[i].scaleLevels = matchedLevels[i];\n    sources[i].multiscaleMetadata.datasets = matchedMetas[i];\n  }\n}","import { VolumeLoadError, VolumeLoadErrorType } from \"../VolumeLoadError.js\";\n/**\n * If `meta` is the top-level metadata of a zarr node formatted according to the OME-Zarr spec version 0.5, returns\n * the object formatted according to v0.4 of the spec. For our purposes this just means flattening out the `ome` key.\n *\n * Return type is `unknown` because this does no actual validation; use `validateOMEZarrMetadata` for that.\n */\nexport const toOMEZarrMetaV4 = meta => meta.ome ?? meta;\nfunction isObjectWithProp(obj, prop) {\n  return typeof obj === \"object\" && obj !== null && prop in obj;\n}\nfunction assertMetadataHasProp(obj, prop, name = \"zarr\") {\n  if (!isObjectWithProp(obj, prop)) {\n    throw new VolumeLoadError(`${name} metadata is missing required entry \"${prop}\"`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n}\nfunction assertPropIsArray(obj, prop, name = \"zarr\") {\n  if (!Array.isArray(obj[prop])) {\n    throw new VolumeLoadError(`${name} metadata entry \"${prop}\" is not an array`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n}\n\n/** Intermediate stage of validation, before we've picked a single multiscale to validate */\n\nexport function assertMetadataHasMultiscales(meta, name = \"zarr\") {\n  // data is an object with a key \"multiscales\", which is a non-empty array\n  assertMetadataHasProp(meta, \"multiscales\", name);\n  assertPropIsArray(meta, \"multiscales\", name);\n}\n\n/**\n * Validates that the `OMEZarrMetadata` record `meta` has the minimal amount of data required to open a volume. Since\n * we only ever open one multiscale, we only validate the multiscale metadata record at index `multiscaleIdx` here.\n * `name` is used in error messages to identify the source of the metadata.\n */\nexport function validateOMEZarrMetadata(meta, multiscaleIdx = 0, name = \"zarr\") {\n  // check that a multiscale metadata entry exists at `multiscaleIdx`\n  const multiscaleMeta = meta.multiscales[multiscaleIdx];\n  if (!multiscaleMeta) {\n    throw new VolumeLoadError(`${name} metadata does not have requested multiscale level ${multiscaleIdx}`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n  const multiscaleMetaName = isObjectWithProp(multiscaleMeta, \"name\") ? ` (\"${multiscaleMeta.name})` : \"\";\n  const multiscaleName = `${name} multiscale ${multiscaleIdx}${multiscaleMetaName}`;\n\n  // multiscale has a key \"axes\", which is an array. Each axis has a \"name\".\n  assertMetadataHasProp(multiscaleMeta, \"axes\", multiscaleName);\n  assertPropIsArray(multiscaleMeta, \"axes\", multiscaleName);\n  multiscaleMeta.axes.forEach((axis, i) => assertMetadataHasProp(axis, \"name\", `${multiscaleName} axis ${i}`));\n\n  // multiscale has a key \"datasets\", which is an array. Each dataset has a \"path\".\n  assertMetadataHasProp(multiscaleMeta, \"datasets\", name);\n  assertPropIsArray(multiscaleMeta, \"datasets\", name);\n  multiscaleMeta.datasets.forEach((data, i) => assertMetadataHasProp(data, \"path\", `${multiscaleName} dataset ${i}`));\n}","export function strip_prefix(path) {\n    // @ts-expect-error - TS can't infer this type correctly\n    return path.slice(1);\n}\nexport function uri2href(url) {\n    let [protocol, rest] = (typeof url === \"string\" ? url : url.href).split(\"://\");\n    if (protocol === \"https\" || protocol === \"http\") {\n        return url;\n    }\n    if (protocol === \"gc\") {\n        return `https://storage.googleapis.com/${rest}`;\n    }\n    if (protocol === \"s3\") {\n        return `https://s3.amazonaws.com/${rest}`;\n    }\n    throw Error(`Protocol not supported, got: ${JSON.stringify(protocol)}`);\n}\nexport function fetch_range(url, offset, length, opts = {}) {\n    if (offset !== undefined && length !== undefined) {\n        // merge request opts\n        opts = {\n            ...opts,\n            headers: {\n                ...opts.headers,\n                Range: `bytes=${offset}-${offset + length - 1}`,\n            },\n        };\n    }\n    return fetch(url, opts);\n}\nexport function merge_init(storeOverrides, requestOverrides) {\n    // Request overrides take precedence over storeOverrides.\n    return {\n        ...storeOverrides,\n        ...requestOverrides,\n        headers: {\n            ...storeOverrides.headers,\n            ...requestOverrides.headers,\n        },\n    };\n}\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(expression, msg = \"\") {\n    if (!expression)\n        throw new Error(msg);\n}\n//# sourceMappingURL=util.js.map","import { fetch_range, merge_init } from \"./util.js\";\nfunction resolve(root, path) {\n    const base = typeof root === \"string\" ? new URL(root) : root;\n    if (!base.pathname.endsWith(\"/\")) {\n        // ensure trailing slash so that base is resolved as _directory_\n        base.pathname += \"/\";\n    }\n    const resolved = new URL(path.slice(1), base);\n    // copy search params to new URL\n    resolved.search = base.search;\n    return resolved;\n}\nasync function handle_response(response) {\n    if (response.status === 404) {\n        return undefined;\n    }\n    if (response.status === 200 || response.status === 206) {\n        return new Uint8Array(await response.arrayBuffer());\n    }\n    throw new Error(`Unexpected response status ${response.status} ${response.statusText}`);\n}\nasync function fetch_suffix(url, suffix_length, init, use_suffix_request) {\n    if (use_suffix_request) {\n        return fetch(url, {\n            ...init,\n            headers: { ...init.headers, Range: `bytes=-${suffix_length}` },\n        });\n    }\n    let response = await fetch(url, { ...init, method: \"HEAD\" });\n    if (!response.ok) {\n        // will be picked up by handle_response\n        return response;\n    }\n    let content_length = response.headers.get(\"Content-Length\");\n    let length = Number(content_length);\n    return fetch_range(url, length - suffix_length, length, init);\n}\n/**\n * Readonly store based in the [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n * Must polyfill `fetch` for use in Node.js.\n *\n * ```typescript\n * import * as zarr from \"zarrita\";\n * const store = new FetchStore(\"http://localhost:8080/data.zarr\");\n * const arr = await zarr.get(store, { kind: \"array\" });\n * ```\n */\nclass FetchStore {\n    url;\n    #overrides;\n    #use_suffix_request;\n    constructor(url, options = {}) {\n        this.url = url;\n        this.#overrides = options.overrides ?? {};\n        this.#use_suffix_request = options.useSuffixRequest ?? false;\n    }\n    #merge_init(overrides) {\n        return merge_init(this.#overrides, overrides);\n    }\n    async get(key, options = {}) {\n        let href = resolve(this.url, key).href;\n        let response = await fetch(href, this.#merge_init(options));\n        return handle_response(response);\n    }\n    async getRange(key, range, options = {}) {\n        let url = resolve(this.url, key);\n        let init = this.#merge_init(options);\n        let response;\n        if (\"suffixLength\" in range) {\n            response = await fetch_suffix(url, range.suffixLength, init, this.#use_suffix_request);\n        }\n        else {\n            response = await fetch_range(url, range.offset, range.length, init);\n        }\n        return handle_response(response);\n    }\n}\nexport default FetchStore;\n//# sourceMappingURL=fetch.js.map","import { FetchStore } from \"zarrita\";\nimport { isChunk } from \"../../VolumeCache.js\";\nexport default function wrapArray(array, basePath, cache, queue) {\n  const path = basePath.endsWith(\"/\") ? basePath.slice(0, -1) : basePath;\n  const keyBase = path + array.path + (array.path.endsWith(\"/\") ? \"\" : \"/\");\n  const getChunk = async (coords, opts) => {\n    if (opts?.subscriber && opts.reportChunk) {\n      opts.reportChunk(coords, opts.subscriber);\n    }\n    const fullKey = keyBase + coords.join(\",\");\n    const cacheResult = cache?.get(fullKey);\n    if (cacheResult && isChunk(cacheResult)) {\n      return cacheResult;\n    }\n    let result;\n    if (queue && opts?.subscriber) {\n      result = await queue.addRequest(fullKey, opts?.subscriber, () => array.getChunk(coords, opts), opts.isPrefetch);\n    } else {\n      result = await array.getChunk(coords, opts);\n    }\n    cache?.insert(fullKey, result);\n    return result;\n  };\n  return new Proxy(array, {\n    get: (target, prop) => {\n      if (prop === \"getChunk\") {\n        return getChunk;\n      }\n\n      // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy#no_private_property_forwarding\n      const value = target[prop];\n      if (value instanceof Function) {\n        return function (...args) {\n          return value.apply(target, args);\n        };\n      }\n      return value;\n    }\n  });\n}\nexport class RelaxedFetchStore extends FetchStore {\n  constructor(baseUrl, options) {\n    super(baseUrl, options);\n  }\n\n  // Solution for https://github.com/manzt/zarrita.js/pull/212\n  // taken from https://github.com/vitessce/vitessce/pull/2069\n  async get(key, options = {}) {\n    try {\n      return await super.get(key, options);\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    } catch (e) {\n      if (e?.message?.startsWith(\"Unexpected response status 403\")) {\n        return undefined;\n      }\n      throw e;\n    }\n  }\n}","/** Object format used when passing multiple requests to RequestQueue at once. */\n\nexport const DEFAULT_REQUEST_CANCEL_REASON = \"request cancelled\";\n\n/**\n * Internal object interface used by RequestQueue to store request metadata and callbacks.\n */\n\n/**\n * Manages a queue of asynchronous requests with unique string keys, which can be added to or cancelled.\n * If redundant requests with the same key are issued, the request action will only be run once per key\n * while the original request is still in the queue.\n */\nexport default class RequestQueue {\n  /**\n   * The maximum number of requests that can be handled concurrently.\n   * Once reached, additional requests will be queued up to run once a running request completes.\n   */\n\n  /**\n   * The maximum number of requests that can be handled concurrently if only low-priority requests are waiting. Set\n   * lower than `concurrencyLimit` to always leave space for high-priority requests. Cannot be set higher than\n   * `concurrencyLimit`.\n   */\n\n  /** A queue of requests that are ready to be executed, in order of request time. */\n\n  /** A queue of low-priority tasks that are ready to be executed. `queue` must be empty before any of these tasks run. */\n\n  /** Stores all requests, even those that are currently active. */\n\n  /** Stores requests whose actions are currently being run. */\n\n  /**\n   * Creates a new RequestQueue.\n   * @param maxActiveRequests The maximum number of requests that will be handled concurrently. This is 10 by default.\n   * @param maxLowPriorityRequests The maximum number of low-priority requests that will be handled concurrently. Equal\n   *    to `maxActiveRequests` by default, but may be set lower to always leave space for new high-priority requests.\n   */\n  constructor(maxActiveRequests = 10, maxLowPriorityRequests = 5) {\n    this.allRequests = new Map();\n    this.activeRequests = new Set();\n    this.queue = [];\n    this.queueLowPriority = [];\n    this.maxActiveRequests = maxActiveRequests;\n    this.maxLowPriorityRequests = Math.min(maxActiveRequests, maxLowPriorityRequests);\n  }\n\n  /**\n   * Stores request metadata to the internal map of all pending requests.\n   * @param key string identifier of the request.\n   * @param requestAction callable function action of the request.\n   * @returns a reference to the new, registered RequestItem.\n   */\n  registerRequest(key, requestAction) {\n    // Create a new promise and store the resolve and reject callbacks for later.\n    // This lets us perform the actual action at a later point, when the request is at the\n    // front of the processing queue.\n    let promiseResolve, promiseReject;\n    const promise = new Promise((resolve, reject) => {\n      promiseResolve = resolve;\n      promiseReject = reject;\n    });\n    // Store the request data.\n    const requestItem = {\n      key: key,\n      action: requestAction,\n      resolve: promiseResolve,\n      reject: promiseReject,\n      promise\n    };\n    this.allRequests.set(key, requestItem);\n    return requestItem;\n  }\n\n  /**\n   * Moves a registered request into the processing queue, clearing any timeouts on the request.\n   * @param key string identifier of the request.\n   * @param lowPriority Whether this request should be added with low priority. False by default.\n   */\n  addRequestToQueue(key, lowPriority) {\n    // Check that this request is not cancelled.\n    if (this.allRequests.has(key)) {\n      // Clear the request timeout, if it has one, since it is being added to the queue.\n      const requestItem = this.allRequests.get(key);\n      if (requestItem && requestItem.timeoutId) {\n        clearTimeout(requestItem.timeoutId);\n        requestItem.timeoutId = undefined;\n      }\n      if (!this.queue.includes(key) && !this.queueLowPriority.includes(key)) {\n        // Add to queue and check if the request can be processed right away.\n        if (lowPriority) {\n          this.queueLowPriority.push(key);\n        } else {\n          this.queue.push(key);\n        }\n        this.dequeue();\n      }\n    }\n  }\n\n  /**\n   * Adds a request with a unique key to the queue, if it doesn't already exist.\n   * @param key The key used to track the request.\n   * @param requestAction Function that will be called to complete the request. The function\n   *  will be run only once per unique key while the request exists, and may be deferred by the\n   *  queue at any time.\n   * @param lowPriority Whether this request should be added with low priority. False by default.\n   * @param delayMs Minimum delay, in milliseconds, before this request should be executed.\n   *\n   * NOTE: Cancelling a request while the action is running WILL NOT stop the action. If this behavior is desired,\n   * actions must be responsible for checking the RequestQueue, determining if the request is still valid (e.g.\n   * using `.hasRequest()`), and stopping or returning early.\n   *\n   * @returns A promise that will resolve on completion of the request, or reject if the request is cancelled.\n   *  If multiple requests are issued with the same key, a promise for the first request will be returned\n   *  until the request is resolved or cancelled.\n   *  Note that the return type of the promise will match that of the first request's instance.\n   */\n  addRequest(key, requestAction, lowPriority = false, delayMs = 0) {\n    if (!this.allRequests.has(key)) {\n      // New request!\n      const requestItem = this.registerRequest(key, requestAction);\n      // If a delay is set, wait to add this to the queue.\n      if (delayMs > 0) {\n        const timeoutId = setTimeout(() => this.addRequestToQueue(key, lowPriority), delayMs);\n        // Save timeout information to request metadata\n        requestItem.timeoutId = timeoutId;\n      } else {\n        // No delay, add immediately\n        this.addRequestToQueue(key, lowPriority);\n      }\n    } else {\n      const lowPriorityIndex = this.queueLowPriority.indexOf(key);\n      if (lowPriorityIndex > -1 && !lowPriority) {\n        // This request is registered and queued, but is now being requested with high priority.\n        // Promote it to high priority.\n        this.queueLowPriority.splice(lowPriorityIndex, 1);\n        this.addRequestToQueue(key);\n      } else if (delayMs <= 0) {\n        // This request is registered, but is now being requested without a delay.\n        // Move into queue immediately if it's not already added, and clear any timeouts it may have.\n        this.addRequestToQueue(key, lowPriority);\n      }\n    }\n    const promise = this.allRequests.get(key)?.promise;\n    if (!promise) {\n      throw new Error(\"Found no promise to return when getting stored request data.\");\n    }\n    return promise;\n  }\n\n  /**\n   * Adds multiple requests to the queue, with an optional delay between each.\n   * @param requests An array of RequestItems, which include a key and a request action.\n   * @param lowPriority Whether these requests should be added with low priority. False by default.\n   * @param delayMs An optional minimum delay in milliseconds to be added between each request.\n   *  For example, a delay of 10 ms will cause the second request to be added to the processing queue\n   *  after 10 ms, the third to added after 20 ms, and so on. Set to 10 ms by default.\n   * @returns An array of promises corresponding to the provided requests. (i.e., the `i`th value\n   * of the returned array will be a Promise for the resolution of `requests[i]`). If a request\n   *  with a matching key is already pending, returns the promise for the initial request.\n   */\n  addRequests(requests, lowPriority = false, delayMs = 10) {\n    const promises = [];\n    for (let i = 0; i < requests.length; i++) {\n      const item = requests[i];\n      const promise = this.addRequest(item.key, item.requestAction, lowPriority, delayMs * i);\n      promises.push(promise);\n    }\n    return promises;\n  }\n\n  /**\n   * Attempts to remove and run the next queued request item, if resources are available.\n   * @returns true if a request was started, or false if there are too many\n   * requests already active.\n   */\n  async dequeue() {\n    const numRequests = this.activeRequests.size;\n    if (numRequests >= this.maxActiveRequests || this.queue.length === 0 && (numRequests >= this.maxLowPriorityRequests || this.queueLowPriority.length === 0)) {\n      return;\n    }\n    const requestKey = this.queue.shift() ?? this.queueLowPriority.shift();\n    if (!requestKey) {\n      return;\n    }\n    if (this.activeRequests.has(requestKey)) {\n      // This request is already active, try the next one instead. (this shouldn't happen)\n      this.dequeue();\n      return;\n    }\n    const requestItem = this.allRequests.get(requestKey);\n    if (!requestItem) {\n      return;\n    }\n    const key = requestItem.key;\n    // Mark that this request is active\n    this.activeRequests.add(key);\n    await requestItem.action().then(requestItem.resolve, requestItem.reject);\n    this.activeRequests.delete(key);\n    this.allRequests.delete(key);\n    this.dequeue();\n  }\n\n  /**\n   * Removes any request matching the provided key from the queue and rejects its promise.\n   * @param key The key that should be matched against.\n   * @param cancelReason A message or object that will be used as the promise rejection.\n   */\n  cancelRequest(key, cancelReason = DEFAULT_REQUEST_CANCEL_REASON) {\n    if (!this.allRequests.has(key)) {\n      return;\n    }\n    const requestItem = this.allRequests.get(key);\n    if (requestItem) {\n      if (requestItem.timeoutId) {\n        // Cancel requests that have not been queued yet.\n        clearTimeout(requestItem.timeoutId);\n      }\n      // Reject the request, then clear from the queue and known requests.\n      requestItem.reject(cancelReason);\n    }\n    const queueIndex = this.queue.indexOf(key);\n    if (queueIndex > -1) {\n      this.queue.splice(queueIndex, 1);\n    } else {\n      const lowPriorityIndex = this.queueLowPriority.indexOf(key);\n      if (lowPriorityIndex > -1) {\n        this.queueLowPriority.splice(lowPriorityIndex, 1);\n      }\n    }\n    this.allRequests.delete(key);\n    this.activeRequests.delete(key);\n  }\n\n  /**\n   * Rejects all request promises and clears the queue.\n   * @param cancelReason A message or object that will be used as the promise rejection.\n   */\n  cancelAllRequests(cancelReason = DEFAULT_REQUEST_CANCEL_REASON) {\n    // Clear the queue so we don't do extra work while filtering it\n    this.queue = [];\n    this.queueLowPriority = [];\n    for (const key of this.allRequests.keys()) {\n      this.cancelRequest(key, cancelReason);\n    }\n  }\n\n  /**\n   * Returns whether a request with the given key exists in the RequestQueue and is not cancelled.\n   * @param key the key to search for.\n   * @returns true if the request is in the RequestQueue.\n   */\n  hasRequest(key) {\n    return this.allRequests.has(key);\n  }\n\n  /**\n   * Returns whether the request with the given key is currently running (not waiting in the queue).\n   * @param key the key to search for.\n   * @returns true if the request is actively running.\n   */\n  requestRunning(key) {\n    return this.activeRequests.has(key);\n  }\n}","import RequestQueue from \"./RequestQueue.js\";\n\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n/**\n * An extension of `RequestQueue` that adds a concept of \"subscribers,\" which may share references to a single request\n * or cancel their subscription without disrupting the request for other subscribers.\n */\nexport default class SubscribableRequestQueue {\n  /** The next unused subscriber ID. Increments whenever a subscriber is added. */\n\n  /**\n   * Map of subscribers keyed by ID. Subscribers store a map to all their subscriptions by request key.\n   * Subscribers are only useful as handles to cancel subscriptions early, so we only need to store rejecters here.\n   */\n\n  /** Map from \"inner\" request (managed by `queue`) to \"outer\" promises generated per-subscriber. */\n\n  /**\n   * Since `SubscribableRequestQueue` wraps `RequestQueue`, its constructor may either take the same arguments as the\n   * `RequestQueue` constructor and create a new `RequestQueue`, or it may take an existing `RequestQueue` to wrap.\n   */\n\n  constructor(maxActiveRequests, maxLowPriorityRequests) {\n    if (typeof maxActiveRequests === \"number\" || maxActiveRequests === undefined) {\n      this.queue = new RequestQueue(maxActiveRequests, maxLowPriorityRequests);\n    } else {\n      this.queue = maxActiveRequests;\n    }\n    this.nextSubscriberId = 0;\n    this.subscribers = new Map();\n    this.requests = new Map();\n  }\n\n  /** Resolves all subscriptions to request `key` with `value` */\n  resolveAll(key, value) {\n    const requests = this.requests.get(key);\n    if (requests) {\n      for (const {\n        resolve,\n        subscriberId\n      } of requests) {\n        resolve(value);\n        this.subscribers.get(subscriberId)?.delete(key);\n      }\n      this.requests.delete(key);\n    }\n  }\n\n  /** Rejects all subscriptions to request `key` with `reason` */\n  rejectAll(key, reason) {\n    const requests = this.requests.get(key);\n    if (requests) {\n      for (const {\n        reject,\n        subscriberId\n      } of requests) {\n        reject(reason);\n        this.subscribers.get(subscriberId)?.delete(key);\n      }\n      this.requests.delete(key);\n    }\n  }\n\n  /** Adds a new request subscriber. Returns a unique ID to identify this subscriber. */\n  addSubscriber() {\n    const subscriberId = this.nextSubscriberId;\n    this.nextSubscriberId++;\n    this.subscribers.set(subscriberId, new Map());\n    return subscriberId;\n  }\n\n  /**\n   * Queues a new request, or adds a subscription if the request is already queued/running.\n   *\n   * If `subscriberId` is already subscribed to the request, this rejects the existing promise and returns a new one.\n   */\n  addRequest(key, subscriberId, requestAction, lowPriority, delayMs) {\n    // Create single underlying request if it does not yet exist\n    this.queue.addRequest(key, requestAction, lowPriority, delayMs).then(value => this.resolveAll(key, value)).catch(reason => this.rejectAll(key, reason));\n    if (!this.requests.has(key)) {\n      this.requests.set(key, []);\n    }\n\n    // Validate subscriber\n    if (subscriberId >= this.nextSubscriberId || subscriberId < 0) {\n      throw new Error(`SubscribableRequestQueue: subscriber id ${subscriberId} has not been registered`);\n    }\n    const subscriber = this.subscribers.get(subscriberId);\n    if (!subscriber) {\n      throw new Error(`SubscribableRequestQueue: subscriber id ${subscriberId} has been removed`);\n    }\n\n    // Create promise and add to list of requests\n    return new Promise((resolve, reject) => {\n      this.requests.get(key)?.push({\n        resolve,\n        reject,\n        subscriberId\n      });\n      const subscriber = this.subscribers.get(subscriberId);\n      const existingRequest = subscriber?.get(key);\n      if (existingRequest) {\n        existingRequest.push(reject);\n      } else {\n        subscriber?.set(key, [reject]);\n      }\n    });\n  }\n\n  /**\n   * Rejects a subscription and removes it from the list of subscriptions for a request, then cancels the underlying\n   * request if it is no longer subscribed and is not running already.\n   */\n  rejectSubscription(key, reject, cancelReason) {\n    // Reject the outer \"subscription\" promise\n    reject(cancelReason);\n\n    // Get the list of subscriptions for this request\n    const subscriptions = this.requests.get(key);\n    if (!subscriptions) {\n      // This should never happen\n      return;\n    }\n    // Remove this request subscription by ref equality to `reject`\n    const idx = subscriptions.findIndex(sub => sub.reject === reject);\n    if (idx >= 0) {\n      subscriptions.splice(idx, 1);\n    }\n\n    // Remove the underlying request if there are no more subscribers and the request is not already running\n    if (subscriptions.length < 1 && !this.queue.requestRunning(key)) {\n      this.queue.cancelRequest(key, cancelReason);\n      this.requests.delete(key);\n    }\n  }\n\n  /** Cancels a request subscription, and cancels the underlying request if it is no longer subscribed or running. */\n  cancelRequest(key, subscriberId, cancelReason) {\n    const subscriber = this.subscribers.get(subscriberId);\n    if (!subscriber) {\n      return false;\n    }\n    const rejecters = subscriber.get(key);\n    if (!rejecters || !rejecters.length) {\n      return false;\n    }\n    for (const reject of rejecters) {\n      this.rejectSubscription(key, reject, cancelReason);\n    }\n    subscriber.delete(key);\n    return true;\n  }\n\n  /** Removes a subscriber and cancels its remaining subscriptions. */\n  removeSubscriber(subscriberId, cancelReason) {\n    const subscriptions = this.subscribers.get(subscriberId);\n    if (subscriptions) {\n      for (const [key, rejecters] of subscriptions.entries()) {\n        for (const reject of rejecters) {\n          this.rejectSubscription(key, reject, cancelReason);\n        }\n      }\n      this.subscribers.delete(subscriberId);\n    }\n  }\n\n  /** Returns whether a request with the given `key` is running or waiting in the queue */\n  hasRequest(key) {\n    return this.queue.hasRequest(key);\n  }\n\n  /** Returns whether a request with the given `key` is running */\n  requestRunning(key) {\n    return this.queue.requestRunning(key);\n  }\n\n  /** Returns whether a subscriber with the given `subscriberId` exists */\n  hasSubscriber(subscriberId) {\n    return this.subscribers.has(subscriberId);\n  }\n\n  /** Returns whether a subscriber with the given `subscriberId` is subscribed to the request with the given `key` */\n  isSubscribed(subscriberId, key) {\n    return this.subscribers.get(subscriberId)?.has(key) ?? false;\n  }\n}","/** The types of requests that can be made to the worker. Mostly corresponds to methods on `IVolumeLoader`. */\nexport let WorkerMsgType = /*#__PURE__*/function (WorkerMsgType) {\n  WorkerMsgType[WorkerMsgType[\"INIT\"] = 0] = \"INIT\";\n  WorkerMsgType[WorkerMsgType[\"CREATE_LOADER\"] = 1] = \"CREATE_LOADER\";\n  WorkerMsgType[WorkerMsgType[\"CLOSE_LOADER\"] = 2] = \"CLOSE_LOADER\";\n  WorkerMsgType[WorkerMsgType[\"CREATE_VOLUME\"] = 3] = \"CREATE_VOLUME\";\n  WorkerMsgType[WorkerMsgType[\"LOAD_DIMS\"] = 4] = \"LOAD_DIMS\";\n  WorkerMsgType[WorkerMsgType[\"LOAD_VOLUME_DATA\"] = 5] = \"LOAD_VOLUME_DATA\";\n  WorkerMsgType[WorkerMsgType[\"SET_PREFETCH_PRIORITY_DIRECTIONS\"] = 6] = \"SET_PREFETCH_PRIORITY_DIRECTIONS\";\n  WorkerMsgType[WorkerMsgType[\"SYNCHRONIZE_MULTICHANNEL_LOADING\"] = 7] = \"SYNCHRONIZE_MULTICHANNEL_LOADING\";\n  WorkerMsgType[WorkerMsgType[\"UPDATE_FETCH_OPTIONS\"] = 8] = \"UPDATE_FETCH_OPTIONS\";\n  return WorkerMsgType;\n}({});\n\n/** The variants of `WorkerMessageType` which represent \"global\" actions that don't require a specific loader */\n\n/** The variants of `WorkerMessageType` which represent actions on a specific loader */\n\n/** The kind of response a worker can return - `SUCCESS`, `ERROR`, or `EVENT`. */\nexport let WorkerResponseResult = /*#__PURE__*/function (WorkerResponseResult) {\n  WorkerResponseResult[WorkerResponseResult[\"SUCCESS\"] = 0] = \"SUCCESS\";\n  WorkerResponseResult[WorkerResponseResult[\"ERROR\"] = 1] = \"ERROR\";\n  WorkerResponseResult[WorkerResponseResult[\"EVENT\"] = 2] = \"EVENT\";\n  return WorkerResponseResult;\n}({});\n\n/** The kind of events that can occur when loading */\nexport let WorkerEventType = /*#__PURE__*/function (WorkerEventType) {\n  /** Fired to update a `Volume`'s `imageInfo` and/or `loadSpec` based on loaded data (time, channels, region, etc.) */\n  WorkerEventType[WorkerEventType[\"METADATA_UPDATE\"] = 0] = \"METADATA_UPDATE\";\n  /** Fired when data for a channel (or batch of channels) is loaded */\n  WorkerEventType[WorkerEventType[\"CHANNEL_LOAD\"] = 1] = \"CHANNEL_LOAD\";\n  return WorkerEventType;\n}({});\n\n/**\n * All messages to/from a worker carry a `msgId`, a `type`, and a `payload` (whose type is determined by `type`).\n * Messages which operate on a specific loader also require a `loaderId`.\n */\n\n/** Maps each `WorkerMsgType` to the type of the payload of requests of that type. */\n\n/** Maps each `WorkerMsgType` to the type of the payload of responses of that type. */\n\n/** Event for when a batch of channel data loads. */\n\n/** Event for when metadata updates. */\n\n/** All valid types of worker requests, with some `WorkerMsgType` and a matching payload type. */\n\n/** All valid types of worker responses: `SUCCESS` with a matching payload, `ERROR` with a message, or an `EVENT`. */","import { Box3, Vector3 } from \"three\";\n/** Recreates a `LoadSpec` that has just been sent to/from a worker to restore three.js object prototypes */\nexport function rebuildLoadSpec(spec) {\n  return {\n    ...spec,\n    subregion: new Box3(new Vector3().copy(spec.subregion.min), new Vector3().copy(spec.subregion.max))\n  };\n}","import { assert } from \"../util.js\";\n/**\n * A codec for bit-rounding.\n *\n * Reduces floating-point precision by truncating mantissa bits during encoding.\n * Decoding is a no-op as the process is lossy and precision cannot be restored.\n *\n * Note: {@link BitroundCodec.encode} is not yet implemented since Zarrita is\n * primarily used in read-only contexts (web browser). If you need encoding support,\n * please open an issue at {@link https://github.com/manzt/zarrita.js/issues}.\n *\n * @see {@link https://github.com/zarr-developers/numcodecs/blob/main/numcodecs/bitround.py}\n * for the original Python implementation.\n *\n * @remarks\n * Data types are not validated, and `float16` arrays are not supported (reflecting browser support).\n */\nexport class BitroundCodec {\n    kind = \"array_to_array\";\n    constructor(configuration, _meta) {\n        assert(configuration.keepbits >= 0, \"keepbits must be zero or positive\");\n    }\n    static fromConfig(configuration, meta) {\n        return new BitroundCodec(configuration, meta);\n    }\n    /**\n     * Encode a chunk of data with bit-rounding.\n     * @param _arr - The chunk to encode\n     */\n    encode(_arr) {\n        throw new Error(\"`BitroundCodec.encode` is not implemented. Please open an issue at https://github.com/manzt/zarrita.js/issues.\");\n    }\n    /**\n     * Decode a chunk of data (no-op).\n     * @param arr - The chunk to decode\n     * @returns The decoded chunk\n     */\n    decode(arr) {\n        return arr; // No-op as bit-rounding is lossy\n    }\n}\n//# sourceMappingURL=bitround.js.map","import { byteswap_inplace, get_ctr, get_strides } from \"../util.js\";\nconst LITTLE_ENDIAN_OS = system_is_little_endian();\nfunction system_is_little_endian() {\n    const a = new Uint32Array([0x12345678]);\n    const b = new Uint8Array(a.buffer, a.byteOffset, a.byteLength);\n    return !(b[0] === 0x12);\n}\nfunction bytes_per_element(TypedArray) {\n    if (\"BYTES_PER_ELEMENT\" in TypedArray) {\n        return TypedArray.BYTES_PER_ELEMENT;\n    }\n    // Unicode string array is backed by a Int32Array.\n    return 4;\n}\nexport class BytesCodec {\n    kind = \"array_to_bytes\";\n    #stride;\n    #TypedArray;\n    #BYTES_PER_ELEMENT;\n    #shape;\n    #endian;\n    constructor(configuration, meta) {\n        this.#endian = configuration?.endian;\n        this.#TypedArray = get_ctr(meta.data_type);\n        this.#shape = meta.shape;\n        this.#stride = get_strides(meta.shape, \"C\");\n        // TODO: fix me.\n        // hack to get bytes per element since it's dynamic for string types.\n        const sample = new this.#TypedArray(0);\n        this.#BYTES_PER_ELEMENT = sample.BYTES_PER_ELEMENT;\n    }\n    static fromConfig(configuration, meta) {\n        return new BytesCodec(configuration, meta);\n    }\n    encode(arr) {\n        let bytes = new Uint8Array(arr.data.buffer);\n        if (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n            byteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n        }\n        return bytes;\n    }\n    decode(bytes) {\n        if (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n            byteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n        }\n        return {\n            data: new this.#TypedArray(bytes.buffer, bytes.byteOffset, bytes.byteLength / this.#BYTES_PER_ELEMENT),\n            shape: this.#shape,\n            stride: this.#stride,\n        };\n    }\n}\n//# sourceMappingURL=bytes.js.map","export class Crc32cCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig() {\n        return new Crc32cCodec();\n    }\n    encode(_) {\n        throw new Error(\"Not implemented\");\n    }\n    decode(arr) {\n        return new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength - 4);\n    }\n}\n//# sourceMappingURL=crc32c.js.map","import { decompress } from \"../util.js\";\nexport class GzipCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig(_) {\n        return new GzipCodec();\n    }\n    encode(_bytes) {\n        throw new Error(\"Gzip encoding is not enabled by default. Please register a custom codec with `numcodecs/gzip`.\");\n    }\n    async decode(bytes) {\n        const buffer = await decompress(bytes, { format: \"gzip\" });\n        return new Uint8Array(buffer);\n    }\n}\n//# sourceMappingURL=gzip.js.map","import { assert, get_strides, json_decode_object } from \"../util.js\";\n// Reference: https://stackoverflow.com/a/21897413\nfunction throw_on_nan_replacer(_key, value) {\n    assert(!Number.isNaN(value), \"JsonCodec allow_nan is false but NaN was encountered during encoding.\");\n    assert(value !== Number.POSITIVE_INFINITY, \"JsonCodec allow_nan is false but Infinity was encountered during encoding.\");\n    assert(value !== Number.NEGATIVE_INFINITY, \"JsonCodec allow_nan is false but -Infinity was encountered during encoding.\");\n    return value;\n}\n// Reference: https://gist.github.com/davidfurlong/463a83a33b70a3b6618e97ec9679e490\nfunction sort_keys_replacer(_key, value) {\n    return value instanceof Object && !Array.isArray(value)\n        ? Object.keys(value)\n            .sort()\n            .reduce((sorted, key) => {\n            sorted[key] = value[key];\n            return sorted;\n        }, {})\n        : value;\n}\nexport class JsonCodec {\n    configuration;\n    kind = \"array_to_bytes\";\n    #encoder_config;\n    #decoder_config;\n    constructor(configuration = {}) {\n        this.configuration = configuration;\n        // Reference: https://github.com/zarr-developers/numcodecs/blob/0878717a3613d91a453fe3d3716aa9c67c023a8b/numcodecs/json.py#L36\n        const { encoding = \"utf-8\", skipkeys = false, ensure_ascii = true, check_circular = true, allow_nan = true, sort_keys = true, indent, strict = true, } = configuration;\n        let separators = configuration.separators;\n        if (!separators) {\n            // ensure separators are explicitly specified, and consistent behaviour across\n            // Python versions, and most compact representation if indent is None\n            if (!indent) {\n                separators = [\",\", \":\"];\n            }\n            else {\n                separators = [\", \", \": \"];\n            }\n        }\n        this.#encoder_config = {\n            encoding,\n            skipkeys,\n            ensure_ascii,\n            check_circular,\n            allow_nan,\n            indent,\n            separators,\n            sort_keys,\n        };\n        this.#decoder_config = { strict };\n    }\n    static fromConfig(configuration) {\n        return new JsonCodec(configuration);\n    }\n    encode(buf) {\n        const { indent, encoding, ensure_ascii, check_circular, allow_nan, sort_keys, } = this.#encoder_config;\n        assert(encoding === \"utf-8\", \"JsonCodec does not yet support non-utf-8 encoding.\");\n        const replacer_functions = [];\n        // By default, for JSON.stringify,\n        // a TypeError will be thrown if one attempts to encode an object with circular references\n        assert(check_circular, \"JsonCodec does not yet support skipping the check for circular references during encoding.\");\n        if (!allow_nan) {\n            // Throw if NaN/Infinity/-Infinity are encountered during encoding.\n            replacer_functions.push(throw_on_nan_replacer);\n        }\n        if (sort_keys) {\n            // We can ensure keys are sorted but not really the opposite since\n            // there is no guarantee of key ordering in JS.\n            replacer_functions.push(sort_keys_replacer);\n        }\n        const items = Array.from(buf.data);\n        items.push(\"|O\");\n        items.push(buf.shape);\n        let replacer;\n        if (replacer_functions.length) {\n            replacer = (key, value) => {\n                let new_value = value;\n                for (let sub_replacer of replacer_functions) {\n                    new_value = sub_replacer(key, new_value);\n                }\n                return new_value;\n            };\n        }\n        let json_str = JSON.stringify(items, replacer, indent);\n        if (ensure_ascii) {\n            // If ensure_ascii is true (the default), the output is guaranteed\n            // to have all incoming non-ASCII characters escaped.\n            // If ensure_ascii is false, these characters will be output as-is.\n            // Reference: https://stackoverflow.com/a/31652607\n            json_str = json_str.replace(/[\\u007F-\\uFFFF]/g, (chr) => {\n                const full_str = `0000${chr.charCodeAt(0).toString(16)}`;\n                const sub_str = full_str.substring(full_str.length - 4);\n                return `\\\\u${sub_str}`;\n            });\n        }\n        return new TextEncoder().encode(json_str);\n    }\n    decode(bytes) {\n        const { strict } = this.#decoder_config;\n        // (i.e., allowing control characters inside strings)\n        assert(strict, \"JsonCodec does not yet support non-strict decoding.\");\n        const items = json_decode_object(bytes);\n        const shape = items.pop();\n        items.pop(); // Pop off dtype (unused)\n        // O-d case\n        assert(shape, \"0D not implemented for JsonCodec.\");\n        const stride = get_strides(shape, \"C\");\n        const data = items;\n        return { data, shape, stride };\n    }\n}\n//# sourceMappingURL=json2.js.map","import { BoolArray, ByteStringArray, UnicodeStringArray, } from \"../typedarray.js\";\nimport { assert, get_strides } from \"../util.js\";\nfunction proxy(arr) {\n    if (arr instanceof BoolArray ||\n        arr instanceof ByteStringArray ||\n        arr instanceof UnicodeStringArray) {\n        // @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n        const arrp = new Proxy(arr, {\n            get(target, prop) {\n                return target.get(Number(prop));\n            },\n            set(target, prop, value) {\n                // @ts-expect-error - value is OK\n                target.set(Number(prop), value);\n                return true;\n            },\n        });\n        return arrp;\n    }\n    // @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n    return arr;\n}\nfunction empty_like(chunk, order) {\n    let data;\n    if (chunk.data instanceof ByteStringArray ||\n        chunk.data instanceof UnicodeStringArray) {\n        data = new chunk.constructor(\n        // @ts-expect-error\n        chunk.data.length, chunk.data.chars);\n    }\n    else {\n        data = new chunk.constructor(chunk.data.length);\n    }\n    return {\n        data,\n        shape: chunk.shape,\n        stride: get_strides(chunk.shape, order),\n    };\n}\nfunction convert_array_order(src, target) {\n    let out = empty_like(src, target);\n    let n_dims = src.shape.length;\n    let size = src.data.length;\n    let index = Array(n_dims).fill(0);\n    let src_data = proxy(src.data);\n    let out_data = proxy(out.data);\n    for (let src_idx = 0; src_idx < size; src_idx++) {\n        let out_idx = 0;\n        for (let dim = 0; dim < n_dims; dim++) {\n            out_idx += index[dim] * out.stride[dim];\n        }\n        out_data[out_idx] = src_data[src_idx];\n        index[0] += 1;\n        for (let dim = 0; dim < n_dims; dim++) {\n            if (index[dim] === src.shape[dim]) {\n                if (dim + 1 === n_dims) {\n                    break;\n                }\n                index[dim] = 0;\n                index[dim + 1] += 1;\n            }\n        }\n    }\n    return out;\n}\n/** Determine the memory order (axis permutation) for a chunk */\nfunction get_order(chunk) {\n    let rank = chunk.shape.length;\n    assert(rank === chunk.stride.length, \"Shape and stride must have the same length.\");\n    return chunk.stride\n        .map((s, i) => ({ stride: s, index: i }))\n        .sort((a, b) => b.stride - a.stride)\n        .map((entry) => entry.index);\n}\nfunction matches_order(chunk, target) {\n    let source = get_order(chunk);\n    assert(source.length === target.length, \"Orders must match\");\n    return source.every((dim, i) => dim === target[i]);\n}\nexport class TransposeCodec {\n    kind = \"array_to_array\";\n    #order;\n    #inverseOrder;\n    constructor(configuration, meta) {\n        let value = configuration.order ?? \"C\";\n        let rank = meta.shape.length;\n        let order = new Array(rank);\n        let inverseOrder = new Array(rank);\n        if (value === \"C\") {\n            for (let i = 0; i < rank; ++i) {\n                order[i] = i;\n                inverseOrder[i] = i;\n            }\n        }\n        else if (value === \"F\") {\n            for (let i = 0; i < rank; ++i) {\n                order[i] = rank - i - 1;\n                inverseOrder[i] = rank - i - 1;\n            }\n        }\n        else {\n            order = value;\n            order.forEach((x, i) => {\n                assert(inverseOrder[x] === undefined, `Invalid permutation: ${JSON.stringify(value)}`);\n                inverseOrder[x] = i;\n            });\n        }\n        this.#order = order;\n        this.#inverseOrder = inverseOrder;\n    }\n    static fromConfig(configuration, meta) {\n        return new TransposeCodec(configuration, meta);\n    }\n    encode(arr) {\n        if (matches_order(arr, this.#inverseOrder)) {\n            // can skip making a copy\n            return arr;\n        }\n        return convert_array_order(arr, this.#inverseOrder);\n    }\n    decode(arr) {\n        return {\n            data: arr.data,\n            shape: arr.shape,\n            stride: get_strides(arr.shape, this.#order),\n        };\n    }\n}\n//# sourceMappingURL=transpose.js.map","import { get_strides } from \"../util.js\";\nexport class VLenUTF8 {\n    kind = \"array_to_bytes\";\n    #shape;\n    #strides;\n    constructor(shape) {\n        this.#shape = shape;\n        this.#strides = get_strides(shape, \"C\");\n    }\n    static fromConfig(_, meta) {\n        return new VLenUTF8(meta.shape);\n    }\n    encode(_chunk) {\n        throw new Error(\"Method not implemented.\");\n    }\n    decode(bytes) {\n        let decoder = new TextDecoder();\n        let view = new DataView(bytes.buffer);\n        let data = Array(view.getUint32(0, true));\n        let pos = 4;\n        for (let i = 0; i < data.length; i++) {\n            let item_length = view.getUint32(pos, true);\n            pos += 4;\n            data[i] = decoder.decode(bytes.buffer.slice(pos, pos + item_length));\n            pos += item_length;\n        }\n        return { data, shape: this.#shape, stride: this.#strides };\n    }\n}\n//# sourceMappingURL=vlen-utf8.js.map","import { decompress } from \"../util.js\";\nexport class ZlibCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig(_) {\n        return new ZlibCodec();\n    }\n    encode(_bytes) {\n        throw new Error(\"Zlib encoding is not enabled by default. Please register a codec with `numcodecs/zlib`.\");\n    }\n    async decode(bytes) {\n        const buffer = await decompress(bytes, { format: \"deflate\" });\n        return new Uint8Array(buffer);\n    }\n}\n//# sourceMappingURL=zlib.js.map","import { BitroundCodec } from \"./codecs/bitround.js\";\nimport { BytesCodec } from \"./codecs/bytes.js\";\nimport { Crc32cCodec } from \"./codecs/crc32c.js\";\nimport { GzipCodec } from \"./codecs/gzip.js\";\nimport { JsonCodec } from \"./codecs/json2.js\";\nimport { TransposeCodec } from \"./codecs/transpose.js\";\nimport { VLenUTF8 } from \"./codecs/vlen-utf8.js\";\nimport { ZlibCodec } from \"./codecs/zlib.js\";\nimport { assert } from \"./util.js\";\nfunction create_default_registry() {\n    return new Map()\n        .set(\"blosc\", () => import(\"numcodecs/blosc\").then((m) => m.default))\n        .set(\"lz4\", () => import(\"numcodecs/lz4\").then((m) => m.default))\n        .set(\"zstd\", () => import(\"numcodecs/zstd\").then((m) => m.default))\n        .set(\"gzip\", () => GzipCodec)\n        .set(\"zlib\", () => ZlibCodec)\n        .set(\"transpose\", () => TransposeCodec)\n        .set(\"bytes\", () => BytesCodec)\n        .set(\"crc32c\", () => Crc32cCodec)\n        .set(\"vlen-utf8\", () => VLenUTF8)\n        .set(\"json2\", () => JsonCodec)\n        .set(\"bitround\", () => BitroundCodec);\n}\nexport const registry = create_default_registry();\nexport function create_codec_pipeline(chunk_metadata) {\n    let codecs;\n    return {\n        async encode(chunk) {\n            if (!codecs)\n                codecs = await load_codecs(chunk_metadata);\n            for (const codec of codecs.array_to_array) {\n                chunk = await codec.encode(chunk);\n            }\n            let bytes = await codecs.array_to_bytes.encode(chunk);\n            for (const codec of codecs.bytes_to_bytes) {\n                bytes = await codec.encode(bytes);\n            }\n            return bytes;\n        },\n        async decode(bytes) {\n            if (!codecs)\n                codecs = await load_codecs(chunk_metadata);\n            for (let i = codecs.bytes_to_bytes.length - 1; i >= 0; i--) {\n                bytes = await codecs.bytes_to_bytes[i].decode(bytes);\n            }\n            let chunk = await codecs.array_to_bytes.decode(bytes);\n            for (let i = codecs.array_to_array.length - 1; i >= 0; i--) {\n                chunk = await codecs.array_to_array[i].decode(chunk);\n            }\n            return chunk;\n        },\n    };\n}\nasync function load_codecs(chunk_meta) {\n    let promises = chunk_meta.codecs.map(async (meta) => {\n        let Codec = await registry.get(meta.name)?.();\n        assert(Codec, `Unknown codec: ${meta.name}`);\n        return { Codec, meta };\n    });\n    let array_to_array = [];\n    let array_to_bytes;\n    let bytes_to_bytes = [];\n    for await (let { Codec, meta } of promises) {\n        let codec = Codec.fromConfig(meta.configuration, chunk_meta);\n        switch (codec.kind) {\n            case \"array_to_array\":\n                array_to_array.push(codec);\n                break;\n            case \"array_to_bytes\":\n                array_to_bytes = codec;\n                break;\n            default:\n                bytes_to_bytes.push(codec);\n        }\n    }\n    if (!array_to_bytes) {\n        assert(is_typed_array_like_meta(chunk_meta), `Cannot encode ${chunk_meta.data_type} to bytes without a codec`);\n        array_to_bytes = BytesCodec.fromConfig({ endian: \"little\" }, chunk_meta);\n    }\n    return { array_to_array, array_to_bytes, bytes_to_bytes };\n}\nfunction is_typed_array_like_meta(meta) {\n    return meta.data_type !== \"v2:object\";\n}\n//# sourceMappingURL=codecs.js.map","import { create_codec_pipeline } from \"../codecs.js\";\nimport { assert } from \"../util.js\";\nconst MAX_BIG_UINT = 18446744073709551615n;\nexport function create_sharded_chunk_getter(location, shard_shape, encode_shard_key, sharding_config) {\n    assert(location.store.getRange, \"Store does not support range requests\");\n    let get_range = location.store.getRange.bind(location.store);\n    let index_shape = shard_shape.map((d, i) => d / sharding_config.chunk_shape[i]);\n    let index_codec = create_codec_pipeline({\n        data_type: \"uint64\",\n        shape: [...index_shape, 2],\n        codecs: sharding_config.index_codecs,\n    });\n    let cache = {};\n    return async (chunk_coord) => {\n        let shard_coord = chunk_coord.map((d, i) => Math.floor(d / index_shape[i]));\n        let shard_path = location.resolve(encode_shard_key(shard_coord)).path;\n        let index;\n        if (shard_path in cache) {\n            index = cache[shard_path];\n        }\n        else {\n            let checksum_size = 4;\n            let index_size = 16 * index_shape.reduce((a, b) => a * b, 1);\n            let bytes = await get_range(shard_path, {\n                suffixLength: index_size + checksum_size,\n            });\n            index = cache[shard_path] = bytes\n                ? await index_codec.decode(bytes)\n                : null;\n        }\n        if (index === null) {\n            return undefined;\n        }\n        let { data, shape, stride } = index;\n        let linear_offset = chunk_coord\n            .map((d, i) => d % shape[i])\n            .reduce((acc, sel, idx) => acc + sel * stride[idx], 0);\n        let offset = data[linear_offset];\n        let length = data[linear_offset + 1];\n        // write null chunk when 2^64-1 indicates fill value\n        if (offset === MAX_BIG_UINT && length === MAX_BIG_UINT) {\n            return undefined;\n        }\n        return get_range(shard_path, {\n            offset: Number(offset),\n            length: Number(length),\n        });\n    };\n}\n//# sourceMappingURL=sharding.js.map","import { create_sharded_chunk_getter } from \"./codecs/sharding.js\";\nimport { create_codec_pipeline } from \"./codecs.js\";\nimport { create_chunk_key_encoder, ensure_correct_scalar, get_ctr, get_strides, is_dtype, is_sharding_codec, } from \"./util.js\";\nexport class Location {\n    store;\n    path;\n    constructor(store, path = \"/\") {\n        this.store = store;\n        this.path = path;\n    }\n    resolve(path) {\n        // reuse URL resolution logic built into the browser\n        // handles relative paths, absolute paths, etc.\n        let root = new URL(`file://${this.path.endsWith(\"/\") ? this.path : `${this.path}/`}`);\n        return new Location(this.store, new URL(path, root).pathname);\n    }\n}\nexport function root(store) {\n    return new Location(store ?? new Map());\n}\nexport class Group extends Location {\n    kind = \"group\";\n    #metadata;\n    constructor(store, path, metadata) {\n        super(store, path);\n        this.#metadata = metadata;\n    }\n    get attrs() {\n        return this.#metadata.attributes;\n    }\n}\nfunction get_array_order(codecs) {\n    const maybe_transpose_codec = codecs.find((c) => c.name === \"transpose\");\n    // @ts-expect-error - TODO: Should validate?\n    return maybe_transpose_codec?.configuration?.order ?? \"C\";\n}\nconst CONTEXT_MARKER = Symbol(\"zarrita.context\");\nexport function get_context(obj) {\n    return obj[CONTEXT_MARKER];\n}\nfunction create_context(location, metadata) {\n    let { configuration } = metadata.codecs.find(is_sharding_codec) ?? {};\n    let shared_context = {\n        encode_chunk_key: create_chunk_key_encoder(metadata.chunk_key_encoding),\n        TypedArray: get_ctr(metadata.data_type),\n        fill_value: metadata.fill_value,\n    };\n    if (configuration) {\n        let native_order = get_array_order(configuration.codecs);\n        return {\n            ...shared_context,\n            kind: \"sharded\",\n            chunk_shape: configuration.chunk_shape,\n            codec: create_codec_pipeline({\n                data_type: metadata.data_type,\n                shape: configuration.chunk_shape,\n                codecs: configuration.codecs,\n            }),\n            get_strides(shape) {\n                return get_strides(shape, native_order);\n            },\n            get_chunk_bytes: create_sharded_chunk_getter(location, metadata.chunk_grid.configuration.chunk_shape, shared_context.encode_chunk_key, configuration),\n        };\n    }\n    let native_order = get_array_order(metadata.codecs);\n    return {\n        ...shared_context,\n        kind: \"regular\",\n        chunk_shape: metadata.chunk_grid.configuration.chunk_shape,\n        codec: create_codec_pipeline({\n            data_type: metadata.data_type,\n            shape: metadata.chunk_grid.configuration.chunk_shape,\n            codecs: metadata.codecs,\n        }),\n        get_strides(shape) {\n            return get_strides(shape, native_order);\n        },\n        async get_chunk_bytes(chunk_coords, options) {\n            let chunk_key = shared_context.encode_chunk_key(chunk_coords);\n            let chunk_path = location.resolve(chunk_key).path;\n            return location.store.get(chunk_path, options);\n        },\n    };\n}\nexport class Array extends Location {\n    kind = \"array\";\n    #metadata;\n    [CONTEXT_MARKER];\n    constructor(store, path, metadata) {\n        super(store, path);\n        this.#metadata = {\n            ...metadata,\n            fill_value: ensure_correct_scalar(metadata),\n        };\n        this[CONTEXT_MARKER] = create_context(this, metadata);\n    }\n    get attrs() {\n        return this.#metadata.attributes;\n    }\n    get shape() {\n        return this.#metadata.shape;\n    }\n    get chunks() {\n        return this[CONTEXT_MARKER].chunk_shape;\n    }\n    get dtype() {\n        return this.#metadata.data_type;\n    }\n    async getChunk(chunk_coords, options) {\n        let context = this[CONTEXT_MARKER];\n        let maybe_bytes = await context.get_chunk_bytes(chunk_coords, options);\n        if (!maybe_bytes) {\n            let size = context.chunk_shape.reduce((a, b) => a * b, 1);\n            let data = new context.TypedArray(size);\n            // @ts-expect-error: TS can't infer that `fill_value` is union (assumes never) but this is ok\n            data.fill(context.fill_value);\n            return {\n                data,\n                shape: context.chunk_shape,\n                stride: context.get_strides(context.chunk_shape),\n            };\n        }\n        return context.codec.decode(maybe_bytes);\n    }\n    /**\n     * A helper method to narrow `zarr.Array` Dtype.\n     *\n     * ```typescript\n     * let arr: zarr.Array<DataType, FetchStore> = zarr.open(store, { kind: \"array\" });\n     *\n     * // Option 1: narrow by scalar type (e.g. \"bool\", \"raw\", \"bigint\", \"number\")\n     * if (arr.is(\"bigint\")) {\n     *   // zarr.Array<\"int64\" | \"uint64\", FetchStore>\n     * }\n     *\n     * // Option 3: exact match\n     * if (arr.is(\"float32\")) {\n     *   // zarr.Array<\"float32\", FetchStore, \"/\">\n     * }\n     * ```\n     */\n    is(query) {\n        return is_dtype(this.dtype, query);\n    }\n}\n//# sourceMappingURL=hierarchy.js.map","import { product, range, slice, slice_indices } from \"./util.js\";\nexport class IndexError extends Error {\n    constructor(msg) {\n        super(msg);\n        this.name = \"IndexError\";\n    }\n}\nfunction err_too_many_indices(selection, shape) {\n    throw new IndexError(`too many indicies for array; expected ${shape.length}, got ${selection.length}`);\n}\nfunction err_boundscheck(dim_len) {\n    throw new IndexError(`index out of bounds for dimension with length ${dim_len}`);\n}\nfunction err_negative_step() {\n    throw new IndexError(\"only slices with step >= 1 are supported\");\n}\nfunction check_selection_length(selection, shape) {\n    if (selection.length > shape.length) {\n        err_too_many_indices(selection, shape);\n    }\n}\nexport function normalize_integer_selection(dim_sel, dim_len) {\n    // normalize type to int\n    dim_sel = Math.trunc(dim_sel);\n    // handle wraparound\n    if (dim_sel < 0) {\n        dim_sel = dim_len + dim_sel;\n    }\n    // handle out of bounds\n    if (dim_sel >= dim_len || dim_sel < 0) {\n        err_boundscheck(dim_len);\n    }\n    return dim_sel;\n}\nclass IntDimIndexer {\n    dim_sel;\n    dim_len;\n    dim_chunk_len;\n    nitems;\n    constructor({ dim_sel, dim_len, dim_chunk_len }) {\n        // normalize\n        dim_sel = normalize_integer_selection(dim_sel, dim_len);\n        // store properties\n        this.dim_sel = dim_sel;\n        this.dim_len = dim_len;\n        this.dim_chunk_len = dim_chunk_len;\n        this.nitems = 1;\n    }\n    *[Symbol.iterator]() {\n        const dim_chunk_ix = Math.floor(this.dim_sel / this.dim_chunk_len);\n        const dim_offset = dim_chunk_ix * this.dim_chunk_len;\n        const dim_chunk_sel = this.dim_sel - dim_offset;\n        yield { dim_chunk_ix, dim_chunk_sel };\n    }\n}\nclass SliceDimIndexer {\n    start;\n    stop;\n    step;\n    dim_len;\n    dim_chunk_len;\n    nitems;\n    nchunks;\n    constructor({ dim_sel, dim_len, dim_chunk_len }) {\n        // normalize\n        const [start, stop, step] = slice_indices(dim_sel, dim_len);\n        this.start = start;\n        this.stop = stop;\n        this.step = step;\n        if (this.step < 1)\n            err_negative_step();\n        // store properties\n        this.dim_len = dim_len;\n        this.dim_chunk_len = dim_chunk_len;\n        this.nitems = Math.max(0, Math.ceil((this.stop - this.start) / this.step));\n        this.nchunks = Math.ceil(this.dim_len / this.dim_chunk_len);\n    }\n    *[Symbol.iterator]() {\n        // figure out the range of chunks we need to visit\n        const dim_chunk_ix_from = Math.floor(this.start / this.dim_chunk_len);\n        const dim_chunk_ix_to = Math.ceil(this.stop / this.dim_chunk_len);\n        for (const dim_chunk_ix of range(dim_chunk_ix_from, dim_chunk_ix_to)) {\n            // compute offsets for chunk within overall array\n            const dim_offset = dim_chunk_ix * this.dim_chunk_len;\n            const dim_limit = Math.min(this.dim_len, (dim_chunk_ix + 1) * this.dim_chunk_len);\n            // determine chunk length, accounting for trailing chunk\n            const dim_chunk_len = dim_limit - dim_offset;\n            let dim_out_offset = 0;\n            let dim_chunk_sel_start = 0;\n            if (this.start < dim_offset) {\n                // selection start before current chunk\n                const remainder = (dim_offset - this.start) % this.step;\n                if (remainder)\n                    dim_chunk_sel_start += this.step - remainder;\n                // compute number of previous items, provides offset into output array\n                dim_out_offset = Math.ceil((dim_offset - this.start) / this.step);\n            }\n            else {\n                // selection starts within current chunk\n                dim_chunk_sel_start = this.start - dim_offset;\n            }\n            // selection starts within current chunk if true,\n            // otherwise selection ends after current chunk.\n            const dim_chunk_sel_stop = this.stop > dim_limit ? dim_chunk_len : this.stop - dim_offset;\n            const dim_chunk_sel = [\n                dim_chunk_sel_start,\n                dim_chunk_sel_stop,\n                this.step,\n            ];\n            const dim_chunk_nitems = Math.ceil((dim_chunk_sel_stop - dim_chunk_sel_start) / this.step);\n            const dim_out_sel = [\n                dim_out_offset,\n                dim_out_offset + dim_chunk_nitems,\n                1,\n            ];\n            yield { dim_chunk_ix, dim_chunk_sel, dim_out_sel };\n        }\n    }\n}\nexport function normalize_selection(selection, shape) {\n    let normalized = [];\n    if (selection === null) {\n        normalized = shape.map((_) => slice(null));\n    }\n    else if (Array.isArray(selection)) {\n        normalized = selection.map((s) => s ?? slice(null));\n    }\n    check_selection_length(normalized, shape);\n    return normalized;\n}\nexport class BasicIndexer {\n    dim_indexers;\n    shape;\n    constructor({ selection, shape, chunk_shape }) {\n        // setup per-dimension indexers\n        this.dim_indexers = normalize_selection(selection, shape).map((dim_sel, i) => {\n            return new (typeof dim_sel === \"number\" ? IntDimIndexer : SliceDimIndexer)({\n                // @ts-expect-error ts inference not strong enough to know correct chunk\n                dim_sel: dim_sel,\n                dim_len: shape[i],\n                dim_chunk_len: chunk_shape[i],\n            });\n        });\n        this.shape = this.dim_indexers\n            .filter((ixr) => ixr instanceof SliceDimIndexer)\n            .map((sixr) => sixr.nitems);\n    }\n    *[Symbol.iterator]() {\n        for (const dim_projections of product(...this.dim_indexers)) {\n            const chunk_coords = dim_projections.map((p) => p.dim_chunk_ix);\n            const mapping = dim_projections.map((p) => {\n                if (\"dim_out_sel\" in p) {\n                    return { from: p.dim_chunk_sel, to: p.dim_out_sel };\n                }\n                return { from: p.dim_chunk_sel, to: null };\n            });\n            yield { chunk_coords, mapping };\n        }\n    }\n}\n//# sourceMappingURL=indexer.js.map","import { get as get_with_setter } from \"./get.js\";\nimport { set as set_with_setter } from \"./set.js\";\n/** A 1D \"view\" of an array that can be used to set values in the array. */\nfunction object_array_view(arr, offset = 0, size) {\n    let length = size ?? arr.length - offset;\n    return {\n        length,\n        subarray(from, to = length) {\n            return object_array_view(arr, offset + from, to - from);\n        },\n        set(data, start = 0) {\n            for (let i = 0; i < data.length; i++) {\n                arr[offset + start + i] = data.get(i);\n            }\n        },\n        get(index) {\n            return arr[offset + index];\n        },\n    };\n}\n/**\n * Convert a chunk to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more than\n * just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the underlying, which is supported by our binary set functions.\n */\nfunction compat_chunk(arr) {\n    if (globalThis.Array.isArray(arr.data)) {\n        return {\n            // @ts-expect-error\n            data: object_array_view(arr.data),\n            stride: arr.stride,\n            bytes_per_element: 1,\n        };\n    }\n    return {\n        data: new Uint8Array(arr.data.buffer, arr.data.byteOffset, arr.data.byteLength),\n        stride: arr.stride,\n        bytes_per_element: arr.data.BYTES_PER_ELEMENT,\n    };\n}\n/** Hack to get the constructor of a typed array constructor from an existing TypedArray. */\nfunction get_typed_array_constructor(arr) {\n    if (\"chars\" in arr) {\n        // our custom TypedArray needs to bind the number of characters per\n        // element to the constructor.\n        return arr.constructor.bind(null, arr.chars);\n    }\n    return arr.constructor;\n}\n/**\n * Convert a scalar to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more\n * than just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the scalar, which is supported by our binary set functions.\n */\nfunction compat_scalar(arr, value) {\n    if (globalThis.Array.isArray(arr.data)) {\n        // @ts-expect-error\n        return object_array_view([value]);\n    }\n    let TypedArray = get_typed_array_constructor(arr.data);\n    // @ts-expect-error - value is a scalar and matches\n    let data = new TypedArray([value]);\n    return new Uint8Array(data.buffer, data.byteOffset, data.byteLength);\n}\nexport const setter = {\n    prepare(data, shape, stride) {\n        return { data, shape, stride };\n    },\n    set_scalar(dest, sel, value) {\n        let view = compat_chunk(dest);\n        set_scalar_binary(view, sel, compat_scalar(dest, value), view.bytes_per_element);\n    },\n    set_from_chunk(dest, src, projections) {\n        let view = compat_chunk(dest);\n        set_from_chunk_binary(view, compat_chunk(src), view.bytes_per_element, projections);\n    },\n};\n/** @category Utility */\nexport async function get(arr, selection = null, opts = {}) {\n    return get_with_setter(arr, selection, opts, setter);\n}\n/** @category Utility */\nexport async function set(arr, selection, value, opts = {}) {\n    return set_with_setter(arr, selection, value, opts, setter);\n}\nfunction indices_len(start, stop, step) {\n    if (step < 0 && stop < start) {\n        return Math.floor((start - stop - 1) / -step) + 1;\n    }\n    if (start < stop)\n        return Math.floor((stop - start - 1) / step) + 1;\n    return 0;\n}\nfunction set_scalar_binary(out, out_selection, value, bytes_per_element) {\n    if (out_selection.length === 0) {\n        out.data.set(value, 0);\n        return;\n    }\n    const [slice, ...slices] = out_selection;\n    const [curr_stride, ...stride] = out.stride;\n    if (typeof slice === \"number\") {\n        const data = out.data.subarray(curr_stride * slice * bytes_per_element);\n        set_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n        return;\n    }\n    const [from, to, step] = slice;\n    const len = indices_len(from, to, step);\n    if (slices.length === 0) {\n        for (let i = 0; i < len; i++) {\n            out.data.set(value, curr_stride * (from + step * i) * bytes_per_element);\n        }\n        return;\n    }\n    for (let i = 0; i < len; i++) {\n        const data = out.data.subarray(curr_stride * (from + step * i) * bytes_per_element);\n        set_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n    }\n}\nfunction set_from_chunk_binary(dest, src, bytes_per_element, projections) {\n    const [proj, ...projs] = projections;\n    const [dstride, ...dstrides] = dest.stride;\n    const [sstride, ...sstrides] = src.stride;\n    if (proj.from === null) {\n        if (projs.length === 0) {\n            dest.data.set(src.data.subarray(0, bytes_per_element), proj.to * bytes_per_element);\n            return;\n        }\n        set_from_chunk_binary({\n            data: dest.data.subarray(dstride * proj.to * bytes_per_element),\n            stride: dstrides,\n        }, src, bytes_per_element, projs);\n        return;\n    }\n    if (proj.to === null) {\n        if (projs.length === 0) {\n            let offset = proj.from * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + bytes_per_element), 0);\n            return;\n        }\n        set_from_chunk_binary(dest, {\n            data: src.data.subarray(sstride * proj.from * bytes_per_element),\n            stride: sstrides,\n        }, bytes_per_element, projs);\n        return;\n    }\n    const [from, to, step] = proj.to;\n    const [sfrom, _, sstep] = proj.from;\n    const len = indices_len(from, to, step);\n    if (projs.length === 0) {\n        // NB: we have a contiguous block of memory\n        // so we can just copy over all the data at once.\n        if (step === 1 && sstep === 1 && dstride === 1 && sstride === 1) {\n            let offset = sfrom * bytes_per_element;\n            let size = len * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + size), from * bytes_per_element);\n            return;\n        }\n        // Otherwise, we have to copy over each element individually.\n        for (let i = 0; i < len; i++) {\n            let offset = sstride * (sfrom + sstep * i) * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + bytes_per_element), dstride * (from + step * i) * bytes_per_element);\n        }\n        return;\n    }\n    for (let i = 0; i < len; i++) {\n        set_from_chunk_binary({\n            data: dest.data.subarray(dstride * (from + i * step) * bytes_per_element),\n            stride: dstrides,\n        }, {\n            data: src.data.subarray(sstride * (sfrom + i * sstep) * bytes_per_element),\n            stride: sstrides,\n        }, bytes_per_element, projs);\n    }\n}\n//# sourceMappingURL=ops.js.map","import { get_context } from \"../hierarchy.js\";\nimport { BasicIndexer } from \"./indexer.js\";\nimport { create_queue } from \"./util.js\";\nfunction unwrap(arr, idx) {\n    return (\"get\" in arr ? arr.get(idx) : arr[idx]);\n}\nexport async function get(arr, selection, opts, setter) {\n    let context = get_context(arr);\n    let indexer = new BasicIndexer({\n        selection,\n        shape: arr.shape,\n        chunk_shape: arr.chunks,\n    });\n    let out = setter.prepare(new context.TypedArray(indexer.shape.reduce((a, b) => a * b, 1)), indexer.shape, context.get_strides(indexer.shape));\n    let queue = opts.create_queue?.() ?? create_queue();\n    for (const { chunk_coords, mapping } of indexer) {\n        queue.add(async () => {\n            let { data, shape, stride } = await arr.getChunk(chunk_coords, opts.opts);\n            let chunk = setter.prepare(data, shape, stride);\n            setter.set_from_chunk(out, chunk, mapping);\n        });\n    }\n    await queue.onIdle();\n    // If the final out shape is empty, we just return a scalar.\n    // @ts-expect-error - TS can't narrow this conditional type\n    return indexer.shape.length === 0 ? unwrap(out.data, 0) : out;\n}\n//# sourceMappingURL=get.js.map","/** Similar to python's `range` function. Supports positive ranges only. */\nexport function* range(start, stop, step = 1) {\n    if (stop === undefined) {\n        stop = start;\n        start = 0;\n    }\n    for (let i = start; i < stop; i += step) {\n        yield i;\n    }\n}\n/**\n * python-like itertools.product generator\n * https://gist.github.com/cybercase/db7dde901d7070c98c48\n */\nexport function* product(...iterables) {\n    if (iterables.length === 0) {\n        return;\n    }\n    // make a list of iterators from the iterables\n    const iterators = iterables.map((it) => it[Symbol.iterator]());\n    const results = iterators.map((it) => it.next());\n    if (results.some((r) => r.done)) {\n        throw new Error(\"Input contains an empty iterator.\");\n    }\n    for (let i = 0;;) {\n        if (results[i].done) {\n            // reset the current iterator\n            iterators[i] = iterables[i][Symbol.iterator]();\n            results[i] = iterators[i].next();\n            // advance, and exit if we've reached the end\n            if (++i >= iterators.length) {\n                return;\n            }\n        }\n        else {\n            // @ts-expect-error - TS can't infer this\n            yield results.map(({ value }) => value);\n            i = 0;\n        }\n        results[i] = iterators[i].next();\n    }\n}\n// https://github.com/python/cpython/blob/263c0dd16017613c5ea2fbfc270be4de2b41b5ad/Objects/sliceobject.c#L376-L519\nexport function slice_indices({ start, stop, step }, length) {\n    if (step === 0) {\n        throw new Error(\"slice step cannot be zero\");\n    }\n    step = step ?? 1;\n    const step_is_negative = step < 0;\n    /* Find lower and upper bounds for start and stop. */\n    const [lower, upper] = step_is_negative ? [-1, length - 1] : [0, length];\n    /* Compute start. */\n    if (start === null) {\n        start = step_is_negative ? upper : lower;\n    }\n    else {\n        if (start < 0) {\n            start += length;\n            if (start < lower) {\n                start = lower;\n            }\n        }\n        else if (start > upper) {\n            start = upper;\n        }\n    }\n    /* Compute stop. */\n    if (stop === null) {\n        stop = step_is_negative ? lower : upper;\n    }\n    else {\n        if (stop < 0) {\n            stop += length;\n            if (stop < lower) {\n                stop = lower;\n            }\n        }\n        else if (stop > upper) {\n            stop = upper;\n        }\n    }\n    return [start, stop, step];\n}\nexport function slice(start, stop, step = null) {\n    if (stop === undefined) {\n        stop = start;\n        start = null;\n    }\n    return {\n        start,\n        stop,\n        step,\n    };\n}\n/** Built-in \"queue\" for awaiting promises. */\nexport function create_queue() {\n    const promises = [];\n    return {\n        add: (fn) => promises.push(fn()),\n        onIdle: () => Promise.all(promises),\n    };\n}\n//# sourceMappingURL=util.js.map","import { KeyError, NodeNotFoundError } from \"./errors.js\";\nimport { Array, Group, Location } from \"./hierarchy.js\";\nimport { ensure_correct_scalar, json_decode_object, rethrow_unless, v2_to_v3_array_metadata, v2_to_v3_group_metadata, } from \"./util.js\";\nlet VERSION_COUNTER = create_version_counter();\nfunction create_version_counter() {\n    let version_counts = new WeakMap();\n    function get_counts(store) {\n        let counts = version_counts.get(store) ?? { v2: 0, v3: 0 };\n        version_counts.set(store, counts);\n        return counts;\n    }\n    return {\n        increment(store, version) {\n            get_counts(store)[version] += 1;\n        },\n        version_max(store) {\n            let counts = get_counts(store);\n            return counts.v3 > counts.v2 ? \"v3\" : \"v2\";\n        },\n    };\n}\nasync function load_attrs(location) {\n    let meta_bytes = await location.store.get(location.resolve(\".zattrs\").path);\n    if (!meta_bytes)\n        return {};\n    return json_decode_object(meta_bytes);\n}\nasync function open_v2(location, options = {}) {\n    let loc = \"store\" in location ? location : new Location(location);\n    let attrs = {};\n    if (options.attrs ?? true)\n        attrs = await load_attrs(loc);\n    if (options.kind === \"array\")\n        return open_array_v2(loc, attrs);\n    if (options.kind === \"group\")\n        return open_group_v2(loc, attrs);\n    return open_array_v2(loc, attrs).catch((err) => {\n        rethrow_unless(err, NodeNotFoundError);\n        return open_group_v2(loc, attrs);\n    });\n}\nasync function open_array_v2(location, attrs) {\n    let { path } = location.resolve(\".zarray\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v2 array\", {\n            cause: new KeyError(path),\n        });\n    }\n    VERSION_COUNTER.increment(location.store, \"v2\");\n    return new Array(location.store, location.path, v2_to_v3_array_metadata(json_decode_object(meta), attrs));\n}\nasync function open_group_v2(location, attrs) {\n    let { path } = location.resolve(\".zgroup\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v2 group\", {\n            cause: new KeyError(path),\n        });\n    }\n    VERSION_COUNTER.increment(location.store, \"v2\");\n    return new Group(location.store, location.path, v2_to_v3_group_metadata(json_decode_object(meta), attrs));\n}\nasync function _open_v3(location) {\n    let { store, path } = location.resolve(\"zarr.json\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v3 array or group\", {\n            cause: new KeyError(path),\n        });\n    }\n    let meta_doc = json_decode_object(meta);\n    if (meta_doc.node_type === \"array\") {\n        meta_doc.fill_value = ensure_correct_scalar(meta_doc);\n    }\n    return meta_doc.node_type === \"array\"\n        ? new Array(store, location.path, meta_doc)\n        : new Group(store, location.path, meta_doc);\n}\nasync function open_v3(location, options = {}) {\n    let loc = \"store\" in location ? location : new Location(location);\n    let node = await _open_v3(loc);\n    VERSION_COUNTER.increment(loc.store, \"v3\");\n    if (options.kind === undefined)\n        return node;\n    if (options.kind === \"array\" && node instanceof Array)\n        return node;\n    if (options.kind === \"group\" && node instanceof Group)\n        return node;\n    let kind = node instanceof Array ? \"array\" : \"group\";\n    throw new Error(`Expected node of kind ${options.kind}, found ${kind}.`);\n}\nexport async function open(location, options = {}) {\n    let store = \"store\" in location ? location.store : location;\n    let version_max = VERSION_COUNTER.version_max(store);\n    // Use the open function for the version with the most successful opens.\n    // Note that here we use the dot syntax to access the open functions\n    // because this enables us to use vi.spyOn during testing.\n    let open_primary = version_max === \"v2\" ? open.v2 : open.v3;\n    let open_secondary = version_max === \"v2\" ? open.v3 : open.v2;\n    return open_primary(location, options).catch((err) => {\n        rethrow_unless(err, NodeNotFoundError);\n        return open_secondary(location, options);\n    });\n}\nopen.v2 = open_v2;\nopen.v3 = open_v3;\n//# sourceMappingURL=open.js.map","/**\n * Custom array-like views (i.e., TypedArrays) for Zarr binary data buffers.\n *\n * @module\n */\n/**\n * An array-like view of a fixed-length boolean buffer.\n *\n * Encoded as 1 byte per value.\n */\nexport class BoolArray {\n    #bytes;\n    constructor(x, byteOffset, length) {\n        if (typeof x === \"number\") {\n            this.#bytes = new Uint8Array(x);\n        }\n        else if (x instanceof ArrayBuffer) {\n            this.#bytes = new Uint8Array(x, byteOffset, length);\n        }\n        else {\n            this.#bytes = new Uint8Array(Array.from(x, (v) => (v ? 1 : 0)));\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return 1;\n    }\n    get byteOffset() {\n        return this.#bytes.byteOffset;\n    }\n    get byteLength() {\n        return this.#bytes.byteLength;\n    }\n    get buffer() {\n        return this.#bytes.buffer;\n    }\n    get length() {\n        return this.#bytes.length;\n    }\n    get(idx) {\n        let value = this.#bytes[idx];\n        return typeof value === \"number\" ? value !== 0 : value;\n    }\n    set(idx, value) {\n        this.#bytes[idx] = value ? 1 : 0;\n    }\n    fill(value) {\n        this.#bytes.fill(value ? 1 : 0);\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n/**\n * An array-like view of a fixed-length byte buffer.\n *\n * Encodes a raw byte sequences without enforced encoding.\n */\nexport class ByteStringArray {\n    _data;\n    chars;\n    #encoder;\n    constructor(chars, x, byteOffset, length) {\n        this.chars = chars;\n        this.#encoder = new TextEncoder();\n        if (typeof x === \"number\") {\n            this._data = new Uint8Array(x * chars);\n        }\n        else if (x instanceof ArrayBuffer) {\n            if (length)\n                length = length * chars;\n            this._data = new Uint8Array(x, byteOffset, length);\n        }\n        else {\n            let values = Array.from(x);\n            this._data = new Uint8Array(values.length * chars);\n            for (let i = 0; i < values.length; i++) {\n                this.set(i, values[i]);\n            }\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return this.chars;\n    }\n    get byteOffset() {\n        return this._data.byteOffset;\n    }\n    get byteLength() {\n        return this._data.byteLength;\n    }\n    get buffer() {\n        return this._data.buffer;\n    }\n    get length() {\n        return this.byteLength / this.BYTES_PER_ELEMENT;\n    }\n    get(idx) {\n        const view = new Uint8Array(this.buffer, this.byteOffset + this.chars * idx, this.chars);\n        // biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n        return new TextDecoder().decode(view).replace(/\\x00/g, \"\");\n    }\n    set(idx, value) {\n        const view = new Uint8Array(this.buffer, this.byteOffset + this.chars * idx, this.chars);\n        view.fill(0); // clear current\n        view.set(this.#encoder.encode(value));\n    }\n    fill(value) {\n        const encoded = this.#encoder.encode(value);\n        for (let i = 0; i < this.length; i++) {\n            this._data.set(encoded, i * this.chars);\n        }\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n/**\n * An array-like view of a fixed-length Unicode string buffer.\n *\n * Encoded as UTF-32 code points.\n */\nexport class UnicodeStringArray {\n    #data;\n    chars;\n    constructor(chars, x, byteOffset, length) {\n        this.chars = chars;\n        if (typeof x === \"number\") {\n            this.#data = new Int32Array(x * chars);\n        }\n        else if (x instanceof ArrayBuffer) {\n            if (length)\n                length *= chars;\n            this.#data = new Int32Array(x, byteOffset, length);\n        }\n        else {\n            const values = x;\n            const d = new UnicodeStringArray(chars, 1);\n            this.#data = new Int32Array((function* () {\n                for (let str of values) {\n                    d.set(0, str);\n                    yield* d.#data;\n                }\n            })());\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return this.#data.BYTES_PER_ELEMENT * this.chars;\n    }\n    get byteLength() {\n        return this.#data.byteLength;\n    }\n    get byteOffset() {\n        return this.#data.byteOffset;\n    }\n    get buffer() {\n        return this.#data.buffer;\n    }\n    get length() {\n        return this.#data.length / this.chars;\n    }\n    get(idx) {\n        const offset = this.chars * idx;\n        let result = \"\";\n        for (let i = 0; i < this.chars; i++) {\n            result += String.fromCodePoint(this.#data[offset + i]);\n        }\n        // biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n        return result.replace(/\\u0000/g, \"\");\n    }\n    set(idx, value) {\n        const offset = this.chars * idx;\n        const view = this.#data.subarray(offset, offset + this.chars);\n        view.fill(0); // clear current\n        for (let i = 0; i < this.chars; i++) {\n            view[i] = value.codePointAt(i) ?? 0;\n        }\n    }\n    fill(value) {\n        // encode once\n        this.set(0, value);\n        // copy the encoded values to all other elements\n        let encoded = this.#data.subarray(0, this.chars);\n        for (let i = 1; i < this.length; i++) {\n            this.#data.set(encoded, i * this.chars);\n        }\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n//# sourceMappingURL=typedarray.js.map","import { BoolArray, ByteStringArray, UnicodeStringArray, } from \"./typedarray.js\";\nexport function json_encode_object(o) {\n    const str = JSON.stringify(o, null, 2);\n    return new TextEncoder().encode(str);\n}\nexport function json_decode_object(bytes) {\n    const str = new TextDecoder().decode(bytes);\n    return JSON.parse(str);\n}\nexport function byteswap_inplace(view, bytes_per_element) {\n    const numFlips = bytes_per_element / 2;\n    const endByteIndex = bytes_per_element - 1;\n    let t = 0;\n    for (let i = 0; i < view.length; i += bytes_per_element) {\n        for (let j = 0; j < numFlips; j += 1) {\n            t = view[i + j];\n            view[i + j] = view[i + endByteIndex - j];\n            view[i + endByteIndex - j] = t;\n        }\n    }\n}\nexport function get_ctr(data_type) {\n    if (data_type === \"v2:object\") {\n        return globalThis.Array;\n    }\n    let match = data_type.match(/v2:([US])(\\d+)/);\n    if (match) {\n        let [, kind, chars] = match;\n        // @ts-expect-error\n        return (kind === \"U\" ? UnicodeStringArray : ByteStringArray).bind(null, Number(chars));\n    }\n    // @ts-expect-error - We've checked that the key exists\n    let ctr = {\n        int8: Int8Array,\n        int16: Int16Array,\n        int32: Int32Array,\n        int64: globalThis.BigInt64Array,\n        uint8: Uint8Array,\n        uint16: Uint16Array,\n        uint32: Uint32Array,\n        uint64: globalThis.BigUint64Array,\n        float16: globalThis.Float16Array,\n        float32: Float32Array,\n        float64: Float64Array,\n        bool: BoolArray,\n    }[data_type];\n    assert(ctr, `Unknown or unsupported data_type: ${data_type}`);\n    return ctr;\n}\n/** Compute strides for 'C' or 'F' ordered array from shape */\nexport function get_strides(shape, order) {\n    const rank = shape.length;\n    if (typeof order === \"string\") {\n        order =\n            order === \"C\"\n                ? Array.from({ length: rank }, (_, i) => i) // Row-major (identity order)\n                : Array.from({ length: rank }, (_, i) => rank - 1 - i); // Column-major (reverse order)\n    }\n    assert(rank === order.length, \"Order length must match the number of dimensions.\");\n    let step = 1;\n    let stride = new Array(rank);\n    for (let i = order.length - 1; i >= 0; i--) {\n        stride[order[i]] = step;\n        step *= shape[order[i]];\n    }\n    return stride;\n}\n// https://zarr-specs.readthedocs.io/en/latest/v3/core/v3.0.html#chunk-key-encoding\nexport function create_chunk_key_encoder({ name, configuration, }) {\n    if (name === \"default\") {\n        const separator = configuration?.separator ?? \"/\";\n        return (chunk_coords) => [\"c\", ...chunk_coords].join(separator);\n    }\n    if (name === \"v2\") {\n        const separator = configuration?.separator ?? \".\";\n        return (chunk_coords) => chunk_coords.join(separator) || \"0\";\n    }\n    throw new Error(`Unknown chunk key encoding: ${name}`);\n}\nfunction coerce_dtype(dtype) {\n    if (dtype === \"|O\") {\n        return { data_type: \"v2:object\" };\n    }\n    let match = dtype.match(/^([<|>])(.*)$/);\n    assert(match, `Invalid dtype: ${dtype}`);\n    let [, endian, rest] = match;\n    let data_type = {\n        b1: \"bool\",\n        i1: \"int8\",\n        u1: \"uint8\",\n        i2: \"int16\",\n        u2: \"uint16\",\n        i4: \"int32\",\n        u4: \"uint32\",\n        i8: \"int64\",\n        u8: \"uint64\",\n        f2: \"float16\",\n        f4: \"float32\",\n        f8: \"float64\",\n    }[rest] ??\n        (rest.startsWith(\"S\") || rest.startsWith(\"U\") ? `v2:${rest}` : undefined);\n    assert(data_type, `Unsupported or unknown dtype: ${dtype}`);\n    if (endian === \"|\") {\n        return { data_type };\n    }\n    return { data_type, endian: endian === \"<\" ? \"little\" : \"big\" };\n}\nexport function v2_to_v3_array_metadata(meta, attributes = {}) {\n    let codecs = [];\n    let dtype = coerce_dtype(meta.dtype);\n    if (meta.order === \"F\") {\n        codecs.push({ name: \"transpose\", configuration: { order: \"F\" } });\n    }\n    if (\"endian\" in dtype && dtype.endian === \"big\") {\n        codecs.push({ name: \"bytes\", configuration: { endian: \"big\" } });\n    }\n    for (let { id, ...configuration } of meta.filters ?? []) {\n        codecs.push({ name: id, configuration });\n    }\n    if (meta.compressor) {\n        let { id, ...configuration } = meta.compressor;\n        codecs.push({ name: id, configuration });\n    }\n    return {\n        zarr_format: 3,\n        node_type: \"array\",\n        shape: meta.shape,\n        data_type: dtype.data_type,\n        chunk_grid: {\n            name: \"regular\",\n            configuration: {\n                chunk_shape: meta.chunks,\n            },\n        },\n        chunk_key_encoding: {\n            name: \"v2\",\n            configuration: {\n                separator: meta.dimension_separator ?? \".\",\n            },\n        },\n        codecs,\n        fill_value: meta.fill_value,\n        attributes,\n    };\n}\nexport function v2_to_v3_group_metadata(_meta, attributes = {}) {\n    return {\n        zarr_format: 3,\n        node_type: \"group\",\n        attributes,\n    };\n}\nexport function is_dtype(dtype, query) {\n    if (query !== \"number\" &&\n        query !== \"bigint\" &&\n        query !== \"boolean\" &&\n        query !== \"object\" &&\n        query !== \"string\") {\n        return dtype === query;\n    }\n    let is_boolean = dtype === \"bool\";\n    if (query === \"boolean\")\n        return is_boolean;\n    let is_string = dtype.startsWith(\"v2:U\") || dtype.startsWith(\"v2:S\");\n    if (query === \"string\")\n        return is_string;\n    let is_bigint = dtype === \"int64\" || dtype === \"uint64\";\n    if (query === \"bigint\")\n        return is_bigint;\n    let is_object = dtype === \"v2:object\";\n    if (query === \"object\")\n        return is_object;\n    return !is_string && !is_bigint && !is_boolean && !is_object;\n}\nexport function is_sharding_codec(codec) {\n    return codec?.name === \"sharding_indexed\";\n}\nexport function ensure_correct_scalar(metadata) {\n    if ((metadata.data_type === \"uint64\" || metadata.data_type === \"int64\") &&\n        metadata.fill_value != null) {\n        // @ts-expect-error - We've narrowed the type of fill_value correctly\n        return BigInt(metadata.fill_value);\n    }\n    return metadata.fill_value;\n}\n/**\n * Ensures an error matches expected type(s), otherwise rethrows.\n *\n * Unmatched errors bubble up, like Python's `except`. Narrows error types for\n * type-safe property access.\n *\n * @see {@link https://gist.github.com/manzt/3702f19abb714e21c22ce48851c75abf}\n *\n * @example\n * ```ts\n * class DatabaseError extends Error { }\n * class NetworkError extends Error { }\n *\n * try {\n *   await db.query();\n * } catch (err) {\n *   rethrow_unless(err, DatabaseError, NetworkError);\n *   err // DatabaseError | NetworkError\n * }\n * ```\n *\n * @param error - The error to check\n * @param errors - Expected error type(s)\n * @throws The original error if it doesn't match expected type(s)\n */\nexport function rethrow_unless(error, ...errors) {\n    if (!errors.some((ErrorClass) => error instanceof ErrorClass)) {\n        throw error;\n    }\n}\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(expression, msg = \"\") {\n    if (!expression) {\n        throw new Error(msg);\n    }\n}\n/**\n * @param {ArrayBuffer |ArrayBufferView | Response} data\n * @param {Object} options\n * @param {CompressionFormat} options.format\n * @param {AbortSignal} [options.signal]\n *\n * @returns {Promise<ArrayBuffer>}\n */\nexport async function decompress(data, { format, signal }) {\n    const response = data instanceof Response ? data : new Response(data);\n    assert(response.body, \"Response does not contain body.\");\n    try {\n        const decompressedResponse = new Response(response.body.pipeThrough(new DecompressionStream(format), { signal }));\n        const buffer = await decompressedResponse.arrayBuffer();\n        return buffer;\n    }\n    catch {\n        signal?.throwIfAborted();\n        throw new Error(`Failed to decode ${format}`);\n    }\n}\n//# sourceMappingURL=util.js.map"],"names":["volumeSize","volumeDims","shape","defaultImageInfo","name","atlasTileDims","subregionSize","subregionOffset","combinedNumChannels","channelNames","channelColors","multiscaleLevel","multiscaleLevelDims","spacing","spaceUnit","timeUnit","dataType","transform","translation","rotation","scale","CImageInfo","constructor","imageInfo","this","currentLevelDims","numChannels","originalSize","physicalPixelSize","spatialUnit","times","timeScale","numMultiscaleLevels","length","computeAtlasSize","volDims","VolumeLoadErrorType","VolumeLoadError","Error","message","options","super","type","UNKNOWN","wrapVolumeLoadError","ignore","e","undefined","console","log","cause","set","allEqual","arr","every","v","pushN","val","n","i","push","directionToIndex","dir","absDir","Number","updateMinMax","minmax","ChunkPrefetchIterator","chunks","tzyxMaxPrefetchOffset","tczyxChunksPerSource","priorityDirections","onlyPriorityDirections","extrema","Infinity","chunk","flat","some","isFinite","directionStates","priorityDirectionStates","direction","start","entries","dimension","tczyxIndex","end","endsPerSource","map","chunkDims","Math","min","sourceEnd","max","directionState","includes","iterateDirections","directions","offset","filter","Array","isArray","offsetDir","newChunk","slice","Symbol","iterator","getSourceChannelNames","src","omeroMetadata","channels","label","idx","channelOffset","cIdx","axesTCZYX","scaleLevels","from","_","getDimensionCount","t","c","z","remapAxesToTCZYX","axes","axisNames","forEach","axis","axisIdx","indexOf","INVALID_METADATA","noXAxis","orderByDimension","valsTCZYX","orderTCZYX","specLen","result","orderByTCZYX","valsDimension","defaultValue","getScale","dataset","transforms","coordinateTransformations","warn","scaleTransform","find","compareZarrArraySize","aArr","aTCZYX","bArr","bTCZYX","diffZ","diffY","diffX","aboutEquals","a","b","abs","scaleTransformsAreEqual","aSrc","aLevel","bSrc","bLevel","aScale","multiscaleMetadata","datasets","bScale","matchSourceScaleLevels","sources","matchedLevels","matchedMetas","scaleIndexes","fill","smallestIdx","smallestSrc","smallestArr","currentIdx","currentSrc","currentArr","ordering","INVALID_MULTI_SOURCE_ZARR","largestT","currentT","matchedScaleLevel","srcIdx","toOMEZarrMetaV4","meta","ome","isObjectWithProp","obj","prop","assertMetadataHasProp","assertPropIsArray","assertMetadataHasMultiscales","validateOMEZarrMetadata","multiscaleIdx","multiscaleMeta","multiscales","multiscaleName","data","fetch_range","url","opts","headers","Range","fetch","resolve","root","path","base","URL","pathname","endsWith","resolved","search","async","handle_response","response","status","Uint8Array","arrayBuffer","statusText","overrides","useSuffixRequest","storeOverrides","requestOverrides","get","key","href","getRange","range","init","suffix_length","use_suffix_request","method","ok","content_length","fetch_suffix","suffixLength","wrapArray","array","basePath","cache","queue","keyBase","getChunk","coords","subscriber","reportChunk","fullKey","join","cacheResult","addRequest","isPrefetch","insert","Proxy","target","value","Function","args","apply","RelaxedFetchStore","baseUrl","startsWith","DEFAULT_REQUEST_CANCEL_REASON","RequestQueue","maxActiveRequests","maxLowPriorityRequests","allRequests","Map","activeRequests","Set","queueLowPriority","registerRequest","requestAction","promiseResolve","promiseReject","promise","Promise","reject","requestItem","action","addRequestToQueue","lowPriority","has","timeoutId","clearTimeout","dequeue","delayMs","lowPriorityIndex","splice","setTimeout","addRequests","requests","promises","item","numRequests","size","requestKey","shift","add","then","delete","cancelRequest","cancelReason","queueIndex","cancelAllRequests","keys","hasRequest","requestRunning","SubscribableRequestQueue","nextSubscriberId","subscribers","resolveAll","subscriberId","rejectAll","reason","addSubscriber","catch","existingRequest","rejectSubscription","subscriptions","findIndex","sub","rejecters","removeSubscriber","hasSubscriber","isSubscribed","WorkerMsgType","WorkerResponseResult","WorkerEventType","rebuildLoadSpec","spec","subregion","copy","BitroundCodec","kind","configuration","_meta","keepbits","fromConfig","encode","_arr","decode","LITTLE_ENDIAN_OS","Uint32Array","buffer","byteOffset","byteLength","system_is_little_endian","bytes_per_element","TypedArray","BYTES_PER_ELEMENT","BytesCodec","endian","data_type","sample","bytes","stride","Crc32cCodec","GzipCodec","_bytes","format","throw_on_nan_replacer","_key","isNaN","POSITIVE_INFINITY","NEGATIVE_INFINITY","sort_keys_replacer","Object","sort","reduce","sorted","JsonCodec","encoding","skipkeys","ensure_ascii","check_circular","allow_nan","sort_keys","indent","strict","separators","buf","replacer_functions","items","replacer","new_value","sub_replacer","json_str","JSON","stringify","replace","chr","full_str","charCodeAt","toString","substring","TextEncoder","pop","proxy","TransposeCodec","order","rank","inverseOrder","x","source","s","index","entry","get_order","dim","matches_order","out","chars","empty_like","n_dims","src_data","out_data","src_idx","out_idx","convert_array_order","VLenUTF8","_chunk","decoder","TextDecoder","view","DataView","getUint32","pos","item_length","ZlibCodec","registry","m","default","create_codec_pipeline","chunk_metadata","codecs","load_codecs","codec","array_to_array","array_to_bytes","bytes_to_bytes","chunk_meta","Codec","MAX_BIG_UINT","create_sharded_chunk_getter","location","shard_shape","encode_shard_key","sharding_config","store","get_range","bind","index_shape","d","chunk_shape","index_codec","index_codecs","chunk_coord","shard_coord","floor","shard_path","checksum_size","index_size","linear_offset","acc","sel","Location","Group","metadata","attrs","attributes","get_array_order","maybe_transpose_codec","CONTEXT_MARKER","get_context","fill_value","shared_context","encode_chunk_key","chunk_key_encoding","native_order","get_strides","get_chunk_bytes","chunk_grid","chunk_coords","chunk_key","chunk_path","create_context","dtype","context","maybe_bytes","is","query","IndexError","msg","IntDimIndexer","dim_sel","dim_len","dim_chunk_len","nitems","trunc","err_boundscheck","normalize_integer_selection","dim_chunk_ix","dim_offset","dim_chunk_sel","SliceDimIndexer","stop","step","nchunks","err_negative_step","ceil","dim_chunk_ix_from","dim_chunk_ix_to","dim_limit","dim_out_offset","dim_chunk_sel_start","remainder","dim_chunk_sel_stop","dim_out_sel","BasicIndexer","dim_indexers","selection","normalized","err_too_many_indices","check_selection_length","normalize_selection","ixr","sixr","dim_projections","p","mapping","to","object_array_view","subarray","compat_chunk","globalThis","setter","prepare","set_scalar","dest","set_scalar_binary","get_typed_array_constructor","compat_scalar","set_from_chunk","projections","set_from_chunk_binary","indexer","create_queue","onIdle","unwrap","indices_len","out_selection","slices","curr_stride","len","proj","projs","dstride","dstrides","sstride","sstrides","sfrom","sstep","product","iterables","iterators","it","results","next","r","done","slice_indices","step_is_negative","lower","upper","fn","all","VERSION_COUNTER","version_counts","WeakMap","get_counts","counts","v2","v3","increment","version","version_max","create_version_counter","open_array_v2","open_group_v2","open","open_primary","open_secondary","err","loc","meta_bytes","load_attrs","node","meta_doc","node_type","_open_v3","BoolArray","ArrayBuffer","ByteStringArray","_data","values","encoded","UnicodeStringArray","Int32Array","str","String","fromCodePoint","codePointAt","json_decode_object","parse","byteswap_inplace","numFlips","endByteIndex","j","get_ctr","match","ctr","int8","Int8Array","int16","Int16Array","int32","int64","BigInt64Array","uint8","uint16","Uint16Array","uint32","uint64","BigUint64Array","float16","Float16Array","float32","Float32Array","float64","Float64Array","bool","assert","create_chunk_key_encoder","separator","v2_to_v3_array_metadata","rest","b1","i1","u1","i2","u2","i4","u4","i8","u8","f2","f4","f8","coerce_dtype","id","filters","compressor","zarr_format","dimension_separator","v2_to_v3_group_metadata","is_dtype","is_boolean","is_string","is_bigint","is_object","is_sharding_codec","ensure_correct_scalar","BigInt","rethrow_unless","error","errors","ErrorClass","expression","decompress","signal","Response","body","decompressedResponse","pipeThrough","DecompressionStream","throwIfAborted"],"sourceRoot":""}