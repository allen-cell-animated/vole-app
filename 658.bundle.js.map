{"version":3,"file":"658.bundle.js","mappings":"iKAUO,SAASA,EAAWC,GACzB,OAAO,IAAI,MAAQA,EAAWC,MAAM,GAAID,EAAWC,MAAM,GAAID,EAAWC,MAAM,GAChF,CCVO,SAASC,IACd,MAAO,CACLC,KAAM,GACNC,cAAe,CAAC,EAAG,GACnBC,cAAe,CAAC,EAAG,EAAG,GACtBC,gBAAiB,CAAC,EAAG,EAAG,GACxBC,qBAAsB,CAAC,GACvBC,aAAc,CAAC,KACfC,cAAe,CAAC,CAAC,IAAK,IAAK,MAC3BC,gBAAiB,EACjBC,oBAAqB,CAAC,CACpBV,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBW,QAAS,CAAC,EAAG,EAAG,EAAG,EAAG,GACtBC,UAAW,GACXC,SAAU,GACVC,SAAU,UAEZC,UAAW,CACTC,YAAa,CAAC,EAAG,EAAG,GACpBC,SAAU,CAAC,EAAG,EAAG,GACjBC,MAAO,CAAC,EAAG,EAAG,IAGpB,CACO,MAAMC,EACX,WAAAC,CAAYC,GACVC,KAAKD,UAAYA,GAzBZ,CACLnB,KAAM,GACNC,cAAe,CAAC,EAAG,GACnBC,cAAe,CAAC,EAAG,EAAG,GACtBC,gBAAiB,CAAC,EAAG,EAAG,GACxBC,qBAAsB,CAAC,GACvBC,aAAc,CAAC,KACfC,cAAe,CAAC,CAAC,IAAK,IAAK,MAC3BC,gBAAiB,EACjBC,oBAAqB,CAAC,CACpBV,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBW,QAAS,CAAC,EAAG,EAAG,EAAG,EAAG,GACtBC,UAAW,GACXC,SAAU,GACVC,SAAU,UAEZC,UAAW,CACTC,YAAa,CAAC,EAAG,EAAG,GACpBC,SAAU,CAAC,EAAG,EAAG,GACjBC,MAAO,CAAC,EAAG,EAAG,IAOlB,CACA,oBAAIK,GACF,OAAOD,KAAKD,UAAUX,oBAAoBY,KAAKD,UAAUZ,gBAC3D,CAGA,eAAIe,GACF,OAAOF,KAAKD,UAAUf,qBAAqBmB,QAAO,CAACC,EAAGC,IAAMD,EAAIC,GAAG,EACrE,CAGA,wBAAIrB,GACF,OAAOgB,KAAKD,UAAUf,oBACxB,CAGA,gBAAIsB,GACF,OAAO9B,EAAWwB,KAAKD,UAAUX,oBAAoB,GACvD,CAGA,cAAIZ,GACF,OAAOA,EAAWwB,KAAKC,iBACzB,CAGA,qBAAIM,GACF,OD3C8B9B,EC2CLuB,KAAKD,UAAUX,oBAAoB,GD1CvD,IAAI,MAAQX,EAAWY,QAAQ,GAAIZ,EAAWY,QAAQ,GAAIZ,EAAWY,QAAQ,IAD/E,IAA2BZ,CC4ChC,CAGA,eAAI+B,GACF,OAAOR,KAAKD,UAAUX,oBAAoB,GAAGE,SAC/C,CAGA,SAAImB,GAEF,OAAOT,KAAKC,iBAAiBvB,MAAM,EACrC,CAGA,aAAIgC,GAEF,OAAOV,KAAKC,iBAAiBZ,QAAQ,EACvC,CAGA,YAAIE,GACF,OAAOS,KAAKC,iBAAiBV,QAC/B,CAGA,uBAAIoB,GACF,OAAOX,KAAKD,UAAUX,oBAAoBwB,MAC5C,CAGA,gBAAI3B,GACF,OAAOe,KAAKD,UAAUd,YACxB,CAGA,iBAAIC,GACF,OAAOc,KAAKD,UAAUb,aACxB,CAGA,iBAAIJ,GACF,OAAO,IAAI,SAAWkB,KAAKD,UAAUjB,cACvC,CAGA,mBAAIC,GACF,OAAO,IAAI,SAAWiB,KAAKD,UAAUhB,gBACvC,CACA,mBAAII,GACF,OAAOa,KAAKD,UAAUZ,eACxB,CAMA,iBAAIN,GACF,OAAO,IAAI,SAAWmB,KAAKD,UAAUlB,cACvC,CACA,aAAIY,GACF,MAAO,CACLC,YAAa,IAAI,SAAWM,KAAKD,UAAUN,UAAUC,aACrDC,SAAU,IAAI,SAAWK,KAAKD,UAAUN,UAAUE,UAClDC,MAAO,IAAI,SAAWI,KAAKD,UAAUN,UAAUG,OAEnD,EAEK,SAASiB,EAAiBd,GAC/B,MAAM,cACJlB,GACEkB,EACEe,EAAUf,EAAUX,oBAAoBW,EAAUZ,iBAExD,MAAO,CAACN,EAAc,GAAKiC,EAAQpC,MAAM,GAAIG,EAAc,GAAKiC,EAAQpC,MAAM,GAChF,C,2EC9HO,IAAIqC,EAAmC,SAAUA,GAOtD,OANAA,EAA6B,QAAI,UACjCA,EAA+B,UAAI,YACnCA,EAA+B,UAAI,YACnCA,EAAsC,iBAAI,mBAC1CA,EAAsC,iBAAI,mBAC1CA,EAA+C,0BAAI,4BAC5CA,CACT,CAR8C,CAQ5C,CAAC,GACI,MAAMC,UAAwBC,MACnC,WAAAnB,CAAYoB,EAASC,GACnBC,MAAMF,EAASC,GACfnB,KAAKpB,KAAO,kBACZoB,KAAKqB,KAAOF,GAASE,MAAQN,EAAoBO,OACnD,EAUK,SAASC,EAAoBL,EAAU,mDAAoDG,EAAON,EAAoBO,QAASE,GACpI,OAAOC,IACL,QAAeC,IAAXF,GAAwBC,IAAMD,EAChC,OAAOC,EAET,GAAIA,aAAaT,EACf,MAAMS,EAGR,MADAE,QAAQC,IAAI,8BAA8BH,KACpC,IAAIT,EAAgBE,EAAS,CACjCG,OACAQ,MAAOJ,GACP,CAEN,CAnBA,IAAkBK,IAAI,oBAAqB,KAC3C,IAAkBA,IAAI,WAAY,KAClC,IAAkBA,IAAI,kBAAmBd,E,kCC1BzC,MAAMe,EAAWC,GAAOA,EAAIC,OAAMC,GAAKA,IAAMF,EAAI,KAC3CG,EAAQ,CAACH,EAAKI,EAAKC,KACvB,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAGC,IACrBN,EAAIO,KAAKH,EACX,EAEII,EAAmBC,IACvB,MAAMC,EAASD,GAAO,EACtB,OAAOC,EAASC,OAAkB,IAAXD,EAAa,EAEtC,SAASE,EAAaR,EAAKS,GACrBT,EAAMS,EAAO,KACfA,EAAO,GAAKT,GAEVA,EAAMS,EAAO,KACfA,EAAO,GAAKT,EAEhB,CAQe,MAAMU,EACnB,WAAAhD,CAAYiD,EAAQC,EAAuBC,EAAsBC,EAAoBC,GAAyB,GAE5G,MAAMC,EAAU,CAAC,CAACC,KAAU,KAAY,CAACA,KAAU,KAAY,CAACA,KAAU,KAAY,CAACA,KAAU,MACjG,IAAK,MAAMC,KAASP,EAClBH,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAC/BR,EAAaU,EAAM,GAAIF,EAAQ,IAIjC,GAAIA,EAAQG,OAAOC,MAAKpB,IAAQO,OAAOc,SAASrB,KAG9C,OAFApC,KAAK0D,gBAAkB,QACvB1D,KAAK2D,wBAA0B,IAKjC3D,KAAK0D,gBAAkB,GACvB1D,KAAK2D,wBAA0B,GAK/B,IAAK,MAAOC,EAAWC,KAAUT,EAAQG,OAAOO,UAAW,CACzD,MAAMC,EAAYH,GAAa,EACzBI,EAAaD,EAAYpB,OAAqB,IAAdoB,GACtC,IAAIE,EACJ,GAAgB,EAAZL,EAAe,CAGjB,MAAMM,EAAgBjB,EAAqBkB,KAAIC,GACtCC,KAAKC,IAAIT,EAAQb,EAAsBe,GAAYK,EAAUJ,GAAc,KAIpF,GAAIjC,EAASmC,GACXD,EAAMC,EAAc,OACf,CAELD,EAAM,GACN,IAAK,MAAO3B,EAAGiC,KAAcL,EAAcJ,UACzC3B,EAAM8B,EAAKM,EAAWtB,EAAqBX,GAAG,GAElD,CAEF,MAGE2B,EAAMI,KAAKG,IAAIX,EAAQb,EAAsBe,GAAY,GAE3D,MAAMU,EAAiB,CACrBb,YACAC,QACAI,MACAlB,OAAQ,IAENG,GAAsBA,EAAmBwB,SAASd,GACpD5D,KAAK2D,wBAAwBpB,KAAKkC,GAG7BtB,GACHnD,KAAK0D,gBAAgBnB,KAAKkC,EAGhC,CAGA,IAAK,MAAMnB,KAASP,EAAQ,CAC1B,IAAK,MAAMN,KAAOzC,KAAK0D,gBACjBJ,EAAMd,EAAiBC,EAAImB,cAAgBnB,EAAIoB,OACjDpB,EAAIM,OAAOR,KAAKe,GAGpB,IAAK,MAAMb,KAAOzC,KAAK2D,wBACjBL,EAAMd,EAAiBC,EAAImB,cAAgBnB,EAAIoB,OACjDpB,EAAIM,OAAOR,KAAKe,EAGtB,CACF,CACA,wBAAQqB,CAAkBC,GACxB,IAAIC,EAAS,EACb,KAAOD,EAAWhE,OAAS,GAAG,CAE5BgE,EAAaA,EAAWE,QAAOrC,IAC7B,MAAMwB,EAAMc,MAAMC,QAAQvC,EAAIwB,KAAOI,KAAKG,OAAO/B,EAAIwB,KAAOxB,EAAIwB,IAChE,OAAoB,EAAhBxB,EAAImB,UACCnB,EAAIoB,MAAQgB,GAAUZ,EAEtBxB,EAAIoB,MAAQgB,GAAUZ,CAC/B,IAIF,IAAK,MAAMxB,KAAOmC,EAAY,CAC5B,MAAMK,EAAYJ,GAA0B,EAAhBpC,EAAImB,UAAgB,GAAK,GACrD,IAAK,MAAMN,KAASb,EAAIM,OAAQ,CAE9B,GAAIgC,MAAMC,QAAQvC,EAAIwB,MAAQX,EAAMd,EAAiBC,EAAImB,YAAcqB,EAAYxC,EAAIwB,IAAIX,EAAM,IAC/F,SAEF,MAAM4B,EAAW5B,EAAM6B,QACvBD,EAAS1C,EAAiBC,EAAImB,aAAeqB,QACvCC,CACR,CACF,CACAL,GAAU,CACZ,CACF,CACA,EAAEO,OAAOC,YAEP,GAAIrF,KAAK2D,wBAAwB/C,OAAS,EACxC,IAAK,MAAM0C,KAASR,EAAsB6B,kBAAkB3E,KAAK2D,+BACzDL,EAKV,IAAK,MAAMA,KAASR,EAAsB6B,kBAAkB3E,KAAK0D,uBACzDJ,CAEV,E,6FC9IK,SAASgC,EAAcC,GAC5B,QAAc7D,IAAV6D,EACF,OAEF,MAAMC,EAAS,qDAAqDC,KAAKF,GACzE,OAAIC,EACK,CAACE,SAASF,EAAO,GAAI,IAAKE,SAASF,EAAO,GAAI,IAAKE,SAASF,EAAO,GAAI,UAE9E,CAEJ,CAGO,SAASG,EAAqBC,GACnC,GAAIA,EAAIC,eAAeC,SAAU,CAC/B,MAAM,SACJA,GACEF,EAAIC,cACFE,EAAQ,GACRC,EAAS,GACf,IAAK,IAAI1D,EAAI,EAAGA,EAAIwD,EAASlF,OAAQ0B,IAAK,CACxC,MAAM2D,EAAUH,EAASxD,GACzByD,EAAMxD,KAAK0D,EAAQC,OAAS,WAAW5D,EAAIsD,EAAIO,iBAC/CH,EAAOzD,KAAK+C,EAAcW,EAAQV,OACpC,CACA,MAAO,CACLQ,QACAC,SAEJ,CACA,MAAMI,EAAOR,EAAIS,UAAU,GACrBzF,EAASwF,EAAO,EAAI,EAAIR,EAAIU,YAAY,GAAG5H,MAAM0H,GAOvD,MAAO,CACLL,MAPYhB,MAAMwB,KAAK,CACvB3F,WACC,CAAC4F,EAAGC,IAAQ,WAAWA,EAAMb,EAAIO,kBAMlCH,OALajB,MAAMwB,KAAK,CACxB3F,WACC,KAAe,IAKpB,CAGO,MAAM8F,EAAoB,EAAEC,EAAGC,EAAGC,KAAO,EAAIlE,OAAOgE,GAAK,GAAKhE,OAAOiE,GAAK,GAAKjE,OAAOkE,GAAK,GAC3F,SAASC,EAAiBC,GAC/B,MAAMV,EAAY,EAAE,GAAI,GAAI,GAAI,GAAI,GAC9BW,EAAY,CAAC,IAAK,IAAK,IAAK,IAAK,KACvCD,EAAKE,SAAQ,CAACC,EAAMT,KAClB,MAAMU,EAAUH,EAAUI,QAAQF,EAAKtI,MACvC,KAAIuI,GAAW,GAGb,MAAM,IAAI,KAAgB,8BAA8BD,EAAKtI,OAAQ,CACnEyC,KAAM,KAAoBgG,mBAH5BhB,EAAUc,GAAWV,CAKvB,IAIF,MAAMa,GAA4B,IAAlBjB,EAAU,GAC1B,GAAIiB,IAA6B,IAAlBjB,EAAU,GACvB,MAAM,IAAI,KAAgB,gBAAgBiB,EAAU,OAAS,qBAAsB,CACjFjG,KAAM,KAAoBgG,mBAG9B,OAAOhB,CACT,CAGO,SAASkB,EAAiBC,EAAWC,GAC1C,MAAMC,EAAUhB,EAAkBe,GAC5BjC,EAAST,MAAM2C,GACrB,IAAIC,EAAS,EAWb,OAVAF,EAAWR,SAAQ,CAAC7E,EAAKqE,KACvB,GAAIrE,GAAO,EAAG,CACZ,GAAIA,GAAOsF,EACT,MAAM,IAAI,KAAgB,kCAAkCtF,IAAO,CACjEf,KAAM,KAAoBgG,mBAG9B7B,EAAOmC,KAAYH,EAAUf,EAC/B,KAEKjB,CACT,CAGO,SAASoC,EAAaC,EAAeJ,EAAYK,GACtD,MAAMtC,EAAS,CAACsC,EAAcA,EAAcA,EAAcA,EAAcA,GAWxE,OAVAL,EAAWR,SAAQ,CAAC7E,EAAKqE,KACvB,GAAIrE,GAAO,EAAG,CACZ,GAAIA,GAAOyF,EAAcjH,OACvB,MAAM,IAAI,KAAgB,kCAAkCwB,IAAO,CACjEf,KAAM,KAAoBgG,mBAG9B7B,EAAOiB,GAAOoB,EAAczF,EAC9B,KAEKoD,CACT,CAGO,SAASuC,EAASC,EAASP,GAChC,MAAMQ,EAAaD,EAAQE,0BAC3B,QAAmBxG,IAAfuG,EAEF,OADAtG,QAAQwG,KAAK,0EACN,CAAC,EAAG,EAAG,EAAG,EAAG,GAItB,MAIMC,EAAiBH,EAAWI,MAJT1B,GAAgB,UAAXA,EAAEtF,OAKhC,OAAK+G,EAKER,EADOQ,EAAexI,MAAMuF,QACRsC,EAAY,IAJrC9F,QAAQwG,KAAK,yFACN,CAAC,EAAG,EAAG,EAAG,EAAG,GAIxB,CAQA,SAASG,EAAqBC,EAAMC,EAAQC,EAAMC,GAChD,MAEMC,GAFKH,EAAO,IAAM,EAAID,EAAK7J,MAAM8J,EAAO,IAAM,IACzCE,EAAO,IAAM,EAAID,EAAK/J,MAAMgK,EAAO,IAAM,GAE9CE,EAAQL,EAAK7J,MAAM8J,EAAO,IAAMC,EAAK/J,MAAMgK,EAAO,IAClDG,EAAQN,EAAK7J,MAAM8J,EAAO,IAAMC,EAAK/J,MAAMgK,EAAO,IACxD,OAAc,IAAVC,GAAyB,IAAVC,GAAyB,IAAVC,EACzB,EACEF,GAAS,GAAKC,GAAS,GAAKC,GAAS,GACtC,EACCF,GAAS,GAAKC,GAAS,GAAKC,GAAS,EACvC,OAEP,CAEJ,CACA,MACMC,EAAc,CAAC1I,EAAGC,IAAMgE,KAAK0E,IAAI3I,EAAIC,GAD3B,KAEhB,SAAS2I,EAAwBC,EAAMC,EAAQC,EAAMC,GACnD,MAAMC,EAAStB,EAASkB,EAAKK,mBAAmBC,SAASL,GAASD,EAAK5C,WACjEmD,EAASzB,EAASoB,EAAKG,mBAAmBC,SAASH,GAASD,EAAK9C,WACvE,OAAOyC,EAAYO,EAAO,GAAIG,EAAO,KAAOV,EAAYO,EAAO,GAAIG,EAAO,KAAOV,EAAYO,EAAO,GAAIG,EAAO,GACjH,CAYO,SAASC,EAAuBC,GACrC,GAAIA,EAAQ9I,OAAS,EACnB,OAIF,MAAM+I,EAAgB5E,MAAMwB,KAAK,CAC/B3F,OAAQ8I,EAAQ9I,SACf,IAAM,KACHgJ,EAAe7E,MAAMwB,KAAK,CAC9B3F,OAAQ8I,EAAQ9I,SACf,IAAM,KAGHiJ,EAAe,IAAI9E,MAAM2E,EAAQ9I,QAAQkJ,KAAK,GACpD,KAAOD,EAAa5H,OAAM,CAACG,EAAKqE,IAAQrE,EAAMsH,EAAQjD,GAAKH,YAAY1F,UAAS,CAE9E,IAAImB,GAAW,EACXgI,EAAc,EACdC,EAAcN,EAAQ,GACtBO,EAAcD,EAAY1D,YAAYuD,EAAa,IACvD,IAAK,IAAIK,EAAa,EAAGA,EAAaR,EAAQ9I,OAAQsJ,IAAc,CAClE,MAAMC,EAAaT,EAAQQ,GACrBE,EAAaD,EAAW7D,YAAYuD,EAAaK,IACjDG,EAAW/B,EAAqB2B,EAAaD,EAAY3D,UAAW+D,EAAYD,EAAW9D,WACjG,GAAKgE,EA0BHtI,GAAW,EACPsI,EAAW,IACbN,EAAcG,EACdF,EAAcG,EACdF,EAAcG,OA9BH,CAEb,QAAiB1I,IAAb2I,EACF,MAAM,IAAI,KAAgB,4DAA6D,CACrFhJ,KAAM,KAAoBiJ,4BAMzBtB,EAAwBgB,EAAaH,EAAaE,GAAcI,EAAYN,EAAaK,KAI5FvI,QAAQwG,KAAK,6FAIf,MAAMoC,EAAWP,EAAY3D,UAAU,IAAM,EAAI4D,EAAYvL,MAAMsL,EAAY3D,UAAU,IAAM,EACzFmE,EAAWL,EAAW9D,UAAU,IAAM,EAAI+D,EAAW1L,MAAMyL,EAAW9D,UAAU,IAAM,EACxFkE,IAAaC,GAGf7I,QAAQwG,KAAK,6DAA6DoC,QAAeC,IAE7F,CAQF,CACA,GAAIzI,EAEF,IAAK,IAAIO,EAAI,EAAGA,EAAIuH,EAAajJ,OAAQ0B,IAAK,CAC5C,MAAM6H,EAAaT,EAAQpH,GACrBmI,EAAoBZ,EAAavH,GACvCqH,EAAcrH,GAAGC,KAAK4H,EAAW7D,YAAYmE,IAC7Cb,EAAatH,GAAGC,KAAK4H,EAAWb,mBAAmBC,SAASkB,IAC5DZ,EAAavH,IAAM,CACrB,MAGA,IAAK,MAAOmE,EAAKiE,KAAWb,EAAa/F,UAAW,CAClD,MAAMqG,EAAaT,EAAQjD,GACrB2D,EAAaD,EAAW7D,YAAYoE,GAEzB,IADApC,EAAqB2B,EAAaD,EAAY3D,UAAW+D,EAAYD,EAAW9D,aAE/FwD,EAAapD,IAAQ,EAEzB,CAEJ,CACA,GAAsC,IAAlCiD,EAAQ,GAAGpD,YAAY1F,OACzB,MAAM,IAAI,KAAgB,sFAAuF,CAC/GS,KAAM,KAAoBiJ,4BAG9B,IAAK,IAAIhI,EAAI,EAAGA,EAAIoH,EAAQ9I,OAAQ0B,IAClCoH,EAAQpH,GAAGgE,YAAcqD,EAAcrH,GACvCoH,EAAQpH,GAAGgH,mBAAmBC,SAAWK,EAAatH,EAE1D,C,kEC9PO,MAAMqI,EAAkBC,GAAQA,EAAKC,KAAOD,EACnD,SAASE,EAAiBC,EAAKC,GAC7B,MAAsB,iBAARD,GAA4B,OAARA,GAAgBC,KAAQD,CAC5D,CACA,SAASE,EAAsBF,EAAKC,EAAMpM,EAAO,QAC/C,IAAKkM,EAAiBC,EAAKC,GACzB,MAAM,IAAI,KAAgB,GAAGpM,yCAA4CoM,KAAS,CAChF3J,KAAM,KAAoBgG,kBAGhC,CACA,SAAS6D,EAAkBH,EAAKC,EAAMpM,EAAO,QAC3C,IAAKmG,MAAMC,QAAQ+F,EAAIC,IACrB,MAAM,IAAI,KAAgB,GAAGpM,qBAAwBoM,qBAAyB,CAC5E3J,KAAM,KAAoBgG,kBAGhC,CAIO,SAAS8D,EAA6BP,EAAMhM,EAAO,QAExDqM,EAAsBL,EAAM,cAAehM,GAC3CsM,EAAkBN,EAAM,cAAehM,EACzC,CAOO,SAASwM,EAAwBR,EAAMS,EAAgB,EAAGzM,EAAO,QAEtE,MAAM0M,EAAiBV,EAAKW,YAAYF,GACxC,IAAKC,EACH,MAAM,IAAI,KAAgB,GAAG1M,uDAA0DyM,IAAiB,CACtGhK,KAAM,KAAoBgG,mBAG9B,MACMmE,EAAiB,GAAG5M,gBAAmByM,IADlBP,EAAiBQ,EAAgB,QAAU,MAAMA,EAAe1M,QAAU,KAIrGqM,EAAsBK,EAAgB,OAAQE,GAC9CN,EAAkBI,EAAgB,OAAQE,GAC1CF,EAAevE,KAAKE,SAAQ,CAACC,EAAM5E,IAAM2I,EAAsB/D,EAAM,OAAQ,GAAGsE,UAAuBlJ,OAGvG2I,EAAsBK,EAAgB,WAAY1M,GAClDsM,EAAkBI,EAAgB,WAAY1M,GAC9C0M,EAAe/B,SAAStC,SAAQ,CAACwE,EAAMnJ,IAAM2I,EAAsBQ,EAAM,OAAQ,GAAGD,aAA0BlJ,MAChH,C,iBC1CO,SAASoJ,EAAYC,EAAK9G,EAAQjE,EAAQgL,EAAO,CAAC,GAWrD,YAVelK,IAAXmD,QAAmCnD,IAAXd,IAExBgL,EAAO,IACAA,EACHC,QAAS,IACFD,EAAKC,QACRC,MAAO,SAASjH,KAAUA,EAASjE,EAAS,OAIjDmL,MAAMJ,EAAKC,EACtB,CC5BA,SAASI,EAAQC,EAAMC,GACnB,MAAMC,EAAuB,iBAATF,EAAoB,IAAIG,IAAIH,GAAQA,EACnDE,EAAKE,SAASC,SAAS,OAExBH,EAAKE,UAAY,KAErB,MAAME,EAAW,IAAIH,IAAIF,EAAK/G,MAAM,GAAIgH,GAGxC,OADAI,EAASC,OAASL,EAAKK,OAChBD,CACX,CACAE,eAAeC,EAAgBC,GAC3B,GAAwB,MAApBA,EAASC,OAAb,CAGA,GAAwB,MAApBD,EAASC,QAAsC,MAApBD,EAASC,OACpC,OAAO,IAAIC,iBAAiBF,EAASG,eAEzC,MAAM,IAAI7L,MAAM,8BAA8B0L,EAASC,UAAUD,EAASI,aAJ1E,CAKJ,C,yBAyDA,QA9BA,MACIpB,IACA,GACA,GACA,WAAA7L,CAAY6L,EAAKxK,EAAU,CAAC,GACxBnB,KAAK2L,IAAMA,EACX3L,MAAK,EAAamB,EAAQ6L,WAAa,CAAC,EACxChN,MAAK,EAAsBmB,EAAQ8L,mBAAoB,CAC3D,CACA,GAAYD,GACR,OD3BmBE,EC2BDlN,MAAK,ED3BYmN,EC2BAH,EDzBhC,IACAE,KACAC,EACHtB,QAAS,IACFqB,EAAerB,WACfsB,EAAiBtB,UAPzB,IAAoBqB,EAAgBC,CC4BvC,CACA,SAAMC,CAAIC,EAAKlM,EAAU,CAAC,GACtB,IAAImM,EAAOtB,EAAQhM,KAAK2L,IAAK0B,GAAKC,KAElC,OAAOZ,QADcX,MAAMuB,EAAMtN,MAAK,EAAYmB,IAEtD,CACA,cAAMoM,CAASF,EAAKG,EAAOrM,EAAU,CAAC,GAClC,IAEIwL,EAFAhB,EAAMK,EAAQhM,KAAK2L,IAAK0B,GACxBI,EAAOzN,MAAK,EAAYmB,GAQ5B,OALIwL,EADA,iBAAkBa,QA/C9Bf,eAA4Bd,EAAK+B,EAAeD,EAAME,GAClD,GAAIA,EACA,OAAO5B,MAAMJ,EAAK,IACX8B,EACH5B,QAAS,IAAK4B,EAAK5B,QAASC,MAAO,UAAU4B,OAGrD,IAAIf,QAAiBZ,MAAMJ,EAAK,IAAK8B,EAAMG,OAAQ,SACnD,IAAKjB,EAASkB,GAEV,OAAOlB,EAEX,IAAImB,EAAiBnB,EAASd,QAAQuB,IAAI,kBACtCxM,EAAS+B,OAAOmL,GACpB,OAAOpC,EAAYC,EAAK/K,EAAS8M,EAAe9M,EAAQ6M,EAC5D,CAiC6BM,CAAapC,EAAK6B,EAAMQ,aAAcP,EAAMzN,MAAK,SAGjD0L,EAAYC,EAAK6B,EAAM3I,OAAQ2I,EAAM5M,OAAQ6M,GAE3Df,EAAgBC,EAC3B,G,aCzEW,SAASsB,EAAUC,EAAOC,EAAUC,EAAOC,GACxD,MACMC,GADOH,EAAS7B,SAAS,KAAO6B,EAAShJ,MAAM,GAAI,GAAKgJ,GACvCD,EAAMhC,MAAQgC,EAAMhC,KAAKI,SAAS,KAAO,GAAK,KAC/DiC,EAAW9B,MAAO+B,EAAQ5C,KAC1BA,GAAM6C,YAAc7C,EAAK8C,aAC3B9C,EAAK8C,YAAYF,EAAQ5C,EAAK6C,YAEhC,MAAME,EAAUL,EAAUE,EAAOI,KAAK,KAChCC,EAAcT,GAAOhB,IAAIuB,GAC/B,GAAIE,IAAe,OAAQA,GACzB,OAAOA,EAET,IAAIrJ,EAOJ,OALEA,EADE6I,GAASzC,GAAM6C,iBACFJ,EAAMS,WAAWH,EAAS/C,GAAM6C,YAAY,IAAMP,EAAMK,SAASC,EAAQ5C,IAAOA,EAAKmD,kBAErFb,EAAMK,SAASC,EAAQ5C,GAExCwC,GAAOY,OAAOL,EAASnJ,GAChBA,CAAM,EAEf,OAAO,IAAIyJ,MAAMf,EAAO,CACtBd,IAAK,CAAC8B,EAAQlE,KACZ,GAAa,aAATA,EACF,OAAOuD,EAIT,MAAMY,EAAQD,EAAOlE,GACrB,OAAImE,aAAiBC,SACZ,YAAaC,GAClB,OAAOF,EAAMG,MAAMJ,EAAQG,EAC7B,EAEKF,CAAK,GAGlB,CACO,MAAMI,UAA0B,EACrC,WAAAzP,CAAY0P,EAASrO,GACnBC,MAAMoO,EAASrO,EACjB,CAIA,SAAMiM,CAAIC,EAAKlM,EAAU,CAAC,GACxB,IACE,aAAaC,MAAMgM,IAAIC,EAAKlM,EAE9B,CAAE,MAAOM,GACP,GAAIA,GAAGP,SAASuO,WAAW,kCACzB,OAEF,MAAMhO,CACR,CACF,E,kCCvDK,MAAMiO,EAAgC,oBAW9B,MAAMC,EA0BnB,WAAA7P,CAAY8P,EAAoB,GAAIC,EAAyB,GAC3D7P,KAAK8P,YAAc,IAAIC,IACvB/P,KAAKgQ,eAAiB,IAAIC,IAC1BjQ,KAAKqO,MAAQ,GACbrO,KAAKkQ,iBAAmB,GACxBlQ,KAAK4P,kBAAoBA,EACzB5P,KAAK6P,uBAAyBxL,KAAKC,IAAIsL,EAAmBC,EAC5D,CAQA,eAAAM,CAAgB9C,EAAK+C,GAInB,IAAIC,EAAgBC,EACpB,MAAMC,EAAU,IAAIC,SAAQ,CAACxE,EAASyE,KACpCJ,EAAiBrE,EACjBsE,EAAgBG,CAAM,IAGlBC,EAAc,CAClBrD,IAAKA,EACLsD,OAAQP,EACRpE,QAASqE,EACTI,OAAQH,EACRC,WAGF,OADAvQ,KAAK8P,YAAYhO,IAAIuL,EAAKqD,GACnBA,CACT,CAOA,iBAAAE,CAAkBvD,EAAKwD,GAErB,GAAI7Q,KAAK8P,YAAYgB,IAAIzD,GAAM,CAE7B,MAAMqD,EAAc1Q,KAAK8P,YAAY1C,IAAIC,GACrCqD,GAAeA,EAAYK,YAC7BC,aAAaN,EAAYK,WACzBL,EAAYK,eAAYrP,GAErB1B,KAAKqO,MAAM3J,SAAS2I,IAASrN,KAAKkQ,iBAAiBxL,SAAS2I,KAE3DwD,EACF7Q,KAAKkQ,iBAAiB3N,KAAK8K,GAE3BrN,KAAKqO,MAAM9L,KAAK8K,GAElBrN,KAAKiR,UAET,CACF,CAoBA,UAAAnC,CAAWzB,EAAK+C,EAAeS,GAAc,EAAOK,EAAU,GAC5D,GAAKlR,KAAK8P,YAAYgB,IAAIzD,GAYnB,CACL,MAAM8D,EAAmBnR,KAAKkQ,iBAAiB9I,QAAQiG,GACnD8D,GAAoB,IAAMN,GAG5B7Q,KAAKkQ,iBAAiBkB,OAAOD,EAAkB,GAC/CnR,KAAK4Q,kBAAkBvD,IACd6D,GAAW,GAGpBlR,KAAK4Q,kBAAkBvD,EAAKwD,EAEhC,KAxBgC,CAE9B,MAAMH,EAAc1Q,KAAKmQ,gBAAgB9C,EAAK+C,GAE9C,GAAIc,EAAU,EAAG,CACf,MAAMH,EAAYM,YAAW,IAAMrR,KAAK4Q,kBAAkBvD,EAAKwD,IAAcK,GAE7ER,EAAYK,UAAYA,CAC1B,MAEE/Q,KAAK4Q,kBAAkBvD,EAAKwD,EAEhC,CAaA,MAAMN,EAAUvQ,KAAK8P,YAAY1C,IAAIC,IAAMkD,QAC3C,IAAKA,EACH,MAAM,IAAItP,MAAM,gEAElB,OAAOsP,CACT,CAaA,WAAAe,CAAYC,EAAUV,GAAc,EAAOK,EAAU,IACnD,MAAMM,EAAW,GACjB,IAAK,IAAIlP,EAAI,EAAGA,EAAIiP,EAAS3Q,OAAQ0B,IAAK,CACxC,MAAMmP,EAAOF,EAASjP,GAChBiO,EAAUvQ,KAAK8O,WAAW2C,EAAKpE,IAAKoE,EAAKrB,cAAeS,EAAaK,EAAU5O,GACrFkP,EAASjP,KAAKgO,EAChB,CACA,OAAOiB,CACT,CAOA,aAAMP,GACJ,MAAMS,EAAc1R,KAAKgQ,eAAe2B,KACxC,GAAID,GAAe1R,KAAK4P,mBAA2C,IAAtB5P,KAAKqO,MAAMzN,SAAiB8Q,GAAe1R,KAAK6P,wBAA2D,IAAjC7P,KAAKkQ,iBAAiBtP,QAC3I,OAEF,MAAMgR,EAAa5R,KAAKqO,MAAMwD,SAAW7R,KAAKkQ,iBAAiB2B,QAC/D,IAAKD,EACH,OAEF,GAAI5R,KAAKgQ,eAAec,IAAIc,GAG1B,YADA5R,KAAKiR,UAGP,MAAMP,EAAc1Q,KAAK8P,YAAY1C,IAAIwE,GACzC,IAAKlB,EACH,OAEF,MAAMrD,EAAMqD,EAAYrD,IAExBrN,KAAKgQ,eAAe8B,IAAIzE,SAClBqD,EAAYC,SAASoB,KAAKrB,EAAY1E,QAAS0E,EAAYD,QACjEzQ,KAAKgQ,eAAegC,OAAO3E,GAC3BrN,KAAK8P,YAAYkC,OAAO3E,GACxBrN,KAAKiR,SACP,CAOA,aAAAgB,CAAc5E,EAAK6E,EAAexC,GAChC,IAAK1P,KAAK8P,YAAYgB,IAAIzD,GACxB,OAEF,MAAMqD,EAAc1Q,KAAK8P,YAAY1C,IAAIC,GACrCqD,IACEA,EAAYK,WAEdC,aAAaN,EAAYK,WAG3BL,EAAYD,OAAOyB,IAErB,MAAMC,EAAanS,KAAKqO,MAAMjH,QAAQiG,GACtC,GAAI8E,GAAc,EAChBnS,KAAKqO,MAAM+C,OAAOe,EAAY,OACzB,CACL,MAAMhB,EAAmBnR,KAAKkQ,iBAAiB9I,QAAQiG,GACnD8D,GAAoB,GACtBnR,KAAKkQ,iBAAiBkB,OAAOD,EAAkB,EAEnD,CACAnR,KAAK8P,YAAYkC,OAAO3E,GACxBrN,KAAKgQ,eAAegC,OAAO3E,EAC7B,CAMA,iBAAA+E,CAAkBF,EAAexC,GAE/B1P,KAAKqO,MAAQ,GACbrO,KAAKkQ,iBAAmB,GACxB,IAAK,MAAM7C,KAAOrN,KAAK8P,YAAYuC,OACjCrS,KAAKiS,cAAc5E,EAAK6E,EAE5B,CAOA,UAAAI,CAAWjF,GACT,OAAOrN,KAAK8P,YAAYgB,IAAIzD,EAC9B,CAOA,cAAAkF,CAAelF,GACb,OAAOrN,KAAKgQ,eAAec,IAAIzD,EACjC,E,gDCjQa,MAAMmF,EAenB,WAAA1S,CAAY8P,EAAmBC,GAE3B7P,KAAKqO,MAD0B,iBAAtBuB,QAAwDlO,IAAtBkO,EAC9B,IAAI,IAAaA,EAAmBC,GAEpCD,EAEf5P,KAAKyS,iBAAmB,EACxBzS,KAAK0S,YAAc,IAAI3C,IACvB/P,KAAKuR,SAAW,IAAIxB,GACtB,CAGA,UAAA4C,CAAWtF,EAAK8B,GACd,MAAMoC,EAAWvR,KAAKuR,SAASnE,IAAIC,GACnC,GAAIkE,EAAU,CACZ,IAAK,MAAM,QACTvF,EAAO,aACP4G,KACGrB,EACHvF,EAAQmD,GACRnP,KAAK0S,YAAYtF,IAAIwF,IAAeZ,OAAO3E,GAE7CrN,KAAKuR,SAASS,OAAO3E,EACvB,CACF,CAGA,SAAAwF,CAAUxF,EAAKyF,GACb,MAAMvB,EAAWvR,KAAKuR,SAASnE,IAAIC,GACnC,GAAIkE,EAAU,CACZ,IAAK,MAAM,OACTd,EAAM,aACNmC,KACGrB,EACHd,EAAOqC,GACP9S,KAAK0S,YAAYtF,IAAIwF,IAAeZ,OAAO3E,GAE7CrN,KAAKuR,SAASS,OAAO3E,EACvB,CACF,CAGA,aAAA0F,GACE,MAAMH,EAAe5S,KAAKyS,iBAG1B,OAFAzS,KAAKyS,mBACLzS,KAAK0S,YAAY5Q,IAAI8Q,EAAc,IAAI7C,KAChC6C,CACT,CAOA,UAAA9D,CAAWzB,EAAKuF,EAAcxC,EAAeS,EAAaK,GAQxD,GANAlR,KAAKqO,MAAMS,WAAWzB,EAAK+C,EAAeS,EAAaK,GAASa,MAAK5C,GAASnP,KAAK2S,WAAWtF,EAAK8B,KAAQ6D,OAAMF,GAAU9S,KAAK6S,UAAUxF,EAAKyF,KAC1I9S,KAAKuR,SAAST,IAAIzD,IACrBrN,KAAKuR,SAASzP,IAAIuL,EAAK,IAIrBuF,GAAgB5S,KAAKyS,kBAAoBG,EAAe,EAC1D,MAAM,IAAI3R,MAAM,2CAA2C2R,6BAG7D,IADmB5S,KAAK0S,YAAYtF,IAAIwF,GAEtC,MAAM,IAAI3R,MAAM,2CAA2C2R,sBAI7D,OAAO,IAAIpC,SAAQ,CAACxE,EAASyE,KAC3BzQ,KAAKuR,SAASnE,IAAIC,IAAM9K,KAAK,CAC3ByJ,UACAyE,SACAmC,iBAEF,MAAMnE,EAAazO,KAAK0S,YAAYtF,IAAIwF,GAClCK,EAAkBxE,GAAYrB,IAAIC,GACpC4F,EACFA,EAAgB1Q,KAAKkO,GAErBhC,GAAY3M,IAAIuL,EAAK,CAACoD,GACxB,GAEJ,CAMA,kBAAAyC,CAAmB7F,EAAKoD,EAAQyB,GAE9BzB,EAAOyB,GAGP,MAAMiB,EAAgBnT,KAAKuR,SAASnE,IAAIC,GACxC,IAAK8F,EAEH,OAGF,MAAM1M,EAAM0M,EAAcC,WAAUC,GAAOA,EAAI5C,SAAWA,IACtDhK,GAAO,GACT0M,EAAc/B,OAAO3K,EAAK,GAIxB0M,EAAcvS,OAAS,IAAMZ,KAAKqO,MAAMkE,eAAelF,KACzDrN,KAAKqO,MAAM4D,cAAc5E,EAAK6E,GAC9BlS,KAAKuR,SAASS,OAAO3E,GAEzB,CAGA,aAAA4E,CAAc5E,EAAKuF,EAAcV,GAC/B,MAAMzD,EAAazO,KAAK0S,YAAYtF,IAAIwF,GACxC,IAAKnE,EACH,OAAO,EAET,MAAM6E,EAAY7E,EAAWrB,IAAIC,GACjC,IAAKiG,IAAcA,EAAU1S,OAC3B,OAAO,EAET,IAAK,MAAM6P,KAAU6C,EACnBtT,KAAKkT,mBAAmB7F,EAAKoD,EAAQyB,GAGvC,OADAzD,EAAWuD,OAAO3E,IACX,CACT,CAGA,gBAAAkG,CAAiBX,EAAcV,GAC7B,MAAMiB,EAAgBnT,KAAK0S,YAAYtF,IAAIwF,GAC3C,GAAIO,EAAe,CACjB,IAAK,MAAO9F,EAAKiG,KAAcH,EAAcrP,UAC3C,IAAK,MAAM2M,KAAU6C,EACnBtT,KAAKkT,mBAAmB7F,EAAKoD,EAAQyB,GAGzClS,KAAK0S,YAAYV,OAAOY,EAC1B,CACF,CAGA,UAAAN,CAAWjF,GACT,OAAOrN,KAAKqO,MAAMiE,WAAWjF,EAC/B,CAGA,cAAAkF,CAAelF,GACb,OAAOrN,KAAKqO,MAAMkE,eAAelF,EACnC,CAGA,aAAAmG,CAAcZ,GACZ,OAAO5S,KAAK0S,YAAY5B,IAAI8B,EAC9B,CAGA,YAAAa,CAAab,EAAcvF,GACzB,OAAOrN,KAAK0S,YAAYtF,IAAIwF,IAAe9B,IAAIzD,KAAQ,CACzD,E,kCCzLF,MAAMqG,EAAgB,QAChBC,EAAiB,QACjBC,EAAoB,eACpBC,EAAiB,wCAMhB,SAASC,EAASnI,GACvB,IAAIoI,EAASpI,EAAIqI,OACjB,GAAID,EAAOtE,WAAWiE,GAAgB,CAEpC,MACMO,EADSF,EAAO5O,MAAMuO,EAAc9S,QACdsT,MAAM,KAClCH,EAAS,WAAWE,EAAa,uBAAuBA,EAAa9O,MAAM,GAAGyJ,KAAK,MACrF,MAAWmF,EAAOtE,WAAWkE,GAE3BI,EAASA,EAAOI,QAAQR,EAAgB,mCAC/BI,EAAOtE,WAAWmE,KAE3BG,EAASA,EAAOI,QAAQP,EAAmBC,IAE7C,OAAOE,CACT,C,qDCvBO,IAAIK,EAA6B,SAAUA,GAUhD,OATAA,EAAcA,EAAoB,KAAI,GAAK,OAC3CA,EAAcA,EAA6B,cAAI,GAAK,gBACpDA,EAAcA,EAA4B,aAAI,GAAK,eACnDA,EAAcA,EAA6B,cAAI,GAAK,gBACpDA,EAAcA,EAAyB,UAAI,GAAK,YAChDA,EAAcA,EAAgC,iBAAI,GAAK,mBACvDA,EAAcA,EAAgD,iCAAI,GAAK,mCACvEA,EAAcA,EAAgD,iCAAI,GAAK,mCACvEA,EAAcA,EAAoC,qBAAI,GAAK,uBACpDA,CACT,CAXwC,CAWtC,CAAC,GAOQC,EAAoC,SAAUA,GAIvD,OAHAA,EAAqBA,EAA8B,QAAI,GAAK,UAC5DA,EAAqBA,EAA4B,MAAI,GAAK,QAC1DA,EAAqBA,EAA4B,MAAI,GAAK,QACnDA,CACT,CAL+C,CAK7C,CAAC,GAGQC,EAA+B,SAAUA,GAKlD,OAHAA,EAAgBA,EAAiC,gBAAI,GAAK,kBAE1DA,EAAgBA,EAA8B,aAAI,GAAK,eAChDA,CACT,CAN0C,CAMxC,CAAC,E,gDC/BI,SAASC,EAAgBC,GAC9B,MAAO,IACFA,EACHC,UAAW,IAAI,OAAK,IAAI,OAAUC,KAAKF,EAAKC,UAAUnQ,MAAM,IAAI,OAAUoQ,KAAKF,EAAKC,UAAUjQ,MAElG,C,qFCUO,MAAMmQ,EACTC,KAAO,iBACP,WAAA9U,CAAY+U,EAAeC,IACvB,QAAOD,EAAcE,UAAY,EAAG,oCACxC,CACA,iBAAOC,CAAWH,EAAejK,GAC7B,OAAO,IAAI+J,EAAcE,EAAejK,EAC5C,CAKA,MAAAqK,CAAOC,GACH,MAAM,IAAIjU,MAAM,iHACpB,CAMA,MAAAkU,CAAOnT,GACH,OAAOA,CACX,ECtCJ,MAAMoT,EACN,WACI,MAAMhV,EAAI,IAAIiV,YAAY,CAAC,YAE3B,QAAkB,KADR,IAAIxI,WAAWzM,EAAEkV,OAAQlV,EAAEmV,WAAYnV,EAAEoV,YACxC,GACf,CALyBC,GAMzB,SAASC,EAAkBC,GACvB,MAAI,sBAAuBA,EAChBA,EAAWC,kBAGf,CACX,CACO,MAAMC,EACTjB,KAAO,iBACP,GACA,GACA,GACA,GACA,GACA,WAAA9U,CAAY+U,EAAejK,GACvB5K,MAAK,EAAU6U,GAAeiB,OAC9B9V,MAAK,GAAc,QAAQ4K,EAAKmL,WAChC/V,MAAK,EAAS4K,EAAKlM,MACnBsB,MAAK,GAAU,QAAY4K,EAAKlM,MAAO,KAGvC,MAAMsX,EAAS,IAAIhW,MAAK,EAAY,GACpCA,MAAK,EAAqBgW,EAAOJ,iBACrC,CACA,iBAAOZ,CAAWH,EAAejK,GAC7B,OAAO,IAAIiL,EAAWhB,EAAejK,EACzC,CACA,MAAAqK,CAAOjT,GACH,IAAIiU,EAAQ,IAAIpJ,WAAW7K,EAAIyJ,KAAK6J,QAIpC,OAHIF,GAAqC,QAAjBpV,MAAK,IACzB,QAAiBiW,EAAOP,EAAkB1V,MAAK,IAE5CiW,CACX,CACA,MAAAd,CAAOc,GAIH,OAHIb,GAAqC,QAAjBpV,MAAK,IACzB,QAAiBiW,EAAOP,EAAkB1V,MAAK,IAE5C,CACHyL,KAAM,IAAIzL,MAAK,EAAYiW,EAAMX,OAAQW,EAAMV,WAAYU,EAAMT,WAAaxV,MAAK,GACnFtB,MAAOsB,MAAK,EACZkW,OAAQlW,MAAK,EAErB,EClDG,MAAMmW,EACTvB,KAAO,iBACP,iBAAOI,GACH,OAAO,IAAImB,CACf,CACA,MAAAlB,CAAOzO,GACH,MAAM,IAAIvF,MAAM,kBACpB,CACA,MAAAkU,CAAOnT,GACH,OAAO,IAAI6K,WAAW7K,EAAIsT,OAAQtT,EAAIuT,WAAYvT,EAAIwT,WAAa,EACvE,ECTG,MAAMY,EACTxB,KAAO,iBACP,iBAAOI,CAAWxO,GACd,OAAO,IAAI4P,CACf,CACA,MAAAnB,CAAOoB,GACH,MAAM,IAAIpV,MAAM,iGACpB,CACA,YAAMkU,CAAOc,GACT,MAAMX,QAAe,QAAWW,EAAO,CAAEK,OAAQ,SACjD,OAAO,IAAIzJ,WAAWyI,EAC1B,ECVJ,SAASiB,EAAsBC,EAAMrH,GAIjC,OAHA,SAAQxM,OAAO8T,MAAMtH,GAAQ,0EAC7B,QAAOA,IAAUxM,OAAO+T,kBAAmB,+EAC3C,QAAOvH,IAAUxM,OAAOgU,kBAAmB,+EACpCxH,CACX,CAEA,SAASyH,EAAmBJ,EAAMrH,GAC9B,OAAOA,aAAiB0H,SAAW9R,MAAMC,QAAQmK,GAC3C0H,OAAOxE,KAAKlD,GACT2H,OACA3W,QAAO,CAAC4W,EAAQ1J,KACjB0J,EAAO1J,GAAO8B,EAAM9B,GACb0J,IACR,CAAC,GACF5H,CACV,CACO,MAAM6H,EACTnC,cACAD,KAAO,iBACP,GACA,GACA,WAAA9U,CAAY+U,EAAgB,CAAC,GACzB7U,KAAK6U,cAAgBA,EAErB,MAAM,SAAEoC,EAAW,QAAO,SAAEC,GAAW,EAAK,aAAEC,GAAe,EAAI,eAAEC,GAAiB,EAAI,UAAEC,GAAY,EAAI,UAAEC,GAAY,EAAI,OAAEC,EAAM,OAAEC,GAAS,GAAU3C,EACzJ,IAAI4C,EAAa5C,EAAc4C,WAC1BA,IAOGA,EAJCF,EAIY,CAAC,KAAM,MAHP,CAAC,IAAK,MAM3BvX,MAAK,EAAkB,CACnBiX,WACAC,WACAC,eACAC,iBACAC,YACAE,SACAE,aACAH,aAEJtX,MAAK,EAAkB,CAAEwX,SAC7B,CACA,iBAAOxC,CAAWH,GACd,OAAO,IAAImC,EAAUnC,EACzB,CACA,MAAAI,CAAOyC,GACH,MAAM,OAAEH,EAAM,SAAEN,EAAQ,aAAEE,EAAY,eAAEC,EAAc,UAAEC,EAAS,UAAEC,GAAetX,MAAK,GACvF,QAAoB,UAAbiX,EAAsB,sDAC7B,MAAMU,EAAqB,IAG3B,QAAOP,EAAgB,8FAClBC,GAEDM,EAAmBpV,KAAKgU,GAExBe,GAGAK,EAAmBpV,KAAKqU,GAE5B,MAAMgB,EAAQ7S,MAAMwB,KAAKmR,EAAIjM,MAG7B,IAAIoM,EAFJD,EAAMrV,KAAK,MACXqV,EAAMrV,KAAKmV,EAAIhZ,OAEXiZ,EAAmB/W,SACnBiX,EAAW,CAACxK,EAAK8B,KACb,IAAI2I,EAAY3I,EAChB,IAAK,IAAI4I,KAAgBJ,EACrBG,EAAYC,EAAa1K,EAAKyK,GAElC,OAAOA,CAAS,GAGxB,IAAIE,EAAWC,KAAKC,UAAUN,EAAOC,EAAUN,GAY/C,OAXIJ,IAKAa,EAAWA,EAAS7D,QAAQ,oBAAqBgE,IAC7C,MAAMC,EAAW,OAAOD,EAAIE,WAAW,GAAGC,SAAS,MAEnD,MAAO,MADSF,EAASG,UAAUH,EAASxX,OAAS,IAC/B,MAGvB,IAAI4X,aAAcvD,OAAO+C,EACpC,CACA,MAAA7C,CAAOc,GACH,MAAM,OAAEuB,GAAWxX,MAAK,GAExB,QAAOwX,EAAQ,uDACf,MAAMI,GAAQ,QAAmB3B,GAC3BvX,EAAQkZ,EAAMa,MAMpB,OALAb,EAAMa,OAEN,QAAO/Z,EAAO,qCAGP,CAAE+M,KADImM,EACElZ,QAAOwX,QAFP,QAAYxX,EAAO,KAGtC,E,cC3GJ,SAASga,EAAM1W,GACX,OAAIA,aAAe,MACfA,aAAe,MACfA,aAAe,KAEF,IAAIiN,MAAMjN,EAAK,CACxBoL,IAAG,CAAC8B,EAAQlE,IACDkE,EAAO9B,IAAIzK,OAAOqI,IAE7BlJ,IAAG,CAACoN,EAAQlE,EAAMmE,KAEdD,EAAOpN,IAAIa,OAAOqI,GAAOmE,IAClB,KAMZnN,CACX,CA0DO,MAAM2W,EACT/D,KAAO,iBACP,GACA,GACA,WAAA9U,CAAY+U,EAAejK,GACvB,IAAIuE,EAAQ0F,EAAc+D,OAAS,IAC/BC,EAAOjO,EAAKlM,MAAMkC,OAClBgY,EAAQ,IAAI7T,MAAM8T,GAClBC,EAAe,IAAI/T,MAAM8T,GAC7B,GAAc,MAAV1J,EACA,IAAK,IAAI7M,EAAI,EAAGA,EAAIuW,IAAQvW,EACxBsW,EAAMtW,GAAKA,EACXwW,EAAaxW,GAAKA,OAGrB,GAAc,MAAV6M,EACL,IAAK,IAAI7M,EAAI,EAAGA,EAAIuW,IAAQvW,EACxBsW,EAAMtW,GAAKuW,EAAOvW,EAAI,EACtBwW,EAAaxW,GAAKuW,EAAOvW,EAAI,OAIjCsW,EAAQzJ,EACRyJ,EAAM3R,SAAQ,CAAC8R,EAAGzW,MACd,aAA2BZ,IAApBoX,EAAaC,GAAkB,wBAAwBd,KAAKC,UAAU/I,MAC7E2J,EAAaC,GAAKzW,CAAC,IAG3BtC,MAAK,EAAS4Y,EACd5Y,MAAK,EAAgB8Y,CACzB,CACA,iBAAO9D,CAAWH,EAAejK,GAC7B,OAAO,IAAI+N,EAAe9D,EAAejK,EAC7C,CACA,MAAAqK,CAAOjT,GACH,OAxCR,SAAuBsB,EAAO4L,GAC1B,IAAI8J,EATR,SAAmB1V,GACf,IAAIuV,EAAOvV,EAAM5E,MAAMkC,OAEvB,OADA,QAAOiY,IAASvV,EAAM4S,OAAOtV,OAAQ,+CAC9B0C,EAAM4S,OACR/R,KAAI,CAAC8U,EAAG3W,KAAM,CAAG4T,OAAQ+C,EAAGC,MAAO5W,MACnCwU,MAAK,CAAC1W,EAAGC,IAAMA,EAAE6V,OAAS9V,EAAE8V,SAC5B/R,KAAKgV,GAAUA,EAAMD,OAC9B,CAEiBE,CAAU9V,GAEvB,OADA,QAAO0V,EAAOpY,SAAWsO,EAAOtO,OAAQ,qBACjCoY,EAAO/W,OAAM,CAACoX,EAAK/W,IAAM+W,IAAQnK,EAAO5M,IACnD,CAoCYgX,CAActX,EAAKhC,MAAK,GAEjBgC,EA7EnB,SAA6B4D,EAAKsJ,GAC9B,IAAIqK,EAlBR,SAAoBjW,EAAOsV,GACvB,IAAInN,EAUJ,OAPIA,EAFAnI,EAAMmI,gBAAgB,MACtBnI,EAAMmI,gBAAgB,KACf,IAAInI,EAAMxD,YAEjBwD,EAAMmI,KAAK7K,OAAQ0C,EAAMmI,KAAK+N,OAGvB,IAAIlW,EAAMxD,YAAYwD,EAAMmI,KAAK7K,QAErC,CACH6K,OACA/M,MAAO4E,EAAM5E,MACbwX,QAAQ,QAAY5S,EAAM5E,MAAOka,GAEzC,CAEca,CAAW7T,EAAKsJ,GACtBwK,EAAS9T,EAAIlH,MAAMkC,OACnB+Q,EAAO/L,EAAI6F,KAAK7K,OAChBsY,EAAQnU,MAAM2U,GAAQ5P,KAAK,GAC3B6P,EAAWjB,EAAM9S,EAAI6F,MACrBmO,EAAWlB,EAAMa,EAAI9N,MACzB,IAAK,IAAIoO,EAAU,EAAGA,EAAUlI,EAAMkI,IAAW,CAC7C,IAAIC,EAAU,EACd,IAAK,IAAIT,EAAM,EAAGA,EAAMK,EAAQL,IAC5BS,GAAWZ,EAAMG,GAAOE,EAAIrD,OAAOmD,GAEvCO,EAASE,GAAWH,EAASE,GAC7BX,EAAM,IAAM,EACZ,IAAK,IAAIG,EAAM,EAAGA,EAAMK,EAAQL,IAC5B,GAAIH,EAAMG,KAASzT,EAAIlH,MAAM2a,GAAM,CAC/B,GAAIA,EAAM,IAAMK,EACZ,MAEJR,EAAMG,GAAO,EACbH,EAAMG,EAAM,IAAM,CACtB,CAER,CACA,OAAOE,CACX,CAsDeQ,CAAoB/X,EAAKhC,MAAK,EACzC,CACA,MAAAmV,CAAOnT,GACH,MAAO,CACHyJ,KAAMzJ,EAAIyJ,KACV/M,MAAOsD,EAAItD,MACXwX,QAAQ,QAAYlU,EAAItD,MAAOsB,MAAK,GAE5C,EC7HG,MAAMga,EACTpF,KAAO,iBACP,GACA,GACA,WAAA9U,CAAYpB,GACRsB,MAAK,EAAStB,EACdsB,MAAK,GAAW,QAAYtB,EAAO,IACvC,CACA,iBAAOsW,CAAWxO,EAAGoE,GACjB,OAAO,IAAIoP,EAASpP,EAAKlM,MAC7B,CACA,MAAAuW,CAAOgF,GACH,MAAM,IAAIhZ,MAAM,0BACpB,CACA,MAAAkU,CAAOc,GACH,IAAIiE,EAAU,IAAIC,YACdC,EAAO,IAAIC,SAASpE,EAAMX,QAC1B7J,EAAO1G,MAAMqV,EAAKE,UAAU,GAAG,IAC/BC,EAAM,EACV,IAAK,IAAIjY,EAAI,EAAGA,EAAImJ,EAAK7K,OAAQ0B,IAAK,CAClC,IAAIkY,EAAcJ,EAAKE,UAAUC,GAAK,GACtCA,GAAO,EACP9O,EAAKnJ,GAAK4X,EAAQ/E,OAAOc,EAAMX,OAAOnQ,MAAMoV,EAAKA,EAAMC,IACvDD,GAAOC,CACX,CACA,MAAO,CAAE/O,OAAM/M,MAAOsB,MAAK,EAAQkW,OAAQlW,MAAK,EACpD,EC1BG,MAAMya,EACT7F,KAAO,iBACP,iBAAOI,CAAWxO,GACd,OAAO,IAAIiU,CACf,CACA,MAAAxF,CAAOoB,GACH,MAAM,IAAIpV,MAAM,0FACpB,CACA,YAAMkU,CAAOc,GACT,MAAMX,QAAe,QAAWW,EAAO,CAAEK,OAAQ,YACjD,OAAO,IAAIzJ,WAAWyI,EAC1B,ECWG,MAAMoF,GAbF,IAAI3K,KACNjO,IAAI,SAAS,IAAM,8BAA0BiQ,MAAM4I,GAAMA,EAAEC,YAC3D9Y,IAAI,OAAO,IAAM,8BAAwBiQ,MAAM4I,GAAMA,EAAEC,YACvD9Y,IAAI,QAAQ,IAAM,8BAAyBiQ,MAAM4I,GAAMA,EAAEC,YACzD9Y,IAAI,QAAQ,IAAMsU,IAClBtU,IAAI,QAAQ,IAAM2Y,IAClB3Y,IAAI,aAAa,IAAM6W,IACvB7W,IAAI,SAAS,IAAM+T,IACnB/T,IAAI,UAAU,IAAMqU,IACpBrU,IAAI,aAAa,IAAMkY,IACvBlY,IAAI,SAAS,IAAMkV,IACnBlV,IAAI,YAAY,IAAM6S,IAGxB,SAASkG,EAAsBC,GAClC,IAAIC,EACJ,MAAO,CACH,YAAM9F,CAAO3R,GACJyX,IACDA,QAAeC,EAAYF,IAC/B,IAAK,MAAMG,KAASF,EAAOG,eACvB5X,QAAc2X,EAAMhG,OAAO3R,GAE/B,IAAI2S,QAAc8E,EAAOI,eAAelG,OAAO3R,GAC/C,IAAK,MAAM2X,KAASF,EAAOK,eACvBnF,QAAcgF,EAAMhG,OAAOgB,GAE/B,OAAOA,CACX,EACA,YAAMd,CAAOc,GACJ8E,IACDA,QAAeC,EAAYF,IAC/B,IAAK,IAAIxY,EAAIyY,EAAOK,eAAexa,OAAS,EAAG0B,GAAK,EAAGA,IACnD2T,QAAc8E,EAAOK,eAAe9Y,GAAG6S,OAAOc,GAElD,IAAI3S,QAAcyX,EAAOI,eAAehG,OAAOc,GAC/C,IAAK,IAAI3T,EAAIyY,EAAOG,eAAeta,OAAS,EAAG0B,GAAK,EAAGA,IACnDgB,QAAcyX,EAAOG,eAAe5Y,GAAG6S,OAAO7R,GAElD,OAAOA,CACX,EAER,CACAmJ,eAAeuO,EAAYK,GACvB,IAMIF,EANA3J,EAAW6J,EAAWN,OAAO5W,KAAIsI,MAAO7B,IACxC,IAAI0Q,QAAcZ,EAAStN,IAAIxC,EAAKhM,KAAlB8b,MAElB,OADA,QAAOY,EAAO,kBAAkB1Q,EAAKhM,QAC9B,CAAE0c,QAAO1Q,OAAM,IAEtBsQ,EAAiB,GAEjBE,EAAiB,GACrB,UAAW,IAAI,MAAEE,EAAK,KAAE1Q,KAAU4G,EAAU,CACxC,IAAIyJ,EAAQK,EAAMtG,WAAWpK,EAAKiK,cAAewG,GACjD,OAAQJ,EAAMrG,MACV,IAAK,iBACDsG,EAAe3Y,KAAK0Y,GACpB,MACJ,IAAK,iBACDE,EAAiBF,EACjB,MACJ,QACIG,EAAe7Y,KAAK0Y,GAEhC,CAKA,OAJKE,KACD,QAMsB,cANUE,EAMxBtF,UANqC,iBAAiBsF,EAAWtF,sCACzEoF,EAAiBtF,EAAWb,WAAW,CAAEc,OAAQ,UAAYuF,IAE1D,CAAEH,iBAAgBC,iBAAgBC,iBAC7C,CC9EA,MAAMG,EAAe,sBACd,SAASC,EAA4BC,EAAUC,EAAaC,EAAkBC,IACjF,QAAOH,EAASI,MAAMtO,SAAU,yCAChC,IAAIuO,EAAYL,EAASI,MAAMtO,SAASwO,KAAKN,EAASI,OAClDG,EAAcN,EAAYvX,KAAI,CAAC8X,EAAG3Z,IAAM2Z,EAAIL,EAAgBM,YAAY5Z,KACxE6Z,EAActB,EAAsB,CACpC9E,UAAW,SACXrX,MAAO,IAAIsd,EAAa,GACxBjB,OAAQa,EAAgBQ,eAExBhO,EAAQ,CAAC,EACb,OAAO3B,MAAO4P,IACV,IAEInD,EAFAoD,EAAcD,EAAYlY,KAAI,CAAC8X,EAAG3Z,IAAM+B,KAAKkY,MAAMN,EAAID,EAAY1Z,MACnEka,EAAaf,EAASzP,QAAQ2P,EAAiBW,IAAcpQ,KAEjE,GAAIsQ,KAAcpO,EACd8K,EAAQ9K,EAAMoO,OAEb,CACD,IAAIC,EAAgB,EAChBC,EAAa,GAAKV,EAAY7b,QAAO,CAACC,EAAGC,IAAMD,EAAIC,GAAG,GACtD4V,QAAc6F,EAAUU,EAAY,CACpCxO,aAAc0O,EAAaD,IAE/BvD,EAAQ9K,EAAMoO,GAAcvG,QAChBkG,EAAYhH,OAAOc,GACzB,IACV,CACA,GAAc,OAAViD,EACA,OAEJ,IAAI,KAAEzN,EAAI,MAAE/M,EAAK,OAAEwX,GAAWgD,EAC1ByD,EAAgBN,EACflY,KAAI,CAAC8X,EAAG3Z,IAAM2Z,EAAIvd,EAAM4D,KACxBnC,QAAO,CAACyc,EAAKC,EAAKpW,IAAQmW,EAAMC,EAAM3G,EAAOzP,IAAM,GACpD5B,EAAS4G,EAAKkR,GACd/b,EAAS6K,EAAKkR,EAAgB,GAElC,OAAI9X,IAAW0W,GAAgB3a,IAAW2a,EAGnCO,EAAUU,EAAY,CACzB3X,OAAQlC,OAAOkC,GACfjE,OAAQ+B,OAAO/B,UALnB,CAME,CAEV,CC7CO,MAAMkc,EACTjB,MACA3P,KACA,WAAApM,CAAY+b,EAAO3P,EAAO,KACtBlM,KAAK6b,MAAQA,EACb7b,KAAKkM,KAAOA,CAChB,CACA,OAAAF,CAAQE,GAGJ,IAAID,EAAO,IAAIG,IAAI,UAAUpM,KAAKkM,KAAKI,SAAS,KAAOtM,KAAKkM,KAAO,GAAGlM,KAAKkM,WAC3E,OAAO,IAAI4Q,EAAS9c,KAAK6b,MAAO,IAAIzP,IAAIF,EAAMD,GAAMI,SACxD,EAEG,SAASJ,EAAK4P,GACjB,OAAO,IAAIiB,EAASjB,GAAS,IAAI9L,IACrC,CACO,MAAMgN,UAAcD,EACvBlI,KAAO,QACP,GACA,WAAA9U,CAAY+b,EAAO3P,EAAM8Q,GACrB5b,MAAMya,EAAO3P,GACblM,MAAK,EAAYgd,CACrB,CACA,SAAIC,GACA,OAAOjd,MAAK,EAAUkd,UAC1B,EAEJ,SAASC,EAAgBpC,GACrB,MAAMqC,EAAwBrC,EAAO1S,MAAMzB,GAAiB,cAAXA,EAAEhI,OAEnD,OAAOwe,GAAuBvI,eAAe+D,OAAS,GAC1D,CACA,MAAMyE,EAAiBjY,OAAO,mBACvB,SAASkY,EAAYvS,GACxB,OAAOA,EAAIsS,EACf,CA6CO,MAAM,UAAcP,EACvBlI,KAAO,QACP,GACA,CAACyI,GACD,WAAAvd,CAAY+b,EAAO3P,EAAM8Q,GACrB5b,MAAMya,EAAO3P,GACblM,MAAK,EAAY,IACVgd,EACHO,YAAY,QAAsBP,IAEtChd,KAAKqd,GAtDb,SAAwB5B,EAAUuB,GAC9B,IAAI,cAAEnI,GAAkBmI,EAASjC,OAAO1S,KAAK,MAAsB,CAAC,EAChEmV,EAAiB,CACjBC,kBAAkB,QAAyBT,EAASU,oBACpD/H,YAAY,QAAQqH,EAASjH,WAC7BwH,WAAYP,EAASO,YAEzB,GAAI1I,EAAe,CACf,IAAI8I,EAAeR,EAAgBtI,EAAckG,QACjD,MAAO,IACAyC,EACH5I,KAAM,UACNsH,YAAarH,EAAcqH,YAC3BjB,MAAOJ,EAAsB,CACzB9E,UAAWiH,EAASjH,UACpBrX,MAAOmW,EAAcqH,YACrBnB,OAAQlG,EAAckG,SAE1B6C,YAAYlf,IACD,QAAYA,EAAOif,GAE9BE,gBAAiBrC,EAA4BC,EAAUuB,EAASc,WAAWjJ,cAAcqH,YAAasB,EAAeC,iBAAkB5I,GAE/I,CACA,IAAI8I,EAAeR,EAAgBH,EAASjC,QAC5C,MAAO,IACAyC,EACH5I,KAAM,UACNsH,YAAac,EAASc,WAAWjJ,cAAcqH,YAC/CjB,MAAOJ,EAAsB,CACzB9E,UAAWiH,EAASjH,UACpBrX,MAAOse,EAASc,WAAWjJ,cAAcqH,YACzCnB,OAAQiC,EAASjC,SAErB6C,YAAYlf,IACD,QAAYA,EAAOif,GAE9B,qBAAME,CAAgBE,EAAc5c,GAChC,IAAI6c,EAAYR,EAAeC,iBAAiBM,GAC5CE,EAAaxC,EAASzP,QAAQgS,GAAW9R,KAC7C,OAAOuP,EAASI,MAAMzO,IAAI6Q,EAAY9c,EAC1C,EAER,CAW+B+c,CAAele,KAAMgd,EAChD,CACA,SAAIC,GACA,OAAOjd,MAAK,EAAUkd,UAC1B,CACA,SAAIxe,GACA,OAAOsB,MAAK,EAAUtB,KAC1B,CACA,UAAIqE,GACA,OAAO/C,KAAKqd,GAAgBnB,WAChC,CACA,SAAIiC,GACA,OAAOne,MAAK,EAAU+V,SAC1B,CACA,cAAMxH,CAASwP,EAAc5c,GACzB,IAAIid,EAAUpe,KAAKqd,GACfgB,QAAoBD,EAAQP,gBAAgBE,EAAc5c,GAC9D,IAAKkd,EAAa,CACd,IAAI1M,EAAOyM,EAAQlC,YAAY/b,QAAO,CAACC,EAAGC,IAAMD,EAAIC,GAAG,GACnDoL,EAAO,IAAI2S,EAAQzI,WAAWhE,GAGlC,OADAlG,EAAK3B,KAAKsU,EAAQb,YACX,CACH9R,OACA/M,MAAO0f,EAAQlC,YACfhG,OAAQkI,EAAQR,YAAYQ,EAAQlC,aAE5C,CACA,OAAOkC,EAAQnD,MAAM9F,OAAOkJ,EAChC,CAkBA,EAAAC,CAAGC,GACC,OAAO,QAASve,KAAKme,MAAOI,EAChC,E,8GC9IG,MAAMC,UAAmBvd,MAC5B,WAAAnB,CAAY2e,GACRrd,MAAMqd,GACNze,KAAKpB,KAAO,YAChB,EA6BJ,MAAM8f,EACFC,QACAC,QACAC,cACAC,OACA,WAAAhf,EAAY,QAAE6e,EAAO,QAAEC,EAAO,cAAEC,IAE5BF,EApBD,SAAqCA,EAASC,GAWjD,OATAD,EAAUta,KAAK0a,MAAMJ,IAEP,IACVA,EAAUC,EAAUD,IAGpBA,GAAWC,GAAWD,EAAU,IAnBxC,SAAyBC,GACrB,MAAM,IAAIJ,EAAW,iDAAiDI,IAC1E,CAkBQI,CAAgBJ,GAEbD,CACX,CAQkBM,CAA4BN,EAASC,GAE/C5e,KAAK2e,QAAUA,EACf3e,KAAK4e,QAAUA,EACf5e,KAAK6e,cAAgBA,EACrB7e,KAAK8e,OAAS,CAClB,CACA,EAAE1Z,OAAOC,YACL,MAAM6Z,EAAe7a,KAAKkY,MAAMvc,KAAK2e,QAAU3e,KAAK6e,eAC9CM,EAAaD,EAAelf,KAAK6e,cACjCO,EAAgBpf,KAAK2e,QAAUQ,OAC/B,CAAED,eAAcE,gBAC1B,EAEJ,MAAMC,EACFxb,MACAyb,KACAC,KACAX,QACAC,cACAC,OACAU,QACA,WAAA1f,EAAY,QAAE6e,EAAO,QAAEC,EAAO,cAAEC,IAE5B,MAAOhb,EAAOyb,EAAMC,IAAQ,QAAcZ,EAASC,GACnD5e,KAAK6D,MAAQA,EACb7D,KAAKsf,KAAOA,EACZtf,KAAKuf,KAAOA,EACRvf,KAAKuf,KAAO,GAxDxB,WACI,MAAM,IAAIf,EAAW,2CACzB,CAuDYiB,GAEJzf,KAAK4e,QAAUA,EACf5e,KAAK6e,cAAgBA,EACrB7e,KAAK8e,OAASza,KAAKG,IAAI,EAAGH,KAAKqb,MAAM1f,KAAKsf,KAAOtf,KAAK6D,OAAS7D,KAAKuf,OACpEvf,KAAKwf,QAAUnb,KAAKqb,KAAK1f,KAAK4e,QAAU5e,KAAK6e,cACjD,CACA,EAAEzZ,OAAOC,YAEL,MAAMsa,EAAoBtb,KAAKkY,MAAMvc,KAAK6D,MAAQ7D,KAAK6e,eACjDe,EAAkBvb,KAAKqb,KAAK1f,KAAKsf,KAAOtf,KAAK6e,eACnD,IAAK,MAAMK,KAAgB,QAAMS,EAAmBC,GAAkB,CAElE,MAAMT,EAAaD,EAAelf,KAAK6e,cACjCgB,EAAYxb,KAAKC,IAAItE,KAAK4e,SAAUM,EAAe,GAAKlf,KAAK6e,eAE7DA,EAAgBgB,EAAYV,EAClC,IAAIW,EAAiB,EACjBC,EAAsB,EAC1B,GAAI/f,KAAK6D,MAAQsb,EAAY,CAEzB,MAAMa,GAAab,EAAanf,KAAK6D,OAAS7D,KAAKuf,KAC/CS,IACAD,GAAuB/f,KAAKuf,KAAOS,GAEvCF,EAAiBzb,KAAKqb,MAAMP,EAAanf,KAAK6D,OAAS7D,KAAKuf,KAChE,MAGIQ,EAAsB/f,KAAK6D,MAAQsb,EAIvC,MAAMc,EAAqBjgB,KAAKsf,KAAOO,EAAYhB,EAAgB7e,KAAKsf,KAAOH,EACzEC,EAAgB,CAClBW,EACAE,EACAjgB,KAAKuf,MAGHW,EAAc,CAChBJ,EACAA,EAHqBzb,KAAKqb,MAAMO,EAAqBF,GAAuB/f,KAAKuf,MAIjF,QAEE,CAAEL,eAAcE,gBAAec,cACzC,CACJ,EAaG,MAAMC,EACTC,aACA1hB,MACA,WAAAoB,EAAY,UAAEugB,EAAS,MAAE3hB,EAAK,YAAEwd,IAE5Blc,KAAKogB,aAhBN,SAA6BC,EAAW3hB,GAC3C,IAAI4hB,EAAa,GAQjB,OAPkB,OAAdD,EACAC,EAAa5hB,EAAMyF,KAAKqC,IAAM,QAAM,QAE/BzB,MAAMC,QAAQqb,KACnBC,EAAaD,EAAUlc,KAAK8U,GAAMA,IAAK,QAAM,SA7GrD,SAAgCoH,EAAW3hB,GACnC2hB,EAAUzf,OAASlC,EAAMkC,QAVjC,SAA8Byf,EAAW3hB,GACrC,MAAM,IAAI8f,EAAW,yCAAyC9f,EAAMkC,eAAeyf,EAAUzf,SACjG,CASQ2f,CAAqBF,EAAW3hB,EAExC,CA2GI8hB,CAAuBF,EAAY5hB,GAC5B4hB,CACX,CAM4BG,CAAoBJ,EAAW3hB,GAAOyF,KAAI,CAACwa,EAASrc,IAC7D,IAAwB,iBAAZqc,EAAuBD,EAAgBW,GAAiB,CAEvEV,QAASA,EACTC,QAASlgB,EAAM4D,GACfuc,cAAe3C,EAAY5Z,OAGnCtC,KAAKtB,MAAQsB,KAAKogB,aACbtb,QAAQ4b,GAAQA,aAAerB,IAC/Blb,KAAKwc,GAASA,EAAK7B,QAC5B,CACA,EAAE1Z,OAAOC,YACL,IAAK,MAAMub,KAAmB,WAAW5gB,KAAKogB,cAAe,CACzD,MAAMrC,EAAe6C,EAAgBzc,KAAK0c,GAAMA,EAAE3B,eAC5C4B,EAAUF,EAAgBzc,KAAK0c,GAC7B,gBAAiBA,EACV,CAAEta,KAAMsa,EAAEzB,cAAe2B,GAAIF,EAAEX,aAEnC,CAAE3Z,KAAMsa,EAAEzB,cAAe2B,GAAI,aAElC,CAAEhD,eAAc+C,UAC1B,CACJ,EC3JJ,SAASE,EAAkBhf,EAAK6C,EAAS,EAAG8M,GACxC,IAAI/Q,EAAS+Q,GAAQ3P,EAAIpB,OAASiE,EAClC,MAAO,CACHjE,SACAqgB,SAAQ,CAAC1a,EAAMwa,EAAKngB,IACTogB,EAAkBhf,EAAK6C,EAAS0B,EAAMwa,EAAKxa,GAEtD,GAAAzE,CAAI2J,EAAM5H,EAAQ,GACd,IAAK,IAAIvB,EAAI,EAAGA,EAAImJ,EAAK7K,OAAQ0B,IAC7BN,EAAI6C,EAAShB,EAAQvB,GAAKmJ,EAAK2B,IAAI9K,EAE3C,EACA8K,IAAI8L,GACOlX,EAAI6C,EAASqU,GAGhC,CAWA,SAASgI,EAAalf,GAClB,OAAImf,WAAWpc,MAAMC,QAAQhD,EAAIyJ,MACtB,CAEHA,KAAMuV,EAAkBhf,EAAIyJ,MAC5ByK,OAAQlU,EAAIkU,OACZR,kBAAmB,GAGpB,CACHjK,KAAM,IAAIoB,WAAW7K,EAAIyJ,KAAK6J,OAAQtT,EAAIyJ,KAAK8J,WAAYvT,EAAIyJ,KAAK+J,YACpEU,OAAQlU,EAAIkU,OACZR,kBAAmB1T,EAAIyJ,KAAKmK,kBAEpC,CA8BO,MAAMwL,EAAS,CAClBC,QAAO,CAAC5V,EAAM/M,EAAOwX,KACV,CAAEzK,OAAM/M,QAAOwX,WAE1B,UAAAoL,CAAWC,EAAM1E,EAAK1N,GAClB,IAAIiL,EAAO8G,EAAaK,GACxBC,EAAkBpH,EAAMyC,EAhBhC,SAAuB7a,EAAKmN,GACxB,GAAIgS,WAAWpc,MAAMC,QAAQhD,EAAIyJ,MAE7B,OAAOuV,EAAkB,CAAC7R,IAE9B,IAEI1D,EAAO,IAzBf,SAAqCzJ,GACjC,MAAI,UAAWA,EAGJA,EAAIlC,YAAYic,KAAK,KAAM/Z,EAAIwX,OAEnCxX,EAAIlC,WACf,CAgBqB2hB,CAA4Bzf,EAAIyJ,MAEtC,CAAe,CAAC0D,IAC3B,OAAO,IAAItC,WAAWpB,EAAK6J,OAAQ7J,EAAK8J,WAAY9J,EAAK+J,WAC7D,CAOqCkM,CAAcH,EAAMpS,GAAQiL,EAAK1E,kBAClE,EACA,cAAAiM,CAAeJ,EAAM3b,EAAKgc,GACtB,IAAIxH,EAAO8G,EAAaK,GACxBM,EAAsBzH,EAAM8G,EAAatb,GAAMwU,EAAK1E,kBAAmBkM,EAC3E,GAGGnV,eAAe,EAAIzK,EAAKqe,EAAY,KAAMzU,EAAO,CAAC,GACrD,OCnFGa,eAAmBzK,EAAKqe,EAAWzU,EAAMwV,GAC5C,IAAIhD,GAAU,QAAYpc,GACtB8f,EAAU,IAAI3B,EAAa,CAC3BE,YACA3hB,MAAOsD,EAAItD,MACXwd,YAAala,EAAIe,SAEjBwW,EAAM6H,EAAOC,QAAQ,IAAIjD,EAAQzI,WAAWmM,EAAQpjB,MAAMyB,QAAO,CAACC,EAAGC,IAAMD,EAAIC,GAAG,IAAKyhB,EAAQpjB,MAAO0f,EAAQR,YAAYkE,EAAQpjB,QAClI2P,EAAQzC,EAAKmW,mBAAoB,UACrC,IAAK,MAAM,aAAEhE,EAAY,QAAE+C,KAAagB,EACpCzT,EAAMyD,KAAIrF,UACN,IAAI,KAAEhB,EAAI,MAAE/M,EAAK,OAAEwX,SAAiBlU,EAAIuM,SAASwP,EAAcnS,EAAKA,MAChEtI,EAAQ8d,EAAOC,QAAQ5V,EAAM/M,EAAOwX,GACxCkL,EAAOO,eAAepI,EAAKjW,EAAOwd,EAAQ,IAMlD,aAHMzS,EAAM2T,SAGoB,IAAzBF,EAAQpjB,MAAMkC,OAtBzB,SAAgBoB,GACZ,MAAQ,QAASA,EAAMA,EAAIoL,IAqB0B,GArBfpL,EAqBe,EApBzD,CAoBwCigB,CAAO1I,EAAI9N,MAAW8N,CAC9D,CD+DWnM,CAAgBpL,EAAKqe,EAAWzU,EAAMwV,EACjD,CAKA,SAASc,EAAYre,EAAOyb,EAAMC,GAC9B,OAAIA,EAAO,GAAKD,EAAOzb,EACZQ,KAAKkY,OAAO1Y,EAAQyb,EAAO,IAAMC,GAAQ,EAEhD1b,EAAQyb,EACDjb,KAAKkY,OAAO+C,EAAOzb,EAAQ,GAAK0b,GAAQ,EAC5C,CACX,CACA,SAASiC,EAAkBjI,EAAK4I,EAAehT,EAAOuG,GAClD,GAA6B,IAAzByM,EAAcvhB,OAEd,YADA2Y,EAAI9N,KAAK3J,IAAIqN,EAAO,GAGxB,MAAOhK,KAAUid,GAAUD,GACpBE,KAAgBnM,GAAUqD,EAAIrD,OACrC,GAAqB,iBAAV/Q,EAGP,YADAqc,EAAkB,CAAE/V,KADP8N,EAAI9N,KAAKwV,SAASoB,EAAcld,EAAQuQ,GAC3BQ,UAAUkM,EAAQjT,EAAOuG,GAGvD,MAAOnP,EAAMwa,EAAIxB,GAAQpa,EACnBmd,EAAMJ,EAAY3b,EAAMwa,EAAIxB,GAClC,GAAsB,IAAlB6C,EAAOxhB,OAMX,IAAK,IAAI0B,EAAI,EAAGA,EAAIggB,EAAKhgB,IAErBkf,EAAkB,CAAE/V,KADP8N,EAAI9N,KAAKwV,SAASoB,GAAe9b,EAAOgZ,EAAOjd,GAAKoT,GACvCQ,UAAUkM,EAAQjT,EAAOuG,QAPnD,IAAK,IAAIpT,EAAI,EAAGA,EAAIggB,EAAKhgB,IACrBiX,EAAI9N,KAAK3J,IAAIqN,EAAOkT,GAAe9b,EAAOgZ,EAAOjd,GAAKoT,EAQlE,CACA,SAASmM,EAAsBN,EAAM3b,EAAK8P,EAAmBkM,GACzD,MAAOW,KAASC,GAASZ,GAClBa,KAAYC,GAAYnB,EAAKrL,QAC7ByM,KAAYC,GAAYhd,EAAIsQ,OACnC,GAAkB,OAAdqM,EAAKhc,KACL,OAAqB,IAAjBic,EAAM5hB,YACN2gB,EAAK9V,KAAK3J,IAAI8D,EAAI6F,KAAKwV,SAAS,EAAGvL,GAAoB6M,EAAKxB,GAAKrL,QAGrEmM,EAAsB,CAClBpW,KAAM8V,EAAK9V,KAAKwV,SAASwB,EAAUF,EAAKxB,GAAKrL,GAC7CQ,OAAQwM,GACT9c,EAAK8P,EAAmB8M,GAG/B,GAAgB,OAAZD,EAAKxB,GAAa,CAClB,GAAqB,IAAjByB,EAAM5hB,OAAc,CACpB,IAAIiE,EAAS0d,EAAKhc,KAAOmP,EAEzB,YADA6L,EAAK9V,KAAK3J,IAAI8D,EAAI6F,KAAKwV,SAASpc,EAAQA,EAAS6Q,GAAoB,EAEzE,CAKA,YAJAmM,EAAsBN,EAAM,CACxB9V,KAAM7F,EAAI6F,KAAKwV,SAAS0B,EAAUJ,EAAKhc,KAAOmP,GAC9CQ,OAAQ0M,GACTlN,EAAmB8M,EAE1B,CACA,MAAOjc,EAAMwa,EAAIxB,GAAQgD,EAAKxB,IACvB8B,EAAOrc,EAAGsc,GAASP,EAAKhc,KACzB+b,EAAMJ,EAAY3b,EAAMwa,EAAIxB,GAClC,GAAqB,IAAjBiD,EAAM5hB,OAgBV,IAAK,IAAI0B,EAAI,EAAGA,EAAIggB,EAAKhgB,IACrBuf,EAAsB,CAClBpW,KAAM8V,EAAK9V,KAAKwV,SAASwB,GAAWlc,EAAOjE,EAAIid,GAAQ7J,GACvDQ,OAAQwM,GACT,CACCjX,KAAM7F,EAAI6F,KAAKwV,SAAS0B,GAAWE,EAAQvgB,EAAIwgB,GAASpN,GACxDQ,OAAQ0M,GACTlN,EAAmB8M,OAvB1B,CAGI,GAAa,IAATjD,GAAwB,IAAVuD,GAA2B,IAAZL,GAA6B,IAAZE,EAAe,CAC7D,IAAI9d,EAASge,EAAQnN,EACjB/D,EAAO2Q,EAAM5M,EAEjB,YADA6L,EAAK9V,KAAK3J,IAAI8D,EAAI6F,KAAKwV,SAASpc,EAAQA,EAAS8M,GAAOpL,EAAOmP,EAEnE,CAEA,IAAK,IAAIpT,EAAI,EAAGA,EAAIggB,EAAKhgB,IAAK,CAC1B,IAAIuC,EAAS8d,GAAWE,EAAQC,EAAQxgB,GAAKoT,EAC7C6L,EAAK9V,KAAK3J,IAAI8D,EAAI6F,KAAKwV,SAASpc,EAAQA,EAAS6Q,GAAoB+M,GAAWlc,EAAOgZ,EAAOjd,GAAKoT,EACvG,CAEJ,CAUJ,C,iBEtLO,SAAUlI,EAAM3J,EAAOyb,EAAMC,EAAO,QAC1B7d,IAAT4d,IACAA,EAAOzb,EACPA,EAAQ,GAEZ,IAAK,IAAIvB,EAAIuB,EAAOvB,EAAIgd,EAAMhd,GAAKid,QACzBjd,CAEd,CAKO,SAAUygB,KAAWC,GACxB,GAAyB,IAArBA,EAAUpiB,OACV,OAGJ,MAAMqiB,EAAYD,EAAU7e,KAAK+e,GAAOA,EAAG9d,OAAOC,cAC5C8d,EAAUF,EAAU9e,KAAK+e,GAAOA,EAAGE,SACzC,GAAID,EAAQ3f,MAAM6f,GAAMA,EAAEC,OACtB,MAAM,IAAIriB,MAAM,qCAEpB,IAAK,IAAIqB,EAAI,IAAK,CACd,GAAI6gB,EAAQ7gB,GAAGghB,MAKX,GAHAL,EAAU3gB,GAAK0gB,EAAU1gB,GAAG8C,OAAOC,YACnC8d,EAAQ7gB,GAAK2gB,EAAU3gB,GAAG8gB,SAEpB9gB,GAAK2gB,EAAUriB,OACjB,kBAKEuiB,EAAQhf,KAAI,EAAGgL,WAAYA,IACjC7M,EAAI,EAER6gB,EAAQ7gB,GAAK2gB,EAAU3gB,GAAG8gB,MAC9B,CACJ,CAEO,SAASG,GAAc,MAAE1f,EAAK,KAAEyb,EAAI,KAAEC,GAAQ3e,GACjD,GAAa,IAAT2e,EACA,MAAM,IAAIte,MAAM,6BAGpB,MAAMuiB,GADNjE,EAAOA,GAAQ,GACiB,GAEzBkE,EAAOC,GAASF,EAAmB,EAAE,EAAG5iB,EAAS,GAAK,CAAC,EAAGA,GA+BjE,OA7Bc,OAAViD,EACAA,EAAQ2f,EAAmBE,EAAQD,EAG/B5f,EAAQ,GACRA,GAASjD,GACG6iB,IACR5f,EAAQ4f,GAGP5f,EAAQ6f,IACb7f,EAAQ6f,GAIH,OAATpE,EACAA,EAAOkE,EAAmBC,EAAQC,EAG9BpE,EAAO,GACPA,GAAQ1e,GACG6iB,IACPnE,EAAOmE,GAGNnE,EAAOoE,IACZpE,EAAOoE,GAGR,CAAC7f,EAAOyb,EAAMC,EACzB,CACO,SAASpa,EAAMtB,EAAOyb,EAAMC,EAAO,MAKtC,YAJa7d,IAAT4d,IACAA,EAAOzb,EACPA,EAAQ,MAEL,CACHA,QACAyb,OACAC,OAER,CAEO,SAASwC,IACZ,MAAMvQ,EAAW,GACjB,MAAO,CACHM,IAAM6R,GAAOnS,EAASjP,KAAKohB,KAC3B3B,OAAQ,IAAMxR,QAAQoT,IAAIpS,GAElC,C,yHClGA,IAAIqS,EACJ,WACI,IAAIC,EAAiB,IAAIC,QACzB,SAASC,EAAWnI,GAChB,IAAIoI,EAASH,EAAe1W,IAAIyO,IAAU,CAAEqI,GAAI,EAAGC,GAAI,GAEvD,OADAL,EAAehiB,IAAI+Z,EAAOoI,GACnBA,CACX,CACA,MAAO,CACH,SAAAG,CAAUvI,EAAOwI,GACbL,EAAWnI,GAAOwI,IAAY,CAClC,EACA,WAAAC,CAAYzI,GACR,IAAIoI,EAASD,EAAWnI,GACxB,OAAOoI,EAAOE,GAAKF,EAAOC,GAAK,KAAO,IAC1C,EAER,CAjBsBK,GAsCtB9X,eAAe+X,EAAc/I,EAAUwB,GACnC,IAAI,KAAE/Q,GAASuP,EAASzP,QAAQ,WAC5BpB,QAAa6Q,EAASI,MAAMzO,IAAIlB,GACpC,IAAKtB,EACD,MAAM,IAAI,IAAkB,WAAY,CACpC/I,MAAO,IAAI,IAASqK,KAI5B,OADA2X,EAAgBO,UAAU3I,EAASI,MAAO,MACnC,IAAI,KAAMJ,EAASI,MAAOJ,EAASvP,MAAM,SAAwB,QAAmBtB,GAAOqS,GACtG,CACAxQ,eAAegY,EAAchJ,EAAUwB,GACnC,IAAI,KAAE/Q,GAASuP,EAASzP,QAAQ,WAC5BpB,QAAa6Q,EAASI,MAAMzO,IAAIlB,GACpC,IAAKtB,EACD,MAAM,IAAI,IAAkB,WAAY,CACpC/I,MAAO,IAAI,IAASqK,KAI5B,OADA2X,EAAgBO,UAAU3I,EAASI,MAAO,MACnC,IAAI,KAAMJ,EAASI,MAAOJ,EAASvP,MAAM,SAAwB,QAAmBtB,GAAOqS,GACtG,CA8BOxQ,eAAeiY,EAAKjJ,EAAUta,EAAU,CAAC,GAC5C,IAAI0a,EAAQ,UAAWJ,EAAWA,EAASI,MAAQJ,EAC/C6I,EAAcT,EAAgBS,YAAYzI,GAI1C8I,EAA+B,OAAhBL,EAAuBI,EAAKR,GAAKQ,EAAKP,GACrDS,EAAiC,OAAhBN,EAAuBI,EAAKP,GAAKO,EAAKR,GAC3D,OAAOS,EAAalJ,EAAUta,GAAS6R,OAAO6R,KAC1C,QAAeA,EAAK,KACbD,EAAenJ,EAAUta,KAExC,CACAujB,EAAKR,GA9ELzX,eAAuBgP,EAAUta,EAAU,CAAC,GACxC,IAAI2jB,EAAM,UAAWrJ,EAAWA,EAAW,IAAI,KAASA,GACpDwB,EAAQ,CAAC,EAGb,OAFI9b,EAAQ8b,OAAS,KACjBA,QAVRxQ,eAA0BgP,GACtB,IAAIsJ,QAAmBtJ,EAASI,MAAMzO,IAAIqO,EAASzP,QAAQ,WAAWE,MACtE,OAAK6Y,GAEE,QAAmBA,GADf,CAAC,CAEhB,CAKsBC,CAAWF,IACR,UAAjB3jB,EAAQyT,KACD4P,EAAcM,EAAK7H,GACT,UAAjB9b,EAAQyT,KACD6P,EAAcK,EAAK7H,GACvBuH,EAAcM,EAAK7H,GAAOjK,OAAO6R,KACpC,QAAeA,EAAK,KACbJ,EAAcK,EAAK7H,KAElC,EAkEAyH,EAAKP,GA3BL1X,eAAuBgP,EAAUta,EAAU,CAAC,GACxC,IAAI2jB,EAAM,UAAWrJ,EAAWA,EAAW,IAAI,KAASA,GACpDwJ,QAlBRxY,eAAwBgP,GACpB,IAAI,MAAEI,EAAK,KAAE3P,GAASuP,EAASzP,QAAQ,aACnCpB,QAAa6Q,EAASI,MAAMzO,IAAIlB,GACpC,IAAKtB,EACD,MAAM,IAAI,IAAkB,oBAAqB,CAC7C/I,MAAO,IAAI,IAASqK,KAG5B,IAAIgZ,GAAW,QAAmBta,GAIlC,MAH2B,UAAvBsa,EAASC,YACTD,EAAS3H,YAAa,QAAsB2H,IAElB,UAAvBA,EAASC,UACV,IAAI,KAAMtJ,EAAOJ,EAASvP,KAAMgZ,GAChC,IAAI,KAAMrJ,EAAOJ,EAASvP,KAAMgZ,EAC1C,CAGqBE,CAASN,GAE1B,GADAjB,EAAgBO,UAAUU,EAAIjJ,MAAO,WAChBna,IAAjBP,EAAQyT,KACR,OAAOqQ,EACX,GAAqB,UAAjB9jB,EAAQyT,MAAoBqQ,aAAgB,KAC5C,OAAOA,EACX,GAAqB,UAAjB9jB,EAAQyT,MAAoBqQ,aAAgB,KAC5C,OAAOA,EACX,IAAIrQ,EAAOqQ,aAAgB,KAAQ,QAAU,QAC7C,MAAM,IAAIhkB,MAAM,yBAAyBE,EAAQyT,eAAeA,KACpE,C,qDCjFO,MAAMyQ,EACT,GACA,WAAAvlB,CAAYiZ,EAAGxD,EAAY3U,GACN,iBAANmY,EACP/Y,MAAK,EAAS,IAAI6M,WAAWkM,GAExBA,aAAauM,YAClBtlB,MAAK,EAAS,IAAI6M,WAAWkM,EAAGxD,EAAY3U,GAG5CZ,MAAK,EAAS,IAAI6M,WAAW9H,MAAMwB,KAAKwS,GAAI7W,GAAOA,EAAI,EAAI,IAEnE,CACA,qBAAI0T,GACA,OAAO,CACX,CACA,cAAIL,GACA,OAAOvV,MAAK,EAAOuV,UACvB,CACA,cAAIC,GACA,OAAOxV,MAAK,EAAOwV,UACvB,CACA,UAAIF,GACA,OAAOtV,MAAK,EAAOsV,MACvB,CACA,UAAI1U,GACA,OAAOZ,MAAK,EAAOY,MACvB,CACA,GAAAwM,CAAI3G,GACA,IAAI0I,EAAQnP,MAAK,EAAOyG,GACxB,MAAwB,iBAAV0I,EAA+B,IAAVA,EAAcA,CACrD,CACA,GAAArN,CAAI2E,EAAK0I,GACLnP,MAAK,EAAOyG,GAAO0I,EAAQ,EAAI,CACnC,CACA,IAAArF,CAAKqF,GACDnP,MAAK,EAAO8J,KAAKqF,EAAQ,EAAI,EACjC,CACA,EAAE/J,OAAOC,YACL,IAAK,IAAI/C,EAAI,EAAGA,EAAItC,KAAKY,OAAQ0B,UACvBtC,KAAKoN,IAAI9K,EAEvB,EAOG,MAAMijB,EACTC,MACAhM,MACA,GACA,WAAA1Z,CAAY0Z,EAAOT,EAAGxD,EAAY3U,GAG9B,GAFAZ,KAAKwZ,MAAQA,EACbxZ,MAAK,EAAW,IAAIwY,YACH,iBAANO,EACP/Y,KAAKwlB,MAAQ,IAAI3Y,WAAWkM,EAAIS,QAE/B,GAAIT,aAAauM,YACd1kB,IACAA,GAAkB4Y,GACtBxZ,KAAKwlB,MAAQ,IAAI3Y,WAAWkM,EAAGxD,EAAY3U,OAE1C,CACD,IAAI6kB,EAAS1gB,MAAMwB,KAAKwS,GACxB/Y,KAAKwlB,MAAQ,IAAI3Y,WAAW4Y,EAAO7kB,OAAS4Y,GAC5C,IAAK,IAAIlX,EAAI,EAAGA,EAAImjB,EAAO7kB,OAAQ0B,IAC/BtC,KAAK8B,IAAIQ,EAAGmjB,EAAOnjB,GAE3B,CACJ,CACA,qBAAIsT,GACA,OAAO5V,KAAKwZ,KAChB,CACA,cAAIjE,GACA,OAAOvV,KAAKwlB,MAAMjQ,UACtB,CACA,cAAIC,GACA,OAAOxV,KAAKwlB,MAAMhQ,UACtB,CACA,UAAIF,GACA,OAAOtV,KAAKwlB,MAAMlQ,MACtB,CACA,UAAI1U,GACA,OAAOZ,KAAKwV,WAAaxV,KAAK4V,iBAClC,CACA,GAAAxI,CAAI3G,GACA,MAAM2T,EAAO,IAAIvN,WAAW7M,KAAKsV,OAAQtV,KAAKuV,WAAavV,KAAKwZ,MAAQ/S,EAAKzG,KAAKwZ,OAElF,OAAO,IAAIW,aAAchF,OAAOiF,GAAMjG,QAAQ,QAAS,GAC3D,CACA,GAAArS,CAAI2E,EAAK0I,GACL,MAAMiL,EAAO,IAAIvN,WAAW7M,KAAKsV,OAAQtV,KAAKuV,WAAavV,KAAKwZ,MAAQ/S,EAAKzG,KAAKwZ,OAClFY,EAAKtQ,KAAK,GACVsQ,EAAKtY,IAAI9B,MAAK,EAASiV,OAAO9F,GAClC,CACA,IAAArF,CAAKqF,GACD,MAAMuW,EAAU1lB,MAAK,EAASiV,OAAO9F,GACrC,IAAK,IAAI7M,EAAI,EAAGA,EAAItC,KAAKY,OAAQ0B,IAC7BtC,KAAKwlB,MAAM1jB,IAAI4jB,EAASpjB,EAAItC,KAAKwZ,MAEzC,CACA,EAAEpU,OAAOC,YACL,IAAK,IAAI/C,EAAI,EAAGA,EAAItC,KAAKY,OAAQ0B,UACvBtC,KAAKoN,IAAI9K,EAEvB,EAOG,MAAMqjB,EACT,GACAnM,MACA,WAAA1Z,CAAY0Z,EAAOT,EAAGxD,EAAY3U,GAE9B,GADAZ,KAAKwZ,MAAQA,EACI,iBAANT,EACP/Y,MAAK,EAAQ,IAAI4lB,WAAW7M,EAAIS,QAE/B,GAAIT,aAAauM,YACd1kB,IACAA,GAAU4Y,GACdxZ,MAAK,EAAQ,IAAI4lB,WAAW7M,EAAGxD,EAAY3U,OAE1C,CACD,MAAM6kB,EAAS1M,EACTkD,EAAI,IAAI0J,EAAmBnM,EAAO,GACxCxZ,MAAK,EAAQ,IAAI4lB,WAAW,YACxB,IAAK,IAAIC,KAAOJ,EACZxJ,EAAEna,IAAI,EAAG+jB,SACF5J,GAAE,CAEhB,CAL2B,GAMhC,CACJ,CACA,qBAAIrG,GACA,OAAO5V,MAAK,EAAM4V,kBAAoB5V,KAAKwZ,KAC/C,CACA,cAAIhE,GACA,OAAOxV,MAAK,EAAMwV,UACtB,CACA,cAAID,GACA,OAAOvV,MAAK,EAAMuV,UACtB,CACA,UAAID,GACA,OAAOtV,MAAK,EAAMsV,MACtB,CACA,UAAI1U,GACA,OAAOZ,MAAK,EAAMY,OAASZ,KAAKwZ,KACpC,CACA,GAAApM,CAAI3G,GACA,MAAM5B,EAAS7E,KAAKwZ,MAAQ/S,EAC5B,IAAIjB,EAAS,GACb,IAAK,IAAIlD,EAAI,EAAGA,EAAItC,KAAKwZ,MAAOlX,IAC5BkD,GAAUsgB,OAAOC,cAAc/lB,MAAK,EAAM6E,EAASvC,IAGvD,OAAOkD,EAAO2O,QAAQ,UAAW,GACrC,CACA,GAAArS,CAAI2E,EAAK0I,GACL,MAAMtK,EAAS7E,KAAKwZ,MAAQ/S,EACtB2T,EAAOpa,MAAK,EAAMihB,SAASpc,EAAQA,EAAS7E,KAAKwZ,OACvDY,EAAKtQ,KAAK,GACV,IAAK,IAAIxH,EAAI,EAAGA,EAAItC,KAAKwZ,MAAOlX,IAC5B8X,EAAK9X,GAAK6M,EAAM6W,YAAY1jB,IAAM,CAE1C,CACA,IAAAwH,CAAKqF,GAEDnP,KAAK8B,IAAI,EAAGqN,GAEZ,IAAIuW,EAAU1lB,MAAK,EAAMihB,SAAS,EAAGjhB,KAAKwZ,OAC1C,IAAK,IAAIlX,EAAI,EAAGA,EAAItC,KAAKY,OAAQ0B,IAC7BtC,MAAK,EAAM8B,IAAI4jB,EAASpjB,EAAItC,KAAKwZ,MAEzC,CACA,EAAEpU,OAAOC,YACL,IAAK,IAAI/C,EAAI,EAAGA,EAAItC,KAAKY,OAAQ0B,UACvBtC,KAAKoN,IAAI9K,EAEvB,E,4JC5LG,SAAS2jB,EAAmBhQ,GAC/B,MAAM4P,GAAM,IAAI1L,aAAchF,OAAOc,GACrC,OAAOgC,KAAKiO,MAAML,EACtB,CACO,SAASM,EAAiB/L,EAAM1E,GACnC,MAAM0Q,EAAW1Q,EAAoB,EAC/B2Q,EAAe3Q,EAAoB,EACzC,IAAI/O,EAAI,EACR,IAAK,IAAIrE,EAAI,EAAGA,EAAI8X,EAAKxZ,OAAQ0B,GAAKoT,EAClC,IAAK,IAAI4Q,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAC/B3f,EAAIyT,EAAK9X,EAAIgkB,GACblM,EAAK9X,EAAIgkB,GAAKlM,EAAK9X,EAAI+jB,EAAeC,GACtClM,EAAK9X,EAAI+jB,EAAeC,GAAK3f,CAGzC,CACO,SAAS4f,EAAQxQ,GACpB,GAAkB,cAAdA,EACA,OAAOoL,WAAWpc,MAEtB,IAAIyhB,EAAQzQ,EAAUyQ,MAAM,kBAC5B,GAAIA,EAAO,CACP,IAAK,CAAE5R,EAAM4E,GAASgN,EAEtB,OAAiB,MAAT5R,EAAe,KAAqB,MAAiBmH,KAAK,KAAMpZ,OAAO6W,GACnF,CAEA,IAAIiN,EAAM,CACNC,KAAMC,UACNC,MAAOC,WACPC,MAAOlB,WACPmB,MAAO5F,WAAW6F,cAClBC,MAAOpa,WACPqa,OAAQC,YACRC,OAAQ/R,YACRgS,OAAQlG,WAAWmG,eACnBC,QAASpG,WAAWqG,aACpBC,QAASC,aACTC,QAASC,aACTC,KAAM,MACR9R,GAEF,OADA+R,EAAOrB,EAAK,qCAAqC1Q,KAC1C0Q,CACX,CAEO,SAAS7I,EAAYlf,EAAOka,GAC/B,MAAMC,EAAOna,EAAMkC,OACE,iBAAVgY,IACPA,EACc,MAAVA,EACM7T,MAAMwB,KAAK,CAAE3F,OAAQiY,IAAQ,CAACrS,EAAGlE,IAAMA,IACvCyC,MAAMwB,KAAK,CAAE3F,OAAQiY,IAAQ,CAACrS,EAAGlE,IAAMuW,EAAO,EAAIvW,KAEhEwlB,EAAOjP,IAASD,EAAMhY,OAAQ,qDAC9B,IAAI2e,EAAO,EACPrJ,EAAS,IAAInR,MAAM8T,GACvB,IAAK,IAAIvW,EAAIsW,EAAMhY,OAAS,EAAG0B,GAAK,EAAGA,IACnC4T,EAAO0C,EAAMtW,IAAMid,EACnBA,GAAQ7gB,EAAMka,EAAMtW,IAExB,OAAO4T,CACX,CAEO,SAAS6R,GAAyB,KAAEnpB,EAAI,cAAEiW,IAC7C,GAAa,YAATjW,EAAoB,CACpB,MAAMopB,EAAYnT,GAAemT,WAAa,IAC9C,OAAQjK,GAAiB,CAAC,OAAQA,GAAcnP,KAAKoZ,EACzD,CACA,GAAa,OAATppB,EAAe,CACf,MAAMopB,EAAYnT,GAAemT,WAAa,IAC9C,OAAQjK,GAAiBA,EAAanP,KAAKoZ,IAAc,GAC7D,CACA,MAAM,IAAI/mB,MAAM,+BAA+BrC,IACnD,CA6BO,SAASqpB,EAAwBrd,EAAMsS,EAAa,CAAC,GACxD,IAAInC,EAAS,GACToD,EA9BR,SAAsBA,GAClB,GAAc,OAAVA,EACA,MAAO,CAAEpI,UAAW,aAExB,IAAIyQ,EAAQrI,EAAMqI,MAAM,iBACxBsB,EAAOtB,EAAO,kBAAkBrI,KAChC,IAAK,CAAErI,EAAQoS,GAAQ1B,EACnBzQ,EAAY,CACZoS,GAAI,OACJC,GAAI,OACJC,GAAI,QACJC,GAAI,QACJC,GAAI,SACJC,GAAI,QACJC,GAAI,SACJC,GAAI,QACJC,GAAI,SACJC,GAAI,UACJC,GAAI,UACJC,GAAI,WACNZ,KACGA,EAAKzY,WAAW,MAAQyY,EAAKzY,WAAW,KAAO,MAAMyY,SAASxmB,GAEnE,OADAomB,EAAO/R,EAAW,iCAAiCoI,KACpC,MAAXrI,EACO,CAAEC,aAEN,CAAEA,YAAWD,OAAmB,MAAXA,EAAiB,SAAW,MAC5D,CAGgBiT,CAAane,EAAKuT,OACX,MAAfvT,EAAKgO,OACLmC,EAAOxY,KAAK,CAAE3D,KAAM,YAAaiW,cAAe,CAAE+D,MAAO,OAEzD,WAAYuF,GAA0B,QAAjBA,EAAMrI,QAC3BiF,EAAOxY,KAAK,CAAE3D,KAAM,QAASiW,cAAe,CAAEiB,OAAQ,SAE1D,IAAK,IAAI,GAAEkT,KAAOnU,KAAmBjK,EAAKqe,SAAW,GACjDlO,EAAOxY,KAAK,CAAE3D,KAAMoqB,EAAInU,kBAE5B,GAAIjK,EAAKse,WAAY,CACjB,IAAI,GAAEF,KAAOnU,GAAkBjK,EAAKse,WACpCnO,EAAOxY,KAAK,CAAE3D,KAAMoqB,EAAInU,iBAC5B,CACA,MAAO,CACHsU,YAAa,EACbhE,UAAW,QACXzmB,MAAOkM,EAAKlM,MACZqX,UAAWoI,EAAMpI,UACjB+H,WAAY,CACRlf,KAAM,UACNiW,cAAe,CACXqH,YAAatR,EAAK7H,SAG1B2a,mBAAoB,CAChB9e,KAAM,KACNiW,cAAe,CACXmT,UAAWpd,EAAKwe,qBAAuB,MAG/CrO,SACAwC,WAAY3S,EAAK2S,WACjBL,aAER,CACO,SAASmM,EAAwBvU,EAAOoI,EAAa,CAAC,GACzD,MAAO,CACHiM,YAAa,EACbhE,UAAW,QACXjI,aAER,CACO,SAASoM,EAASnL,EAAOI,GAC5B,GAAc,WAAVA,GACU,WAAVA,GACU,YAAVA,GACU,WAAVA,GACU,WAAVA,EACA,OAAOJ,IAAUI,EAErB,IAAIgL,EAAuB,SAAVpL,EACjB,GAAc,YAAVI,EACA,OAAOgL,EACX,IAAIC,EAAYrL,EAAM1O,WAAW,SAAW0O,EAAM1O,WAAW,QAC7D,GAAc,WAAV8O,EACA,OAAOiL,EACX,IAAIC,EAAsB,UAAVtL,GAA+B,WAAVA,EACrC,GAAc,WAAVI,EACA,OAAOkL,EACX,IAAIC,EAAsB,cAAVvL,EAChB,MAAc,WAAVI,EACOmL,IACHF,GAAcC,GAAcF,GAAeG,EACvD,CACO,SAASC,EAAkB1O,GAC9B,MAAuB,qBAAhBA,GAAOrc,IAClB,CACO,SAASgrB,EAAsB5M,GAClC,MAA4B,WAAvBA,EAASjH,WAAiD,UAAvBiH,EAASjH,WACtB,MAAvBiH,EAASO,WAINP,EAASO,WAFLsM,OAAO7M,EAASO,WAG/B,CA0BO,SAASuM,EAAeC,KAAUC,GACrC,IAAKA,EAAOxmB,MAAMymB,GAAeF,aAAiBE,IAC9C,MAAMF,CAEd,CAgBO,SAASjC,EAAOoC,EAAYzL,EAAM,IACrC,IAAKyL,EACD,MAAM,IAAIjpB,MAAMwd,EAExB,CASOhS,eAAe0d,EAAW1e,GAAM,OAAE6K,EAAM,OAAE8T,IAC7C,MAAMzd,EAAWlB,aAAgB4e,SAAW5e,EAAO,IAAI4e,SAAS5e,GAChEqc,EAAOnb,EAAS2d,KAAM,mCACtB,IACI,MAAMC,EAAuB,IAAIF,SAAS1d,EAAS2d,KAAKE,YAAY,IAAIC,oBAAoBnU,GAAS,CAAE8T,YAEvG,aADqBG,EAAqBzd,aAE9C,CACA,MAEI,MADAsd,GAAQM,iBACF,IAAIzpB,MAAM,oBAAoBqV,IACxC,CACJ,C","sources":["webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/VolumeDims.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/ImageInfo.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/VolumeLoadError.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/ChunkPrefetchIterator.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/utils.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/validation.js","webpack://@aics/vole-app/./node_modules/@zarrita/storage/dist/src/util.js","webpack://@aics/vole-app/./node_modules/@zarrita/storage/dist/src/fetch.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/loaders/zarr_utils/wrappers.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/RequestQueue.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/SubscribableRequestQueue.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/utils/url_utils.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/workers/types.js","webpack://@aics/vole-app/./node_modules/@aics/vole-core/es/workers/util.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/bitround.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/bytes.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/crc32c.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/gzip.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/json2.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/transpose.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/vlen-utf8.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/zlib.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/codecs/sharding.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/hierarchy.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/indexer.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/ops.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/get.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/indexing/util.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/open.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/typedarray.js","webpack://@aics/vole-app/./node_modules/zarrita/dist/src/util.js"],"sourcesContent":["import { Vector3 } from \"three\";\nexport function defaultVolumeDims() {\n  return {\n    shape: [0, 0, 0, 0, 0],\n    spacing: [1, 1, 1, 1, 1],\n    spaceUnit: \"m\",\n    timeUnit: \"s\",\n    dataType: \"uint8\"\n  };\n}\nexport function volumeSize(volumeDims) {\n  return new Vector3(volumeDims.shape[4], volumeDims.shape[3], volumeDims.shape[2]);\n}\nexport function physicalPixelSize(volumeDims) {\n  return new Vector3(volumeDims.spacing[4], volumeDims.spacing[3], volumeDims.spacing[2]);\n}","import { volumeSize, physicalPixelSize } from \"./VolumeDims.js\";\nimport { Vector3, Vector2 } from \"three\";\nexport function defaultImageInfo() {\n  return {\n    name: \"\",\n    atlasTileDims: [1, 1],\n    subregionSize: [1, 1, 1],\n    subregionOffset: [0, 0, 0],\n    numChannelsPerSource: [1],\n    channelNames: [\"0\"],\n    channelColors: [[255, 255, 255]],\n    multiscaleLevel: 0,\n    multiscaleLevelDims: [{\n      shape: [1, 1, 1, 1, 1],\n      spacing: [1, 1, 1, 1, 1],\n      spaceUnit: \"\",\n      timeUnit: \"\",\n      dataType: \"uint8\"\n    }],\n    transform: {\n      translation: [0, 0, 0],\n      rotation: [0, 0, 0],\n      scale: [1, 1, 1]\n    }\n  };\n}\nexport class CImageInfo {\n  constructor(imageInfo) {\n    this.imageInfo = imageInfo || defaultImageInfo();\n  }\n  get currentLevelDims() {\n    return this.imageInfo.multiscaleLevelDims[this.imageInfo.multiscaleLevel];\n  }\n\n  /** Number of channels in the image */\n  get numChannels() {\n    return this.imageInfo.numChannelsPerSource.reduce((a, b) => a + b, 0);\n  }\n\n  /** Number of channels per source, ordered by source index */\n  get numChannelsPerSource() {\n    return this.imageInfo.numChannelsPerSource;\n  }\n\n  /** XYZ size of the *original* (not downsampled) volume, in pixels */\n  get originalSize() {\n    return volumeSize(this.imageInfo.multiscaleLevelDims[0]);\n  }\n\n  /** Size of the volume, in pixels */\n  get volumeSize() {\n    return volumeSize(this.currentLevelDims);\n  }\n\n  /** Size of a single *original* (not downsampled) pixel, in spatial units */\n  get physicalPixelSize() {\n    return physicalPixelSize(this.imageInfo.multiscaleLevelDims[0]);\n  }\n\n  /** Symbol of physical spatial unit used by `physicalPixelSize` */\n  get spatialUnit() {\n    return this.imageInfo.multiscaleLevelDims[0].spaceUnit;\n  }\n\n  /** Number of timesteps in the time series, or 1 if the image is not a time series */\n  get times() {\n    // 0 is T\n    return this.currentLevelDims.shape[0];\n  }\n\n  /** Size of each timestep in temporal units */\n  get timeScale() {\n    // 0 is T\n    return this.currentLevelDims.spacing[0];\n  }\n\n  /** Symbol of physical time unit used by `timeScale` */\n  get timeUnit() {\n    return this.currentLevelDims.timeUnit;\n  }\n\n  /** Number of scale levels available for this volume */\n  get numMultiscaleLevels() {\n    return this.imageInfo.multiscaleLevelDims.length;\n  }\n\n  /** The names of each channel */\n  get channelNames() {\n    return this.imageInfo.channelNames;\n  }\n\n  /** Optional overrides to default channel colors, in 0-255 range */\n  get channelColors() {\n    return this.imageInfo.channelColors;\n  }\n\n  /** Size of the currently loaded subregion, in pixels */\n  get subregionSize() {\n    return new Vector3(...this.imageInfo.subregionSize);\n  }\n\n  /** Offset of the loaded subregion into the total volume, in pixels */\n  get subregionOffset() {\n    return new Vector3(...this.imageInfo.subregionOffset);\n  }\n  get multiscaleLevel() {\n    return this.imageInfo.multiscaleLevel;\n  }\n\n  /**\n   * XY dimensions of the texture atlas used by `RayMarchedAtlasVolume` and `Atlas2DSlice`, in number of z-slice\n   * tiles (not pixels). Chosen by the loader to lay out the 3D volume in the squarest possible 2D texture atlas.\n   */\n  get atlasTileDims() {\n    return new Vector2(...this.imageInfo.atlasTileDims);\n  }\n  get transform() {\n    return {\n      translation: new Vector3(...this.imageInfo.transform.translation),\n      rotation: new Vector3(...this.imageInfo.transform.rotation),\n      scale: new Vector3(...this.imageInfo.transform.scale)\n    };\n  }\n}\nexport function computeAtlasSize(imageInfo) {\n  const {\n    atlasTileDims\n  } = imageInfo;\n  const volDims = imageInfo.multiscaleLevelDims[imageInfo.multiscaleLevel];\n  // TCZYX: 4 = x, 3 = y\n  return [atlasTileDims[0] * volDims.shape[4], atlasTileDims[1] * volDims.shape[3]];\n}","import { errorConstructors } from \"serialize-error\";\nimport { NodeNotFoundError, KeyError } from \"zarrita\";\n// geotiff doesn't export its error types...\n\n/** Groups possible load errors into a few broad categories which we can give similar guidance to the user about. */\nexport let VolumeLoadErrorType = /*#__PURE__*/function (VolumeLoadErrorType) {\n  VolumeLoadErrorType[\"UNKNOWN\"] = \"unknown\";\n  VolumeLoadErrorType[\"NOT_FOUND\"] = \"not_found\";\n  VolumeLoadErrorType[\"TOO_LARGE\"] = \"too_large\";\n  VolumeLoadErrorType[\"LOAD_DATA_FAILED\"] = \"load_data_failed\";\n  VolumeLoadErrorType[\"INVALID_METADATA\"] = \"invalid_metadata\";\n  VolumeLoadErrorType[\"INVALID_MULTI_SOURCE_ZARR\"] = \"invalid_multi_source_zarr\";\n  return VolumeLoadErrorType;\n}({});\nexport class VolumeLoadError extends Error {\n  constructor(message, options) {\n    super(message, options);\n    this.name = \"VolumeLoadError\";\n    this.type = options?.type ?? VolumeLoadErrorType.UNKNOWN;\n  }\n}\n\n// serialize-error only ever calls an error constructor with zero arguments. The required `ErrorConstructor`\n// type is a bit too restrictive - as long as the constructor can be called with no arguments it's fine.\nerrorConstructors.set(\"NodeNotFoundError\", NodeNotFoundError);\nerrorConstructors.set(\"KeyError\", KeyError);\nerrorConstructors.set(\"VolumeLoadError\", VolumeLoadError);\n\n/** Curried function to re-throw an error wrapped in a `VolumeLoadError` with the given `message` and `type`. */\nexport function wrapVolumeLoadError(message = \"Unknown error occurred while loading volume data\", type = VolumeLoadErrorType.UNKNOWN, ignore) {\n  return e => {\n    if (ignore !== undefined && e === ignore) {\n      return e;\n    }\n    if (e instanceof VolumeLoadError) {\n      throw e;\n    }\n    console.log(`Error loading volume data: ${e}`);\n    throw new VolumeLoadError(message, {\n      type,\n      cause: e\n    });\n  };\n}","const allEqual = arr => arr.every(v => v === arr[0]);\nconst pushN = (arr, val, n) => {\n  for (let i = 0; i < n; i++) {\n    arr.push(val);\n  }\n};\nconst directionToIndex = dir => {\n  const absDir = dir >> 1; // shave off sign bit to get index in TZYX\n  return absDir + Number(absDir !== 0); // convert TZYX -> TCZYX by skipping c (index 1)\n};\nfunction updateMinMax(val, minmax) {\n  if (val < minmax[0]) {\n    minmax[0] = val;\n  }\n  if (val > minmax[1]) {\n    minmax[1] = val;\n  }\n}\n\n/**\n * Since the user is most likely to want nearby data (in space or time) first, we should prefetch those chunks first.\n *\n * Given a list of just-loaded chunks and some bounds, `ChunkPrefetchIterator` iterates evenly outwards in T/Z/Y/X.\n */\n// NOTE: Assumes `chunks` form a rectangular prism! Will create gaps otherwise! (in practice they always should)\nexport default class ChunkPrefetchIterator {\n  constructor(chunks, tzyxMaxPrefetchOffset, tczyxChunksPerSource, priorityDirections, onlyPriorityDirections = false) {\n    // Get min and max chunk coordinates for T/Z/Y/X\n    const extrema = [[Infinity, -Infinity], [Infinity, -Infinity], [Infinity, -Infinity], [Infinity, -Infinity]];\n    for (const chunk of chunks) {\n      updateMinMax(chunk[0], extrema[0]);\n      updateMinMax(chunk[2], extrema[1]);\n      updateMinMax(chunk[3], extrema[2]);\n      updateMinMax(chunk[4], extrema[3]);\n    }\n\n    // Bail out if we have any non-finite values in the extrema (the iterator will be empty)\n    if (extrema.flat().some(val => !Number.isFinite(val))) {\n      this.directionStates = [];\n      this.priorityDirectionStates = [];\n      return;\n    }\n\n    // Create `PrefetchDirectionState`s for each direction\n    this.directionStates = [];\n    this.priorityDirectionStates = [];\n\n    // iterating like this: direction is the index in the flattened entries\n    // and corresponds to our +T, -T, +Z, -Z, +Y, -Y, +X, -X directions in order\n    // because extrema is in TZYX order.\n    for (const [direction, start] of extrema.flat().entries()) {\n      const dimension = direction >> 1; // shave off sign bit to get index in TZYX\n      const tczyxIndex = dimension + Number(dimension !== 0); // convert TZYX -> TCZYX by skipping c (index 1)\n      let end;\n      if (direction & 1) {\n        // Positive direction - end is either the max coordinate in the fetched set plus the max offset in this\n        // dimension, or the max chunk coordinate in this dimension, whichever comes first\n        const endsPerSource = tczyxChunksPerSource.map(chunkDims => {\n          return Math.min(start + tzyxMaxPrefetchOffset[dimension], chunkDims[tczyxIndex] - 1);\n        });\n\n        // Save some time: if all sources have the same end, we can just store that\n        if (allEqual(endsPerSource)) {\n          end = endsPerSource[0];\n        } else {\n          // Otherwise, expand our ends per source array to ends per channel\n          end = [];\n          for (const [i, sourceEnd] of endsPerSource.entries()) {\n            pushN(end, sourceEnd, tczyxChunksPerSource[i][1]);\n          }\n        }\n        // end = Math.min(start + tzyxMaxPrefetchOffset[dimension], tczyxChunksPerDimension[dimension] - 1);\n      } else {\n        // Negative direction - end is either the min coordinate in the fetched set minus the max offset in this\n        // dimension, or 0, whichever comes first\n        end = Math.max(start - tzyxMaxPrefetchOffset[dimension], 0);\n      }\n      const directionState = {\n        direction,\n        start,\n        end,\n        chunks: []\n      };\n      if (priorityDirections && priorityDirections.includes(direction)) {\n        this.priorityDirectionStates.push(directionState);\n      } else {\n        // we have an option setting that can let us ignore non-priority directions\n        if (!onlyPriorityDirections) {\n          this.directionStates.push(directionState);\n        }\n      }\n    }\n\n    // Fill each `PrefetchDirectionState` with chunks at the border of the fetched set\n    for (const chunk of chunks) {\n      for (const dir of this.directionStates) {\n        if (chunk[directionToIndex(dir.direction)] === dir.start) {\n          dir.chunks.push(chunk);\n        }\n      }\n      for (const dir of this.priorityDirectionStates) {\n        if (chunk[directionToIndex(dir.direction)] === dir.start) {\n          dir.chunks.push(chunk);\n        }\n      }\n    }\n  }\n  static *iterateDirections(directions) {\n    let offset = 1;\n    while (directions.length > 0) {\n      // Remove directions in which we have reached the end (or, if per-channel ends, the end for all channels)\n      directions = directions.filter(dir => {\n        const end = Array.isArray(dir.end) ? Math.max(...dir.end) : dir.end;\n        if (dir.direction & 1) {\n          return dir.start + offset <= end;\n        } else {\n          return dir.start - offset >= end;\n        }\n      });\n\n      // Yield chunks one chunk farther out in every remaining direction\n      for (const dir of directions) {\n        const offsetDir = offset * (dir.direction & 1 ? 1 : -1);\n        for (const chunk of dir.chunks) {\n          // Skip this chunk if this channel has a specific per-channel end and we've reached it\n          if (Array.isArray(dir.end) && chunk[directionToIndex(dir.direction)] + offsetDir > dir.end[chunk[1]]) {\n            continue;\n          }\n          const newChunk = chunk.slice();\n          newChunk[directionToIndex(dir.direction)] += offsetDir;\n          yield newChunk;\n        }\n      }\n      offset += 1;\n    }\n  }\n  *[Symbol.iterator]() {\n    // Yield all chunks in priority direction(s) first, if any\n    if (this.priorityDirectionStates.length > 0) {\n      for (const chunk of ChunkPrefetchIterator.iterateDirections(this.priorityDirectionStates)) {\n        yield chunk;\n      }\n    }\n\n    // Then yield all chunks in other directions\n    for (const chunk of ChunkPrefetchIterator.iterateDirections(this.directionStates)) {\n      yield chunk;\n    }\n  }\n}","import { VolumeLoadErrorType, VolumeLoadError } from \"../VolumeLoadError.js\";\n/**\n * Attempts to parse `color` as a 24-bit (6-digit) hexadecimal color with a possible leading `#`.\n *\n * Six-digit hex is the only allowable color representation in the OMERO metadata spec.\n */\nexport function parseHexColor(color) {\n  if (color === undefined) {\n    return undefined;\n  }\n  const result = /^#?([a-fA-F\\d]{2})([a-fA-F\\d]{2})([a-fA-F\\d]{2})$/i.exec(color);\n  if (result) {\n    return [parseInt(result[1], 16), parseInt(result[2], 16), parseInt(result[3], 16)];\n  } else {\n    return undefined;\n  }\n}\n\n/** Extracts channel names from a `ZarrSource`. Handles missing `omeroMetadata`. Does *not* resolve name collisions. */\nexport function getSourceChannelMeta(src) {\n  if (src.omeroMetadata?.channels) {\n    const {\n      channels\n    } = src.omeroMetadata;\n    const names = [];\n    const colors = [];\n    for (let i = 0; i < channels.length; i++) {\n      const channel = channels[i];\n      names.push(channel.label ?? `Channel ${i + src.channelOffset}`);\n      colors.push(parseHexColor(channel.color));\n    }\n    return {\n      names,\n      colors\n    };\n  }\n  const cIdx = src.axesTCZYX[1];\n  const length = cIdx < 0 ? 1 : src.scaleLevels[0].shape[cIdx];\n  const names = Array.from({\n    length\n  }, (_, idx) => `Channel ${idx + src.channelOffset}`);\n  const colors = Array.from({\n    length\n  }, () => undefined);\n  return {\n    names,\n    colors\n  };\n}\n\n/** Turns `axesTCZYX` into the number of dimensions in the array */\nexport const getDimensionCount = ([t, c, z]) => 2 + Number(t > -1) + Number(c > -1) + Number(z > -1);\nexport function remapAxesToTCZYX(axes) {\n  const axesTCZYX = [-1, -1, -1, -1, -1];\n  const axisNames = [\"t\", \"c\", \"z\", \"y\", \"x\"];\n  axes.forEach((axis, idx) => {\n    const axisIdx = axisNames.indexOf(axis.name);\n    if (axisIdx > -1) {\n      axesTCZYX[axisIdx] = idx;\n    } else {\n      throw new VolumeLoadError(`Unrecognized axis in zarr: ${axis.name}`, {\n        type: VolumeLoadErrorType.INVALID_METADATA\n      });\n    }\n  });\n\n  // it is possible that Z might not exist but we require X and Y at least.\n  const noXAxis = axesTCZYX[4] === -1;\n  if (noXAxis || axesTCZYX[3] === -1) {\n    throw new VolumeLoadError(`Did not find ${noXAxis ? \"an X\" : \"a Y\"} axis in zarr`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n  return axesTCZYX;\n}\n\n/** Reorder an array of values [T, C, Z, Y, X] to the given dimension order */\nexport function orderByDimension(valsTCZYX, orderTCZYX) {\n  const specLen = getDimensionCount(orderTCZYX);\n  const result = Array(specLen);\n  let curIdx = 0;\n  orderTCZYX.forEach((val, idx) => {\n    if (val >= 0) {\n      if (val >= specLen) {\n        throw new VolumeLoadError(`Unexpected axis index in zarr: ${val}`, {\n          type: VolumeLoadErrorType.INVALID_METADATA\n        });\n      }\n      result[curIdx++] = valsTCZYX[idx];\n    }\n  });\n  return result;\n}\n\n/** Reorder an array of values in the given dimension order to [T, C, Z, Y, X] */\nexport function orderByTCZYX(valsDimension, orderTCZYX, defaultValue) {\n  const result = [defaultValue, defaultValue, defaultValue, defaultValue, defaultValue];\n  orderTCZYX.forEach((val, idx) => {\n    if (val >= 0) {\n      if (val >= valsDimension.length) {\n        throw new VolumeLoadError(`Unexpected axis index in zarr: ${val}`, {\n          type: VolumeLoadErrorType.INVALID_METADATA\n        });\n      }\n      result[idx] = valsDimension[val];\n    }\n  });\n  return result;\n}\n\n/** Select the scale transform from an OME metadata object with coordinate transforms, and return it in TCZYX order */\nexport function getScale(dataset, orderTCZYX) {\n  const transforms = dataset.coordinateTransformations;\n  if (transforms === undefined) {\n    console.warn(\"WARNING: OMEZarrLoader: no coordinate transformations for scale level.\");\n    return [1, 1, 1, 1, 1];\n  }\n\n  // this assumes we'll never encounter the \"path\" variant\n  const isScaleTransform = t => t.type === \"scale\";\n\n  // there can be any number of coordinateTransformations\n  // but there must be only one of type \"scale\".\n  const scaleTransform = transforms.find(isScaleTransform);\n  if (!scaleTransform) {\n    console.warn(`WARNING: OMEZarrLoader: no coordinate transformation of type \"scale\" for scale level.`);\n    return [1, 1, 1, 1, 1];\n  }\n  const scale = scaleTransform.scale.slice();\n  return orderByTCZYX(scale, orderTCZYX, 1);\n}\n\n/**\n * Defines a partial order of zarr arrays based on their size. Specifically:\n * - If array size x, y, z are all equal, the arrays are equal\n * - otherwise, if all xyz of `a` are less than or equal to those of `b`, `a` is less than `b` (and vice versa)\n * - if some xyz is less and some is greater, the arrays are uncomparable\n */\nfunction compareZarrArraySize(aArr, aTCZYX, bArr, bTCZYX) {\n  const aZ = aTCZYX[2] > -1 ? aArr.shape[aTCZYX[2]] : 1;\n  const bZ = bTCZYX[2] > -1 ? bArr.shape[bTCZYX[2]] : 1;\n  const diffZ = aZ - bZ;\n  const diffY = aArr.shape[aTCZYX[3]] - bArr.shape[bTCZYX[3]];\n  const diffX = aArr.shape[aTCZYX[4]] - bArr.shape[bTCZYX[4]];\n  if (diffZ === 0 && diffY === 0 && diffX === 0) {\n    return 0;\n  } else if (diffZ <= 0 && diffY <= 0 && diffX <= 0) {\n    return -1;\n  } else if (diffZ >= 0 && diffY >= 0 && diffX >= 0) {\n    return 1;\n  } else {\n    return undefined;\n  }\n}\nconst EPSILON = 0.00001;\nconst aboutEquals = (a, b) => Math.abs(a - b) < EPSILON;\nfunction scaleTransformsAreEqual(aSrc, aLevel, bSrc, bLevel) {\n  const aScale = getScale(aSrc.multiscaleMetadata.datasets[aLevel], aSrc.axesTCZYX);\n  const bScale = getScale(bSrc.multiscaleMetadata.datasets[bLevel], bSrc.axesTCZYX);\n  return aboutEquals(aScale[2], bScale[2]) && aboutEquals(aScale[3], bScale[3]) && aboutEquals(aScale[4], bScale[4]);\n}\n\n/**\n * Ensures that all scale levels in `sources` are matched up by size. More precisely: enforces that, for any scale\n * level `i`, the size of zarr array `s[i]` is equal for every source `s`. We accomplish this by removing any arrays\n * (and their associated OME dataset metadata) which don't match up in all sources.\n *\n * Note that this function modifies the input `sources` array rather than returning a new value.\n *\n * Assumes all sources have scale levels ordered by size from largest to smallest. (This should always be true for\n * compliant OME-Zarr data.)\n */\nexport function matchSourceScaleLevels(sources) {\n  if (sources.length < 2) {\n    return;\n  }\n\n  // Save matching scale levels and metadata here\n  const matchedLevels = Array.from({\n    length: sources.length\n  }, () => []);\n  const matchedMetas = Array.from({\n    length: sources.length\n  }, () => []);\n\n  // Start as many index counters as we have sources\n  const scaleIndexes = new Array(sources.length).fill(0);\n  while (scaleIndexes.every((val, idx) => val < sources[idx].scaleLevels.length)) {\n    // First pass: find the smallest source / determine if all sources are equal\n    let allEqual = true;\n    let smallestIdx = 0;\n    let smallestSrc = sources[0];\n    let smallestArr = smallestSrc.scaleLevels[scaleIndexes[0]];\n    for (let currentIdx = 1; currentIdx < sources.length; currentIdx++) {\n      const currentSrc = sources[currentIdx];\n      const currentArr = currentSrc.scaleLevels[scaleIndexes[currentIdx]];\n      const ordering = compareZarrArraySize(smallestArr, smallestSrc.axesTCZYX, currentArr, currentSrc.axesTCZYX);\n      if (!ordering) {\n        // Arrays are equal, or they are uncomparable\n        if (ordering === undefined) {\n          throw new VolumeLoadError(\"Incompatible zarr arrays: pixel dimensions are mismatched\", {\n            type: VolumeLoadErrorType.INVALID_MULTI_SOURCE_ZARR\n          });\n        }\n\n        // Now we know the arrays are equal, but they may still be invalid to match up because...\n        // ...they have different scale transformations\n        if (!scaleTransformsAreEqual(smallestSrc, scaleIndexes[smallestIdx], currentSrc, scaleIndexes[currentIdx])) {\n          // today we are going to treat this as a warning.\n          // For our implementation it is enough that the xyz pixel ranges are the same.\n          // Ideally scale*arraysize=physical size is really the quantity that should be equal, for combining two volume data sets as channels.\n          console.warn(\"Incompatible zarr arrays: scale levels of equal size have different scale transformations\");\n        }\n\n        // ...they have different numbers of timesteps\n        const largestT = smallestSrc.axesTCZYX[0] > -1 ? smallestArr.shape[smallestSrc.axesTCZYX[0]] : 1;\n        const currentT = currentSrc.axesTCZYX[0] > -1 ? currentArr.shape[currentSrc.axesTCZYX[0]] : 1;\n        if (largestT !== currentT) {\n          // we also treat this as a warning.\n          // In OmeZarrLoader we will take the minimum T size of all sources\n          console.warn(`Incompatible zarr arrays: different numbers of timesteps: ${largestT} vs ${currentT}`);\n        }\n      } else {\n        allEqual = false;\n        if (ordering > 0) {\n          smallestIdx = currentIdx;\n          smallestSrc = currentSrc;\n          smallestArr = currentArr;\n        }\n      }\n    }\n    if (allEqual) {\n      // We've found a matching set of scale levels! Save it and increment all indexes\n      for (let i = 0; i < scaleIndexes.length; i++) {\n        const currentSrc = sources[i];\n        const matchedScaleLevel = scaleIndexes[i];\n        matchedLevels[i].push(currentSrc.scaleLevels[matchedScaleLevel]);\n        matchedMetas[i].push(currentSrc.multiscaleMetadata.datasets[matchedScaleLevel]);\n        scaleIndexes[i] += 1;\n      }\n    } else {\n      // Increment the indexes of the sources which are larger than the smallest\n      for (const [idx, srcIdx] of scaleIndexes.entries()) {\n        const currentSrc = sources[idx];\n        const currentArr = currentSrc.scaleLevels[srcIdx];\n        const ordering = compareZarrArraySize(smallestArr, smallestSrc.axesTCZYX, currentArr, currentSrc.axesTCZYX);\n        if (ordering !== 0) {\n          scaleIndexes[idx] += 1;\n        }\n      }\n    }\n  }\n  if (sources[0].scaleLevels.length === 0) {\n    throw new VolumeLoadError(\"Incompatible zarr arrays: no sets of scale levels found that matched in all sources\", {\n      type: VolumeLoadErrorType.INVALID_MULTI_SOURCE_ZARR\n    });\n  }\n  for (let i = 0; i < sources.length; i++) {\n    sources[i].scaleLevels = matchedLevels[i];\n    sources[i].multiscaleMetadata.datasets = matchedMetas[i];\n  }\n}","import { VolumeLoadError, VolumeLoadErrorType } from \"../VolumeLoadError.js\";\n/**\n * If `meta` is the top-level metadata of a zarr node formatted according to the OME-Zarr spec version 0.5, returns\n * the object formatted according to v0.4 of the spec. For our purposes this just means flattening out the `ome` key.\n *\n * Return type is `unknown` because this does no actual validation; use `validateOMEZarrMetadata` for that.\n */\nexport const toOMEZarrMetaV4 = meta => meta.ome ?? meta;\nfunction isObjectWithProp(obj, prop) {\n  return typeof obj === \"object\" && obj !== null && prop in obj;\n}\nfunction assertMetadataHasProp(obj, prop, name = \"zarr\") {\n  if (!isObjectWithProp(obj, prop)) {\n    throw new VolumeLoadError(`${name} metadata is missing required entry \"${prop}\"`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n}\nfunction assertPropIsArray(obj, prop, name = \"zarr\") {\n  if (!Array.isArray(obj[prop])) {\n    throw new VolumeLoadError(`${name} metadata entry \"${prop}\" is not an array`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n}\n\n/** Intermediate stage of validation, before we've picked a single multiscale to validate */\n\nexport function assertMetadataHasMultiscales(meta, name = \"zarr\") {\n  // data is an object with a key \"multiscales\", which is a non-empty array\n  assertMetadataHasProp(meta, \"multiscales\", name);\n  assertPropIsArray(meta, \"multiscales\", name);\n}\n\n/**\n * Validates that the `OMEZarrMetadata` record `meta` has the minimal amount of data required to open a volume. Since\n * we only ever open one multiscale, we only validate the multiscale metadata record at index `multiscaleIdx` here.\n * `name` is used in error messages to identify the source of the metadata.\n */\nexport function validateOMEZarrMetadata(meta, multiscaleIdx = 0, name = \"zarr\") {\n  // check that a multiscale metadata entry exists at `multiscaleIdx`\n  const multiscaleMeta = meta.multiscales[multiscaleIdx];\n  if (!multiscaleMeta) {\n    throw new VolumeLoadError(`${name} metadata does not have requested multiscale level ${multiscaleIdx}`, {\n      type: VolumeLoadErrorType.INVALID_METADATA\n    });\n  }\n  const multiscaleMetaName = isObjectWithProp(multiscaleMeta, \"name\") ? ` (\"${multiscaleMeta.name})` : \"\";\n  const multiscaleName = `${name} multiscale ${multiscaleIdx}${multiscaleMetaName}`;\n\n  // multiscale has a key \"axes\", which is an array. Each axis has a \"name\".\n  assertMetadataHasProp(multiscaleMeta, \"axes\", multiscaleName);\n  assertPropIsArray(multiscaleMeta, \"axes\", multiscaleName);\n  multiscaleMeta.axes.forEach((axis, i) => assertMetadataHasProp(axis, \"name\", `${multiscaleName} axis ${i}`));\n\n  // multiscale has a key \"datasets\", which is an array. Each dataset has a \"path\".\n  assertMetadataHasProp(multiscaleMeta, \"datasets\", name);\n  assertPropIsArray(multiscaleMeta, \"datasets\", name);\n  multiscaleMeta.datasets.forEach((data, i) => assertMetadataHasProp(data, \"path\", `${multiscaleName} dataset ${i}`));\n}","export function strip_prefix(path) {\n    // @ts-expect-error - TS can't infer this type correctly\n    return path.slice(1);\n}\nexport function uri2href(url) {\n    let [protocol, rest] = (typeof url === \"string\" ? url : url.href).split(\"://\");\n    if (protocol === \"https\" || protocol === \"http\") {\n        return url;\n    }\n    if (protocol === \"gc\") {\n        return `https://storage.googleapis.com/${rest}`;\n    }\n    if (protocol === \"s3\") {\n        return `https://s3.amazonaws.com/${rest}`;\n    }\n    throw Error(`Protocol not supported, got: ${JSON.stringify(protocol)}`);\n}\nexport function fetch_range(url, offset, length, opts = {}) {\n    if (offset !== undefined && length !== undefined) {\n        // merge request opts\n        opts = {\n            ...opts,\n            headers: {\n                ...opts.headers,\n                Range: `bytes=${offset}-${offset + length - 1}`,\n            },\n        };\n    }\n    return fetch(url, opts);\n}\nexport function merge_init(storeOverrides, requestOverrides) {\n    // Request overrides take precedence over storeOverrides.\n    return {\n        ...storeOverrides,\n        ...requestOverrides,\n        headers: {\n            ...storeOverrides.headers,\n            ...requestOverrides.headers,\n        },\n    };\n}\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(expression, msg = \"\") {\n    if (!expression)\n        throw new Error(msg);\n}\n//# sourceMappingURL=util.js.map","import { fetch_range, merge_init } from \"./util.js\";\nfunction resolve(root, path) {\n    const base = typeof root === \"string\" ? new URL(root) : root;\n    if (!base.pathname.endsWith(\"/\")) {\n        // ensure trailing slash so that base is resolved as _directory_\n        base.pathname += \"/\";\n    }\n    const resolved = new URL(path.slice(1), base);\n    // copy search params to new URL\n    resolved.search = base.search;\n    return resolved;\n}\nasync function handle_response(response) {\n    if (response.status === 404) {\n        return undefined;\n    }\n    if (response.status === 200 || response.status === 206) {\n        return new Uint8Array(await response.arrayBuffer());\n    }\n    throw new Error(`Unexpected response status ${response.status} ${response.statusText}`);\n}\nasync function fetch_suffix(url, suffix_length, init, use_suffix_request) {\n    if (use_suffix_request) {\n        return fetch(url, {\n            ...init,\n            headers: { ...init.headers, Range: `bytes=-${suffix_length}` },\n        });\n    }\n    let response = await fetch(url, { ...init, method: \"HEAD\" });\n    if (!response.ok) {\n        // will be picked up by handle_response\n        return response;\n    }\n    let content_length = response.headers.get(\"Content-Length\");\n    let length = Number(content_length);\n    return fetch_range(url, length - suffix_length, length, init);\n}\n/**\n * Readonly store based in the [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n * Must polyfill `fetch` for use in Node.js.\n *\n * ```typescript\n * import * as zarr from \"zarrita\";\n * const store = new FetchStore(\"http://localhost:8080/data.zarr\");\n * const arr = await zarr.get(store, { kind: \"array\" });\n * ```\n */\nclass FetchStore {\n    url;\n    #overrides;\n    #use_suffix_request;\n    constructor(url, options = {}) {\n        this.url = url;\n        this.#overrides = options.overrides ?? {};\n        this.#use_suffix_request = options.useSuffixRequest ?? false;\n    }\n    #merge_init(overrides) {\n        return merge_init(this.#overrides, overrides);\n    }\n    async get(key, options = {}) {\n        let href = resolve(this.url, key).href;\n        let response = await fetch(href, this.#merge_init(options));\n        return handle_response(response);\n    }\n    async getRange(key, range, options = {}) {\n        let url = resolve(this.url, key);\n        let init = this.#merge_init(options);\n        let response;\n        if (\"suffixLength\" in range) {\n            response = await fetch_suffix(url, range.suffixLength, init, this.#use_suffix_request);\n        }\n        else {\n            response = await fetch_range(url, range.offset, range.length, init);\n        }\n        return handle_response(response);\n    }\n}\nexport default FetchStore;\n//# sourceMappingURL=fetch.js.map","import { FetchStore } from \"zarrita\";\nimport { isChunk } from \"../../VolumeCache.js\";\nexport default function wrapArray(array, basePath, cache, queue) {\n  const path = basePath.endsWith(\"/\") ? basePath.slice(0, -1) : basePath;\n  const keyBase = path + array.path + (array.path.endsWith(\"/\") ? \"\" : \"/\");\n  const getChunk = async (coords, opts) => {\n    if (opts?.subscriber && opts.reportChunk) {\n      opts.reportChunk(coords, opts.subscriber);\n    }\n    const fullKey = keyBase + coords.join(\",\");\n    const cacheResult = cache?.get(fullKey);\n    if (cacheResult && isChunk(cacheResult)) {\n      return cacheResult;\n    }\n    let result;\n    if (queue && opts?.subscriber) {\n      result = await queue.addRequest(fullKey, opts?.subscriber, () => array.getChunk(coords, opts), opts.isPrefetch);\n    } else {\n      result = await array.getChunk(coords, opts);\n    }\n    cache?.insert(fullKey, result);\n    return result;\n  };\n  return new Proxy(array, {\n    get: (target, prop) => {\n      if (prop === \"getChunk\") {\n        return getChunk;\n      }\n\n      // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy#no_private_property_forwarding\n      const value = target[prop];\n      if (value instanceof Function) {\n        return function (...args) {\n          return value.apply(target, args);\n        };\n      }\n      return value;\n    }\n  });\n}\nexport class RelaxedFetchStore extends FetchStore {\n  constructor(baseUrl, options) {\n    super(baseUrl, options);\n  }\n\n  // Solution for https://github.com/manzt/zarrita.js/pull/212\n  // taken from https://github.com/vitessce/vitessce/pull/2069\n  async get(key, options = {}) {\n    try {\n      return await super.get(key, options);\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    } catch (e) {\n      if (e?.message?.startsWith(\"Unexpected response status 403\")) {\n        return undefined;\n      }\n      throw e;\n    }\n  }\n}","/** Object format used when passing multiple requests to RequestQueue at once. */\n\nexport const DEFAULT_REQUEST_CANCEL_REASON = \"request cancelled\";\n\n/**\n * Internal object interface used by RequestQueue to store request metadata and callbacks.\n */\n\n/**\n * Manages a queue of asynchronous requests with unique string keys, which can be added to or cancelled.\n * If redundant requests with the same key are issued, the request action will only be run once per key\n * while the original request is still in the queue.\n */\nexport default class RequestQueue {\n  /**\n   * The maximum number of requests that can be handled concurrently.\n   * Once reached, additional requests will be queued up to run once a running request completes.\n   */\n\n  /**\n   * The maximum number of requests that can be handled concurrently if only low-priority requests are waiting. Set\n   * lower than `concurrencyLimit` to always leave space for high-priority requests. Cannot be set higher than\n   * `concurrencyLimit`.\n   */\n\n  /** A queue of requests that are ready to be executed, in order of request time. */\n\n  /** A queue of low-priority tasks that are ready to be executed. `queue` must be empty before any of these tasks run. */\n\n  /** Stores all requests, even those that are currently active. */\n\n  /** Stores requests whose actions are currently being run. */\n\n  /**\n   * Creates a new RequestQueue.\n   * @param maxActiveRequests The maximum number of requests that will be handled concurrently. This is 10 by default.\n   * @param maxLowPriorityRequests The maximum number of low-priority requests that will be handled concurrently. Equal\n   *    to `maxActiveRequests` by default, but may be set lower to always leave space for new high-priority requests.\n   */\n  constructor(maxActiveRequests = 10, maxLowPriorityRequests = 5) {\n    this.allRequests = new Map();\n    this.activeRequests = new Set();\n    this.queue = [];\n    this.queueLowPriority = [];\n    this.maxActiveRequests = maxActiveRequests;\n    this.maxLowPriorityRequests = Math.min(maxActiveRequests, maxLowPriorityRequests);\n  }\n\n  /**\n   * Stores request metadata to the internal map of all pending requests.\n   * @param key string identifier of the request.\n   * @param requestAction callable function action of the request.\n   * @returns a reference to the new, registered RequestItem.\n   */\n  registerRequest(key, requestAction) {\n    // Create a new promise and store the resolve and reject callbacks for later.\n    // This lets us perform the actual action at a later point, when the request is at the\n    // front of the processing queue.\n    let promiseResolve, promiseReject;\n    const promise = new Promise((resolve, reject) => {\n      promiseResolve = resolve;\n      promiseReject = reject;\n    });\n    // Store the request data.\n    const requestItem = {\n      key: key,\n      action: requestAction,\n      resolve: promiseResolve,\n      reject: promiseReject,\n      promise\n    };\n    this.allRequests.set(key, requestItem);\n    return requestItem;\n  }\n\n  /**\n   * Moves a registered request into the processing queue, clearing any timeouts on the request.\n   * @param key string identifier of the request.\n   * @param lowPriority Whether this request should be added with low priority. False by default.\n   */\n  addRequestToQueue(key, lowPriority) {\n    // Check that this request is not cancelled.\n    if (this.allRequests.has(key)) {\n      // Clear the request timeout, if it has one, since it is being added to the queue.\n      const requestItem = this.allRequests.get(key);\n      if (requestItem && requestItem.timeoutId) {\n        clearTimeout(requestItem.timeoutId);\n        requestItem.timeoutId = undefined;\n      }\n      if (!this.queue.includes(key) && !this.queueLowPriority.includes(key)) {\n        // Add to queue and check if the request can be processed right away.\n        if (lowPriority) {\n          this.queueLowPriority.push(key);\n        } else {\n          this.queue.push(key);\n        }\n        this.dequeue();\n      }\n    }\n  }\n\n  /**\n   * Adds a request with a unique key to the queue, if it doesn't already exist.\n   * @param key The key used to track the request.\n   * @param requestAction Function that will be called to complete the request. The function\n   *  will be run only once per unique key while the request exists, and may be deferred by the\n   *  queue at any time.\n   * @param lowPriority Whether this request should be added with low priority. False by default.\n   * @param delayMs Minimum delay, in milliseconds, before this request should be executed.\n   *\n   * NOTE: Cancelling a request while the action is running WILL NOT stop the action. If this behavior is desired,\n   * actions must be responsible for checking the RequestQueue, determining if the request is still valid (e.g.\n   * using `.hasRequest()`), and stopping or returning early.\n   *\n   * @returns A promise that will resolve on completion of the request, or reject if the request is cancelled.\n   *  If multiple requests are issued with the same key, a promise for the first request will be returned\n   *  until the request is resolved or cancelled.\n   *  Note that the return type of the promise will match that of the first request's instance.\n   */\n  addRequest(key, requestAction, lowPriority = false, delayMs = 0) {\n    if (!this.allRequests.has(key)) {\n      // New request!\n      const requestItem = this.registerRequest(key, requestAction);\n      // If a delay is set, wait to add this to the queue.\n      if (delayMs > 0) {\n        const timeoutId = setTimeout(() => this.addRequestToQueue(key, lowPriority), delayMs);\n        // Save timeout information to request metadata\n        requestItem.timeoutId = timeoutId;\n      } else {\n        // No delay, add immediately\n        this.addRequestToQueue(key, lowPriority);\n      }\n    } else {\n      const lowPriorityIndex = this.queueLowPriority.indexOf(key);\n      if (lowPriorityIndex > -1 && !lowPriority) {\n        // This request is registered and queued, but is now being requested with high priority.\n        // Promote it to high priority.\n        this.queueLowPriority.splice(lowPriorityIndex, 1);\n        this.addRequestToQueue(key);\n      } else if (delayMs <= 0) {\n        // This request is registered, but is now being requested without a delay.\n        // Move into queue immediately if it's not already added, and clear any timeouts it may have.\n        this.addRequestToQueue(key, lowPriority);\n      }\n    }\n    const promise = this.allRequests.get(key)?.promise;\n    if (!promise) {\n      throw new Error(\"Found no promise to return when getting stored request data.\");\n    }\n    return promise;\n  }\n\n  /**\n   * Adds multiple requests to the queue, with an optional delay between each.\n   * @param requests An array of RequestItems, which include a key and a request action.\n   * @param lowPriority Whether these requests should be added with low priority. False by default.\n   * @param delayMs An optional minimum delay in milliseconds to be added between each request.\n   *  For example, a delay of 10 ms will cause the second request to be added to the processing queue\n   *  after 10 ms, the third to added after 20 ms, and so on. Set to 10 ms by default.\n   * @returns An array of promises corresponding to the provided requests. (i.e., the `i`th value\n   * of the returned array will be a Promise for the resolution of `requests[i]`). If a request\n   *  with a matching key is already pending, returns the promise for the initial request.\n   */\n  addRequests(requests, lowPriority = false, delayMs = 10) {\n    const promises = [];\n    for (let i = 0; i < requests.length; i++) {\n      const item = requests[i];\n      const promise = this.addRequest(item.key, item.requestAction, lowPriority, delayMs * i);\n      promises.push(promise);\n    }\n    return promises;\n  }\n\n  /**\n   * Attempts to remove and run the next queued request item, if resources are available.\n   * @returns true if a request was started, or false if there are too many\n   * requests already active.\n   */\n  async dequeue() {\n    const numRequests = this.activeRequests.size;\n    if (numRequests >= this.maxActiveRequests || this.queue.length === 0 && (numRequests >= this.maxLowPriorityRequests || this.queueLowPriority.length === 0)) {\n      return;\n    }\n    const requestKey = this.queue.shift() ?? this.queueLowPriority.shift();\n    if (!requestKey) {\n      return;\n    }\n    if (this.activeRequests.has(requestKey)) {\n      // This request is already active, try the next one instead. (this shouldn't happen)\n      this.dequeue();\n      return;\n    }\n    const requestItem = this.allRequests.get(requestKey);\n    if (!requestItem) {\n      return;\n    }\n    const key = requestItem.key;\n    // Mark that this request is active\n    this.activeRequests.add(key);\n    await requestItem.action().then(requestItem.resolve, requestItem.reject);\n    this.activeRequests.delete(key);\n    this.allRequests.delete(key);\n    this.dequeue();\n  }\n\n  /**\n   * Removes any request matching the provided key from the queue and rejects its promise.\n   * @param key The key that should be matched against.\n   * @param cancelReason A message or object that will be used as the promise rejection.\n   */\n  cancelRequest(key, cancelReason = DEFAULT_REQUEST_CANCEL_REASON) {\n    if (!this.allRequests.has(key)) {\n      return;\n    }\n    const requestItem = this.allRequests.get(key);\n    if (requestItem) {\n      if (requestItem.timeoutId) {\n        // Cancel requests that have not been queued yet.\n        clearTimeout(requestItem.timeoutId);\n      }\n      // Reject the request, then clear from the queue and known requests.\n      requestItem.reject(cancelReason);\n    }\n    const queueIndex = this.queue.indexOf(key);\n    if (queueIndex > -1) {\n      this.queue.splice(queueIndex, 1);\n    } else {\n      const lowPriorityIndex = this.queueLowPriority.indexOf(key);\n      if (lowPriorityIndex > -1) {\n        this.queueLowPriority.splice(lowPriorityIndex, 1);\n      }\n    }\n    this.allRequests.delete(key);\n    this.activeRequests.delete(key);\n  }\n\n  /**\n   * Rejects all request promises and clears the queue.\n   * @param cancelReason A message or object that will be used as the promise rejection.\n   */\n  cancelAllRequests(cancelReason = DEFAULT_REQUEST_CANCEL_REASON) {\n    // Clear the queue so we don't do extra work while filtering it\n    this.queue = [];\n    this.queueLowPriority = [];\n    for (const key of this.allRequests.keys()) {\n      this.cancelRequest(key, cancelReason);\n    }\n  }\n\n  /**\n   * Returns whether a request with the given key exists in the RequestQueue and is not cancelled.\n   * @param key the key to search for.\n   * @returns true if the request is in the RequestQueue.\n   */\n  hasRequest(key) {\n    return this.allRequests.has(key);\n  }\n\n  /**\n   * Returns whether the request with the given key is currently running (not waiting in the queue).\n   * @param key the key to search for.\n   * @returns true if the request is actively running.\n   */\n  requestRunning(key) {\n    return this.activeRequests.has(key);\n  }\n}","import RequestQueue from \"./RequestQueue.js\";\n\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n/**\n * An extension of `RequestQueue` that adds a concept of \"subscribers,\" which may share references to a single request\n * or cancel their subscription without disrupting the request for other subscribers.\n */\nexport default class SubscribableRequestQueue {\n  /** The next unused subscriber ID. Increments whenever a subscriber is added. */\n\n  /**\n   * Map of subscribers keyed by ID. Subscribers store a map to all their subscriptions by request key.\n   * Subscribers are only useful as handles to cancel subscriptions early, so we only need to store rejecters here.\n   */\n\n  /** Map from \"inner\" request (managed by `queue`) to \"outer\" promises generated per-subscriber. */\n\n  /**\n   * Since `SubscribableRequestQueue` wraps `RequestQueue`, its constructor may either take the same arguments as the\n   * `RequestQueue` constructor and create a new `RequestQueue`, or it may take an existing `RequestQueue` to wrap.\n   */\n\n  constructor(maxActiveRequests, maxLowPriorityRequests) {\n    if (typeof maxActiveRequests === \"number\" || maxActiveRequests === undefined) {\n      this.queue = new RequestQueue(maxActiveRequests, maxLowPriorityRequests);\n    } else {\n      this.queue = maxActiveRequests;\n    }\n    this.nextSubscriberId = 0;\n    this.subscribers = new Map();\n    this.requests = new Map();\n  }\n\n  /** Resolves all subscriptions to request `key` with `value` */\n  resolveAll(key, value) {\n    const requests = this.requests.get(key);\n    if (requests) {\n      for (const {\n        resolve,\n        subscriberId\n      } of requests) {\n        resolve(value);\n        this.subscribers.get(subscriberId)?.delete(key);\n      }\n      this.requests.delete(key);\n    }\n  }\n\n  /** Rejects all subscriptions to request `key` with `reason` */\n  rejectAll(key, reason) {\n    const requests = this.requests.get(key);\n    if (requests) {\n      for (const {\n        reject,\n        subscriberId\n      } of requests) {\n        reject(reason);\n        this.subscribers.get(subscriberId)?.delete(key);\n      }\n      this.requests.delete(key);\n    }\n  }\n\n  /** Adds a new request subscriber. Returns a unique ID to identify this subscriber. */\n  addSubscriber() {\n    const subscriberId = this.nextSubscriberId;\n    this.nextSubscriberId++;\n    this.subscribers.set(subscriberId, new Map());\n    return subscriberId;\n  }\n\n  /**\n   * Queues a new request, or adds a subscription if the request is already queued/running.\n   *\n   * If `subscriberId` is already subscribed to the request, this rejects the existing promise and returns a new one.\n   */\n  addRequest(key, subscriberId, requestAction, lowPriority, delayMs) {\n    // Create single underlying request if it does not yet exist\n    this.queue.addRequest(key, requestAction, lowPriority, delayMs).then(value => this.resolveAll(key, value)).catch(reason => this.rejectAll(key, reason));\n    if (!this.requests.has(key)) {\n      this.requests.set(key, []);\n    }\n\n    // Validate subscriber\n    if (subscriberId >= this.nextSubscriberId || subscriberId < 0) {\n      throw new Error(`SubscribableRequestQueue: subscriber id ${subscriberId} has not been registered`);\n    }\n    const subscriber = this.subscribers.get(subscriberId);\n    if (!subscriber) {\n      throw new Error(`SubscribableRequestQueue: subscriber id ${subscriberId} has been removed`);\n    }\n\n    // Create promise and add to list of requests\n    return new Promise((resolve, reject) => {\n      this.requests.get(key)?.push({\n        resolve,\n        reject,\n        subscriberId\n      });\n      const subscriber = this.subscribers.get(subscriberId);\n      const existingRequest = subscriber?.get(key);\n      if (existingRequest) {\n        existingRequest.push(reject);\n      } else {\n        subscriber?.set(key, [reject]);\n      }\n    });\n  }\n\n  /**\n   * Rejects a subscription and removes it from the list of subscriptions for a request, then cancels the underlying\n   * request if it is no longer subscribed and is not running already.\n   */\n  rejectSubscription(key, reject, cancelReason) {\n    // Reject the outer \"subscription\" promise\n    reject(cancelReason);\n\n    // Get the list of subscriptions for this request\n    const subscriptions = this.requests.get(key);\n    if (!subscriptions) {\n      // This should never happen\n      return;\n    }\n    // Remove this request subscription by ref equality to `reject`\n    const idx = subscriptions.findIndex(sub => sub.reject === reject);\n    if (idx >= 0) {\n      subscriptions.splice(idx, 1);\n    }\n\n    // Remove the underlying request if there are no more subscribers and the request is not already running\n    if (subscriptions.length < 1 && !this.queue.requestRunning(key)) {\n      this.queue.cancelRequest(key, cancelReason);\n      this.requests.delete(key);\n    }\n  }\n\n  /** Cancels a request subscription, and cancels the underlying request if it is no longer subscribed or running. */\n  cancelRequest(key, subscriberId, cancelReason) {\n    const subscriber = this.subscribers.get(subscriberId);\n    if (!subscriber) {\n      return false;\n    }\n    const rejecters = subscriber.get(key);\n    if (!rejecters || !rejecters.length) {\n      return false;\n    }\n    for (const reject of rejecters) {\n      this.rejectSubscription(key, reject, cancelReason);\n    }\n    subscriber.delete(key);\n    return true;\n  }\n\n  /** Removes a subscriber and cancels its remaining subscriptions. */\n  removeSubscriber(subscriberId, cancelReason) {\n    const subscriptions = this.subscribers.get(subscriberId);\n    if (subscriptions) {\n      for (const [key, rejecters] of subscriptions.entries()) {\n        for (const reject of rejecters) {\n          this.rejectSubscription(key, reject, cancelReason);\n        }\n      }\n      this.subscribers.delete(subscriberId);\n    }\n  }\n\n  /** Returns whether a request with the given `key` is running or waiting in the queue */\n  hasRequest(key) {\n    return this.queue.hasRequest(key);\n  }\n\n  /** Returns whether a request with the given `key` is running */\n  requestRunning(key) {\n    return this.queue.requestRunning(key);\n  }\n\n  /** Returns whether a subscriber with the given `subscriberId` exists */\n  hasSubscriber(subscriberId) {\n    return this.subscribers.has(subscriberId);\n  }\n\n  /** Returns whether a subscriber with the given `subscriberId` is subscribed to the request with the given `key` */\n  isSubscribed(subscriberId, key) {\n    return this.subscribers.get(subscriberId)?.has(key) ?? false;\n  }\n}","const S3_URL_PREFIX = \"s3://\";\nconst GCS_URL_PREFIX = \"gs://\";\nconst VAST_FILES_PREFIX = \"/allen/aics/\";\nconst VAST_FILES_URL = \"https://vast-files.int.allencell.org/\";\n\n/**\n * Remaps non-standard URIs (e.g. S3 (`s3://`), Google Cloud Storage (`gs://`), or\n * VAST files (`/allen/aics/`)) to a standard HTTPS URL.\n */\nexport function remapUri(url) {\n  let newUrl = url.trim();\n  if (newUrl.startsWith(S3_URL_PREFIX)) {\n    // remap s3://bucket/key to https://bucket.s3.amazonaws.com/key\n    const s3Path = newUrl.slice(S3_URL_PREFIX.length);\n    const pathSegments = s3Path.split(\"/\");\n    newUrl = `https://${pathSegments[0]}.s3.amazonaws.com/${pathSegments.slice(1).join(\"/\")}`;\n  } else if (newUrl.startsWith(GCS_URL_PREFIX)) {\n    // remap gs://bucket/key to https://storage.googleapis.com/bucket/key\n    newUrl = newUrl.replace(GCS_URL_PREFIX, \"https://storage.googleapis.com/\");\n  } else if (newUrl.startsWith(VAST_FILES_PREFIX)) {\n    // remap /allen/aics/... to https://vast-files.int.allencell.org/...\n    newUrl = newUrl.replace(VAST_FILES_PREFIX, VAST_FILES_URL);\n  }\n  return newUrl;\n}","/** The types of requests that can be made to the worker. Mostly corresponds to methods on `IVolumeLoader`. */\nexport let WorkerMsgType = /*#__PURE__*/function (WorkerMsgType) {\n  WorkerMsgType[WorkerMsgType[\"INIT\"] = 0] = \"INIT\";\n  WorkerMsgType[WorkerMsgType[\"CREATE_LOADER\"] = 1] = \"CREATE_LOADER\";\n  WorkerMsgType[WorkerMsgType[\"CLOSE_LOADER\"] = 2] = \"CLOSE_LOADER\";\n  WorkerMsgType[WorkerMsgType[\"CREATE_VOLUME\"] = 3] = \"CREATE_VOLUME\";\n  WorkerMsgType[WorkerMsgType[\"LOAD_DIMS\"] = 4] = \"LOAD_DIMS\";\n  WorkerMsgType[WorkerMsgType[\"LOAD_VOLUME_DATA\"] = 5] = \"LOAD_VOLUME_DATA\";\n  WorkerMsgType[WorkerMsgType[\"SET_PREFETCH_PRIORITY_DIRECTIONS\"] = 6] = \"SET_PREFETCH_PRIORITY_DIRECTIONS\";\n  WorkerMsgType[WorkerMsgType[\"SYNCHRONIZE_MULTICHANNEL_LOADING\"] = 7] = \"SYNCHRONIZE_MULTICHANNEL_LOADING\";\n  WorkerMsgType[WorkerMsgType[\"UPDATE_FETCH_OPTIONS\"] = 8] = \"UPDATE_FETCH_OPTIONS\";\n  return WorkerMsgType;\n}({});\n\n/** The variants of `WorkerMessageType` which represent \"global\" actions that don't require a specific loader */\n\n/** The variants of `WorkerMessageType` which represent actions on a specific loader */\n\n/** The kind of response a worker can return - `SUCCESS`, `ERROR`, or `EVENT`. */\nexport let WorkerResponseResult = /*#__PURE__*/function (WorkerResponseResult) {\n  WorkerResponseResult[WorkerResponseResult[\"SUCCESS\"] = 0] = \"SUCCESS\";\n  WorkerResponseResult[WorkerResponseResult[\"ERROR\"] = 1] = \"ERROR\";\n  WorkerResponseResult[WorkerResponseResult[\"EVENT\"] = 2] = \"EVENT\";\n  return WorkerResponseResult;\n}({});\n\n/** The kind of events that can occur when loading */\nexport let WorkerEventType = /*#__PURE__*/function (WorkerEventType) {\n  /** Fired to update a `Volume`'s `imageInfo` and/or `loadSpec` based on loaded data (time, channels, region, etc.) */\n  WorkerEventType[WorkerEventType[\"METADATA_UPDATE\"] = 0] = \"METADATA_UPDATE\";\n  /** Fired when data for a channel (or batch of channels) is loaded */\n  WorkerEventType[WorkerEventType[\"CHANNEL_LOAD\"] = 1] = \"CHANNEL_LOAD\";\n  return WorkerEventType;\n}({});\n\n/**\n * All messages to/from a worker carry a `msgId`, a `type`, and a `payload` (whose type is determined by `type`).\n * Messages which operate on a specific loader also require a `loaderId`.\n */\n\n/** Maps each `WorkerMsgType` to the type of the payload of requests of that type. */\n\n/** Maps each `WorkerMsgType` to the type of the payload of responses of that type. */\n\n/** Event for when a batch of channel data loads. */\n\n/** Event for when metadata updates. */\n\n/** All valid types of worker requests, with some `WorkerMsgType` and a matching payload type. */\n\n/** All valid types of worker responses: `SUCCESS` with a matching payload, `ERROR` with a message, or an `EVENT`. */","import { Box3, Vector3 } from \"three\";\n/** Recreates a `LoadSpec` that has just been sent to/from a worker to restore three.js object prototypes */\nexport function rebuildLoadSpec(spec) {\n  return {\n    ...spec,\n    subregion: new Box3(new Vector3().copy(spec.subregion.min), new Vector3().copy(spec.subregion.max))\n  };\n}","import { assert } from \"../util.js\";\n/**\n * A codec for bit-rounding.\n *\n * Reduces floating-point precision by truncating mantissa bits during encoding.\n * Decoding is a no-op as the process is lossy and precision cannot be restored.\n *\n * Note: {@link BitroundCodec.encode} is not yet implemented since Zarrita is\n * primarily used in read-only contexts (web browser). If you need encoding support,\n * please open an issue at {@link https://github.com/manzt/zarrita.js/issues}.\n *\n * @see {@link https://github.com/zarr-developers/numcodecs/blob/main/numcodecs/bitround.py}\n * for the original Python implementation.\n *\n * @remarks\n * Data types are not validated, and `float16` arrays are not supported (reflecting browser support).\n */\nexport class BitroundCodec {\n    kind = \"array_to_array\";\n    constructor(configuration, _meta) {\n        assert(configuration.keepbits >= 0, \"keepbits must be zero or positive\");\n    }\n    static fromConfig(configuration, meta) {\n        return new BitroundCodec(configuration, meta);\n    }\n    /**\n     * Encode a chunk of data with bit-rounding.\n     * @param _arr - The chunk to encode\n     */\n    encode(_arr) {\n        throw new Error(\"`BitroundCodec.encode` is not implemented. Please open an issue at https://github.com/manzt/zarrita.js/issues.\");\n    }\n    /**\n     * Decode a chunk of data (no-op).\n     * @param arr - The chunk to decode\n     * @returns The decoded chunk\n     */\n    decode(arr) {\n        return arr; // No-op as bit-rounding is lossy\n    }\n}\n//# sourceMappingURL=bitround.js.map","import { byteswap_inplace, get_ctr, get_strides } from \"../util.js\";\nconst LITTLE_ENDIAN_OS = system_is_little_endian();\nfunction system_is_little_endian() {\n    const a = new Uint32Array([0x12345678]);\n    const b = new Uint8Array(a.buffer, a.byteOffset, a.byteLength);\n    return !(b[0] === 0x12);\n}\nfunction bytes_per_element(TypedArray) {\n    if (\"BYTES_PER_ELEMENT\" in TypedArray) {\n        return TypedArray.BYTES_PER_ELEMENT;\n    }\n    // Unicode string array is backed by a Int32Array.\n    return 4;\n}\nexport class BytesCodec {\n    kind = \"array_to_bytes\";\n    #stride;\n    #TypedArray;\n    #BYTES_PER_ELEMENT;\n    #shape;\n    #endian;\n    constructor(configuration, meta) {\n        this.#endian = configuration?.endian;\n        this.#TypedArray = get_ctr(meta.data_type);\n        this.#shape = meta.shape;\n        this.#stride = get_strides(meta.shape, \"C\");\n        // TODO: fix me.\n        // hack to get bytes per element since it's dynamic for string types.\n        const sample = new this.#TypedArray(0);\n        this.#BYTES_PER_ELEMENT = sample.BYTES_PER_ELEMENT;\n    }\n    static fromConfig(configuration, meta) {\n        return new BytesCodec(configuration, meta);\n    }\n    encode(arr) {\n        let bytes = new Uint8Array(arr.data.buffer);\n        if (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n            byteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n        }\n        return bytes;\n    }\n    decode(bytes) {\n        if (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n            byteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n        }\n        return {\n            data: new this.#TypedArray(bytes.buffer, bytes.byteOffset, bytes.byteLength / this.#BYTES_PER_ELEMENT),\n            shape: this.#shape,\n            stride: this.#stride,\n        };\n    }\n}\n//# sourceMappingURL=bytes.js.map","export class Crc32cCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig() {\n        return new Crc32cCodec();\n    }\n    encode(_) {\n        throw new Error(\"Not implemented\");\n    }\n    decode(arr) {\n        return new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength - 4);\n    }\n}\n//# sourceMappingURL=crc32c.js.map","import { decompress } from \"../util.js\";\nexport class GzipCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig(_) {\n        return new GzipCodec();\n    }\n    encode(_bytes) {\n        throw new Error(\"Gzip encoding is not enabled by default. Please register a custom codec with `numcodecs/gzip`.\");\n    }\n    async decode(bytes) {\n        const buffer = await decompress(bytes, { format: \"gzip\" });\n        return new Uint8Array(buffer);\n    }\n}\n//# sourceMappingURL=gzip.js.map","import { assert, get_strides, json_decode_object } from \"../util.js\";\n// Reference: https://stackoverflow.com/a/21897413\nfunction throw_on_nan_replacer(_key, value) {\n    assert(!Number.isNaN(value), \"JsonCodec allow_nan is false but NaN was encountered during encoding.\");\n    assert(value !== Number.POSITIVE_INFINITY, \"JsonCodec allow_nan is false but Infinity was encountered during encoding.\");\n    assert(value !== Number.NEGATIVE_INFINITY, \"JsonCodec allow_nan is false but -Infinity was encountered during encoding.\");\n    return value;\n}\n// Reference: https://gist.github.com/davidfurlong/463a83a33b70a3b6618e97ec9679e490\nfunction sort_keys_replacer(_key, value) {\n    return value instanceof Object && !Array.isArray(value)\n        ? Object.keys(value)\n            .sort()\n            .reduce((sorted, key) => {\n            sorted[key] = value[key];\n            return sorted;\n        }, {})\n        : value;\n}\nexport class JsonCodec {\n    configuration;\n    kind = \"array_to_bytes\";\n    #encoder_config;\n    #decoder_config;\n    constructor(configuration = {}) {\n        this.configuration = configuration;\n        // Reference: https://github.com/zarr-developers/numcodecs/blob/0878717a3613d91a453fe3d3716aa9c67c023a8b/numcodecs/json.py#L36\n        const { encoding = \"utf-8\", skipkeys = false, ensure_ascii = true, check_circular = true, allow_nan = true, sort_keys = true, indent, strict = true, } = configuration;\n        let separators = configuration.separators;\n        if (!separators) {\n            // ensure separators are explicitly specified, and consistent behaviour across\n            // Python versions, and most compact representation if indent is None\n            if (!indent) {\n                separators = [\",\", \":\"];\n            }\n            else {\n                separators = [\", \", \": \"];\n            }\n        }\n        this.#encoder_config = {\n            encoding,\n            skipkeys,\n            ensure_ascii,\n            check_circular,\n            allow_nan,\n            indent,\n            separators,\n            sort_keys,\n        };\n        this.#decoder_config = { strict };\n    }\n    static fromConfig(configuration) {\n        return new JsonCodec(configuration);\n    }\n    encode(buf) {\n        const { indent, encoding, ensure_ascii, check_circular, allow_nan, sort_keys, } = this.#encoder_config;\n        assert(encoding === \"utf-8\", \"JsonCodec does not yet support non-utf-8 encoding.\");\n        const replacer_functions = [];\n        // By default, for JSON.stringify,\n        // a TypeError will be thrown if one attempts to encode an object with circular references\n        assert(check_circular, \"JsonCodec does not yet support skipping the check for circular references during encoding.\");\n        if (!allow_nan) {\n            // Throw if NaN/Infinity/-Infinity are encountered during encoding.\n            replacer_functions.push(throw_on_nan_replacer);\n        }\n        if (sort_keys) {\n            // We can ensure keys are sorted but not really the opposite since\n            // there is no guarantee of key ordering in JS.\n            replacer_functions.push(sort_keys_replacer);\n        }\n        const items = Array.from(buf.data);\n        items.push(\"|O\");\n        items.push(buf.shape);\n        let replacer;\n        if (replacer_functions.length) {\n            replacer = (key, value) => {\n                let new_value = value;\n                for (let sub_replacer of replacer_functions) {\n                    new_value = sub_replacer(key, new_value);\n                }\n                return new_value;\n            };\n        }\n        let json_str = JSON.stringify(items, replacer, indent);\n        if (ensure_ascii) {\n            // If ensure_ascii is true (the default), the output is guaranteed\n            // to have all incoming non-ASCII characters escaped.\n            // If ensure_ascii is false, these characters will be output as-is.\n            // Reference: https://stackoverflow.com/a/31652607\n            json_str = json_str.replace(/[\\u007F-\\uFFFF]/g, (chr) => {\n                const full_str = `0000${chr.charCodeAt(0).toString(16)}`;\n                const sub_str = full_str.substring(full_str.length - 4);\n                return `\\\\u${sub_str}`;\n            });\n        }\n        return new TextEncoder().encode(json_str);\n    }\n    decode(bytes) {\n        const { strict } = this.#decoder_config;\n        // (i.e., allowing control characters inside strings)\n        assert(strict, \"JsonCodec does not yet support non-strict decoding.\");\n        const items = json_decode_object(bytes);\n        const shape = items.pop();\n        items.pop(); // Pop off dtype (unused)\n        // O-d case\n        assert(shape, \"0D not implemented for JsonCodec.\");\n        const stride = get_strides(shape, \"C\");\n        const data = items;\n        return { data, shape, stride };\n    }\n}\n//# sourceMappingURL=json2.js.map","import { BoolArray, ByteStringArray, UnicodeStringArray, } from \"../typedarray.js\";\nimport { assert, get_strides } from \"../util.js\";\nfunction proxy(arr) {\n    if (arr instanceof BoolArray ||\n        arr instanceof ByteStringArray ||\n        arr instanceof UnicodeStringArray) {\n        // @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n        const arrp = new Proxy(arr, {\n            get(target, prop) {\n                return target.get(Number(prop));\n            },\n            set(target, prop, value) {\n                // @ts-expect-error - value is OK\n                target.set(Number(prop), value);\n                return true;\n            },\n        });\n        return arrp;\n    }\n    // @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n    return arr;\n}\nfunction empty_like(chunk, order) {\n    let data;\n    if (chunk.data instanceof ByteStringArray ||\n        chunk.data instanceof UnicodeStringArray) {\n        data = new chunk.constructor(\n        // @ts-expect-error\n        chunk.data.length, chunk.data.chars);\n    }\n    else {\n        data = new chunk.constructor(chunk.data.length);\n    }\n    return {\n        data,\n        shape: chunk.shape,\n        stride: get_strides(chunk.shape, order),\n    };\n}\nfunction convert_array_order(src, target) {\n    let out = empty_like(src, target);\n    let n_dims = src.shape.length;\n    let size = src.data.length;\n    let index = Array(n_dims).fill(0);\n    let src_data = proxy(src.data);\n    let out_data = proxy(out.data);\n    for (let src_idx = 0; src_idx < size; src_idx++) {\n        let out_idx = 0;\n        for (let dim = 0; dim < n_dims; dim++) {\n            out_idx += index[dim] * out.stride[dim];\n        }\n        out_data[out_idx] = src_data[src_idx];\n        index[0] += 1;\n        for (let dim = 0; dim < n_dims; dim++) {\n            if (index[dim] === src.shape[dim]) {\n                if (dim + 1 === n_dims) {\n                    break;\n                }\n                index[dim] = 0;\n                index[dim + 1] += 1;\n            }\n        }\n    }\n    return out;\n}\n/** Determine the memory order (axis permutation) for a chunk */\nfunction get_order(chunk) {\n    let rank = chunk.shape.length;\n    assert(rank === chunk.stride.length, \"Shape and stride must have the same length.\");\n    return chunk.stride\n        .map((s, i) => ({ stride: s, index: i }))\n        .sort((a, b) => b.stride - a.stride)\n        .map((entry) => entry.index);\n}\nfunction matches_order(chunk, target) {\n    let source = get_order(chunk);\n    assert(source.length === target.length, \"Orders must match\");\n    return source.every((dim, i) => dim === target[i]);\n}\nexport class TransposeCodec {\n    kind = \"array_to_array\";\n    #order;\n    #inverseOrder;\n    constructor(configuration, meta) {\n        let value = configuration.order ?? \"C\";\n        let rank = meta.shape.length;\n        let order = new Array(rank);\n        let inverseOrder = new Array(rank);\n        if (value === \"C\") {\n            for (let i = 0; i < rank; ++i) {\n                order[i] = i;\n                inverseOrder[i] = i;\n            }\n        }\n        else if (value === \"F\") {\n            for (let i = 0; i < rank; ++i) {\n                order[i] = rank - i - 1;\n                inverseOrder[i] = rank - i - 1;\n            }\n        }\n        else {\n            order = value;\n            order.forEach((x, i) => {\n                assert(inverseOrder[x] === undefined, `Invalid permutation: ${JSON.stringify(value)}`);\n                inverseOrder[x] = i;\n            });\n        }\n        this.#order = order;\n        this.#inverseOrder = inverseOrder;\n    }\n    static fromConfig(configuration, meta) {\n        return new TransposeCodec(configuration, meta);\n    }\n    encode(arr) {\n        if (matches_order(arr, this.#inverseOrder)) {\n            // can skip making a copy\n            return arr;\n        }\n        return convert_array_order(arr, this.#inverseOrder);\n    }\n    decode(arr) {\n        return {\n            data: arr.data,\n            shape: arr.shape,\n            stride: get_strides(arr.shape, this.#order),\n        };\n    }\n}\n//# sourceMappingURL=transpose.js.map","import { get_strides } from \"../util.js\";\nexport class VLenUTF8 {\n    kind = \"array_to_bytes\";\n    #shape;\n    #strides;\n    constructor(shape) {\n        this.#shape = shape;\n        this.#strides = get_strides(shape, \"C\");\n    }\n    static fromConfig(_, meta) {\n        return new VLenUTF8(meta.shape);\n    }\n    encode(_chunk) {\n        throw new Error(\"Method not implemented.\");\n    }\n    decode(bytes) {\n        let decoder = new TextDecoder();\n        let view = new DataView(bytes.buffer);\n        let data = Array(view.getUint32(0, true));\n        let pos = 4;\n        for (let i = 0; i < data.length; i++) {\n            let item_length = view.getUint32(pos, true);\n            pos += 4;\n            data[i] = decoder.decode(bytes.buffer.slice(pos, pos + item_length));\n            pos += item_length;\n        }\n        return { data, shape: this.#shape, stride: this.#strides };\n    }\n}\n//# sourceMappingURL=vlen-utf8.js.map","import { decompress } from \"../util.js\";\nexport class ZlibCodec {\n    kind = \"bytes_to_bytes\";\n    static fromConfig(_) {\n        return new ZlibCodec();\n    }\n    encode(_bytes) {\n        throw new Error(\"Zlib encoding is not enabled by default. Please register a codec with `numcodecs/zlib`.\");\n    }\n    async decode(bytes) {\n        const buffer = await decompress(bytes, { format: \"deflate\" });\n        return new Uint8Array(buffer);\n    }\n}\n//# sourceMappingURL=zlib.js.map","import { BitroundCodec } from \"./codecs/bitround.js\";\nimport { BytesCodec } from \"./codecs/bytes.js\";\nimport { Crc32cCodec } from \"./codecs/crc32c.js\";\nimport { GzipCodec } from \"./codecs/gzip.js\";\nimport { JsonCodec } from \"./codecs/json2.js\";\nimport { TransposeCodec } from \"./codecs/transpose.js\";\nimport { VLenUTF8 } from \"./codecs/vlen-utf8.js\";\nimport { ZlibCodec } from \"./codecs/zlib.js\";\nimport { assert } from \"./util.js\";\nfunction create_default_registry() {\n    return new Map()\n        .set(\"blosc\", () => import(\"numcodecs/blosc\").then((m) => m.default))\n        .set(\"lz4\", () => import(\"numcodecs/lz4\").then((m) => m.default))\n        .set(\"zstd\", () => import(\"numcodecs/zstd\").then((m) => m.default))\n        .set(\"gzip\", () => GzipCodec)\n        .set(\"zlib\", () => ZlibCodec)\n        .set(\"transpose\", () => TransposeCodec)\n        .set(\"bytes\", () => BytesCodec)\n        .set(\"crc32c\", () => Crc32cCodec)\n        .set(\"vlen-utf8\", () => VLenUTF8)\n        .set(\"json2\", () => JsonCodec)\n        .set(\"bitround\", () => BitroundCodec);\n}\nexport const registry = create_default_registry();\nexport function create_codec_pipeline(chunk_metadata) {\n    let codecs;\n    return {\n        async encode(chunk) {\n            if (!codecs)\n                codecs = await load_codecs(chunk_metadata);\n            for (const codec of codecs.array_to_array) {\n                chunk = await codec.encode(chunk);\n            }\n            let bytes = await codecs.array_to_bytes.encode(chunk);\n            for (const codec of codecs.bytes_to_bytes) {\n                bytes = await codec.encode(bytes);\n            }\n            return bytes;\n        },\n        async decode(bytes) {\n            if (!codecs)\n                codecs = await load_codecs(chunk_metadata);\n            for (let i = codecs.bytes_to_bytes.length - 1; i >= 0; i--) {\n                bytes = await codecs.bytes_to_bytes[i].decode(bytes);\n            }\n            let chunk = await codecs.array_to_bytes.decode(bytes);\n            for (let i = codecs.array_to_array.length - 1; i >= 0; i--) {\n                chunk = await codecs.array_to_array[i].decode(chunk);\n            }\n            return chunk;\n        },\n    };\n}\nasync function load_codecs(chunk_meta) {\n    let promises = chunk_meta.codecs.map(async (meta) => {\n        let Codec = await registry.get(meta.name)?.();\n        assert(Codec, `Unknown codec: ${meta.name}`);\n        return { Codec, meta };\n    });\n    let array_to_array = [];\n    let array_to_bytes;\n    let bytes_to_bytes = [];\n    for await (let { Codec, meta } of promises) {\n        let codec = Codec.fromConfig(meta.configuration, chunk_meta);\n        switch (codec.kind) {\n            case \"array_to_array\":\n                array_to_array.push(codec);\n                break;\n            case \"array_to_bytes\":\n                array_to_bytes = codec;\n                break;\n            default:\n                bytes_to_bytes.push(codec);\n        }\n    }\n    if (!array_to_bytes) {\n        assert(is_typed_array_like_meta(chunk_meta), `Cannot encode ${chunk_meta.data_type} to bytes without a codec`);\n        array_to_bytes = BytesCodec.fromConfig({ endian: \"little\" }, chunk_meta);\n    }\n    return { array_to_array, array_to_bytes, bytes_to_bytes };\n}\nfunction is_typed_array_like_meta(meta) {\n    return meta.data_type !== \"v2:object\";\n}\n//# sourceMappingURL=codecs.js.map","import { create_codec_pipeline } from \"../codecs.js\";\nimport { assert } from \"../util.js\";\nconst MAX_BIG_UINT = 18446744073709551615n;\nexport function create_sharded_chunk_getter(location, shard_shape, encode_shard_key, sharding_config) {\n    assert(location.store.getRange, \"Store does not support range requests\");\n    let get_range = location.store.getRange.bind(location.store);\n    let index_shape = shard_shape.map((d, i) => d / sharding_config.chunk_shape[i]);\n    let index_codec = create_codec_pipeline({\n        data_type: \"uint64\",\n        shape: [...index_shape, 2],\n        codecs: sharding_config.index_codecs,\n    });\n    let cache = {};\n    return async (chunk_coord) => {\n        let shard_coord = chunk_coord.map((d, i) => Math.floor(d / index_shape[i]));\n        let shard_path = location.resolve(encode_shard_key(shard_coord)).path;\n        let index;\n        if (shard_path in cache) {\n            index = cache[shard_path];\n        }\n        else {\n            let checksum_size = 4;\n            let index_size = 16 * index_shape.reduce((a, b) => a * b, 1);\n            let bytes = await get_range(shard_path, {\n                suffixLength: index_size + checksum_size,\n            });\n            index = cache[shard_path] = bytes\n                ? await index_codec.decode(bytes)\n                : null;\n        }\n        if (index === null) {\n            return undefined;\n        }\n        let { data, shape, stride } = index;\n        let linear_offset = chunk_coord\n            .map((d, i) => d % shape[i])\n            .reduce((acc, sel, idx) => acc + sel * stride[idx], 0);\n        let offset = data[linear_offset];\n        let length = data[linear_offset + 1];\n        // write null chunk when 2^64-1 indicates fill value\n        if (offset === MAX_BIG_UINT && length === MAX_BIG_UINT) {\n            return undefined;\n        }\n        return get_range(shard_path, {\n            offset: Number(offset),\n            length: Number(length),\n        });\n    };\n}\n//# sourceMappingURL=sharding.js.map","import { create_sharded_chunk_getter } from \"./codecs/sharding.js\";\nimport { create_codec_pipeline } from \"./codecs.js\";\nimport { create_chunk_key_encoder, ensure_correct_scalar, get_ctr, get_strides, is_dtype, is_sharding_codec, } from \"./util.js\";\nexport class Location {\n    store;\n    path;\n    constructor(store, path = \"/\") {\n        this.store = store;\n        this.path = path;\n    }\n    resolve(path) {\n        // reuse URL resolution logic built into the browser\n        // handles relative paths, absolute paths, etc.\n        let root = new URL(`file://${this.path.endsWith(\"/\") ? this.path : `${this.path}/`}`);\n        return new Location(this.store, new URL(path, root).pathname);\n    }\n}\nexport function root(store) {\n    return new Location(store ?? new Map());\n}\nexport class Group extends Location {\n    kind = \"group\";\n    #metadata;\n    constructor(store, path, metadata) {\n        super(store, path);\n        this.#metadata = metadata;\n    }\n    get attrs() {\n        return this.#metadata.attributes;\n    }\n}\nfunction get_array_order(codecs) {\n    const maybe_transpose_codec = codecs.find((c) => c.name === \"transpose\");\n    // @ts-expect-error - TODO: Should validate?\n    return maybe_transpose_codec?.configuration?.order ?? \"C\";\n}\nconst CONTEXT_MARKER = Symbol(\"zarrita.context\");\nexport function get_context(obj) {\n    return obj[CONTEXT_MARKER];\n}\nfunction create_context(location, metadata) {\n    let { configuration } = metadata.codecs.find(is_sharding_codec) ?? {};\n    let shared_context = {\n        encode_chunk_key: create_chunk_key_encoder(metadata.chunk_key_encoding),\n        TypedArray: get_ctr(metadata.data_type),\n        fill_value: metadata.fill_value,\n    };\n    if (configuration) {\n        let native_order = get_array_order(configuration.codecs);\n        return {\n            ...shared_context,\n            kind: \"sharded\",\n            chunk_shape: configuration.chunk_shape,\n            codec: create_codec_pipeline({\n                data_type: metadata.data_type,\n                shape: configuration.chunk_shape,\n                codecs: configuration.codecs,\n            }),\n            get_strides(shape) {\n                return get_strides(shape, native_order);\n            },\n            get_chunk_bytes: create_sharded_chunk_getter(location, metadata.chunk_grid.configuration.chunk_shape, shared_context.encode_chunk_key, configuration),\n        };\n    }\n    let native_order = get_array_order(metadata.codecs);\n    return {\n        ...shared_context,\n        kind: \"regular\",\n        chunk_shape: metadata.chunk_grid.configuration.chunk_shape,\n        codec: create_codec_pipeline({\n            data_type: metadata.data_type,\n            shape: metadata.chunk_grid.configuration.chunk_shape,\n            codecs: metadata.codecs,\n        }),\n        get_strides(shape) {\n            return get_strides(shape, native_order);\n        },\n        async get_chunk_bytes(chunk_coords, options) {\n            let chunk_key = shared_context.encode_chunk_key(chunk_coords);\n            let chunk_path = location.resolve(chunk_key).path;\n            return location.store.get(chunk_path, options);\n        },\n    };\n}\nexport class Array extends Location {\n    kind = \"array\";\n    #metadata;\n    [CONTEXT_MARKER];\n    constructor(store, path, metadata) {\n        super(store, path);\n        this.#metadata = {\n            ...metadata,\n            fill_value: ensure_correct_scalar(metadata),\n        };\n        this[CONTEXT_MARKER] = create_context(this, metadata);\n    }\n    get attrs() {\n        return this.#metadata.attributes;\n    }\n    get shape() {\n        return this.#metadata.shape;\n    }\n    get chunks() {\n        return this[CONTEXT_MARKER].chunk_shape;\n    }\n    get dtype() {\n        return this.#metadata.data_type;\n    }\n    async getChunk(chunk_coords, options) {\n        let context = this[CONTEXT_MARKER];\n        let maybe_bytes = await context.get_chunk_bytes(chunk_coords, options);\n        if (!maybe_bytes) {\n            let size = context.chunk_shape.reduce((a, b) => a * b, 1);\n            let data = new context.TypedArray(size);\n            // @ts-expect-error: TS can't infer that `fill_value` is union (assumes never) but this is ok\n            data.fill(context.fill_value);\n            return {\n                data,\n                shape: context.chunk_shape,\n                stride: context.get_strides(context.chunk_shape),\n            };\n        }\n        return context.codec.decode(maybe_bytes);\n    }\n    /**\n     * A helper method to narrow `zarr.Array` Dtype.\n     *\n     * ```typescript\n     * let arr: zarr.Array<DataType, FetchStore> = zarr.open(store, { kind: \"array\" });\n     *\n     * // Option 1: narrow by scalar type (e.g. \"bool\", \"raw\", \"bigint\", \"number\")\n     * if (arr.is(\"bigint\")) {\n     *   // zarr.Array<\"int64\" | \"uint64\", FetchStore>\n     * }\n     *\n     * // Option 3: exact match\n     * if (arr.is(\"float32\")) {\n     *   // zarr.Array<\"float32\", FetchStore, \"/\">\n     * }\n     * ```\n     */\n    is(query) {\n        return is_dtype(this.dtype, query);\n    }\n}\n//# sourceMappingURL=hierarchy.js.map","import { product, range, slice, slice_indices } from \"./util.js\";\nexport class IndexError extends Error {\n    constructor(msg) {\n        super(msg);\n        this.name = \"IndexError\";\n    }\n}\nfunction err_too_many_indices(selection, shape) {\n    throw new IndexError(`too many indicies for array; expected ${shape.length}, got ${selection.length}`);\n}\nfunction err_boundscheck(dim_len) {\n    throw new IndexError(`index out of bounds for dimension with length ${dim_len}`);\n}\nfunction err_negative_step() {\n    throw new IndexError(\"only slices with step >= 1 are supported\");\n}\nfunction check_selection_length(selection, shape) {\n    if (selection.length > shape.length) {\n        err_too_many_indices(selection, shape);\n    }\n}\nexport function normalize_integer_selection(dim_sel, dim_len) {\n    // normalize type to int\n    dim_sel = Math.trunc(dim_sel);\n    // handle wraparound\n    if (dim_sel < 0) {\n        dim_sel = dim_len + dim_sel;\n    }\n    // handle out of bounds\n    if (dim_sel >= dim_len || dim_sel < 0) {\n        err_boundscheck(dim_len);\n    }\n    return dim_sel;\n}\nclass IntDimIndexer {\n    dim_sel;\n    dim_len;\n    dim_chunk_len;\n    nitems;\n    constructor({ dim_sel, dim_len, dim_chunk_len }) {\n        // normalize\n        dim_sel = normalize_integer_selection(dim_sel, dim_len);\n        // store properties\n        this.dim_sel = dim_sel;\n        this.dim_len = dim_len;\n        this.dim_chunk_len = dim_chunk_len;\n        this.nitems = 1;\n    }\n    *[Symbol.iterator]() {\n        const dim_chunk_ix = Math.floor(this.dim_sel / this.dim_chunk_len);\n        const dim_offset = dim_chunk_ix * this.dim_chunk_len;\n        const dim_chunk_sel = this.dim_sel - dim_offset;\n        yield { dim_chunk_ix, dim_chunk_sel };\n    }\n}\nclass SliceDimIndexer {\n    start;\n    stop;\n    step;\n    dim_len;\n    dim_chunk_len;\n    nitems;\n    nchunks;\n    constructor({ dim_sel, dim_len, dim_chunk_len }) {\n        // normalize\n        const [start, stop, step] = slice_indices(dim_sel, dim_len);\n        this.start = start;\n        this.stop = stop;\n        this.step = step;\n        if (this.step < 1)\n            err_negative_step();\n        // store properties\n        this.dim_len = dim_len;\n        this.dim_chunk_len = dim_chunk_len;\n        this.nitems = Math.max(0, Math.ceil((this.stop - this.start) / this.step));\n        this.nchunks = Math.ceil(this.dim_len / this.dim_chunk_len);\n    }\n    *[Symbol.iterator]() {\n        // figure out the range of chunks we need to visit\n        const dim_chunk_ix_from = Math.floor(this.start / this.dim_chunk_len);\n        const dim_chunk_ix_to = Math.ceil(this.stop / this.dim_chunk_len);\n        for (const dim_chunk_ix of range(dim_chunk_ix_from, dim_chunk_ix_to)) {\n            // compute offsets for chunk within overall array\n            const dim_offset = dim_chunk_ix * this.dim_chunk_len;\n            const dim_limit = Math.min(this.dim_len, (dim_chunk_ix + 1) * this.dim_chunk_len);\n            // determine chunk length, accounting for trailing chunk\n            const dim_chunk_len = dim_limit - dim_offset;\n            let dim_out_offset = 0;\n            let dim_chunk_sel_start = 0;\n            if (this.start < dim_offset) {\n                // selection start before current chunk\n                const remainder = (dim_offset - this.start) % this.step;\n                if (remainder)\n                    dim_chunk_sel_start += this.step - remainder;\n                // compute number of previous items, provides offset into output array\n                dim_out_offset = Math.ceil((dim_offset - this.start) / this.step);\n            }\n            else {\n                // selection starts within current chunk\n                dim_chunk_sel_start = this.start - dim_offset;\n            }\n            // selection starts within current chunk if true,\n            // otherwise selection ends after current chunk.\n            const dim_chunk_sel_stop = this.stop > dim_limit ? dim_chunk_len : this.stop - dim_offset;\n            const dim_chunk_sel = [\n                dim_chunk_sel_start,\n                dim_chunk_sel_stop,\n                this.step,\n            ];\n            const dim_chunk_nitems = Math.ceil((dim_chunk_sel_stop - dim_chunk_sel_start) / this.step);\n            const dim_out_sel = [\n                dim_out_offset,\n                dim_out_offset + dim_chunk_nitems,\n                1,\n            ];\n            yield { dim_chunk_ix, dim_chunk_sel, dim_out_sel };\n        }\n    }\n}\nexport function normalize_selection(selection, shape) {\n    let normalized = [];\n    if (selection === null) {\n        normalized = shape.map((_) => slice(null));\n    }\n    else if (Array.isArray(selection)) {\n        normalized = selection.map((s) => s ?? slice(null));\n    }\n    check_selection_length(normalized, shape);\n    return normalized;\n}\nexport class BasicIndexer {\n    dim_indexers;\n    shape;\n    constructor({ selection, shape, chunk_shape }) {\n        // setup per-dimension indexers\n        this.dim_indexers = normalize_selection(selection, shape).map((dim_sel, i) => {\n            return new (typeof dim_sel === \"number\" ? IntDimIndexer : SliceDimIndexer)({\n                // @ts-expect-error ts inference not strong enough to know correct chunk\n                dim_sel: dim_sel,\n                dim_len: shape[i],\n                dim_chunk_len: chunk_shape[i],\n            });\n        });\n        this.shape = this.dim_indexers\n            .filter((ixr) => ixr instanceof SliceDimIndexer)\n            .map((sixr) => sixr.nitems);\n    }\n    *[Symbol.iterator]() {\n        for (const dim_projections of product(...this.dim_indexers)) {\n            const chunk_coords = dim_projections.map((p) => p.dim_chunk_ix);\n            const mapping = dim_projections.map((p) => {\n                if (\"dim_out_sel\" in p) {\n                    return { from: p.dim_chunk_sel, to: p.dim_out_sel };\n                }\n                return { from: p.dim_chunk_sel, to: null };\n            });\n            yield { chunk_coords, mapping };\n        }\n    }\n}\n//# sourceMappingURL=indexer.js.map","import { get as get_with_setter } from \"./get.js\";\nimport { set as set_with_setter } from \"./set.js\";\n/** A 1D \"view\" of an array that can be used to set values in the array. */\nfunction object_array_view(arr, offset = 0, size) {\n    let length = size ?? arr.length - offset;\n    return {\n        length,\n        subarray(from, to = length) {\n            return object_array_view(arr, offset + from, to - from);\n        },\n        set(data, start = 0) {\n            for (let i = 0; i < data.length; i++) {\n                arr[offset + start + i] = data.get(i);\n            }\n        },\n        get(index) {\n            return arr[offset + index];\n        },\n    };\n}\n/**\n * Convert a chunk to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more than\n * just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the underlying, which is supported by our binary set functions.\n */\nfunction compat_chunk(arr) {\n    if (globalThis.Array.isArray(arr.data)) {\n        return {\n            // @ts-expect-error\n            data: object_array_view(arr.data),\n            stride: arr.stride,\n            bytes_per_element: 1,\n        };\n    }\n    return {\n        data: new Uint8Array(arr.data.buffer, arr.data.byteOffset, arr.data.byteLength),\n        stride: arr.stride,\n        bytes_per_element: arr.data.BYTES_PER_ELEMENT,\n    };\n}\n/** Hack to get the constructor of a typed array constructor from an existing TypedArray. */\nfunction get_typed_array_constructor(arr) {\n    if (\"chars\" in arr) {\n        // our custom TypedArray needs to bind the number of characters per\n        // element to the constructor.\n        return arr.constructor.bind(null, arr.chars);\n    }\n    return arr.constructor;\n}\n/**\n * Convert a scalar to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more\n * than just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the scalar, which is supported by our binary set functions.\n */\nfunction compat_scalar(arr, value) {\n    if (globalThis.Array.isArray(arr.data)) {\n        // @ts-expect-error\n        return object_array_view([value]);\n    }\n    let TypedArray = get_typed_array_constructor(arr.data);\n    // @ts-expect-error - value is a scalar and matches\n    let data = new TypedArray([value]);\n    return new Uint8Array(data.buffer, data.byteOffset, data.byteLength);\n}\nexport const setter = {\n    prepare(data, shape, stride) {\n        return { data, shape, stride };\n    },\n    set_scalar(dest, sel, value) {\n        let view = compat_chunk(dest);\n        set_scalar_binary(view, sel, compat_scalar(dest, value), view.bytes_per_element);\n    },\n    set_from_chunk(dest, src, projections) {\n        let view = compat_chunk(dest);\n        set_from_chunk_binary(view, compat_chunk(src), view.bytes_per_element, projections);\n    },\n};\n/** @category Utility */\nexport async function get(arr, selection = null, opts = {}) {\n    return get_with_setter(arr, selection, opts, setter);\n}\n/** @category Utility */\nexport async function set(arr, selection, value, opts = {}) {\n    return set_with_setter(arr, selection, value, opts, setter);\n}\nfunction indices_len(start, stop, step) {\n    if (step < 0 && stop < start) {\n        return Math.floor((start - stop - 1) / -step) + 1;\n    }\n    if (start < stop)\n        return Math.floor((stop - start - 1) / step) + 1;\n    return 0;\n}\nfunction set_scalar_binary(out, out_selection, value, bytes_per_element) {\n    if (out_selection.length === 0) {\n        out.data.set(value, 0);\n        return;\n    }\n    const [slice, ...slices] = out_selection;\n    const [curr_stride, ...stride] = out.stride;\n    if (typeof slice === \"number\") {\n        const data = out.data.subarray(curr_stride * slice * bytes_per_element);\n        set_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n        return;\n    }\n    const [from, to, step] = slice;\n    const len = indices_len(from, to, step);\n    if (slices.length === 0) {\n        for (let i = 0; i < len; i++) {\n            out.data.set(value, curr_stride * (from + step * i) * bytes_per_element);\n        }\n        return;\n    }\n    for (let i = 0; i < len; i++) {\n        const data = out.data.subarray(curr_stride * (from + step * i) * bytes_per_element);\n        set_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n    }\n}\nfunction set_from_chunk_binary(dest, src, bytes_per_element, projections) {\n    const [proj, ...projs] = projections;\n    const [dstride, ...dstrides] = dest.stride;\n    const [sstride, ...sstrides] = src.stride;\n    if (proj.from === null) {\n        if (projs.length === 0) {\n            dest.data.set(src.data.subarray(0, bytes_per_element), proj.to * bytes_per_element);\n            return;\n        }\n        set_from_chunk_binary({\n            data: dest.data.subarray(dstride * proj.to * bytes_per_element),\n            stride: dstrides,\n        }, src, bytes_per_element, projs);\n        return;\n    }\n    if (proj.to === null) {\n        if (projs.length === 0) {\n            let offset = proj.from * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + bytes_per_element), 0);\n            return;\n        }\n        set_from_chunk_binary(dest, {\n            data: src.data.subarray(sstride * proj.from * bytes_per_element),\n            stride: sstrides,\n        }, bytes_per_element, projs);\n        return;\n    }\n    const [from, to, step] = proj.to;\n    const [sfrom, _, sstep] = proj.from;\n    const len = indices_len(from, to, step);\n    if (projs.length === 0) {\n        // NB: we have a contiguous block of memory\n        // so we can just copy over all the data at once.\n        if (step === 1 && sstep === 1 && dstride === 1 && sstride === 1) {\n            let offset = sfrom * bytes_per_element;\n            let size = len * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + size), from * bytes_per_element);\n            return;\n        }\n        // Otherwise, we have to copy over each element individually.\n        for (let i = 0; i < len; i++) {\n            let offset = sstride * (sfrom + sstep * i) * bytes_per_element;\n            dest.data.set(src.data.subarray(offset, offset + bytes_per_element), dstride * (from + step * i) * bytes_per_element);\n        }\n        return;\n    }\n    for (let i = 0; i < len; i++) {\n        set_from_chunk_binary({\n            data: dest.data.subarray(dstride * (from + i * step) * bytes_per_element),\n            stride: dstrides,\n        }, {\n            data: src.data.subarray(sstride * (sfrom + i * sstep) * bytes_per_element),\n            stride: sstrides,\n        }, bytes_per_element, projs);\n    }\n}\n//# sourceMappingURL=ops.js.map","import { get_context } from \"../hierarchy.js\";\nimport { BasicIndexer } from \"./indexer.js\";\nimport { create_queue } from \"./util.js\";\nfunction unwrap(arr, idx) {\n    return (\"get\" in arr ? arr.get(idx) : arr[idx]);\n}\nexport async function get(arr, selection, opts, setter) {\n    let context = get_context(arr);\n    let indexer = new BasicIndexer({\n        selection,\n        shape: arr.shape,\n        chunk_shape: arr.chunks,\n    });\n    let out = setter.prepare(new context.TypedArray(indexer.shape.reduce((a, b) => a * b, 1)), indexer.shape, context.get_strides(indexer.shape));\n    let queue = opts.create_queue?.() ?? create_queue();\n    for (const { chunk_coords, mapping } of indexer) {\n        queue.add(async () => {\n            let { data, shape, stride } = await arr.getChunk(chunk_coords, opts.opts);\n            let chunk = setter.prepare(data, shape, stride);\n            setter.set_from_chunk(out, chunk, mapping);\n        });\n    }\n    await queue.onIdle();\n    // If the final out shape is empty, we just return a scalar.\n    // @ts-expect-error - TS can't narrow this conditional type\n    return indexer.shape.length === 0 ? unwrap(out.data, 0) : out;\n}\n//# sourceMappingURL=get.js.map","/** Similar to python's `range` function. Supports positive ranges only. */\nexport function* range(start, stop, step = 1) {\n    if (stop === undefined) {\n        stop = start;\n        start = 0;\n    }\n    for (let i = start; i < stop; i += step) {\n        yield i;\n    }\n}\n/**\n * python-like itertools.product generator\n * https://gist.github.com/cybercase/db7dde901d7070c98c48\n */\nexport function* product(...iterables) {\n    if (iterables.length === 0) {\n        return;\n    }\n    // make a list of iterators from the iterables\n    const iterators = iterables.map((it) => it[Symbol.iterator]());\n    const results = iterators.map((it) => it.next());\n    if (results.some((r) => r.done)) {\n        throw new Error(\"Input contains an empty iterator.\");\n    }\n    for (let i = 0;;) {\n        if (results[i].done) {\n            // reset the current iterator\n            iterators[i] = iterables[i][Symbol.iterator]();\n            results[i] = iterators[i].next();\n            // advance, and exit if we've reached the end\n            if (++i >= iterators.length) {\n                return;\n            }\n        }\n        else {\n            // @ts-expect-error - TS can't infer this\n            yield results.map(({ value }) => value);\n            i = 0;\n        }\n        results[i] = iterators[i].next();\n    }\n}\n// https://github.com/python/cpython/blob/263c0dd16017613c5ea2fbfc270be4de2b41b5ad/Objects/sliceobject.c#L376-L519\nexport function slice_indices({ start, stop, step }, length) {\n    if (step === 0) {\n        throw new Error(\"slice step cannot be zero\");\n    }\n    step = step ?? 1;\n    const step_is_negative = step < 0;\n    /* Find lower and upper bounds for start and stop. */\n    const [lower, upper] = step_is_negative ? [-1, length - 1] : [0, length];\n    /* Compute start. */\n    if (start === null) {\n        start = step_is_negative ? upper : lower;\n    }\n    else {\n        if (start < 0) {\n            start += length;\n            if (start < lower) {\n                start = lower;\n            }\n        }\n        else if (start > upper) {\n            start = upper;\n        }\n    }\n    /* Compute stop. */\n    if (stop === null) {\n        stop = step_is_negative ? lower : upper;\n    }\n    else {\n        if (stop < 0) {\n            stop += length;\n            if (stop < lower) {\n                stop = lower;\n            }\n        }\n        else if (stop > upper) {\n            stop = upper;\n        }\n    }\n    return [start, stop, step];\n}\nexport function slice(start, stop, step = null) {\n    if (stop === undefined) {\n        stop = start;\n        start = null;\n    }\n    return {\n        start,\n        stop,\n        step,\n    };\n}\n/** Built-in \"queue\" for awaiting promises. */\nexport function create_queue() {\n    const promises = [];\n    return {\n        add: (fn) => promises.push(fn()),\n        onIdle: () => Promise.all(promises),\n    };\n}\n//# sourceMappingURL=util.js.map","import { KeyError, NodeNotFoundError } from \"./errors.js\";\nimport { Array, Group, Location } from \"./hierarchy.js\";\nimport { ensure_correct_scalar, json_decode_object, rethrow_unless, v2_to_v3_array_metadata, v2_to_v3_group_metadata, } from \"./util.js\";\nlet VERSION_COUNTER = create_version_counter();\nfunction create_version_counter() {\n    let version_counts = new WeakMap();\n    function get_counts(store) {\n        let counts = version_counts.get(store) ?? { v2: 0, v3: 0 };\n        version_counts.set(store, counts);\n        return counts;\n    }\n    return {\n        increment(store, version) {\n            get_counts(store)[version] += 1;\n        },\n        version_max(store) {\n            let counts = get_counts(store);\n            return counts.v3 > counts.v2 ? \"v3\" : \"v2\";\n        },\n    };\n}\nasync function load_attrs(location) {\n    let meta_bytes = await location.store.get(location.resolve(\".zattrs\").path);\n    if (!meta_bytes)\n        return {};\n    return json_decode_object(meta_bytes);\n}\nasync function open_v2(location, options = {}) {\n    let loc = \"store\" in location ? location : new Location(location);\n    let attrs = {};\n    if (options.attrs ?? true)\n        attrs = await load_attrs(loc);\n    if (options.kind === \"array\")\n        return open_array_v2(loc, attrs);\n    if (options.kind === \"group\")\n        return open_group_v2(loc, attrs);\n    return open_array_v2(loc, attrs).catch((err) => {\n        rethrow_unless(err, NodeNotFoundError);\n        return open_group_v2(loc, attrs);\n    });\n}\nasync function open_array_v2(location, attrs) {\n    let { path } = location.resolve(\".zarray\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v2 array\", {\n            cause: new KeyError(path),\n        });\n    }\n    VERSION_COUNTER.increment(location.store, \"v2\");\n    return new Array(location.store, location.path, v2_to_v3_array_metadata(json_decode_object(meta), attrs));\n}\nasync function open_group_v2(location, attrs) {\n    let { path } = location.resolve(\".zgroup\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v2 group\", {\n            cause: new KeyError(path),\n        });\n    }\n    VERSION_COUNTER.increment(location.store, \"v2\");\n    return new Group(location.store, location.path, v2_to_v3_group_metadata(json_decode_object(meta), attrs));\n}\nasync function _open_v3(location) {\n    let { store, path } = location.resolve(\"zarr.json\");\n    let meta = await location.store.get(path);\n    if (!meta) {\n        throw new NodeNotFoundError(\"v3 array or group\", {\n            cause: new KeyError(path),\n        });\n    }\n    let meta_doc = json_decode_object(meta);\n    if (meta_doc.node_type === \"array\") {\n        meta_doc.fill_value = ensure_correct_scalar(meta_doc);\n    }\n    return meta_doc.node_type === \"array\"\n        ? new Array(store, location.path, meta_doc)\n        : new Group(store, location.path, meta_doc);\n}\nasync function open_v3(location, options = {}) {\n    let loc = \"store\" in location ? location : new Location(location);\n    let node = await _open_v3(loc);\n    VERSION_COUNTER.increment(loc.store, \"v3\");\n    if (options.kind === undefined)\n        return node;\n    if (options.kind === \"array\" && node instanceof Array)\n        return node;\n    if (options.kind === \"group\" && node instanceof Group)\n        return node;\n    let kind = node instanceof Array ? \"array\" : \"group\";\n    throw new Error(`Expected node of kind ${options.kind}, found ${kind}.`);\n}\nexport async function open(location, options = {}) {\n    let store = \"store\" in location ? location.store : location;\n    let version_max = VERSION_COUNTER.version_max(store);\n    // Use the open function for the version with the most successful opens.\n    // Note that here we use the dot syntax to access the open functions\n    // because this enables us to use vi.spyOn during testing.\n    let open_primary = version_max === \"v2\" ? open.v2 : open.v3;\n    let open_secondary = version_max === \"v2\" ? open.v3 : open.v2;\n    return open_primary(location, options).catch((err) => {\n        rethrow_unless(err, NodeNotFoundError);\n        return open_secondary(location, options);\n    });\n}\nopen.v2 = open_v2;\nopen.v3 = open_v3;\n//# sourceMappingURL=open.js.map","/**\n * Custom array-like views (i.e., TypedArrays) for Zarr binary data buffers.\n *\n * @module\n */\n/**\n * An array-like view of a fixed-length boolean buffer.\n *\n * Encoded as 1 byte per value.\n */\nexport class BoolArray {\n    #bytes;\n    constructor(x, byteOffset, length) {\n        if (typeof x === \"number\") {\n            this.#bytes = new Uint8Array(x);\n        }\n        else if (x instanceof ArrayBuffer) {\n            this.#bytes = new Uint8Array(x, byteOffset, length);\n        }\n        else {\n            this.#bytes = new Uint8Array(Array.from(x, (v) => (v ? 1 : 0)));\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return 1;\n    }\n    get byteOffset() {\n        return this.#bytes.byteOffset;\n    }\n    get byteLength() {\n        return this.#bytes.byteLength;\n    }\n    get buffer() {\n        return this.#bytes.buffer;\n    }\n    get length() {\n        return this.#bytes.length;\n    }\n    get(idx) {\n        let value = this.#bytes[idx];\n        return typeof value === \"number\" ? value !== 0 : value;\n    }\n    set(idx, value) {\n        this.#bytes[idx] = value ? 1 : 0;\n    }\n    fill(value) {\n        this.#bytes.fill(value ? 1 : 0);\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n/**\n * An array-like view of a fixed-length byte buffer.\n *\n * Encodes a raw byte sequences without enforced encoding.\n */\nexport class ByteStringArray {\n    _data;\n    chars;\n    #encoder;\n    constructor(chars, x, byteOffset, length) {\n        this.chars = chars;\n        this.#encoder = new TextEncoder();\n        if (typeof x === \"number\") {\n            this._data = new Uint8Array(x * chars);\n        }\n        else if (x instanceof ArrayBuffer) {\n            if (length)\n                length = length * chars;\n            this._data = new Uint8Array(x, byteOffset, length);\n        }\n        else {\n            let values = Array.from(x);\n            this._data = new Uint8Array(values.length * chars);\n            for (let i = 0; i < values.length; i++) {\n                this.set(i, values[i]);\n            }\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return this.chars;\n    }\n    get byteOffset() {\n        return this._data.byteOffset;\n    }\n    get byteLength() {\n        return this._data.byteLength;\n    }\n    get buffer() {\n        return this._data.buffer;\n    }\n    get length() {\n        return this.byteLength / this.BYTES_PER_ELEMENT;\n    }\n    get(idx) {\n        const view = new Uint8Array(this.buffer, this.byteOffset + this.chars * idx, this.chars);\n        // biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n        return new TextDecoder().decode(view).replace(/\\x00/g, \"\");\n    }\n    set(idx, value) {\n        const view = new Uint8Array(this.buffer, this.byteOffset + this.chars * idx, this.chars);\n        view.fill(0); // clear current\n        view.set(this.#encoder.encode(value));\n    }\n    fill(value) {\n        const encoded = this.#encoder.encode(value);\n        for (let i = 0; i < this.length; i++) {\n            this._data.set(encoded, i * this.chars);\n        }\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n/**\n * An array-like view of a fixed-length Unicode string buffer.\n *\n * Encoded as UTF-32 code points.\n */\nexport class UnicodeStringArray {\n    #data;\n    chars;\n    constructor(chars, x, byteOffset, length) {\n        this.chars = chars;\n        if (typeof x === \"number\") {\n            this.#data = new Int32Array(x * chars);\n        }\n        else if (x instanceof ArrayBuffer) {\n            if (length)\n                length *= chars;\n            this.#data = new Int32Array(x, byteOffset, length);\n        }\n        else {\n            const values = x;\n            const d = new UnicodeStringArray(chars, 1);\n            this.#data = new Int32Array((function* () {\n                for (let str of values) {\n                    d.set(0, str);\n                    yield* d.#data;\n                }\n            })());\n        }\n    }\n    get BYTES_PER_ELEMENT() {\n        return this.#data.BYTES_PER_ELEMENT * this.chars;\n    }\n    get byteLength() {\n        return this.#data.byteLength;\n    }\n    get byteOffset() {\n        return this.#data.byteOffset;\n    }\n    get buffer() {\n        return this.#data.buffer;\n    }\n    get length() {\n        return this.#data.length / this.chars;\n    }\n    get(idx) {\n        const offset = this.chars * idx;\n        let result = \"\";\n        for (let i = 0; i < this.chars; i++) {\n            result += String.fromCodePoint(this.#data[offset + i]);\n        }\n        // biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n        return result.replace(/\\u0000/g, \"\");\n    }\n    set(idx, value) {\n        const offset = this.chars * idx;\n        const view = this.#data.subarray(offset, offset + this.chars);\n        view.fill(0); // clear current\n        for (let i = 0; i < this.chars; i++) {\n            view[i] = value.codePointAt(i) ?? 0;\n        }\n    }\n    fill(value) {\n        // encode once\n        this.set(0, value);\n        // copy the encoded values to all other elements\n        let encoded = this.#data.subarray(0, this.chars);\n        for (let i = 1; i < this.length; i++) {\n            this.#data.set(encoded, i * this.chars);\n        }\n    }\n    *[Symbol.iterator]() {\n        for (let i = 0; i < this.length; i++) {\n            yield this.get(i);\n        }\n    }\n}\n//# sourceMappingURL=typedarray.js.map","import { BoolArray, ByteStringArray, UnicodeStringArray, } from \"./typedarray.js\";\nexport function json_encode_object(o) {\n    const str = JSON.stringify(o, null, 2);\n    return new TextEncoder().encode(str);\n}\nexport function json_decode_object(bytes) {\n    const str = new TextDecoder().decode(bytes);\n    return JSON.parse(str);\n}\nexport function byteswap_inplace(view, bytes_per_element) {\n    const numFlips = bytes_per_element / 2;\n    const endByteIndex = bytes_per_element - 1;\n    let t = 0;\n    for (let i = 0; i < view.length; i += bytes_per_element) {\n        for (let j = 0; j < numFlips; j += 1) {\n            t = view[i + j];\n            view[i + j] = view[i + endByteIndex - j];\n            view[i + endByteIndex - j] = t;\n        }\n    }\n}\nexport function get_ctr(data_type) {\n    if (data_type === \"v2:object\") {\n        return globalThis.Array;\n    }\n    let match = data_type.match(/v2:([US])(\\d+)/);\n    if (match) {\n        let [, kind, chars] = match;\n        // @ts-expect-error\n        return (kind === \"U\" ? UnicodeStringArray : ByteStringArray).bind(null, Number(chars));\n    }\n    // @ts-expect-error - We've checked that the key exists\n    let ctr = {\n        int8: Int8Array,\n        int16: Int16Array,\n        int32: Int32Array,\n        int64: globalThis.BigInt64Array,\n        uint8: Uint8Array,\n        uint16: Uint16Array,\n        uint32: Uint32Array,\n        uint64: globalThis.BigUint64Array,\n        float16: globalThis.Float16Array,\n        float32: Float32Array,\n        float64: Float64Array,\n        bool: BoolArray,\n    }[data_type];\n    assert(ctr, `Unknown or unsupported data_type: ${data_type}`);\n    return ctr;\n}\n/** Compute strides for 'C' or 'F' ordered array from shape */\nexport function get_strides(shape, order) {\n    const rank = shape.length;\n    if (typeof order === \"string\") {\n        order =\n            order === \"C\"\n                ? Array.from({ length: rank }, (_, i) => i) // Row-major (identity order)\n                : Array.from({ length: rank }, (_, i) => rank - 1 - i); // Column-major (reverse order)\n    }\n    assert(rank === order.length, \"Order length must match the number of dimensions.\");\n    let step = 1;\n    let stride = new Array(rank);\n    for (let i = order.length - 1; i >= 0; i--) {\n        stride[order[i]] = step;\n        step *= shape[order[i]];\n    }\n    return stride;\n}\n// https://zarr-specs.readthedocs.io/en/latest/v3/core/v3.0.html#chunk-key-encoding\nexport function create_chunk_key_encoder({ name, configuration, }) {\n    if (name === \"default\") {\n        const separator = configuration?.separator ?? \"/\";\n        return (chunk_coords) => [\"c\", ...chunk_coords].join(separator);\n    }\n    if (name === \"v2\") {\n        const separator = configuration?.separator ?? \".\";\n        return (chunk_coords) => chunk_coords.join(separator) || \"0\";\n    }\n    throw new Error(`Unknown chunk key encoding: ${name}`);\n}\nfunction coerce_dtype(dtype) {\n    if (dtype === \"|O\") {\n        return { data_type: \"v2:object\" };\n    }\n    let match = dtype.match(/^([<|>])(.*)$/);\n    assert(match, `Invalid dtype: ${dtype}`);\n    let [, endian, rest] = match;\n    let data_type = {\n        b1: \"bool\",\n        i1: \"int8\",\n        u1: \"uint8\",\n        i2: \"int16\",\n        u2: \"uint16\",\n        i4: \"int32\",\n        u4: \"uint32\",\n        i8: \"int64\",\n        u8: \"uint64\",\n        f2: \"float16\",\n        f4: \"float32\",\n        f8: \"float64\",\n    }[rest] ??\n        (rest.startsWith(\"S\") || rest.startsWith(\"U\") ? `v2:${rest}` : undefined);\n    assert(data_type, `Unsupported or unknown dtype: ${dtype}`);\n    if (endian === \"|\") {\n        return { data_type };\n    }\n    return { data_type, endian: endian === \"<\" ? \"little\" : \"big\" };\n}\nexport function v2_to_v3_array_metadata(meta, attributes = {}) {\n    let codecs = [];\n    let dtype = coerce_dtype(meta.dtype);\n    if (meta.order === \"F\") {\n        codecs.push({ name: \"transpose\", configuration: { order: \"F\" } });\n    }\n    if (\"endian\" in dtype && dtype.endian === \"big\") {\n        codecs.push({ name: \"bytes\", configuration: { endian: \"big\" } });\n    }\n    for (let { id, ...configuration } of meta.filters ?? []) {\n        codecs.push({ name: id, configuration });\n    }\n    if (meta.compressor) {\n        let { id, ...configuration } = meta.compressor;\n        codecs.push({ name: id, configuration });\n    }\n    return {\n        zarr_format: 3,\n        node_type: \"array\",\n        shape: meta.shape,\n        data_type: dtype.data_type,\n        chunk_grid: {\n            name: \"regular\",\n            configuration: {\n                chunk_shape: meta.chunks,\n            },\n        },\n        chunk_key_encoding: {\n            name: \"v2\",\n            configuration: {\n                separator: meta.dimension_separator ?? \".\",\n            },\n        },\n        codecs,\n        fill_value: meta.fill_value,\n        attributes,\n    };\n}\nexport function v2_to_v3_group_metadata(_meta, attributes = {}) {\n    return {\n        zarr_format: 3,\n        node_type: \"group\",\n        attributes,\n    };\n}\nexport function is_dtype(dtype, query) {\n    if (query !== \"number\" &&\n        query !== \"bigint\" &&\n        query !== \"boolean\" &&\n        query !== \"object\" &&\n        query !== \"string\") {\n        return dtype === query;\n    }\n    let is_boolean = dtype === \"bool\";\n    if (query === \"boolean\")\n        return is_boolean;\n    let is_string = dtype.startsWith(\"v2:U\") || dtype.startsWith(\"v2:S\");\n    if (query === \"string\")\n        return is_string;\n    let is_bigint = dtype === \"int64\" || dtype === \"uint64\";\n    if (query === \"bigint\")\n        return is_bigint;\n    let is_object = dtype === \"v2:object\";\n    if (query === \"object\")\n        return is_object;\n    return !is_string && !is_bigint && !is_boolean && !is_object;\n}\nexport function is_sharding_codec(codec) {\n    return codec?.name === \"sharding_indexed\";\n}\nexport function ensure_correct_scalar(metadata) {\n    if ((metadata.data_type === \"uint64\" || metadata.data_type === \"int64\") &&\n        metadata.fill_value != null) {\n        // @ts-expect-error - We've narrowed the type of fill_value correctly\n        return BigInt(metadata.fill_value);\n    }\n    return metadata.fill_value;\n}\n/**\n * Ensures an error matches expected type(s), otherwise rethrows.\n *\n * Unmatched errors bubble up, like Python's `except`. Narrows error types for\n * type-safe property access.\n *\n * @see {@link https://gist.github.com/manzt/3702f19abb714e21c22ce48851c75abf}\n *\n * @example\n * ```ts\n * class DatabaseError extends Error { }\n * class NetworkError extends Error { }\n *\n * try {\n *   await db.query();\n * } catch (err) {\n *   rethrow_unless(err, DatabaseError, NetworkError);\n *   err // DatabaseError | NetworkError\n * }\n * ```\n *\n * @param error - The error to check\n * @param errors - Expected error type(s)\n * @throws The original error if it doesn't match expected type(s)\n */\nexport function rethrow_unless(error, ...errors) {\n    if (!errors.some((ErrorClass) => error instanceof ErrorClass)) {\n        throw error;\n    }\n}\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(expression, msg = \"\") {\n    if (!expression) {\n        throw new Error(msg);\n    }\n}\n/**\n * @param {ArrayBuffer |ArrayBufferView | Response} data\n * @param {Object} options\n * @param {CompressionFormat} options.format\n * @param {AbortSignal} [options.signal]\n *\n * @returns {Promise<ArrayBuffer>}\n */\nexport async function decompress(data, { format, signal }) {\n    const response = data instanceof Response ? data : new Response(data);\n    assert(response.body, \"Response does not contain body.\");\n    try {\n        const decompressedResponse = new Response(response.body.pipeThrough(new DecompressionStream(format), { signal }));\n        const buffer = await decompressedResponse.arrayBuffer();\n        return buffer;\n    }\n    catch {\n        signal?.throwIfAborted();\n        throw new Error(`Failed to decode ${format}`);\n    }\n}\n//# sourceMappingURL=util.js.map"],"names":["volumeSize","volumeDims","shape","defaultImageInfo","name","atlasTileDims","subregionSize","subregionOffset","numChannelsPerSource","channelNames","channelColors","multiscaleLevel","multiscaleLevelDims","spacing","spaceUnit","timeUnit","dataType","transform","translation","rotation","scale","CImageInfo","constructor","imageInfo","this","currentLevelDims","numChannels","reduce","a","b","originalSize","physicalPixelSize","spatialUnit","times","timeScale","numMultiscaleLevels","length","computeAtlasSize","volDims","VolumeLoadErrorType","VolumeLoadError","Error","message","options","super","type","UNKNOWN","wrapVolumeLoadError","ignore","e","undefined","console","log","cause","set","allEqual","arr","every","v","pushN","val","n","i","push","directionToIndex","dir","absDir","Number","updateMinMax","minmax","ChunkPrefetchIterator","chunks","tzyxMaxPrefetchOffset","tczyxChunksPerSource","priorityDirections","onlyPriorityDirections","extrema","Infinity","chunk","flat","some","isFinite","directionStates","priorityDirectionStates","direction","start","entries","dimension","tczyxIndex","end","endsPerSource","map","chunkDims","Math","min","sourceEnd","max","directionState","includes","iterateDirections","directions","offset","filter","Array","isArray","offsetDir","newChunk","slice","Symbol","iterator","parseHexColor","color","result","exec","parseInt","getSourceChannelMeta","src","omeroMetadata","channels","names","colors","channel","label","channelOffset","cIdx","axesTCZYX","scaleLevels","from","_","idx","getDimensionCount","t","c","z","remapAxesToTCZYX","axes","axisNames","forEach","axis","axisIdx","indexOf","INVALID_METADATA","noXAxis","orderByDimension","valsTCZYX","orderTCZYX","specLen","curIdx","orderByTCZYX","valsDimension","defaultValue","getScale","dataset","transforms","coordinateTransformations","warn","scaleTransform","find","compareZarrArraySize","aArr","aTCZYX","bArr","bTCZYX","diffZ","diffY","diffX","aboutEquals","abs","scaleTransformsAreEqual","aSrc","aLevel","bSrc","bLevel","aScale","multiscaleMetadata","datasets","bScale","matchSourceScaleLevels","sources","matchedLevels","matchedMetas","scaleIndexes","fill","smallestIdx","smallestSrc","smallestArr","currentIdx","currentSrc","currentArr","ordering","INVALID_MULTI_SOURCE_ZARR","largestT","currentT","matchedScaleLevel","srcIdx","toOMEZarrMetaV4","meta","ome","isObjectWithProp","obj","prop","assertMetadataHasProp","assertPropIsArray","assertMetadataHasMultiscales","validateOMEZarrMetadata","multiscaleIdx","multiscaleMeta","multiscales","multiscaleName","data","fetch_range","url","opts","headers","Range","fetch","resolve","root","path","base","URL","pathname","endsWith","resolved","search","async","handle_response","response","status","Uint8Array","arrayBuffer","statusText","overrides","useSuffixRequest","storeOverrides","requestOverrides","get","key","href","getRange","range","init","suffix_length","use_suffix_request","method","ok","content_length","fetch_suffix","suffixLength","wrapArray","array","basePath","cache","queue","keyBase","getChunk","coords","subscriber","reportChunk","fullKey","join","cacheResult","addRequest","isPrefetch","insert","Proxy","target","value","Function","args","apply","RelaxedFetchStore","baseUrl","startsWith","DEFAULT_REQUEST_CANCEL_REASON","RequestQueue","maxActiveRequests","maxLowPriorityRequests","allRequests","Map","activeRequests","Set","queueLowPriority","registerRequest","requestAction","promiseResolve","promiseReject","promise","Promise","reject","requestItem","action","addRequestToQueue","lowPriority","has","timeoutId","clearTimeout","dequeue","delayMs","lowPriorityIndex","splice","setTimeout","addRequests","requests","promises","item","numRequests","size","requestKey","shift","add","then","delete","cancelRequest","cancelReason","queueIndex","cancelAllRequests","keys","hasRequest","requestRunning","SubscribableRequestQueue","nextSubscriberId","subscribers","resolveAll","subscriberId","rejectAll","reason","addSubscriber","catch","existingRequest","rejectSubscription","subscriptions","findIndex","sub","rejecters","removeSubscriber","hasSubscriber","isSubscribed","S3_URL_PREFIX","GCS_URL_PREFIX","VAST_FILES_PREFIX","VAST_FILES_URL","remapUri","newUrl","trim","pathSegments","split","replace","WorkerMsgType","WorkerResponseResult","WorkerEventType","rebuildLoadSpec","spec","subregion","copy","BitroundCodec","kind","configuration","_meta","keepbits","fromConfig","encode","_arr","decode","LITTLE_ENDIAN_OS","Uint32Array","buffer","byteOffset","byteLength","system_is_little_endian","bytes_per_element","TypedArray","BYTES_PER_ELEMENT","BytesCodec","endian","data_type","sample","bytes","stride","Crc32cCodec","GzipCodec","_bytes","format","throw_on_nan_replacer","_key","isNaN","POSITIVE_INFINITY","NEGATIVE_INFINITY","sort_keys_replacer","Object","sort","sorted","JsonCodec","encoding","skipkeys","ensure_ascii","check_circular","allow_nan","sort_keys","indent","strict","separators","buf","replacer_functions","items","replacer","new_value","sub_replacer","json_str","JSON","stringify","chr","full_str","charCodeAt","toString","substring","TextEncoder","pop","proxy","TransposeCodec","order","rank","inverseOrder","x","source","s","index","entry","get_order","dim","matches_order","out","chars","empty_like","n_dims","src_data","out_data","src_idx","out_idx","convert_array_order","VLenUTF8","_chunk","decoder","TextDecoder","view","DataView","getUint32","pos","item_length","ZlibCodec","registry","m","default","create_codec_pipeline","chunk_metadata","codecs","load_codecs","codec","array_to_array","array_to_bytes","bytes_to_bytes","chunk_meta","Codec","MAX_BIG_UINT","create_sharded_chunk_getter","location","shard_shape","encode_shard_key","sharding_config","store","get_range","bind","index_shape","d","chunk_shape","index_codec","index_codecs","chunk_coord","shard_coord","floor","shard_path","checksum_size","index_size","linear_offset","acc","sel","Location","Group","metadata","attrs","attributes","get_array_order","maybe_transpose_codec","CONTEXT_MARKER","get_context","fill_value","shared_context","encode_chunk_key","chunk_key_encoding","native_order","get_strides","get_chunk_bytes","chunk_grid","chunk_coords","chunk_key","chunk_path","create_context","dtype","context","maybe_bytes","is","query","IndexError","msg","IntDimIndexer","dim_sel","dim_len","dim_chunk_len","nitems","trunc","err_boundscheck","normalize_integer_selection","dim_chunk_ix","dim_offset","dim_chunk_sel","SliceDimIndexer","stop","step","nchunks","err_negative_step","ceil","dim_chunk_ix_from","dim_chunk_ix_to","dim_limit","dim_out_offset","dim_chunk_sel_start","remainder","dim_chunk_sel_stop","dim_out_sel","BasicIndexer","dim_indexers","selection","normalized","err_too_many_indices","check_selection_length","normalize_selection","ixr","sixr","dim_projections","p","mapping","to","object_array_view","subarray","compat_chunk","globalThis","setter","prepare","set_scalar","dest","set_scalar_binary","get_typed_array_constructor","compat_scalar","set_from_chunk","projections","set_from_chunk_binary","indexer","create_queue","onIdle","unwrap","indices_len","out_selection","slices","curr_stride","len","proj","projs","dstride","dstrides","sstride","sstrides","sfrom","sstep","product","iterables","iterators","it","results","next","r","done","slice_indices","step_is_negative","lower","upper","fn","all","VERSION_COUNTER","version_counts","WeakMap","get_counts","counts","v2","v3","increment","version","version_max","create_version_counter","open_array_v2","open_group_v2","open","open_primary","open_secondary","err","loc","meta_bytes","load_attrs","node","meta_doc","node_type","_open_v3","BoolArray","ArrayBuffer","ByteStringArray","_data","values","encoded","UnicodeStringArray","Int32Array","str","String","fromCodePoint","codePointAt","json_decode_object","parse","byteswap_inplace","numFlips","endByteIndex","j","get_ctr","match","ctr","int8","Int8Array","int16","Int16Array","int32","int64","BigInt64Array","uint8","uint16","Uint16Array","uint32","uint64","BigUint64Array","float16","Float16Array","float32","Float32Array","float64","Float64Array","bool","assert","create_chunk_key_encoder","separator","v2_to_v3_array_metadata","rest","b1","i1","u1","i2","u2","i4","u4","i8","u8","f2","f4","f8","coerce_dtype","id","filters","compressor","zarr_format","dimension_separator","v2_to_v3_group_metadata","is_dtype","is_boolean","is_string","is_bigint","is_object","is_sharding_codec","ensure_correct_scalar","BigInt","rethrow_unless","error","errors","ErrorClass","expression","decompress","signal","Response","body","decompressedResponse","pipeThrough","DecompressionStream","throwIfAborted"],"sourceRoot":""}